2023-12-01 09:54:04,271:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gat', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-09-54-04', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=123, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=0, last_hidden_dim=512, logger=<Logger log_output (INFO)>)
2023-12-01 09:54:23,577:INFO::node_type_num: 4
2023-12-01 09:54:27,956:INFO::=============== Prepare basic data stage finish, use 23.685802459716797 time.
2023-12-01 09:54:46,163:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:23,692:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:23,814:INFO::its now!!!!!!!!5
2023-12-01 09:55:38,124:INFO::its now!!!!!!!!0
2023-12-01 09:55:38,187:INFO::its now!!!!!!!!3
2023-12-01 09:55:38,737:INFO::its now!!!!!!!!5
2023-12-01 09:55:39,346:INFO::its now!!!!!!!!
2023-12-01 09:55:39,347:INFO::its now!!!!!!!! on 
2023-12-01 09:55:39,659:INFO::its now!!!!!!!!5
2023-12-01 09:55:39,869:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:39,873:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.3724 | Train_Classification_Loss 1.4038 | Dmon_Loss -0.0628 | Val_Loss 1.3514 | Search Time(s) 18.2998 | Infer Time(s) 0.2144 | Time(s) 18.5142 
2023-12-01 09:55:39,967:INFO::cluster info:
0: 0;	1: 2;	2: 0;	3: 2;	4: 0;	5: 3;	6: 2;	7: 2;	8: 1;	9: 1;	10: 1;	11: 3;	12: 3;	13: 2;	14: 2;	15: 3;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 3;	24: 3;	25: 2;	26: 1;	27: 2;	28: 1;	29: 2;	30: 2;	31: 3;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 1;	26099: 0;	26100: 2;	26101: 2;	26102: 1;	26103: 1;	26104: 2;	26105: 1;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:39,969:INFO::Epoch: 1
tensor([[0.5050, 0.4950, 0.4950, 0.4950],
        [0.4950, 0.4950, 0.4950, 0.4950],
        [0.4950, 0.4950, 0.4950, 0.4950],
        [0.4950, 0.4950, 0.4950, 0.4950]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:39,970:INFO::its now!!!!!!!!5
2023-12-01 09:55:40,183:INFO::its now!!!!!!!!0
2023-12-01 09:55:40,184:INFO::its now!!!!!!!!3
2023-12-01 09:55:40,295:INFO::its now!!!!!!!!5
2023-12-01 09:55:40,542:INFO::its now!!!!!!!!
2023-12-01 09:55:40,542:INFO::its now!!!!!!!! on 
2023-12-01 09:55:40,682:INFO::its now!!!!!!!!5
2023-12-01 09:55:42,186:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3936 | Train_Classification_Loss 1.4249 | Dmon_Loss -0.0625 | Val_Loss 1.3600 | Search Time(s) 0.6928 | Infer Time(s) 1.5242 | Time(s) 2.2170 
2023-12-01 09:55:42,230:INFO::cluster info:
0: 3;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 1;	7: 3;	8: 1;	9: 1;	10: 2;	11: 1;	12: 0;	13: 3;	14: 0;	15: 0;	16: 3;	17: 3;	18: 2;	19: 3;	20: 3;	21: 1;	22: 0;	23: 1;	24: 2;	25: 2;	26: 0;	27: 1;	28: 0;	29: 0;	30: 2;	31: 0;	32: 1;	33: 1;	34: 1;	35: 1;	36: 0;	37: 0;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 1;	26099: 1;	26100: 3;	26101: 0;	26102: 2;	26103: 0;	26104: 1;	26105: 1;	26106: 0;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 09:55:42,232:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:55:42,235:INFO::Epoch: 2
tensor([[0.5080, 0.4911, 0.4911, 0.4911],
        [0.4941, 0.4911, 0.4911, 0.4911],
        [0.4903, 0.4911, 0.4911, 0.4911],
        [0.4912, 0.4911, 0.4911, 0.4911]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:42,236:INFO::its now!!!!!!!!5
2023-12-01 09:55:42,438:INFO::its now!!!!!!!!0
2023-12-01 09:55:42,439:INFO::its now!!!!!!!!3
2023-12-01 09:55:42,571:INFO::its now!!!!!!!!5
2023-12-01 09:55:42,789:INFO::its now!!!!!!!!
2023-12-01 09:55:42,789:INFO::its now!!!!!!!! on 
2023-12-01 09:55:42,928:INFO::its now!!!!!!!!5
2023-12-01 09:55:43,131:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:43,140:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3466 | Train_Classification_Loss 1.3779 | Dmon_Loss -0.0625 | Val_Loss 1.3467 | Search Time(s) 0.6745 | Infer Time(s) 0.2244 | Time(s) 0.8989 
2023-12-01 09:55:43,203:INFO::cluster info:
0: 1;	1: 1;	2: 0;	3: 0;	4: 0;	5: 3;	6: 0;	7: 2;	8: 3;	9: 2;	10: 0;	11: 1;	12: 2;	13: 0;	14: 3;	15: 3;	16: 3;	17: 3;	18: 1;	19: 0;	20: 3;	21: 1;	22: 0;	23: 3;	24: 3;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 2;	32: 3;	33: 3;	34: 0;	35: 3;	36: 0;	37: 0;	38: 0;	39: 3;	40: 3;	41: 3;	42: 0;	43: 0;	44
26098: 2;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 0;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 0;	26127: 3;	
2023-12-01 09:55:43,204:INFO::Validation loss decreased (inf --> 1.346656).  Saving model ...
2023-12-01 09:55:43,206:INFO::Epoch: 3
tensor([[0.5048, 0.4901, 0.4901, 0.4901],
        [0.4924, 0.4901, 0.4901, 0.4901],
        [0.4943, 0.4891, 0.4901, 0.4901],
        [0.4861, 0.4901, 0.4901, 0.4901]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:43,207:INFO::its now!!!!!!!!5
2023-12-01 09:55:43,405:INFO::its now!!!!!!!!0
2023-12-01 09:55:43,406:INFO::its now!!!!!!!!3
2023-12-01 09:55:43,537:INFO::its now!!!!!!!!5
2023-12-01 09:55:43,759:INFO::its now!!!!!!!!
2023-12-01 09:55:43,759:INFO::its now!!!!!!!! on 
2023-12-01 09:55:43,882:INFO::its now!!!!!!!!5
2023-12-01 09:55:44,088:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:44,090:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3432 | Train_Classification_Loss 1.3745 | Dmon_Loss -0.0627 | Val_Loss 1.3399 | Search Time(s) 0.6694 | Infer Time(s) 0.2134 | Time(s) 0.8828 
2023-12-01 09:55:44,134:INFO::cluster info:
0: 2;	1: 3;	2: 0;	3: 1;	4: 1;	5: 0;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 1;	12: 2;	13: 2;	14: 1;	15: 0;	16: 1;	17: 1;	18: 1;	19: 2;	20: 1;	21: 2;	22: 2;	23: 1;	24: 0;	25: 3;	26: 1;	27: 1;	28: 1;	29: 2;	30: 1;	31: 2;	32: 1;	33: 2;	34: 0;	35: 1;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 2;	26105: 3;	26106: 3;	26107: 0;	26108: 1;	26109: 1;	26110: 1;	26111: 2;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 2;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 2;	
2023-12-01 09:55:44,135:INFO::Validation loss decreased (1.346656 --> 1.339905).  Saving model ...
2023-12-01 09:55:44,137:INFO::Epoch: 4
tensor([[0.5060, 0.4905, 0.4905, 0.4905],
        [0.4943, 0.4905, 0.4905, 0.4905],
        [0.4965, 0.4891, 0.4905, 0.4905],
        [0.4880, 0.4889, 0.4905, 0.4905]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:44,138:INFO::its now!!!!!!!!5
2023-12-01 09:55:44,361:INFO::its now!!!!!!!!0
2023-12-01 09:55:44,362:INFO::its now!!!!!!!!3
2023-12-01 09:55:44,476:INFO::its now!!!!!!!!5
2023-12-01 09:55:44,679:INFO::its now!!!!!!!!
2023-12-01 09:55:44,679:INFO::its now!!!!!!!! on 
2023-12-01 09:55:44,920:INFO::its now!!!!!!!!5
2023-12-01 09:55:45,212:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:45,214:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3152 | Train_Classification_Loss 1.3467 | Dmon_Loss -0.0630 | Val_Loss 1.3285 | Search Time(s) 0.7778 | Infer Time(s) 0.2991 | Time(s) 1.0769 
2023-12-01 09:55:45,261:INFO::cluster info:
0: 3;	1: 1;	2: 1;	3: 0;	4: 1;	5: 2;	6: 1;	7: 3;	8: 0;	9: 1;	10: 3;	11: 3;	12: 0;	13: 0;	14: 0;	15: 3;	16: 3;	17: 2;	18: 3;	19: 0;	20: 0;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 0;	27: 0;	28: 3;	29: 0;	30: 2;	31: 1;	32: 2;	33: 0;	34: 3;	35: 0;	36: 0;	37: 0;	38: 3;	39: 3;	40: 1;	41: 1;	42: 3;	43: 3;	44
26098: 0;	26099: 1;	26100: 1;	26101: 0;	26102: 3;	26103: 1;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 09:55:45,262:INFO::Validation loss decreased (1.339905 --> 1.328450).  Saving model ...
2023-12-01 09:55:45,265:INFO::Epoch: 5
tensor([[0.5070, 0.4910, 0.4910, 0.4910],
        [0.4886, 0.4910, 0.4910, 0.4910],
        [0.4974, 0.4892, 0.4910, 0.4910],
        [0.4898, 0.4884, 0.4907, 0.4910]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:45,265:INFO::its now!!!!!!!!5
2023-12-01 09:55:45,477:INFO::its now!!!!!!!!0
2023-12-01 09:55:45,478:INFO::its now!!!!!!!!3
2023-12-01 09:55:45,620:INFO::its now!!!!!!!!5
2023-12-01 09:55:45,824:INFO::its now!!!!!!!!
2023-12-01 09:55:45,825:INFO::its now!!!!!!!! on 
2023-12-01 09:55:45,947:INFO::its now!!!!!!!!5
2023-12-01 09:55:46,169:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:46,364:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3106 | Train_Classification_Loss 1.3421 | Dmon_Loss -0.0630 | Val_Loss 1.2873 | Search Time(s) 0.6774 | Infer Time(s) 0.2303 | Time(s) 0.9077 
2023-12-01 09:55:46,425:INFO::cluster info:
0: 2;	1: 3;	2: 2;	3: 2;	4: 1;	5: 2;	6: 1;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 0;	14: 2;	15: 1;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 3;	24: 3;	25: 1;	26: 1;	27: 1;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 3;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 0;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:46,426:INFO::Validation loss decreased (1.328450 --> 1.287312).  Saving model ...
2023-12-01 09:55:46,428:INFO::Epoch: 6
tensor([[0.5012, 0.4952, 0.4952, 0.4952],
        [0.4942, 0.4913, 0.4952, 0.4952],
        [0.4980, 0.4934, 0.4952, 0.4952],
        [0.4960, 0.4923, 0.4949, 0.4912]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:46,429:INFO::its now!!!!!!!!5
2023-12-01 09:55:46,753:INFO::its now!!!!!!!!0
2023-12-01 09:55:46,754:INFO::its now!!!!!!!!3
2023-12-01 09:55:46,868:INFO::its now!!!!!!!!5
2023-12-01 09:55:47,362:INFO::its now!!!!!!!!
2023-12-01 09:55:47,362:INFO::its now!!!!!!!! on 
2023-12-01 09:55:47,506:INFO::its now!!!!!!!!5
2023-12-01 09:55:47,700:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:47,721:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.2965 | Train_Classification_Loss 1.3280 | Dmon_Loss -0.0630 | Val_Loss 1.2716 | Search Time(s) 1.0597 | Infer Time(s) 0.2147 | Time(s) 1.2744 
2023-12-01 09:55:47,766:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 0;	7: 2;	8: 2;	9: 0;	10: 0;	11: 2;	12: 2;	13: 3;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 1;	28: 2;	29: 1;	30: 2;	31: 3;	32: 2;	33: 3;	34: 1;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 2;	26099: 3;	26100: 2;	26101: 0;	26102: 1;	26103: 1;	26104: 2;	26105: 1;	26106: 3;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:47,767:INFO::Validation loss decreased (1.287312 --> 1.271614).  Saving model ...
2023-12-01 09:55:47,770:INFO::Epoch: 7
tensor([[0.4981, 0.4983, 0.4983, 0.4983],
        [0.4984, 0.4924, 0.4975, 0.4983],
        [0.5001, 0.4964, 0.4983, 0.4983],
        [0.4994, 0.4952, 0.4979, 0.4922]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:47,771:INFO::its now!!!!!!!!5
2023-12-01 09:55:47,977:INFO::its now!!!!!!!!0
2023-12-01 09:55:47,978:INFO::its now!!!!!!!!3
2023-12-01 09:55:48,110:INFO::its now!!!!!!!!5
2023-12-01 09:55:48,379:INFO::its now!!!!!!!!
2023-12-01 09:55:48,379:INFO::its now!!!!!!!! on 
2023-12-01 09:55:48,505:INFO::its now!!!!!!!!5
2023-12-01 09:55:48,700:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.3138 | Train_Classification_Loss 1.3450 | Dmon_Loss -0.0625 | Val_Loss 1.3242 | Search Time(s) 0.7357 | Infer Time(s) 0.1967 | Time(s) 0.9324 
2023-12-01 09:55:48,742:INFO::cluster info:
0: 1;	1: 0;	2: 1;	3: 1;	4: 1;	5: 2;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 1;	18: 1;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 1;	25: 3;	26: 1;	27: 0;	28: 0;	29: 2;	30: 1;	31: 1;	32: 1;	33: 1;	34: 0;	35: 1;	36: 1;	37: 1;	38: 1;	39: 1;	40: 0;	41: 2;	42: 1;	43: 1;	44
26098: 2;	26099: 1;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 1;	26106: 0;	26107: 0;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 09:55:48,743:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:55:48,746:INFO::Epoch: 8
tensor([[0.5047, 0.4999, 0.5011, 0.5011],
        [0.5006, 0.4946, 0.5000, 0.5011],
        [0.4992, 0.4992, 0.5011, 0.5011],
        [0.5011, 0.4979, 0.5007, 0.4944]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:48,747:INFO::its now!!!!!!!!5
2023-12-01 09:55:48,953:INFO::its now!!!!!!!!0
2023-12-01 09:55:48,954:INFO::its now!!!!!!!!3
2023-12-01 09:55:49,069:INFO::its now!!!!!!!!5
2023-12-01 09:55:49,281:INFO::its now!!!!!!!!
2023-12-01 09:55:49,282:INFO::its now!!!!!!!! on 
2023-12-01 09:55:49,407:INFO::its now!!!!!!!!5
2023-12-01 09:55:49,622:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:49,624:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.2556 | Train_Classification_Loss 1.2871 | Dmon_Loss -0.0630 | Val_Loss 1.2394 | Search Time(s) 0.6549 | Infer Time(s) 0.2230 | Time(s) 0.8779 
2023-12-01 09:55:49,669:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 0;	9: 0;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 1;	16: 2;	17: 3;	18: 0;	19: 2;	20: 0;	21: 0;	22: 2;	23: 2;	24: 0;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 1;	34: 2;	35: 2;	36: 1;	37: 2;	38: 3;	39: 1;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 2;	26099: 1;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:49,671:INFO::Validation loss decreased (1.271614 --> 1.239355).  Saving model ...
2023-12-01 09:55:49,673:INFO::Epoch: 9
tensor([[0.5083, 0.5026, 0.5044, 0.5044],
        [0.5044, 0.4981, 0.5031, 0.5024],
        [0.5053, 0.5026, 0.5026, 0.5044],
        [0.5021, 0.5012, 0.5040, 0.4979]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:49,674:INFO::its now!!!!!!!!5
2023-12-01 09:55:49,886:INFO::its now!!!!!!!!0
2023-12-01 09:55:49,887:INFO::its now!!!!!!!!3
2023-12-01 09:55:50,002:INFO::its now!!!!!!!!5
2023-12-01 09:55:50,210:INFO::its now!!!!!!!!
2023-12-01 09:55:50,210:INFO::its now!!!!!!!! on 
2023-12-01 09:55:50,334:INFO::its now!!!!!!!!5
2023-12-01 09:55:50,600:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:50,602:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.2190 | Train_Classification_Loss 1.2506 | Dmon_Loss -0.0630 | Val_Loss 1.2184 | Search Time(s) 0.6569 | Infer Time(s) 0.2714 | Time(s) 0.9283 
2023-12-01 09:55:50,658:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 1;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 2;	25: 2;	26: 0;	27: 2;	28: 1;	29: 0;	30: 2;	31: 1;	32: 2;	33: 1;	34: 3;	35: 2;	36: 2;	37: 1;	38: 2;	39: 1;	40: 1;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 3;	26100: 2;	26101: 0;	26102: 2;	26103: 1;	26104: 0;	26105: 1;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:50,658:INFO::Validation loss decreased (1.239355 --> 1.218403).  Saving model ...
2023-12-01 09:55:50,660:INFO::Epoch: 10
tensor([[0.5104, 0.5011, 0.5032, 0.5032],
        [0.5065, 0.4964, 0.5019, 0.5002],
        [0.5100, 0.5014, 0.5004, 0.5032],
        [0.4985, 0.5000, 0.5057, 0.4961]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:50,661:INFO::its now!!!!!!!!5
2023-12-01 09:55:50,896:INFO::its now!!!!!!!!0
2023-12-01 09:55:50,897:INFO::its now!!!!!!!!3
2023-12-01 09:55:51,010:INFO::its now!!!!!!!!5
2023-12-01 09:55:51,220:INFO::its now!!!!!!!!
2023-12-01 09:55:51,220:INFO::its now!!!!!!!! on 
2023-12-01 09:55:51,342:INFO::its now!!!!!!!!5
2023-12-01 09:55:51,539:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:51,541:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.2087 | Train_Classification_Loss 1.2402 | Dmon_Loss -0.0630 | Val_Loss 1.1945 | Search Time(s) 0.6769 | Infer Time(s) 0.2035 | Time(s) 0.8803 
2023-12-01 09:55:51,584:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 1;	4: 0;	5: 1;	6: 2;	7: 0;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 1;	16: 2;	17: 2;	18: 2;	19: 0;	20: 0;	21: 2;	22: 0;	23: 2;	24: 3;	25: 2;	26: 3;	27: 0;	28: 2;	29: 0;	30: 2;	31: 2;	32: 2;	33: 2;	34: 0;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 0;	41: 0;	42: 2;	43: 3;	44
26098: 2;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 0;	26105: 3;	26106: 3;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:51,713:INFO::Validation loss decreased (1.218403 --> 1.194524).  Saving model ...
2023-12-01 09:55:51,718:INFO::Epoch: 11
tensor([[0.5116, 0.5033, 0.5055, 0.5055],
        [0.5077, 0.4989, 0.5042, 0.5020],
        [0.5151, 0.5037, 0.5023, 0.5055],
        [0.5008, 0.5023, 0.5065, 0.4987]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:51,719:INFO::its now!!!!!!!!5
2023-12-01 09:55:52,074:INFO::its now!!!!!!!!0
2023-12-01 09:55:52,075:INFO::its now!!!!!!!!3
2023-12-01 09:55:52,194:INFO::its now!!!!!!!!5
2023-12-01 09:55:52,414:INFO::its now!!!!!!!!
2023-12-01 09:55:52,414:INFO::its now!!!!!!!! on 
2023-12-01 09:55:52,537:INFO::its now!!!!!!!!5
2023-12-01 09:55:52,751:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:52,753:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.1694 | Train_Classification_Loss 1.2009 | Dmon_Loss -0.0630 | Val_Loss 1.1634 | Search Time(s) 0.8148 | Infer Time(s) 0.2227 | Time(s) 1.0375 
2023-12-01 09:55:52,799:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 1;	7: 2;	8: 0;	9: 2;	10: 2;	11: 0;	12: 0;	13: 0;	14: 2;	15: 2;	16: 1;	17: 0;	18: 2;	19: 1;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 1;	27: 1;	28: 0;	29: 2;	30: 0;	31: 2;	32: 2;	33: 2;	34: 2;	35: 0;	36: 0;	37: 3;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 2;	26103: 3;	26104: 2;	26105: 3;	26106: 3;	26107: 1;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 09:55:52,800:INFO::Validation loss decreased (1.194524 --> 1.163419).  Saving model ...
2023-12-01 09:55:52,804:INFO::Epoch: 12
tensor([[0.5126, 0.4997, 0.5020, 0.5020],
        [0.5083, 0.4949, 0.5006, 0.4982],
        [0.5219, 0.5002, 0.4985, 0.5020],
        [0.4961, 0.4988, 0.5070, 0.4946]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:52,804:INFO::its now!!!!!!!!5
2023-12-01 09:55:53,028:INFO::its now!!!!!!!!0
2023-12-01 09:55:53,029:INFO::its now!!!!!!!!3
2023-12-01 09:55:53,143:INFO::its now!!!!!!!!5
2023-12-01 09:55:53,379:INFO::its now!!!!!!!!
2023-12-01 09:55:53,379:INFO::its now!!!!!!!! on 
2023-12-01 09:55:53,504:INFO::its now!!!!!!!!5
2023-12-01 09:55:53,746:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:53,748:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.1468 | Train_Classification_Loss 1.1783 | Dmon_Loss -0.0631 | Val_Loss 1.1292 | Search Time(s) 0.6971 | Infer Time(s) 0.2478 | Time(s) 0.9450 
2023-12-01 09:55:53,798:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 2;	4: 0;	5: 3;	6: 2;	7: 0;	8: 1;	9: 3;	10: 2;	11: 2;	12: 2;	13: 1;	14: 2;	15: 2;	16: 0;	17: 2;	18: 0;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 2;	25: 2;	26: 0;	27: 2;	28: 0;	29: 1;	30: 2;	31: 0;	32: 3;	33: 1;	34: 0;	35: 0;	36: 2;	37: 1;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 3;	26101: 3;	26102: 0;	26103: 1;	26104: 2;	26105: 1;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:53,799:INFO::Validation loss decreased (1.163419 --> 1.129169).  Saving model ...
2023-12-01 09:55:53,801:INFO::Epoch: 13
tensor([[0.5134, 0.4959, 0.4983, 0.4983],
        [0.5088, 0.4907, 0.4968, 0.4943],
        [0.5282, 0.4964, 0.4946, 0.4983],
        [0.4914, 0.4950, 0.5072, 0.4904]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:53,802:INFO::its now!!!!!!!!5
2023-12-01 09:55:54,022:INFO::its now!!!!!!!!0
2023-12-01 09:55:54,023:INFO::its now!!!!!!!!3
2023-12-01 09:55:54,136:INFO::its now!!!!!!!!5
2023-12-01 09:55:54,355:INFO::its now!!!!!!!!
2023-12-01 09:55:54,355:INFO::its now!!!!!!!! on 
2023-12-01 09:55:54,479:INFO::its now!!!!!!!!5
2023-12-01 09:55:54,716:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:54,718:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.1111 | Train_Classification_Loss 1.1427 | Dmon_Loss -0.0631 | Val_Loss 1.0895 | Search Time(s) 0.6732 | Infer Time(s) 0.2436 | Time(s) 0.9168 
2023-12-01 09:55:54,770:INFO::cluster info:
0: 2;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 1;	7: 0;	8: 0;	9: 2;	10: 0;	11: 0;	12: 0;	13: 2;	14: 2;	15: 2;	16: 0;	17: 1;	18: 0;	19: 2;	20: 0;	21: 2;	22: 0;	23: 1;	24: 1;	25: 2;	26: 1;	27: 3;	28: 2;	29: 0;	30: 0;	31: 2;	32: 2;	33: 1;	34: 0;	35: 2;	36: 2;	37: 1;	38: 2;	39: 2;	40: 0;	41: 2;	42: 2;	43: 1;	44
26098: 0;	26099: 1;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 2;	26105: 1;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 0;	26111: 2;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:54,771:INFO::Validation loss decreased (1.129169 --> 1.089485).  Saving model ...
2023-12-01 09:55:54,773:INFO::Epoch: 14
tensor([[0.5154, 0.4956, 0.4980, 0.4980],
        [0.5092, 0.4903, 0.4965, 0.4939],
        [0.5356, 0.4961, 0.4942, 0.4980],
        [0.4910, 0.4947, 0.5073, 0.4901]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:54,774:INFO::its now!!!!!!!!5
2023-12-01 09:55:54,987:INFO::its now!!!!!!!!0
2023-12-01 09:55:54,989:INFO::its now!!!!!!!!3
2023-12-01 09:55:55,102:INFO::its now!!!!!!!!5
2023-12-01 09:55:55,326:INFO::its now!!!!!!!!
2023-12-01 09:55:55,326:INFO::its now!!!!!!!! on 
2023-12-01 09:55:55,450:INFO::its now!!!!!!!!5
2023-12-01 09:55:55,659:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:55,662:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.0768 | Train_Classification_Loss 1.1083 | Dmon_Loss -0.0631 | Val_Loss 1.0443 | Search Time(s) 0.6707 | Infer Time(s) 0.2180 | Time(s) 0.8887 
2023-12-01 09:55:55,711:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 2;	5: 0;	6: 1;	7: 2;	8: 0;	9: 2;	10: 2;	11: 2;	12: 0;	13: 0;	14: 2;	15: 0;	16: 2;	17: 2;	18: 1;	19: 2;	20: 2;	21: 0;	22: 0;	23: 0;	24: 2;	25: 2;	26: 1;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 1;	34: 2;	35: 0;	36: 0;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 3;	26104: 2;	26105: 1;	26106: 3;	26107: 2;	26108: 2;	26109: 2;	26110: 0;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 0;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:55,712:INFO::Validation loss decreased (1.089485 --> 1.044298).  Saving model ...
2023-12-01 09:55:55,715:INFO::Epoch: 15
tensor([[0.5180, 0.4917, 0.4942, 0.4942],
        [0.5094, 0.4861, 0.4927, 0.4901],
        [0.5429, 0.4923, 0.4904, 0.4942],
        [0.4866, 0.4909, 0.5073, 0.4859]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:55,715:INFO::its now!!!!!!!!5
2023-12-01 09:55:55,946:INFO::its now!!!!!!!!0
2023-12-01 09:55:55,947:INFO::its now!!!!!!!!3
2023-12-01 09:55:56,061:INFO::its now!!!!!!!!5
2023-12-01 09:55:56,283:INFO::its now!!!!!!!!
2023-12-01 09:55:56,283:INFO::its now!!!!!!!! on 
2023-12-01 09:55:56,408:INFO::its now!!!!!!!!5
2023-12-01 09:55:56,605:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:56,606:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.0460 | Train_Classification_Loss 1.0775 | Dmon_Loss -0.0631 | Val_Loss 0.9961 | Search Time(s) 0.6862 | Infer Time(s) 0.2050 | Time(s) 0.8912 
2023-12-01 09:55:56,655:INFO::cluster info:
0: 1;	1: 0;	2: 0;	3: 0;	4: 1;	5: 2;	6: 2;	7: 0;	8: 2;	9: 0;	10: 2;	11: 2;	12: 2;	13: 0;	14: 2;	15: 0;	16: 2;	17: 1;	18: 0;	19: 1;	20: 0;	21: 0;	22: 2;	23: 1;	24: 0;	25: 1;	26: 1;	27: 2;	28: 3;	29: 0;	30: 0;	31: 1;	32: 2;	33: 0;	34: 0;	35: 0;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 2;	42: 0;	43: 2;	44
26098: 1;	26099: 1;	26100: 1;	26101: 0;	26102: 3;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 0;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 0;	26116: 1;	26117: 1;	26118: 0;	26119: 2;	26120: 0;	26121: 2;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:55:56,656:INFO::Validation loss decreased (1.044298 --> 0.996073).  Saving model ...
2023-12-01 09:55:56,659:INFO::Epoch: 16
tensor([[0.5209, 0.4903, 0.4928, 0.4928],
        [0.5096, 0.4846, 0.4913, 0.4886],
        [0.5510, 0.4909, 0.4890, 0.4928],
        [0.4850, 0.4895, 0.5073, 0.4844]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:56,659:INFO::its now!!!!!!!!5
2023-12-01 09:55:56,873:INFO::its now!!!!!!!!0
2023-12-01 09:55:56,874:INFO::its now!!!!!!!!3
2023-12-01 09:55:56,990:INFO::its now!!!!!!!!5
2023-12-01 09:55:57,215:INFO::its now!!!!!!!!
2023-12-01 09:55:57,215:INFO::its now!!!!!!!! on 
2023-12-01 09:55:57,340:INFO::its now!!!!!!!!5
2023-12-01 09:55:57,553:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:57,555:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 0.9720 | Train_Classification_Loss 1.0036 | Dmon_Loss -0.0632 | Val_Loss 0.9434 | Search Time(s) 0.6768 | Infer Time(s) 0.2204 | Time(s) 0.8972 
2023-12-01 09:55:57,610:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 0;	4: 1;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 0;	12: 0;	13: 2;	14: 0;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 2;	23: 0;	24: 0;	25: 2;	26: 0;	27: 2;	28: 2;	29: 2;	30: 1;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 2;	26107: 1;	26108: 2;	26109: 2;	26110: 0;	26111: 2;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:57,612:INFO::Validation loss decreased (0.996073 --> 0.943368).  Saving model ...
2023-12-01 09:55:57,615:INFO::Epoch: 17
tensor([[0.5249, 0.4862, 0.4887, 0.4887],
        [0.5105, 0.4802, 0.4872, 0.4845],
        [0.5572, 0.4868, 0.4848, 0.4887],
        [0.4803, 0.4854, 0.5074, 0.4800]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:57,616:INFO::its now!!!!!!!!5
2023-12-01 09:55:57,823:INFO::its now!!!!!!!!0
2023-12-01 09:55:57,824:INFO::its now!!!!!!!!3
2023-12-01 09:55:57,939:INFO::its now!!!!!!!!5
2023-12-01 09:55:58,175:INFO::its now!!!!!!!!
2023-12-01 09:55:58,176:INFO::its now!!!!!!!! on 
2023-12-01 09:55:58,301:INFO::its now!!!!!!!!5
2023-12-01 09:55:58,520:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:58,522:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 0.9542 | Train_Classification_Loss 0.9857 | Dmon_Loss -0.0631 | Val_Loss 0.8859 | Search Time(s) 0.6822 | Infer Time(s) 0.2264 | Time(s) 0.9086 
2023-12-01 09:55:58,575:INFO::cluster info:
0: 2;	1: 0;	2: 3;	3: 1;	4: 0;	5: 0;	6: 3;	7: 1;	8: 2;	9: 2;	10: 2;	11: 1;	12: 2;	13: 0;	14: 0;	15: 2;	16: 1;	17: 2;	18: 0;	19: 2;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 2;	26: 2;	27: 3;	28: 1;	29: 1;	30: 0;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 0;	39: 1;	40: 2;	41: 0;	42: 0;	43: 1;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 3;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 0;	26111: 2;	26112: 0;	26113: 2;	26114: 0;	26115: 1;	26116: 0;	26117: 1;	26118: 2;	26119: 1;	26120: 2;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:55:58,576:INFO::Validation loss decreased (0.943368 --> 0.885864).  Saving model ...
2023-12-01 09:55:58,579:INFO::Epoch: 18
tensor([[0.5279, 0.4846, 0.4871, 0.4871],
        [0.5111, 0.4784, 0.4856, 0.4828],
        [0.5650, 0.4852, 0.4832, 0.4871],
        [0.4784, 0.4838, 0.5074, 0.4782]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:58,580:INFO::its now!!!!!!!!5
2023-12-01 09:55:58,816:INFO::its now!!!!!!!!0
2023-12-01 09:55:58,817:INFO::its now!!!!!!!!3
2023-12-01 09:55:58,931:INFO::its now!!!!!!!!5
2023-12-01 09:55:59,135:INFO::its now!!!!!!!!
2023-12-01 09:55:59,135:INFO::its now!!!!!!!! on 
2023-12-01 09:55:59,258:INFO::its now!!!!!!!!5
2023-12-01 09:55:59,460:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:55:59,461:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 0.9029 | Train_Classification_Loss 0.9345 | Dmon_Loss -0.0632 | Val_Loss 0.8267 | Search Time(s) 0.6746 | Infer Time(s) 0.2094 | Time(s) 0.8841 
2023-12-01 09:55:59,504:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 1;	4: 0;	5: 0;	6: 3;	7: 1;	8: 1;	9: 0;	10: 0;	11: 2;	12: 2;	13: 1;	14: 0;	15: 2;	16: 0;	17: 2;	18: 1;	19: 0;	20: 2;	21: 2;	22: 0;	23: 2;	24: 0;	25: 0;	26: 1;	27: 1;	28: 1;	29: 1;	30: 0;	31: 2;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 0;	42: 1;	43: 0;	44
26098: 2;	26099: 0;	26100: 2;	26101: 3;	26102: 3;	26103: 0;	26104: 2;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 0;	26111: 2;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 1;	26118: 1;	26119: 1;	26120: 0;	26121: 2;	26122: 0;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:55:59,505:INFO::Validation loss decreased (0.885864 --> 0.826718).  Saving model ...
2023-12-01 09:55:59,510:INFO::Epoch: 19
tensor([[0.5349, 0.4834, 0.4859, 0.4859],
        [0.5127, 0.4772, 0.4845, 0.4817],
        [0.5723, 0.4840, 0.4820, 0.4859],
        [0.4772, 0.4827, 0.5074, 0.4769]], device='cuda:0', requires_grad=True)
2023-12-01 09:55:59,511:INFO::its now!!!!!!!!5
2023-12-01 09:55:59,710:INFO::its now!!!!!!!!0
2023-12-01 09:55:59,711:INFO::its now!!!!!!!!3
2023-12-01 09:55:59,826:INFO::its now!!!!!!!!5
2023-12-01 09:56:00,042:INFO::its now!!!!!!!!
2023-12-01 09:56:00,043:INFO::its now!!!!!!!! on 
2023-12-01 09:56:00,166:INFO::its now!!!!!!!!5
2023-12-01 09:56:00,394:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:00,395:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 0.8308 | Train_Classification_Loss 0.8625 | Dmon_Loss -0.0634 | Val_Loss 0.7689 | Search Time(s) 0.6544 | Infer Time(s) 0.2324 | Time(s) 0.8868 
2023-12-01 09:56:00,446:INFO::cluster info:
0: 1;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 2;	8: 0;	9: 1;	10: 2;	11: 1;	12: 2;	13: 1;	14: 0;	15: 2;	16: 0;	17: 2;	18: 1;	19: 1;	20: 2;	21: 0;	22: 1;	23: 2;	24: 0;	25: 3;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 2;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 0;	26100: 0;	26101: 1;	26102: 1;	26103: 0;	26104: 2;	26105: 2;	26106: 2;	26107: 1;	26108: 0;	26109: 2;	26110: 0;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 2;	26118: 0;	26119: 1;	26120: 2;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 09:56:00,447:INFO::Validation loss decreased (0.826718 --> 0.768859).  Saving model ...
2023-12-01 09:56:00,450:INFO::Epoch: 20
tensor([[0.5392, 0.4769, 0.4795, 0.4795],
        [0.5162, 0.4704, 0.4780, 0.4752],
        [0.5788, 0.4775, 0.4755, 0.4795],
        [0.4701, 0.4762, 0.5074, 0.4701]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:00,450:INFO::its now!!!!!!!!5
2023-12-01 09:56:00,663:INFO::its now!!!!!!!!0
2023-12-01 09:56:00,664:INFO::its now!!!!!!!!3
2023-12-01 09:56:00,779:INFO::its now!!!!!!!!5
2023-12-01 09:56:00,999:INFO::its now!!!!!!!!
2023-12-01 09:56:00,999:INFO::its now!!!!!!!! on 
2023-12-01 09:56:01,124:INFO::its now!!!!!!!!5
2023-12-01 09:56:01,359:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:01,361:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 0.7808 | Train_Classification_Loss 0.8125 | Dmon_Loss -0.0634 | Val_Loss 0.7095 | Search Time(s) 0.6685 | Infer Time(s) 0.2433 | Time(s) 0.9118 
2023-12-01 09:56:01,413:INFO::cluster info:
0: 3;	1: 0;	2: 2;	3: 1;	4: 0;	5: 2;	6: 1;	7: 2;	8: 2;	9: 0;	10: 1;	11: 3;	12: 0;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 0;	20: 0;	21: 0;	22: 1;	23: 1;	24: 0;	25: 0;	26: 1;	27: 2;	28: 2;	29: 3;	30: 2;	31: 1;	32: 2;	33: 2;	34: 1;	35: 2;	36: 0;	37: 2;	38: 0;	39: 2;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 1;	26099: 3;	26100: 0;	26101: 0;	26102: 2;	26103: 1;	26104: 0;	26105: 0;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 09:56:01,414:INFO::Validation loss decreased (0.768859 --> 0.709540).  Saving model ...
2023-12-01 09:56:01,416:INFO::Epoch: 21
tensor([[0.5453, 0.4701, 0.4727, 0.4727],
        [0.5184, 0.4632, 0.4711, 0.4683],
        [0.5853, 0.4707, 0.4686, 0.4727],
        [0.4627, 0.4694, 0.5074, 0.4629]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:01,417:INFO::its now!!!!!!!!5
2023-12-01 09:56:01,663:INFO::its now!!!!!!!!0
2023-12-01 09:56:01,664:INFO::its now!!!!!!!!3
2023-12-01 09:56:01,780:INFO::its now!!!!!!!!5
2023-12-01 09:56:02,009:INFO::its now!!!!!!!!
2023-12-01 09:56:02,010:INFO::its now!!!!!!!! on 
2023-12-01 09:56:02,135:INFO::its now!!!!!!!!5
2023-12-01 09:56:02,348:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:02,349:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 0.7468 | Train_Classification_Loss 0.7785 | Dmon_Loss -0.0634 | Val_Loss 0.6509 | Search Time(s) 0.7135 | Infer Time(s) 0.2204 | Time(s) 0.9339 
2023-12-01 09:56:02,391:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 2;	6: 2;	7: 2;	8: 1;	9: 3;	10: 2;	11: 2;	12: 0;	13: 1;	14: 1;	15: 2;	16: 3;	17: 2;	18: 0;	19: 2;	20: 0;	21: 2;	22: 1;	23: 0;	24: 0;	25: 2;	26: 0;	27: 2;	28: 2;	29: 0;	30: 1;	31: 3;	32: 0;	33: 0;	34: 0;	35: 2;	36: 1;	37: 1;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 1;	26100: 2;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 3;	26106: 3;	26107: 0;	26108: 1;	26109: 2;	26110: 0;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:02,392:INFO::Validation loss decreased (0.709540 --> 0.650909).  Saving model ...
2023-12-01 09:56:02,394:INFO::Epoch: 22
tensor([[0.5490, 0.4616, 0.4641, 0.4641],
        [0.5223, 0.4544, 0.4626, 0.4597],
        [0.5899, 0.4622, 0.4600, 0.4641],
        [0.4537, 0.4608, 0.5074, 0.4541]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:02,395:INFO::its now!!!!!!!!5
2023-12-01 09:56:02,618:INFO::its now!!!!!!!!0
2023-12-01 09:56:02,619:INFO::its now!!!!!!!!3
2023-12-01 09:56:02,736:INFO::its now!!!!!!!!5
2023-12-01 09:56:02,971:INFO::its now!!!!!!!!
2023-12-01 09:56:02,971:INFO::its now!!!!!!!! on 
2023-12-01 09:56:03,094:INFO::its now!!!!!!!!5
2023-12-01 09:56:03,327:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:03,328:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 0.7113 | Train_Classification_Loss 0.7432 | Dmon_Loss -0.0639 | Val_Loss 0.5966 | Search Time(s) 0.6955 | Infer Time(s) 0.2394 | Time(s) 0.9348 
2023-12-01 09:56:03,383:INFO::cluster info:
0: 1;	1: 2;	2: 0;	3: 1;	4: 3;	5: 2;	6: 1;	7: 2;	8: 2;	9: 0;	10: 0;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 0;	17: 0;	18: 0;	19: 1;	20: 0;	21: 2;	22: 1;	23: 1;	24: 0;	25: 0;	26: 1;	27: 2;	28: 1;	29: 1;	30: 0;	31: 1;	32: 0;	33: 2;	34: 2;	35: 0;	36: 0;	37: 1;	38: 0;	39: 0;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 2;	26099: 1;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:03,385:INFO::Validation loss decreased (0.650909 --> 0.596628).  Saving model ...
2023-12-01 09:56:03,388:INFO::Epoch: 23
tensor([[0.5515, 0.4583, 0.4609, 0.4609],
        [0.5265, 0.4509, 0.4593, 0.4564],
        [0.5961, 0.4589, 0.4567, 0.4609],
        [0.4502, 0.4575, 0.5074, 0.4507]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:03,390:INFO::its now!!!!!!!!5
2023-12-01 09:56:03,607:INFO::its now!!!!!!!!0
2023-12-01 09:56:03,608:INFO::its now!!!!!!!!3
2023-12-01 09:56:03,722:INFO::its now!!!!!!!!5
2023-12-01 09:56:03,959:INFO::its now!!!!!!!!
2023-12-01 09:56:03,959:INFO::its now!!!!!!!! on 
2023-12-01 09:56:04,086:INFO::its now!!!!!!!!5
2023-12-01 09:56:04,316:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:04,318:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 0.7116 | Train_Classification_Loss 0.7434 | Dmon_Loss -0.0638 | Val_Loss 0.5450 | Search Time(s) 0.6933 | Infer Time(s) 0.2384 | Time(s) 0.9316 
2023-12-01 09:56:04,362:INFO::cluster info:
0: 2;	1: 0;	2: 0;	3: 1;	4: 0;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 0;	12: 0;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 0;	23: 1;	24: 2;	25: 3;	26: 0;	27: 2;	28: 1;	29: 1;	30: 2;	31: 1;	32: 0;	33: 0;	34: 2;	35: 0;	36: 1;	37: 1;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 2;	26103: 0;	26104: 1;	26105: 2;	26106: 0;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 0;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:04,363:INFO::Validation loss decreased (0.596628 --> 0.545039).  Saving model ...
2023-12-01 09:56:04,366:INFO::Epoch: 24
tensor([[0.5535, 0.4519, 0.4545, 0.4545],
        [0.5318, 0.4444, 0.4530, 0.4500],
        [0.6017, 0.4525, 0.4503, 0.4545],
        [0.4435, 0.4512, 0.5073, 0.4441]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:04,367:INFO::its now!!!!!!!!5
2023-12-01 09:56:04,556:INFO::its now!!!!!!!!0
2023-12-01 09:56:04,557:INFO::its now!!!!!!!!3
2023-12-01 09:56:04,672:INFO::its now!!!!!!!!5
2023-12-01 09:56:04,878:INFO::its now!!!!!!!!
2023-12-01 09:56:04,879:INFO::its now!!!!!!!! on 
2023-12-01 09:56:05,002:INFO::its now!!!!!!!!5
2023-12-01 09:56:05,207:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:05,209:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 0.6379 | Train_Classification_Loss 0.6699 | Dmon_Loss -0.0640 | Val_Loss 0.4970 | Search Time(s) 0.6306 | Infer Time(s) 0.2124 | Time(s) 0.8430 
2023-12-01 09:56:05,259:INFO::cluster info:
0: 3;	1: 1;	2: 2;	3: 1;	4: 0;	5: 3;	6: 1;	7: 1;	8: 2;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 0;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 0;	25: 3;	26: 1;	27: 1;	28: 2;	29: 1;	30: 0;	31: 1;	32: 3;	33: 2;	34: 0;	35: 2;	36: 2;	37: 0;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 1;	26105: 1;	26106: 0;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:05,260:INFO::Validation loss decreased (0.545039 --> 0.497036).  Saving model ...
2023-12-01 09:56:05,262:INFO::Epoch: 25
tensor([[0.5558, 0.4467, 0.4493, 0.4493],
        [0.5373, 0.4391, 0.4478, 0.4449],
        [0.6060, 0.4474, 0.4452, 0.4493],
        [0.4381, 0.4460, 0.5072, 0.4388]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:05,456:INFO::its now!!!!!!!!5
2023-12-01 09:56:05,834:INFO::its now!!!!!!!!0
2023-12-01 09:56:05,835:INFO::its now!!!!!!!!3
2023-12-01 09:56:05,974:INFO::its now!!!!!!!!5
2023-12-01 09:56:06,250:INFO::its now!!!!!!!!
2023-12-01 09:56:06,250:INFO::its now!!!!!!!! on 
2023-12-01 09:56:06,375:INFO::its now!!!!!!!!5
2023-12-01 09:56:06,625:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:06,627:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 0.6004 | Train_Classification_Loss 0.6328 | Dmon_Loss -0.0647 | Val_Loss 0.4571 | Search Time(s) 1.1063 | Infer Time(s) 0.2590 | Time(s) 1.3653 
2023-12-01 09:56:06,698:INFO::cluster info:
0: 0;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 3;	7: 1;	8: 1;	9: 0;	10: 1;	11: 0;	12: 2;	13: 0;	14: 1;	15: 2;	16: 0;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 1;	34: 2;	35: 2;	36: 0;	37: 1;	38: 0;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 3;	26102: 1;	26103: 2;	26104: 3;	26105: 1;	26106: 3;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:06,699:INFO::Validation loss decreased (0.497036 --> 0.457094).  Saving model ...
2023-12-01 09:56:06,701:INFO::Epoch: 26
tensor([[0.5588, 0.4405, 0.4432, 0.4432],
        [0.5305, 0.4351, 0.4416, 0.4386],
        [0.5989, 0.4412, 0.4424, 0.4432],
        [0.4317, 0.4434, 0.4995, 0.4324]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:06,702:INFO::its now!!!!!!!!5
2023-12-01 09:56:07,005:INFO::its now!!!!!!!!0
2023-12-01 09:56:07,007:INFO::its now!!!!!!!!3
2023-12-01 09:56:07,183:INFO::its now!!!!!!!!5
2023-12-01 09:56:07,534:INFO::its now!!!!!!!!
2023-12-01 09:56:07,535:INFO::its now!!!!!!!! on 
2023-12-01 09:56:07,659:INFO::its now!!!!!!!!5
2023-12-01 09:56:07,905:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:07,906:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 0.5908 | Train_Classification_Loss 0.6235 | Dmon_Loss -0.0653 | Val_Loss 0.4175 | Search Time(s) 0.9521 | Infer Time(s) 0.2539 | Time(s) 1.2060 
2023-12-01 09:56:07,966:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 1;	4: 0;	5: 0;	6: 3;	7: 1;	8: 2;	9: 2;	10: 1;	11: 1;	12: 2;	13: 0;	14: 1;	15: 2;	16: 1;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 3;	26: 1;	27: 3;	28: 0;	29: 1;	30: 1;	31: 1;	32: 0;	33: 2;	34: 2;	35: 3;	36: 0;	37: 0;	38: 0;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 3;	26104: 0;	26105: 1;	26106: 2;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:07,967:INFO::Validation loss decreased (0.457094 --> 0.417467).  Saving model ...
2023-12-01 09:56:07,971:INFO::Epoch: 27
tensor([[0.5620, 0.4327, 0.4354, 0.4354],
        [0.5301, 0.4280, 0.4338, 0.4308],
        [0.5944, 0.4334, 0.4361, 0.4354],
        [0.4236, 0.4371, 0.4955, 0.4245]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:07,972:INFO::its now!!!!!!!!5
2023-12-01 09:56:08,184:INFO::its now!!!!!!!!0
2023-12-01 09:56:08,185:INFO::its now!!!!!!!!3
2023-12-01 09:56:08,301:INFO::its now!!!!!!!!5
2023-12-01 09:56:08,543:INFO::its now!!!!!!!!
2023-12-01 09:56:08,544:INFO::its now!!!!!!!! on 
2023-12-01 09:56:08,667:INFO::its now!!!!!!!!5
2023-12-01 09:56:08,901:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:08,902:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 0.5611 | Train_Classification_Loss 0.5942 | Dmon_Loss -0.0661 | Val_Loss 0.3815 | Search Time(s) 0.6924 | Infer Time(s) 0.2420 | Time(s) 0.9345 
2023-12-01 09:56:08,945:INFO::cluster info:
0: 1;	1: 1;	2: 0;	3: 1;	4: 0;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 3;	11: 2;	12: 2;	13: 0;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 0;	25: 1;	26: 1;	27: 1;	28: 0;	29: 1;	30: 1;	31: 1;	32: 1;	33: 0;	34: 2;	35: 3;	36: 3;	37: 1;	38: 0;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 0;	26100: 3;	26101: 2;	26102: 0;	26103: 1;	26104: 2;	26105: 2;	26106: 0;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:08,946:INFO::Validation loss decreased (0.417467 --> 0.381539).  Saving model ...
2023-12-01 09:56:08,949:INFO::Epoch: 28
tensor([[0.5655, 0.4289, 0.4315, 0.4315],
        [0.5320, 0.4245, 0.4299, 0.4269],
        [0.5931, 0.4295, 0.4329, 0.4315],
        [0.4196, 0.4340, 0.4936, 0.4205]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:08,950:INFO::its now!!!!!!!!5
2023-12-01 09:56:09,161:INFO::its now!!!!!!!!0
2023-12-01 09:56:09,162:INFO::its now!!!!!!!!3
2023-12-01 09:56:09,277:INFO::its now!!!!!!!!5
2023-12-01 09:56:09,521:INFO::its now!!!!!!!!
2023-12-01 09:56:09,521:INFO::its now!!!!!!!! on 
2023-12-01 09:56:09,646:INFO::its now!!!!!!!!5
2023-12-01 09:56:09,857:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 0.5756 | Train_Classification_Loss 0.6094 | Dmon_Loss -0.0675 | Val_Loss 0.4023 | Search Time(s) 0.6907 | Infer Time(s) 0.2190 | Time(s) 0.9097 
2023-12-01 09:56:09,910:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 3;	10: 1;	11: 1;	12: 2;	13: 0;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 0;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 0;	31: 1;	32: 1;	33: 2;	34: 2;	35: 1;	36: 1;	37: 3;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 0;	26099: 1;	26100: 0;	26101: 0;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:09,911:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:09,915:INFO::Epoch: 29
tensor([[0.5645, 0.4261, 0.4288, 0.4288],
        [0.5348, 0.4220, 0.4272, 0.4242],
        [0.5915, 0.4268, 0.4306, 0.4288],
        [0.4168, 0.4317, 0.4926, 0.4177]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:09,916:INFO::its now!!!!!!!!5
2023-12-01 09:56:10,131:INFO::its now!!!!!!!!0
2023-12-01 09:56:10,132:INFO::its now!!!!!!!!3
2023-12-01 09:56:10,247:INFO::its now!!!!!!!!5
2023-12-01 09:56:10,457:INFO::its now!!!!!!!!
2023-12-01 09:56:10,457:INFO::its now!!!!!!!! on 
2023-12-01 09:56:10,581:INFO::its now!!!!!!!!5
2023-12-01 09:56:10,812:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:10,814:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 0.5071 | Train_Classification_Loss 0.5411 | Dmon_Loss -0.0680 | Val_Loss 0.3367 | Search Time(s) 0.6638 | Infer Time(s) 0.2379 | Time(s) 0.9018 
2023-12-01 09:56:10,858:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 2;	9: 3;	10: 1;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 0;	29: 1;	30: 1;	31: 1;	32: 3;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 0;	26099: 1;	26100: 2;	26101: 1;	26102: 1;	26103: 3;	26104: 2;	26105: 2;	26106: 3;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:56:10,859:INFO::Validation loss decreased (0.381539 --> 0.336728).  Saving model ...
2023-12-01 09:56:10,862:INFO::Epoch: 30
tensor([[0.5639, 0.4253, 0.4280, 0.4280],
        [0.5377, 0.4213, 0.4264, 0.4234],
        [0.5917, 0.4260, 0.4300, 0.4280],
        [0.4159, 0.4311, 0.4922, 0.4169]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:10,863:INFO::its now!!!!!!!!5
2023-12-01 09:56:11,072:INFO::its now!!!!!!!!0
2023-12-01 09:56:11,073:INFO::its now!!!!!!!!3
2023-12-01 09:56:11,189:INFO::its now!!!!!!!!5
2023-12-01 09:56:11,421:INFO::its now!!!!!!!!
2023-12-01 09:56:11,421:INFO::its now!!!!!!!! on 
2023-12-01 09:56:11,544:INFO::its now!!!!!!!!5
2023-12-01 09:56:11,752:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:11,754:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 0.4541 | Train_Classification_Loss 0.4884 | Dmon_Loss -0.0686 | Val_Loss 0.3205 | Search Time(s) 0.6782 | Infer Time(s) 0.2146 | Time(s) 0.8928 
2023-12-01 09:56:11,798:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 0;	5: 3;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 0;	21: 2;	22: 1;	23: 1;	24: 3;	25: 1;	26: 1;	27: 1;	28: 0;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 0;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 0;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 09:56:11,799:INFO::Validation loss decreased (0.336728 --> 0.320528).  Saving model ...
2023-12-01 09:56:11,802:INFO::Epoch: 31
tensor([[0.5621, 0.4248, 0.4275, 0.4276],
        [0.5389, 0.4208, 0.4258, 0.4229],
        [0.5915, 0.4254, 0.4295, 0.4275],
        [0.4156, 0.4307, 0.4917, 0.4163]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:11,802:INFO::its now!!!!!!!!5
2023-12-01 09:56:12,040:INFO::its now!!!!!!!!0
2023-12-01 09:56:12,041:INFO::its now!!!!!!!!3
2023-12-01 09:56:12,155:INFO::its now!!!!!!!!5
2023-12-01 09:56:12,398:INFO::its now!!!!!!!!
2023-12-01 09:56:12,398:INFO::its now!!!!!!!! on 
2023-12-01 09:56:12,522:INFO::its now!!!!!!!!5
2023-12-01 09:56:12,796:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 0.4790 | Train_Classification_Loss 0.5142 | Dmon_Loss -0.0703 | Val_Loss 0.3675 | Search Time(s) 0.7151 | Infer Time(s) 0.2809 | Time(s) 0.9960 
2023-12-01 09:56:12,834:INFO::cluster info:
0: 0;	1: 1;	2: 2;	3: 1;	4: 0;	5: 1;	6: 1;	7: 1;	8: 3;	9: 1;	10: 1;	11: 1;	12: 2;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 0;	27: 1;	28: 1;	29: 3;	30: 1;	31: 1;	32: 1;	33: 0;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 2;	26105: 0;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 09:56:12,835:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:12,837:INFO::Epoch: 32
tensor([[0.5625, 0.4233, 0.4260, 0.4262],
        [0.5408, 0.4193, 0.4243, 0.4214],
        [0.5907, 0.4240, 0.4281, 0.4260],
        [0.4141, 0.4292, 0.4915, 0.4148]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:12,838:INFO::its now!!!!!!!!5
2023-12-01 09:56:13,048:INFO::its now!!!!!!!!0
2023-12-01 09:56:13,048:INFO::its now!!!!!!!!3
2023-12-01 09:56:13,162:INFO::its now!!!!!!!!5
2023-12-01 09:56:13,356:INFO::its now!!!!!!!!
2023-12-01 09:56:13,356:INFO::its now!!!!!!!! on 
2023-12-01 09:56:13,480:INFO::its now!!!!!!!!5
2023-12-01 09:56:13,684:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 0.4685 | Train_Classification_Loss 0.5048 | Dmon_Loss -0.0728 | Val_Loss 0.3410 | Search Time(s) 0.6373 | Infer Time(s) 0.2106 | Time(s) 0.8479 
2023-12-01 09:56:13,723:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 1;	12: 0;	13: 0;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 0;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 0;	29: 1;	30: 1;	31: 1;	32: 1;	33: 0;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 3;	26103: 1;	26104: 0;	26105: 0;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:13,724:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:56:13,727:INFO::Epoch: 33
tensor([[0.5632, 0.4219, 0.4245, 0.4248],
        [0.5433, 0.4178, 0.4228, 0.4199],
        [0.5892, 0.4225, 0.4266, 0.4246],
        [0.4127, 0.4277, 0.4914, 0.4134]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:13,727:INFO::its now!!!!!!!!5
2023-12-01 09:56:13,960:INFO::its now!!!!!!!!0
2023-12-01 09:56:13,961:INFO::its now!!!!!!!!3
2023-12-01 09:56:14,076:INFO::its now!!!!!!!!5
2023-12-01 09:56:14,336:INFO::its now!!!!!!!!
2023-12-01 09:56:14,339:INFO::its now!!!!!!!! on 
2023-12-01 09:56:14,474:INFO::its now!!!!!!!!5
2023-12-01 09:56:14,833:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 0.4494 | Train_Classification_Loss 0.4862 | Dmon_Loss -0.0737 | Val_Loss 0.3370 | Search Time(s) 0.7460 | Infer Time(s) 0.3623 | Time(s) 1.1083 
2023-12-01 09:56:14,920:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 3;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 0;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 0;	31: 1;	32: 1;	33: 2;	34: 2;	35: 0;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 0;	26101: 2;	26102: 3;	26103: 1;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 09:56:14,921:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:56:14,924:INFO::Epoch: 34
tensor([[0.5634, 0.4193, 0.4220, 0.4222],
        [0.5463, 0.4151, 0.4202, 0.4174],
        [0.5871, 0.4200, 0.4239, 0.4220],
        [0.4101, 0.4251, 0.4915, 0.4107]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:14,925:INFO::its now!!!!!!!!5
2023-12-01 09:56:15,207:INFO::its now!!!!!!!!0
2023-12-01 09:56:15,209:INFO::its now!!!!!!!!3
2023-12-01 09:56:15,322:INFO::its now!!!!!!!!5
2023-12-01 09:56:15,543:INFO::its now!!!!!!!!
2023-12-01 09:56:15,543:INFO::its now!!!!!!!! on 
2023-12-01 09:56:15,667:INFO::its now!!!!!!!!5
2023-12-01 09:56:15,881:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:15,883:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 0.4379 | Train_Classification_Loss 0.4774 | Dmon_Loss -0.0790 | Val_Loss 0.3183 | Search Time(s) 0.7376 | Infer Time(s) 0.2230 | Time(s) 0.9606 
2023-12-01 09:56:15,931:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 3;	11: 1;	12: 2;	13: 0;	14: 1;	15: 2;	16: 2;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 0;	31: 1;	32: 3;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 3;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:15,932:INFO::Validation loss decreased (0.320528 --> 0.318318).  Saving model ...
2023-12-01 09:56:15,934:INFO::Epoch: 35
tensor([[0.5629, 0.4163, 0.4190, 0.4193],
        [0.5498, 0.4119, 0.4172, 0.4144],
        [0.5859, 0.4170, 0.4208, 0.4190],
        [0.4070, 0.4220, 0.4916, 0.4077]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:15,935:INFO::its now!!!!!!!!5
2023-12-01 09:56:16,132:INFO::its now!!!!!!!!0
2023-12-01 09:56:16,133:INFO::its now!!!!!!!!3
2023-12-01 09:56:16,248:INFO::its now!!!!!!!!5
2023-12-01 09:56:16,459:INFO::its now!!!!!!!!
2023-12-01 09:56:16,460:INFO::its now!!!!!!!! on 
2023-12-01 09:56:16,584:INFO::its now!!!!!!!!5
2023-12-01 09:56:16,801:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:16,802:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 0.3847 | Train_Classification_Loss 0.4251 | Dmon_Loss -0.0807 | Val_Loss 0.3093 | Search Time(s) 0.6429 | Infer Time(s) 0.2260 | Time(s) 0.8689 
2023-12-01 09:56:16,860:INFO::cluster info:
0: 1;	1: 1;	2: 0;	3: 1;	4: 1;	5: 1;	6: 1;	7: 3;	8: 1;	9: 1;	10: 1;	11: 3;	12: 2;	13: 0;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 0;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 09:56:16,861:INFO::Validation loss decreased (0.318318 --> 0.309298).  Saving model ...
2023-12-01 09:56:16,863:INFO::Epoch: 36
tensor([[0.5636, 0.4064, 0.4091, 0.4094],
        [0.5538, 0.4017, 0.4073, 0.4045],
        [0.5845, 0.4071, 0.4107, 0.4091],
        [0.3968, 0.4119, 0.4917, 0.3976]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:16,864:INFO::its now!!!!!!!!5
2023-12-01 09:56:17,086:INFO::its now!!!!!!!!0
2023-12-01 09:56:17,087:INFO::its now!!!!!!!!3
2023-12-01 09:56:17,203:INFO::its now!!!!!!!!5
2023-12-01 09:56:17,418:INFO::its now!!!!!!!!
2023-12-01 09:56:17,419:INFO::its now!!!!!!!! on 
2023-12-01 09:56:17,543:INFO::its now!!!!!!!!5
2023-12-01 09:56:17,766:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:17,768:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 0.3588 | Train_Classification_Loss 0.4004 | Dmon_Loss -0.0834 | Val_Loss 0.3049 | Search Time(s) 0.6752 | Infer Time(s) 0.2293 | Time(s) 0.9045 
2023-12-01 09:56:17,818:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 3;	9: 1;	10: 1;	11: 3;	12: 2;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 3;	19: 1;	20: 0;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 3;	33: 2;	34: 2;	35: 2;	36: 1;	37: 0;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:17,820:INFO::Validation loss decreased (0.309298 --> 0.304911).  Saving model ...
2023-12-01 09:56:17,823:INFO::Epoch: 37
tensor([[0.5644, 0.4008, 0.4035, 0.4037],
        [0.5577, 0.3958, 0.4017, 0.3988],
        [0.5836, 0.4014, 0.4049, 0.4035],
        [0.3911, 0.4061, 0.4919, 0.3919]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:17,824:INFO::its now!!!!!!!!5
2023-12-01 09:56:18,082:INFO::its now!!!!!!!!0
2023-12-01 09:56:18,083:INFO::its now!!!!!!!!3
2023-12-01 09:56:18,199:INFO::its now!!!!!!!!5
2023-12-01 09:56:18,446:INFO::its now!!!!!!!!
2023-12-01 09:56:18,446:INFO::its now!!!!!!!! on 
2023-12-01 09:56:18,571:INFO::its now!!!!!!!!5
2023-12-01 09:56:18,763:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:18,764:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 0.3575 | Train_Classification_Loss 0.4011 | Dmon_Loss -0.0873 | Val_Loss 0.2844 | Search Time(s) 0.7426 | Infer Time(s) 0.2001 | Time(s) 0.9426 
2023-12-01 09:56:18,801:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 3;	6: 1;	7: 1;	8: 1;	9: 1;	10: 0;	11: 3;	12: 3;	13: 0;	14: 1;	15: 0;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 1;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 0;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 1;	44
26098: 3;	26099: 1;	26100: 0;	26101: 1;	26102: 3;	26103: 2;	26104: 0;	26105: 1;	26106: 3;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 09:56:18,802:INFO::Validation loss decreased (0.304911 --> 0.284418).  Saving model ...
2023-12-01 09:56:18,805:INFO::Epoch: 38
tensor([[0.5643, 0.3944, 0.3970, 0.3973],
        [0.5623, 0.3892, 0.3952, 0.3924],
        [0.5833, 0.3950, 0.3983, 0.3971],
        [0.3845, 0.3995, 0.4920, 0.3854]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:18,806:INFO::its now!!!!!!!!5
2023-12-01 09:56:18,998:INFO::its now!!!!!!!!0
2023-12-01 09:56:18,999:INFO::its now!!!!!!!!3
2023-12-01 09:56:19,114:INFO::its now!!!!!!!!5
2023-12-01 09:56:19,313:INFO::its now!!!!!!!!
2023-12-01 09:56:19,313:INFO::its now!!!!!!!! on 
2023-12-01 09:56:19,438:INFO::its now!!!!!!!!5
2023-12-01 09:56:19,659:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 0.3715 | Train_Classification_Loss 0.4182 | Dmon_Loss -0.0933 | Val_Loss 0.2864 | Search Time(s) 0.6283 | Infer Time(s) 0.2290 | Time(s) 0.8573 
2023-12-01 09:56:19,695:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 0;	21: 2;	22: 1;	23: 1;	24: 0;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 0;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 0;	26099: 1;	26100: 2;	26101: 0;	26102: 1;	26103: 1;	26104: 3;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 09:56:19,696:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:19,698:INFO::Epoch: 39
tensor([[0.5637, 0.3910, 0.3937, 0.3940],
        [0.5648, 0.3857, 0.3919, 0.3890],
        [0.5839, 0.3917, 0.3949, 0.3937],
        [0.3811, 0.3961, 0.4922, 0.3820]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:19,698:INFO::its now!!!!!!!!5
2023-12-01 09:56:19,888:INFO::its now!!!!!!!!0
2023-12-01 09:56:19,889:INFO::its now!!!!!!!!3
2023-12-01 09:56:20,004:INFO::its now!!!!!!!!5
2023-12-01 09:56:20,201:INFO::its now!!!!!!!!
2023-12-01 09:56:20,201:INFO::its now!!!!!!!! on 
2023-12-01 09:56:20,327:INFO::its now!!!!!!!!5
2023-12-01 09:56:20,523:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:20,524:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 0.3506 | Train_Classification_Loss 0.3993 | Dmon_Loss -0.0974 | Val_Loss 0.2253 | Search Time(s) 0.6293 | Infer Time(s) 0.1975 | Time(s) 0.8268 
2023-12-01 09:56:20,577:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 3;	8: 1;	9: 1;	10: 1;	11: 3;	12: 2;	13: 2;	14: 3;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 3;	31: 1;	32: 3;	33: 2;	34: 2;	35: 2;	36: 2;	37: 0;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 2;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:20,579:INFO::Validation loss decreased (0.284418 --> 0.225307).  Saving model ...
2023-12-01 09:56:20,582:INFO::Epoch: 40
tensor([[0.5631, 0.3855, 0.3882, 0.3884],
        [0.5689, 0.3800, 0.3864, 0.3835],
        [0.5808, 0.3861, 0.3892, 0.3882],
        [0.3755, 0.3905, 0.4922, 0.3764]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:20,582:INFO::its now!!!!!!!!5
2023-12-01 09:56:20,793:INFO::its now!!!!!!!!0
2023-12-01 09:56:20,794:INFO::its now!!!!!!!!3
2023-12-01 09:56:20,907:INFO::its now!!!!!!!!5
2023-12-01 09:56:21,130:INFO::its now!!!!!!!!
2023-12-01 09:56:21,130:INFO::its now!!!!!!!! on 
2023-12-01 09:56:21,254:INFO::its now!!!!!!!!5
2023-12-01 09:56:21,515:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 0.3583 | Train_Classification_Loss 0.4090 | Dmon_Loss -0.1014 | Val_Loss 0.2883 | Search Time(s) 0.6668 | Infer Time(s) 0.2683 | Time(s) 0.9351 
2023-12-01 09:56:21,559:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 3;	9: 1;	10: 2;	11: 1;	12: 2;	13: 0;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 0;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 0;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 0;	26099: 1;	26100: 1;	26101: 0;	26102: 1;	26103: 0;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 0;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 09:56:21,560:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:21,562:INFO::Epoch: 41
tensor([[0.5627, 0.3875, 0.3902, 0.3904],
        [0.5716, 0.3821, 0.3884, 0.3855],
        [0.5774, 0.3881, 0.3913, 0.3902],
        [0.3775, 0.3925, 0.4926, 0.3784]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:21,563:INFO::its now!!!!!!!!5
2023-12-01 09:56:21,788:INFO::its now!!!!!!!!0
2023-12-01 09:56:21,789:INFO::its now!!!!!!!!3
2023-12-01 09:56:21,903:INFO::its now!!!!!!!!5
2023-12-01 09:56:22,132:INFO::its now!!!!!!!!
2023-12-01 09:56:22,132:INFO::its now!!!!!!!! on 
2023-12-01 09:56:22,256:INFO::its now!!!!!!!!5
2023-12-01 09:56:22,464:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:22,466:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 0.3627 | Train_Classification_Loss 0.4161 | Dmon_Loss -0.1067 | Val_Loss 0.2128 | Search Time(s) 0.6898 | Infer Time(s) 0.2134 | Time(s) 0.9032 
2023-12-01 09:56:22,512:INFO::cluster info:
0: 3;	1: 1;	2: 3;	3: 1;	4: 1;	5: 3;	6: 1;	7: 1;	8: 1;	9: 1;	10: 3;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 3;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 1;	26105: 2;	26106: 0;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:22,513:INFO::Validation loss decreased (0.225307 --> 0.212800).  Saving model ...
2023-12-01 09:56:22,516:INFO::Epoch: 42
tensor([[0.5616, 0.3862, 0.3889, 0.3892],
        [0.5747, 0.3808, 0.3871, 0.3842],
        [0.5749, 0.3868, 0.3900, 0.3889],
        [0.3762, 0.3912, 0.4928, 0.3771]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:22,516:INFO::its now!!!!!!!!5
2023-12-01 09:56:22,727:INFO::its now!!!!!!!!0
2023-12-01 09:56:22,728:INFO::its now!!!!!!!!3
2023-12-01 09:56:22,842:INFO::its now!!!!!!!!5
2023-12-01 09:56:23,047:INFO::its now!!!!!!!!
2023-12-01 09:56:23,047:INFO::its now!!!!!!!! on 
2023-12-01 09:56:23,171:INFO::its now!!!!!!!!5
2023-12-01 09:56:23,378:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 0.3129 | Train_Classification_Loss 0.3678 | Dmon_Loss -0.1099 | Val_Loss 0.2729 | Search Time(s) 0.6495 | Infer Time(s) 0.2144 | Time(s) 0.8639 
2023-12-01 09:56:23,417:INFO::cluster info:
0: 1;	1: 1;	2: 0;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 0;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 0;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 3;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 0;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 09:56:23,418:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:23,421:INFO::Epoch: 43
tensor([[0.5622, 0.3869, 0.3896, 0.3899],
        [0.5735, 0.3815, 0.3878, 0.3849],
        [0.5728, 0.3876, 0.3907, 0.3897],
        [0.3770, 0.3920, 0.4936, 0.3779]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:23,422:INFO::its now!!!!!!!!5
2023-12-01 09:56:23,677:INFO::its now!!!!!!!!0
2023-12-01 09:56:23,678:INFO::its now!!!!!!!!3
2023-12-01 09:56:23,792:INFO::its now!!!!!!!!5
2023-12-01 09:56:24,028:INFO::its now!!!!!!!!
2023-12-01 09:56:24,028:INFO::its now!!!!!!!! on 
2023-12-01 09:56:24,152:INFO::its now!!!!!!!!5
2023-12-01 09:56:24,372:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 0.2942 | Train_Classification_Loss 0.3547 | Dmon_Loss -0.1211 | Val_Loss 0.2419 | Search Time(s) 0.7253 | Infer Time(s) 0.2284 | Time(s) 0.9537 
2023-12-01 09:56:24,426:INFO::cluster info:
0: 3;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 1;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:24,427:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:56:24,429:INFO::Epoch: 44
tensor([[0.5612, 0.3864, 0.3891, 0.3894],
        [0.5726, 0.3810, 0.3873, 0.3844],
        [0.5704, 0.3871, 0.3902, 0.3892],
        [0.3765, 0.3914, 0.4943, 0.3774]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:24,430:INFO::its now!!!!!!!!5
2023-12-01 09:56:24,624:INFO::its now!!!!!!!!0
2023-12-01 09:56:24,626:INFO::its now!!!!!!!!3
2023-12-01 09:56:24,741:INFO::its now!!!!!!!!5
2023-12-01 09:56:24,944:INFO::its now!!!!!!!!
2023-12-01 09:56:24,944:INFO::its now!!!!!!!! on 
2023-12-01 09:56:25,067:INFO::its now!!!!!!!!5
2023-12-01 09:56:25,264:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 0.3008 | Train_Classification_Loss 0.3604 | Dmon_Loss -0.1190 | Val_Loss 0.2552 | Search Time(s) 0.6325 | Infer Time(s) 0.2045 | Time(s) 0.8370 
2023-12-01 09:56:25,313:INFO::cluster info:
0: 3;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 1;	
2023-12-01 09:56:25,318:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:56:25,326:INFO::Epoch: 45
tensor([[0.5607, 0.3886, 0.3913, 0.3916],
        [0.5721, 0.3833, 0.3895, 0.3866],
        [0.5692, 0.3893, 0.3925, 0.3914],
        [0.3787, 0.3937, 0.4948, 0.3796]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:25,326:INFO::its now!!!!!!!!5
2023-12-01 09:56:25,534:INFO::its now!!!!!!!!0
2023-12-01 09:56:25,535:INFO::its now!!!!!!!!3
2023-12-01 09:56:25,650:INFO::its now!!!!!!!!5
2023-12-01 09:56:25,876:INFO::its now!!!!!!!!
2023-12-01 09:56:25,876:INFO::its now!!!!!!!! on 
2023-12-01 09:56:26,000:INFO::its now!!!!!!!!5
2023-12-01 09:56:26,205:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 0.3141 | Train_Classification_Loss 0.3800 | Dmon_Loss -0.1318 | Val_Loss 0.2367 | Search Time(s) 0.6738 | Infer Time(s) 0.2124 | Time(s) 0.8862 
2023-12-01 09:56:26,248:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 2;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:26,249:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:56:26,252:INFO::Epoch: 46
tensor([[0.5604, 0.3897, 0.3924, 0.3927],
        [0.5731, 0.3844, 0.3906, 0.3877],
        [0.5668, 0.3904, 0.3936, 0.3925],
        [0.3798, 0.3948, 0.4956, 0.3807]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:26,253:INFO::its now!!!!!!!!5
2023-12-01 09:56:26,481:INFO::its now!!!!!!!!0
2023-12-01 09:56:26,482:INFO::its now!!!!!!!!3
2023-12-01 09:56:26,597:INFO::its now!!!!!!!!5
2023-12-01 09:56:26,824:INFO::its now!!!!!!!!
2023-12-01 09:56:26,824:INFO::its now!!!!!!!! on 
2023-12-01 09:56:26,949:INFO::its now!!!!!!!!5
2023-12-01 09:56:27,140:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 0.2363 | Train_Classification_Loss 0.3054 | Dmon_Loss -0.1380 | Val_Loss 0.2508 | Search Time(s) 0.6912 | Infer Time(s) 0.1995 | Time(s) 0.8906 
2023-12-01 09:56:27,177:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 09:56:27,178:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:56:27,181:INFO::Epoch: 47
tensor([[0.5603, 0.3909, 0.3936, 0.3939],
        [0.5745, 0.3856, 0.3918, 0.3889],
        [0.5630, 0.3916, 0.3948, 0.3936],
        [0.3810, 0.3960, 0.4964, 0.3819]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:27,181:INFO::its now!!!!!!!!5
2023-12-01 09:56:27,400:INFO::its now!!!!!!!!0
2023-12-01 09:56:27,401:INFO::its now!!!!!!!!3
2023-12-01 09:56:27,515:INFO::its now!!!!!!!!5
2023-12-01 09:56:27,742:INFO::its now!!!!!!!!
2023-12-01 09:56:27,743:INFO::its now!!!!!!!! on 
2023-12-01 09:56:27,865:INFO::its now!!!!!!!!5
2023-12-01 09:56:28,071:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 0.2460 | Train_Classification_Loss 0.3158 | Dmon_Loss -0.1396 | Val_Loss 0.2470 | Search Time(s) 0.6792 | Infer Time(s) 0.2134 | Time(s) 0.8926 
2023-12-01 09:56:28,113:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 2;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 0;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 3;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 0;	26101: 2;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:28,114:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 09:56:28,117:INFO::Epoch: 48
tensor([[0.5602, 0.3936, 0.3962, 0.3965],
        [0.5767, 0.3883, 0.3944, 0.3916],
        [0.5586, 0.3942, 0.3975, 0.3963],
        [0.3837, 0.3987, 0.4970, 0.3846]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:28,118:INFO::its now!!!!!!!!5
2023-12-01 09:56:28,342:INFO::its now!!!!!!!!0
2023-12-01 09:56:28,342:INFO::its now!!!!!!!!3
2023-12-01 09:56:28,457:INFO::its now!!!!!!!!5
2023-12-01 09:56:28,654:INFO::its now!!!!!!!!
2023-12-01 09:56:28,655:INFO::its now!!!!!!!! on 
2023-12-01 09:56:28,779:INFO::its now!!!!!!!!5
2023-12-01 09:56:28,991:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 0.2773 | Train_Classification_Loss 0.3501 | Dmon_Loss -0.1457 | Val_Loss 0.2404 | Search Time(s) 0.6562 | Infer Time(s) 0.2214 | Time(s) 0.8777 
2023-12-01 09:56:29,056:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 0;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:56:29,057:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 09:56:29,059:INFO::Epoch: 49
tensor([[0.5600, 0.3965, 0.3991, 0.3994],
        [0.5772, 0.3913, 0.3973, 0.3945],
        [0.5554, 0.3971, 0.4004, 0.3992],
        [0.3866, 0.4016, 0.4977, 0.3875]], device='cuda:0', requires_grad=True)
2023-12-01 09:56:29,060:INFO::its now!!!!!!!!5
2023-12-01 09:56:29,305:INFO::its now!!!!!!!!0
2023-12-01 09:56:29,307:INFO::its now!!!!!!!!3
2023-12-01 09:56:29,427:INFO::its now!!!!!!!!5
2023-12-01 09:56:29,640:INFO::its now!!!!!!!!
2023-12-01 09:56:29,640:INFO::its now!!!!!!!! on 
2023-12-01 09:56:29,763:INFO::its now!!!!!!!!5
2023-12-01 09:56:29,990:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 0.2392 | Train_Classification_Loss 0.3152 | Dmon_Loss -0.1521 | Val_Loss 0.2486 | Search Time(s) 0.6991 | Infer Time(s) 0.2324 | Time(s) 0.9315 
2023-12-01 09:56:30,032:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 2;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 09:56:30,033:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 09:56:30,034:INFO::Eearly stopping!
2023-12-01 09:56:30,253:INFO::############### Search Stage Ends! ###############
2023-12-01 09:56:30,253:INFO::=============== Retrain Stage Starts:
2023-12-01 09:56:30,253:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:30,308:INFO::node_assign_Counter:
Counter({-1: 14328, 2: 5453, 1: 4760, 3: 981, 0: 606})
2023-12-01 09:56:30,308:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:56:30,778:INFO::============= repeat round: 0; seed: 123
2023-12-01 09:56:30,820:INFO::arch_weights:
[[0.5616434  0.3862094  0.38890037 0.38915825]
 [0.5747259  0.3807519  0.3870882  0.38421053]
 [0.57486427 0.3868489  0.389974   0.38893867]
 [0.37620953 0.3912035  0.49284744 0.37714255]]
2023-12-01 09:56:30,821:INFO::arch_weights_softmax:
[[0.2839282  0.23824209 0.23888405 0.23894565]
 [0.28742838 0.23674883 0.23825368 0.23756906]
 [0.28652206 0.23741274 0.23815583 0.23790939]
 [0.24156031 0.24520957 0.27144435 0.24178581]]
2023-12-01 09:56:30,821:INFO::genotype choice:
['gcn', 'gcn', 'gcn', 'mean']
2023-12-01 09:56:31,409:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.4257 | Val_Loss 1.3569 | Time(s) 0.5506
2023-12-01 09:56:31,926:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3672 | Val_Loss 1.3309 | Time(s) 0.3597
2023-12-01 09:56:31,969:INFO::Validation loss decreased (inf --> 1.330910).  Saving model ...
2023-12-01 09:56:32,316:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3574 | Val_Loss 1.3069 | Time(s) 0.3461
2023-12-01 09:56:32,337:INFO::Validation loss decreased (1.330910 --> 1.306901).  Saving model ...
2023-12-01 09:56:32,698:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.3150 | Val_Loss 1.2835 | Time(s) 0.3614
2023-12-01 09:56:32,710:INFO::Validation loss decreased (1.306901 --> 1.283527).  Saving model ...
2023-12-01 09:56:33,068:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.3024 | Val_Loss 1.2582 | Time(s) 0.3570
2023-12-01 09:56:33,080:INFO::Validation loss decreased (1.283527 --> 1.258168).  Saving model ...
2023-12-01 09:56:33,441:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.2894 | Val_Loss 1.2302 | Time(s) 0.3610
2023-12-01 09:56:33,452:INFO::Validation loss decreased (1.258168 --> 1.230164).  Saving model ...
2023-12-01 09:56:33,804:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.2519 | Val_Loss 1.1990 | Time(s) 0.3523
2023-12-01 09:56:33,814:INFO::Validation loss decreased (1.230164 --> 1.198966).  Saving model ...
2023-12-01 09:56:34,165:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.2082 | Val_Loss 1.1635 | Time(s) 0.3510
2023-12-01 09:56:34,235:INFO::Validation loss decreased (1.198966 --> 1.163483).  Saving model ...
2023-12-01 09:56:34,615:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.1638 | Val_Loss 1.1219 | Time(s) 0.3797
2023-12-01 09:56:34,628:INFO::Validation loss decreased (1.163483 --> 1.121944).  Saving model ...
2023-12-01 09:56:34,985:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.1431 | Val_Loss 1.0729 | Time(s) 0.3575
2023-12-01 09:56:34,996:INFO::Validation loss decreased (1.121944 --> 1.072929).  Saving model ...
2023-12-01 09:56:35,351:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.1196 | Val_Loss 1.0165 | Time(s) 0.3541
2023-12-01 09:56:35,361:INFO::Validation loss decreased (1.072929 --> 1.016541).  Saving model ...
2023-12-01 09:56:35,716:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.0696 | Val_Loss 0.9551 | Time(s) 0.3543
2023-12-01 09:56:35,728:INFO::Validation loss decreased (1.016541 --> 0.955078).  Saving model ...
2023-12-01 09:56:36,089:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 1.0193 | Val_Loss 0.8907 | Time(s) 0.3611
2023-12-01 09:56:36,102:INFO::Validation loss decreased (0.955078 --> 0.890716).  Saving model ...
2023-12-01 09:56:36,475:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 0.9781 | Val_Loss 0.8281 | Time(s) 0.3736
2023-12-01 09:56:36,488:INFO::Validation loss decreased (0.890716 --> 0.828088).  Saving model ...
2023-12-01 09:56:36,848:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 0.9521 | Val_Loss 0.7660 | Time(s) 0.3603
2023-12-01 09:56:36,861:INFO::Validation loss decreased (0.828088 --> 0.766026).  Saving model ...
2023-12-01 09:56:37,226:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 0.9046 | Val_Loss 0.7091 | Time(s) 0.3650
2023-12-01 09:56:37,236:INFO::Validation loss decreased (0.766026 --> 0.709065).  Saving model ...
2023-12-01 09:56:37,587:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 0.8332 | Val_Loss 0.6515 | Time(s) 0.3497
2023-12-01 09:56:37,598:INFO::Validation loss decreased (0.709065 --> 0.651465).  Saving model ...
2023-12-01 09:56:37,950:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 0.8332 | Val_Loss 0.5937 | Time(s) 0.3506
2023-12-01 09:56:37,975:INFO::Validation loss decreased (0.651465 --> 0.593744).  Saving model ...
2023-12-01 09:56:38,369:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 0.7608 | Val_Loss 0.5402 | Time(s) 0.3929
2023-12-01 09:56:38,384:INFO::Validation loss decreased (0.593744 --> 0.540187).  Saving model ...
2023-12-01 09:56:38,746:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 0.7507 | Val_Loss 0.4953 | Time(s) 0.3614
2023-12-01 09:56:38,757:INFO::Validation loss decreased (0.540187 --> 0.495283).  Saving model ...
2023-12-01 09:56:39,157:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 0.7156 | Val_Loss 0.4584 | Time(s) 0.3990
2023-12-01 09:56:39,175:INFO::Validation loss decreased (0.495283 --> 0.458401).  Saving model ...
2023-12-01 09:56:39,577:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 0.6855 | Val_Loss 0.4269 | Time(s) 0.4025
2023-12-01 09:56:39,588:INFO::Validation loss decreased (0.458401 --> 0.426862).  Saving model ...
2023-12-01 09:56:39,977:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 0.6877 | Val_Loss 0.3947 | Time(s) 0.3876
2023-12-01 09:56:39,992:INFO::Validation loss decreased (0.426862 --> 0.394691).  Saving model ...
2023-12-01 09:56:40,391:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 0.6818 | Val_Loss 0.3667 | Time(s) 0.3989
2023-12-01 09:56:40,403:INFO::Validation loss decreased (0.394691 --> 0.366686).  Saving model ...
2023-12-01 09:56:40,770:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 0.6320 | Val_Loss 0.3483 | Time(s) 0.3673
2023-12-01 09:56:40,784:INFO::Validation loss decreased (0.366686 --> 0.348309).  Saving model ...
2023-12-01 09:56:41,149:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 0.6047 | Val_Loss 0.3321 | Time(s) 0.3640
2023-12-01 09:56:41,162:INFO::Validation loss decreased (0.348309 --> 0.332137).  Saving model ...
2023-12-01 09:56:41,527:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 0.6175 | Val_Loss 0.3180 | Time(s) 0.3650
2023-12-01 09:56:41,540:INFO::Validation loss decreased (0.332137 --> 0.317997).  Saving model ...
2023-12-01 09:56:41,905:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 0.6082 | Val_Loss 0.3036 | Time(s) 0.3653
2023-12-01 09:56:41,918:INFO::Validation loss decreased (0.317997 --> 0.303637).  Saving model ...
2023-12-01 09:56:42,295:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 0.6054 | Val_Loss 0.2897 | Time(s) 0.3760
2023-12-01 09:56:42,311:INFO::Validation loss decreased (0.303637 --> 0.289668).  Saving model ...
2023-12-01 09:56:42,689:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 0.6465 | Val_Loss 0.2789 | Time(s) 0.3763
2023-12-01 09:56:42,702:INFO::Validation loss decreased (0.289668 --> 0.278854).  Saving model ...
2023-12-01 09:56:43,061:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 0.5313 | Val_Loss 0.2650 | Time(s) 0.3581
2023-12-01 09:56:43,073:INFO::Validation loss decreased (0.278854 --> 0.265034).  Saving model ...
2023-12-01 09:56:43,438:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 0.5517 | Val_Loss 0.2551 | Time(s) 0.3650
2023-12-01 09:56:43,455:INFO::Validation loss decreased (0.265034 --> 0.255132).  Saving model ...
2023-12-01 09:56:43,849:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 0.5615 | Val_Loss 0.2485 | Time(s) 0.3941
2023-12-01 09:56:43,865:INFO::Validation loss decreased (0.255132 --> 0.248489).  Saving model ...
2023-12-01 09:56:44,258:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 0.5589 | Val_Loss 0.2483 | Time(s) 0.3934
2023-12-01 09:56:44,272:INFO::Validation loss decreased (0.248489 --> 0.248301).  Saving model ...
2023-12-01 09:56:44,680:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 0.5472 | Val_Loss 0.2514 | Time(s) 0.4079
2023-12-01 09:56:44,682:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:45,053:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 0.5117 | Val_Loss 0.2526 | Time(s) 0.3704
2023-12-01 09:56:45,054:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:56:45,438:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 0.4957 | Val_Loss 0.2490 | Time(s) 0.3827
2023-12-01 09:56:45,439:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:56:45,824:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 0.5211 | Val_Loss 0.2460 | Time(s) 0.3842
2023-12-01 09:56:45,837:INFO::Validation loss decreased (0.248301 --> 0.246048).  Saving model ...
2023-12-01 09:56:46,202:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 0.4860 | Val_Loss 0.2405 | Time(s) 0.3650
2023-12-01 09:56:46,215:INFO::Validation loss decreased (0.246048 --> 0.240458).  Saving model ...
2023-12-01 09:56:46,584:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 0.4919 | Val_Loss 0.2339 | Time(s) 0.3686
2023-12-01 09:56:46,599:INFO::Validation loss decreased (0.240458 --> 0.233867).  Saving model ...
2023-12-01 09:56:46,970:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 0.4578 | Val_Loss 0.2320 | Time(s) 0.3706
2023-12-01 09:56:46,981:INFO::Validation loss decreased (0.233867 --> 0.231990).  Saving model ...
2023-12-01 09:56:47,363:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 0.4976 | Val_Loss 0.2321 | Time(s) 0.3810
2023-12-01 09:56:47,364:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:47,762:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 0.4555 | Val_Loss 0.2332 | Time(s) 0.3962
2023-12-01 09:56:47,763:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:56:48,148:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 0.4100 | Val_Loss 0.2342 | Time(s) 0.3850
2023-12-01 09:56:48,149:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:56:48,542:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 0.4071 | Val_Loss 0.2383 | Time(s) 0.3939
2023-12-01 09:56:48,543:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:56:48,950:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 0.4118 | Val_Loss 0.2394 | Time(s) 0.4063
2023-12-01 09:56:48,953:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:56:49,337:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 0.3888 | Val_Loss 0.2345 | Time(s) 0.3846
2023-12-01 09:56:49,338:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 09:56:49,744:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 0.4067 | Val_Loss 0.2282 | Time(s) 0.4035
2023-12-01 09:56:49,760:INFO::Validation loss decreased (0.231990 --> 0.228223).  Saving model ...
2023-12-01 09:56:50,154:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 0.3929 | Val_Loss 0.2206 | Time(s) 0.3929
2023-12-01 09:56:50,170:INFO::Validation loss decreased (0.228223 --> 0.220569).  Saving model ...
2023-12-01 09:56:50,566:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 0.3800 | Val_Loss 0.2150 | Time(s) 0.3946
2023-12-01 09:56:50,581:INFO::Validation loss decreased (0.220569 --> 0.214984).  Saving model ...
2023-12-01 09:56:50,951:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 0.3772 | Val_Loss 0.2108 | Time(s) 0.3697
2023-12-01 09:56:50,963:INFO::Validation loss decreased (0.214984 --> 0.210758).  Saving model ...
2023-12-01 09:56:51,314:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.3529 | Val_Loss 0.2098 | Time(s) 0.3511
2023-12-01 09:56:51,325:INFO::Validation loss decreased (0.210758 --> 0.209783).  Saving model ...
2023-12-01 09:56:51,675:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.4252 | Val_Loss 0.2077 | Time(s) 0.3493
2023-12-01 09:56:51,685:INFO::Validation loss decreased (0.209783 --> 0.207692).  Saving model ...
2023-12-01 09:56:52,037:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 0.3964 | Val_Loss 0.2055 | Time(s) 0.3511
2023-12-01 09:56:52,047:INFO::Validation loss decreased (0.207692 --> 0.205464).  Saving model ...
2023-12-01 09:56:52,400:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.3646 | Val_Loss 0.2033 | Time(s) 0.3530
2023-12-01 09:56:52,411:INFO::Validation loss decreased (0.205464 --> 0.203258).  Saving model ...
2023-12-01 09:56:52,768:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.3872 | Val_Loss 0.2044 | Time(s) 0.3570
2023-12-01 09:56:52,769:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:53,121:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.3632 | Val_Loss 0.2063 | Time(s) 0.3518
2023-12-01 09:56:53,122:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:56:53,492:INFO::Epoch 00057 | lr 0.00050 |Train_Loss 0.3473 | Val_Loss 0.2061 | Time(s) 0.3701
2023-12-01 09:56:53,492:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:56:53,843:INFO::Epoch 00058 | lr 0.00050 |Train_Loss 0.3875 | Val_Loss 0.2036 | Time(s) 0.3512
2023-12-01 09:56:53,844:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:56:54,195:INFO::Epoch 00059 | lr 0.00050 |Train_Loss 0.3405 | Val_Loss 0.1992 | Time(s) 0.3511
2023-12-01 09:56:54,206:INFO::Validation loss decreased (0.203258 --> 0.199195).  Saving model ...
2023-12-01 09:56:54,567:INFO::Epoch 00060 | lr 0.00050 |Train_Loss 0.3551 | Val_Loss 0.1951 | Time(s) 0.3614
2023-12-01 09:56:54,579:INFO::Validation loss decreased (0.199195 --> 0.195100).  Saving model ...
2023-12-01 09:56:54,930:INFO::Epoch 00061 | lr 0.00050 |Train_Loss 0.3410 | Val_Loss 0.1951 | Time(s) 0.3506
2023-12-01 09:56:54,931:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:55,294:INFO::Epoch 00062 | lr 0.00050 |Train_Loss 0.3547 | Val_Loss 0.1996 | Time(s) 0.3630
2023-12-01 09:56:55,295:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:56:55,646:INFO::Epoch 00063 | lr 0.00050 |Train_Loss 0.3390 | Val_Loss 0.2032 | Time(s) 0.3507
2023-12-01 09:56:55,646:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:56:55,996:INFO::Epoch 00064 | lr 0.00050 |Train_Loss 0.3544 | Val_Loss 0.2022 | Time(s) 0.3487
2023-12-01 09:56:55,996:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:56:56,366:INFO::Epoch 00065 | lr 0.00050 |Train_Loss 0.2969 | Val_Loss 0.1984 | Time(s) 0.3688
2023-12-01 09:56:56,367:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:56:56,721:INFO::Epoch 00066 | lr 0.00050 |Train_Loss 0.3312 | Val_Loss 0.1943 | Time(s) 0.3543
2023-12-01 09:56:56,731:INFO::Validation loss decreased (0.195100 --> 0.194317).  Saving model ...
2023-12-01 09:56:57,082:INFO::Epoch 00067 | lr 0.00050 |Train_Loss 0.3158 | Val_Loss 0.1928 | Time(s) 0.3509
2023-12-01 09:56:57,095:INFO::Validation loss decreased (0.194317 --> 0.192762).  Saving model ...
2023-12-01 09:56:57,464:INFO::Epoch 00068 | lr 0.00050 |Train_Loss 0.2983 | Val_Loss 0.1913 | Time(s) 0.3690
2023-12-01 09:56:57,475:INFO::Validation loss decreased (0.192762 --> 0.191309).  Saving model ...
2023-12-01 09:56:57,825:INFO::Epoch 00069 | lr 0.00050 |Train_Loss 0.3482 | Val_Loss 0.1914 | Time(s) 0.3488
2023-12-01 09:56:57,826:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:56:58,200:INFO::Epoch 00070 | lr 0.00050 |Train_Loss 0.3028 | Val_Loss 0.1933 | Time(s) 0.3738
2023-12-01 09:56:58,201:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:56:58,552:INFO::Epoch 00071 | lr 0.00050 |Train_Loss 0.3266 | Val_Loss 0.1955 | Time(s) 0.3501
2023-12-01 09:56:58,553:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:56:58,905:INFO::Epoch 00072 | lr 0.00050 |Train_Loss 0.3194 | Val_Loss 0.1938 | Time(s) 0.3515
2023-12-01 09:56:58,905:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:56:59,271:INFO::Epoch 00073 | lr 0.00050 |Train_Loss 0.3203 | Val_Loss 0.1936 | Time(s) 0.3650
2023-12-01 09:56:59,271:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:56:59,625:INFO::Epoch 00074 | lr 0.00050 |Train_Loss 0.2892 | Val_Loss 0.1945 | Time(s) 0.3536
2023-12-01 09:56:59,626:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 09:56:59,991:INFO::Epoch 00075 | lr 0.00050 |Train_Loss 0.2909 | Val_Loss 0.1953 | Time(s) 0.3647
2023-12-01 09:56:59,992:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 09:57:00,363:INFO::Epoch 00076 | lr 0.00050 |Train_Loss 0.2696 | Val_Loss 0.1964 | Time(s) 0.3715
2023-12-01 09:57:00,364:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 09:57:00,364:INFO::Eearly stopping!
2023-12-01 09:57:00,364:INFO::
testing...
2023-12-01 09:57:00,547:INFO::submit dir: submit/submit_gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:00,874:INFO::{'micro-f1': 0.9334507042253521, 'macro-f1': 0.9294343615921331}
2023-12-01 09:57:01,049:INFO::############### Retrain Stage Ends! #################
2023-12-01 09:57:01,050:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gat', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-09-54-04', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=666, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=1, last_hidden_dim=512, logger=<Logger log_output (INFO)>)
2023-12-01 09:57:17,914:INFO::node_type_num: 4
2023-12-01 09:57:17,931:INFO::=============== Prepare basic data stage finish, use 16.881717443466187 time.
2023-12-01 09:57:18,064:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:19,515:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:19,516:INFO::its now!!!!!!!!5
2023-12-01 09:57:19,872:INFO::its now!!!!!!!!0
2023-12-01 09:57:19,873:INFO::its now!!!!!!!!3
2023-12-01 09:57:19,994:INFO::its now!!!!!!!!5
2023-12-01 09:57:20,522:INFO::its now!!!!!!!!
2023-12-01 09:57:20,522:INFO::its now!!!!!!!! on 
2023-12-01 09:57:20,658:INFO::its now!!!!!!!!5
2023-12-01 09:57:20,922:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:20,941:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.3755 | Train_Classification_Loss 1.4069 | Dmon_Loss -0.0629 | Val_Loss 1.3566 | Search Time(s) 1.1508 | Infer Time(s) 0.2679 | Time(s) 1.4187 
2023-12-01 09:57:21,006:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 3;	4: 3;	5: 1;	6: 3;	7: 1;	8: 1;	9: 0;	10: 3;	11: 3;	12: 2;	13: 3;	14: 3;	15: 1;	16: 3;	17: 3;	18: 1;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 3;	37: 2;	38: 3;	39: 1;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 0;	26100: 1;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 1;	
2023-12-01 09:57:21,009:INFO::Epoch: 1
tensor([[0.4950, 0.4950, 0.4950, 0.4950],
        [0.4950, 0.4950, 0.4950, 0.4950],
        [0.4950, 0.4950, 0.4950, 0.4950],
        [0.4950, 0.4950, 0.4950, 0.4950]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:21,010:INFO::its now!!!!!!!!5
2023-12-01 09:57:21,221:INFO::its now!!!!!!!!0
2023-12-01 09:57:21,222:INFO::its now!!!!!!!!3
2023-12-01 09:57:21,340:INFO::its now!!!!!!!!5
2023-12-01 09:57:21,623:INFO::its now!!!!!!!!
2023-12-01 09:57:21,623:INFO::its now!!!!!!!! on 
2023-12-01 09:57:21,763:INFO::its now!!!!!!!!5
2023-12-01 09:57:21,979:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.4354 | Train_Classification_Loss 1.4669 | Dmon_Loss -0.0631 | Val_Loss 1.3649 | Search Time(s) 0.7352 | Infer Time(s) 0.2364 | Time(s) 0.9716 
2023-12-01 09:57:22,051:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 2;	8: 3;	9: 2;	10: 0;	11: 3;	12: 0;	13: 3;	14: 3;	15: 1;	16: 3;	17: 1;	18: 3;	19: 2;	20: 3;	21: 3;	22: 3;	23: 0;	24: 3;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 0;	32: 2;	33: 1;	34: 3;	35: 1;	36: 1;	37: 3;	38: 3;	39: 3;	40: 0;	41: 3;	42: 3;	43: 0;	44
26098: 2;	26099: 3;	26100: 0;	26101: 1;	26102: 3;	26103: 0;	26104: 0;	26105: 3;	26106: 1;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 2;	
2023-12-01 09:57:22,053:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:57:22,057:INFO::Epoch: 2
tensor([[0.4926, 0.4904, 0.4904, 0.4904],
        [0.4932, 0.4904, 0.4904, 0.4904],
        [0.4923, 0.4904, 0.4904, 0.4904],
        [0.4897, 0.4904, 0.4904, 0.4904]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:22,058:INFO::its now!!!!!!!!5
2023-12-01 09:57:22,281:INFO::its now!!!!!!!!0
2023-12-01 09:57:22,283:INFO::its now!!!!!!!!3
2023-12-01 09:57:22,416:INFO::its now!!!!!!!!5
2023-12-01 09:57:22,631:INFO::its now!!!!!!!!
2023-12-01 09:57:22,631:INFO::its now!!!!!!!! on 
2023-12-01 09:57:22,753:INFO::its now!!!!!!!!5
2023-12-01 09:57:22,985:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:22,987:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3234 | Train_Classification_Loss 1.3549 | Dmon_Loss -0.0629 | Val_Loss 1.3218 | Search Time(s) 0.6933 | Infer Time(s) 0.2383 | Time(s) 0.9316 
2023-12-01 09:57:23,034:INFO::cluster info:
0: 3;	1: 1;	2: 1;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 0;	9: 3;	10: 2;	11: 1;	12: 3;	13: 2;	14: 3;	15: 3;	16: 2;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 2;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 3;	35: 1;	36: 1;	37: 2;	38: 1;	39: 2;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 3;	26103: 0;	26104: 3;	26105: 2;	26106: 1;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 09:57:23,036:INFO::Validation loss decreased (inf --> 1.321820).  Saving model ...
2023-12-01 09:57:23,039:INFO::Epoch: 3
tensor([[0.4916, 0.4901, 0.4901, 0.4901],
        [0.4931, 0.4901, 0.4901, 0.4901],
        [0.4909, 0.4901, 0.4901, 0.4901],
        [0.4938, 0.4868, 0.4901, 0.4901]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:23,039:INFO::its now!!!!!!!!5
2023-12-01 09:57:23,255:INFO::its now!!!!!!!!0
2023-12-01 09:57:23,256:INFO::its now!!!!!!!!3
2023-12-01 09:57:23,370:INFO::its now!!!!!!!!5
2023-12-01 09:57:23,616:INFO::its now!!!!!!!!
2023-12-01 09:57:23,616:INFO::its now!!!!!!!! on 
2023-12-01 09:57:23,737:INFO::its now!!!!!!!!5
2023-12-01 09:57:23,960:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:23,961:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3004 | Train_Classification_Loss 1.3318 | Dmon_Loss -0.0629 | Val_Loss 1.3024 | Search Time(s) 0.6953 | Infer Time(s) 0.2284 | Time(s) 0.9237 
2023-12-01 09:57:24,002:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 0;	6: 3;	7: 1;	8: 2;	9: 2;	10: 1;	11: 2;	12: 1;	13: 3;	14: 3;	15: 3;	16: 1;	17: 0;	18: 3;	19: 1;	20: 3;	21: 3;	22: 3;	23: 3;	24: 0;	25: 0;	26: 1;	27: 2;	28: 3;	29: 3;	30: 3;	31: 0;	32: 3;	33: 1;	34: 2;	35: 1;	36: 3;	37: 3;	38: 0;	39: 3;	40: 3;	41: 3;	42: 3;	43: 2;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 1;	26103: 3;	26104: 0;	26105: 1;	26106: 3;	26107: 2;	26108: 1;	26109: 3;	26110: 3;	26111: 3;	26112: 1;	26113: 3;	26114: 3;	26115: 3;	26116: 2;	26117: 0;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 1;	
2023-12-01 09:57:24,003:INFO::Validation loss decreased (1.321820 --> 1.302428).  Saving model ...
2023-12-01 09:57:24,006:INFO::Epoch: 4
tensor([[0.4907, 0.4854, 0.4854, 0.4854],
        [0.4926, 0.4854, 0.4854, 0.4854],
        [0.4900, 0.4854, 0.4854, 0.4854],
        [0.4955, 0.4812, 0.4854, 0.4854]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:24,006:INFO::its now!!!!!!!!5
2023-12-01 09:57:24,227:INFO::its now!!!!!!!!0
2023-12-01 09:57:24,228:INFO::its now!!!!!!!!3
2023-12-01 09:57:24,341:INFO::its now!!!!!!!!5
2023-12-01 09:57:24,573:INFO::its now!!!!!!!!
2023-12-01 09:57:24,573:INFO::its now!!!!!!!! on 
2023-12-01 09:57:24,694:INFO::its now!!!!!!!!5
2023-12-01 09:57:24,884:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:24,886:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3001 | Train_Classification_Loss 1.3315 | Dmon_Loss -0.0629 | Val_Loss 1.2805 | Search Time(s) 0.6833 | Infer Time(s) 0.1975 | Time(s) 0.8808 
2023-12-01 09:57:24,938:INFO::cluster info:
0: 3;	1: 0;	2: 2;	3: 3;	4: 0;	5: 1;	6: 0;	7: 1;	8: 1;	9: 1;	10: 3;	11: 1;	12: 2;	13: 3;	14: 3;	15: 3;	16: 1;	17: 2;	18: 3;	19: 3;	20: 2;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 0;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 3;	35: 2;	36: 3;	37: 0;	38: 3;	39: 2;	40: 2;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 2;	
2023-12-01 09:57:24,939:INFO::Validation loss decreased (1.302428 --> 1.280452).  Saving model ...
2023-12-01 09:57:24,942:INFO::Epoch: 5
tensor([[0.4913, 0.4829, 0.4829, 0.4829],
        [0.4939, 0.4829, 0.4829, 0.4829],
        [0.4891, 0.4829, 0.4829, 0.4829],
        [0.4977, 0.4782, 0.4829, 0.4829]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:24,943:INFO::its now!!!!!!!!5
2023-12-01 09:57:25,129:INFO::its now!!!!!!!!0
2023-12-01 09:57:25,130:INFO::its now!!!!!!!!3
2023-12-01 09:57:25,244:INFO::its now!!!!!!!!5
2023-12-01 09:57:25,461:INFO::its now!!!!!!!!
2023-12-01 09:57:25,461:INFO::its now!!!!!!!! on 
2023-12-01 09:57:25,582:INFO::its now!!!!!!!!5
2023-12-01 09:57:25,800:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:25,801:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.2653 | Train_Classification_Loss 1.2967 | Dmon_Loss -0.0629 | Val_Loss 1.2551 | Search Time(s) 0.6360 | Infer Time(s) 0.2250 | Time(s) 0.8610 
2023-12-01 09:57:25,848:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 2;	12: 3;	13: 2;	14: 3;	15: 0;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 1;	25: 0;	26: 1;	27: 2;	28: 1;	29: 3;	30: 3;	31: 3;	32: 1;	33: 0;	34: 3;	35: 0;	36: 3;	37: 3;	38: 1;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 1;	26099: 0;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 0;	26105: 0;	26106: 1;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 1;	26113: 3;	26114: 3;	26115: 3;	26116: 1;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 09:57:25,849:INFO::Validation loss decreased (1.280452 --> 1.255119).  Saving model ...
2023-12-01 09:57:25,853:INFO::Epoch: 6
tensor([[0.4897, 0.4819, 0.4819, 0.4819],
        [0.4947, 0.4819, 0.4819, 0.4819],
        [0.4890, 0.4819, 0.4819, 0.4819],
        [0.5003, 0.4769, 0.4819, 0.4819]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:25,853:INFO::its now!!!!!!!!5
2023-12-01 09:57:26,070:INFO::its now!!!!!!!!0
2023-12-01 09:57:26,071:INFO::its now!!!!!!!!3
2023-12-01 09:57:26,185:INFO::its now!!!!!!!!5
2023-12-01 09:57:26,434:INFO::its now!!!!!!!!
2023-12-01 09:57:26,434:INFO::its now!!!!!!!! on 
2023-12-01 09:57:26,556:INFO::its now!!!!!!!!5
2023-12-01 09:57:26,773:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:26,776:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.2367 | Train_Classification_Loss 1.2681 | Dmon_Loss -0.0629 | Val_Loss 1.2260 | Search Time(s) 0.6988 | Infer Time(s) 0.2246 | Time(s) 0.9234 
2023-12-01 09:57:26,823:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 1;	8: 3;	9: 2;	10: 0;	11: 3;	12: 2;	13: 3;	14: 3;	15: 2;	16: 0;	17: 3;	18: 3;	19: 1;	20: 2;	21: 2;	22: 0;	23: 3;	24: 2;	25: 3;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 0;	32: 3;	33: 3;	34: 3;	35: 0;	36: 3;	37: 2;	38: 0;	39: 0;	40: 3;	41: 3;	42: 3;	43: 0;	44
26098: 3;	26099: 0;	26100: 0;	26101: 3;	26102: 1;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 09:57:26,824:INFO::Validation loss decreased (1.255119 --> 1.225968).  Saving model ...
2023-12-01 09:57:26,827:INFO::Epoch: 7
tensor([[0.4875, 0.4799, 0.4799, 0.4799],
        [0.4967, 0.4799, 0.4799, 0.4799],
        [0.4887, 0.4799, 0.4799, 0.4799],
        [0.5033, 0.4747, 0.4799, 0.4799]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:26,827:INFO::its now!!!!!!!!5
2023-12-01 09:57:27,050:INFO::its now!!!!!!!!0
2023-12-01 09:57:27,051:INFO::its now!!!!!!!!3
2023-12-01 09:57:27,162:INFO::its now!!!!!!!!5
2023-12-01 09:57:27,370:INFO::its now!!!!!!!!
2023-12-01 09:57:27,370:INFO::its now!!!!!!!! on 
2023-12-01 09:57:27,491:INFO::its now!!!!!!!!5
2023-12-01 09:57:27,675:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:27,677:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.2027 | Train_Classification_Loss 1.2342 | Dmon_Loss -0.0629 | Val_Loss 1.1926 | Search Time(s) 0.6602 | Infer Time(s) 0.1907 | Time(s) 0.8510 
2023-12-01 09:57:27,715:INFO::cluster info:
0: 3;	1: 3;	2: 2;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 2;	9: 3;	10: 3;	11: 3;	12: 2;	13: 3;	14: 3;	15: 3;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 1;	22: 0;	23: 0;	24: 2;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 1;	26099: 3;	26100: 3;	26101: 2;	26102: 1;	26103: 2;	26104: 0;	26105: 3;	26106: 2;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 09:57:27,717:INFO::Validation loss decreased (1.225968 --> 1.192645).  Saving model ...
2023-12-01 09:57:27,720:INFO::Epoch: 8
tensor([[0.4902, 0.4784, 0.4784, 0.4784],
        [0.4982, 0.4784, 0.4784, 0.4784],
        [0.4890, 0.4784, 0.4784, 0.4784],
        [0.5070, 0.4731, 0.4784, 0.4784]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:27,721:INFO::its now!!!!!!!!5
2023-12-01 09:57:27,936:INFO::its now!!!!!!!!0
2023-12-01 09:57:27,937:INFO::its now!!!!!!!!3
2023-12-01 09:57:28,049:INFO::its now!!!!!!!!5
2023-12-01 09:57:28,254:INFO::its now!!!!!!!!
2023-12-01 09:57:28,255:INFO::its now!!!!!!!! on 
2023-12-01 09:57:28,376:INFO::its now!!!!!!!!5
2023-12-01 09:57:28,612:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:28,614:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.1912 | Train_Classification_Loss 1.2226 | Dmon_Loss -0.0629 | Val_Loss 1.1547 | Search Time(s) 0.6523 | Infer Time(s) 0.2430 | Time(s) 0.8952 
2023-12-01 09:57:28,663:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 3;	5: 1;	6: 3;	7: 3;	8: 1;	9: 2;	10: 3;	11: 3;	12: 2;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 1;	21: 3;	22: 3;	23: 1;	24: 3;	25: 0;	26: 1;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 1;	34: 1;	35: 3;	36: 2;	37: 3;	38: 2;	39: 3;	40: 3;	41: 3;	42: 3;	43: 1;	44
26098: 0;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 2;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 2;	
2023-12-01 09:57:28,665:INFO::Validation loss decreased (1.192645 --> 1.154669).  Saving model ...
2023-12-01 09:57:28,668:INFO::Epoch: 9
tensor([[0.4923, 0.4750, 0.4750, 0.4750],
        [0.4994, 0.4750, 0.4750, 0.4750],
        [0.4889, 0.4750, 0.4750, 0.4750],
        [0.5115, 0.4697, 0.4750, 0.4750]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:28,669:INFO::its now!!!!!!!!5
2023-12-01 09:57:28,961:INFO::its now!!!!!!!!0
2023-12-01 09:57:28,962:INFO::its now!!!!!!!!3
2023-12-01 09:57:29,074:INFO::its now!!!!!!!!5
2023-12-01 09:57:29,293:INFO::its now!!!!!!!!
2023-12-01 09:57:29,293:INFO::its now!!!!!!!! on 
2023-12-01 09:57:29,414:INFO::its now!!!!!!!!5
2023-12-01 09:57:29,640:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:29,642:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.1707 | Train_Classification_Loss 1.2022 | Dmon_Loss -0.0629 | Val_Loss 1.1119 | Search Time(s) 0.7430 | Infer Time(s) 0.2319 | Time(s) 0.9749 
2023-12-01 09:57:29,691:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 0;	9: 3;	10: 3;	11: 2;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 3;	22: 0;	23: 3;	24: 2;	25: 0;	26: 0;	27: 3;	28: 3;	29: 2;	30: 3;	31: 0;	32: 3;	33: 1;	34: 3;	35: 1;	36: 3;	37: 0;	38: 3;	39: 2;	40: 2;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 0;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 1;	
2023-12-01 09:57:29,693:INFO::Validation loss decreased (1.154669 --> 1.111932).  Saving model ...
2023-12-01 09:57:29,696:INFO::Epoch: 10
tensor([[0.4934, 0.4734, 0.4734, 0.4734],
        [0.5009, 0.4734, 0.4734, 0.4734],
        [0.4904, 0.4734, 0.4734, 0.4734],
        [0.5171, 0.4681, 0.4734, 0.4734]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:29,697:INFO::its now!!!!!!!!5
2023-12-01 09:57:29,912:INFO::its now!!!!!!!!0
2023-12-01 09:57:29,913:INFO::its now!!!!!!!!3
2023-12-01 09:57:30,026:INFO::its now!!!!!!!!5
2023-12-01 09:57:30,238:INFO::its now!!!!!!!!
2023-12-01 09:57:30,238:INFO::its now!!!!!!!! on 
2023-12-01 09:57:30,359:INFO::its now!!!!!!!!5
2023-12-01 09:57:30,551:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:30,552:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.1018 | Train_Classification_Loss 1.1333 | Dmon_Loss -0.0629 | Val_Loss 1.0630 | Search Time(s) 0.6592 | Infer Time(s) 0.1985 | Time(s) 0.8577 
2023-12-01 09:57:30,595:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 1;	11: 3;	12: 1;	13: 0;	14: 3;	15: 3;	16: 3;	17: 2;	18: 1;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 0;	25: 2;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 0;	32: 3;	33: 0;	34: 3;	35: 3;	36: 0;	37: 2;	38: 0;	39: 0;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 2;	26102: 0;	26103: 2;	26104: 2;	26105: 3;	26106: 0;	26107: 3;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 3;	26114: 3;	26115: 3;	26116: 0;	26117: 3;	26118: 3;	26119: 0;	26120: 3;	26121: 3;	26122: 0;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 09:57:30,597:INFO::Validation loss decreased (1.111932 --> 1.062971).  Saving model ...
2023-12-01 09:57:30,600:INFO::Epoch: 11
tensor([[0.4976, 0.4750, 0.4750, 0.4750],
        [0.5033, 0.4750, 0.4750, 0.4750],
        [0.4918, 0.4750, 0.4750, 0.4750],
        [0.5233, 0.4697, 0.4750, 0.4750]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:30,601:INFO::its now!!!!!!!!5
2023-12-01 09:57:30,826:INFO::its now!!!!!!!!0
2023-12-01 09:57:30,827:INFO::its now!!!!!!!!3
2023-12-01 09:57:30,939:INFO::its now!!!!!!!!5
2023-12-01 09:57:31,165:INFO::its now!!!!!!!!
2023-12-01 09:57:31,166:INFO::its now!!!!!!!! on 
2023-12-01 09:57:31,286:INFO::its now!!!!!!!!5
2023-12-01 09:57:31,507:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:31,509:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.0643 | Train_Classification_Loss 1.0958 | Dmon_Loss -0.0630 | Val_Loss 1.0081 | Search Time(s) 0.6827 | Infer Time(s) 0.2264 | Time(s) 0.9091 
2023-12-01 09:57:31,555:INFO::cluster info:
0: 1;	1: 3;	2: 1;	3: 3;	4: 2;	5: 0;	6: 3;	7: 3;	8: 0;	9: 3;	10: 0;	11: 3;	12: 3;	13: 0;	14: 3;	15: 3;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 1;	22: 1;	23: 0;	24: 0;	25: 3;	26: 2;	27: 2;	28: 2;	29: 0;	30: 3;	31: 0;	32: 0;	33: 1;	34: 3;	35: 3;	36: 0;	37: 1;	38: 1;	39: 0;	40: 3;	41: 3;	42: 3;	43: 0;	44
26098: 2;	26099: 3;	26100: 1;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 3;	26121: 3;	26122: 0;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 09:57:31,557:INFO::Validation loss decreased (1.062971 --> 1.008057).  Saving model ...
2023-12-01 09:57:31,560:INFO::Epoch: 12
tensor([[0.5054, 0.4773, 0.4773, 0.4773],
        [0.5046, 0.4773, 0.4773, 0.4773],
        [0.4922, 0.4773, 0.4773, 0.4773],
        [0.5300, 0.4720, 0.4773, 0.4773]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:31,561:INFO::its now!!!!!!!!5
2023-12-01 09:57:31,776:INFO::its now!!!!!!!!0
2023-12-01 09:57:31,777:INFO::its now!!!!!!!!3
2023-12-01 09:57:31,891:INFO::its now!!!!!!!!5
2023-12-01 09:57:32,102:INFO::its now!!!!!!!!
2023-12-01 09:57:32,102:INFO::its now!!!!!!!! on 
2023-12-01 09:57:32,223:INFO::its now!!!!!!!!5
2023-12-01 09:57:32,445:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:32,447:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.0259 | Train_Classification_Loss 1.0574 | Dmon_Loss -0.0630 | Val_Loss 0.9477 | Search Time(s) 0.6594 | Infer Time(s) 0.2284 | Time(s) 0.8878 
2023-12-01 09:57:32,506:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 1;	6: 0;	7: 3;	8: 3;	9: 2;	10: 3;	11: 1;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 2;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 1;	33: 0;	34: 3;	35: 3;	36: 0;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 3;	43: 0;	44
26098: 0;	26099: 3;	26100: 0;	26101: 2;	26102: 3;	26103: 0;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 09:57:32,507:INFO::Validation loss decreased (1.008057 --> 0.947733).  Saving model ...
2023-12-01 09:57:32,510:INFO::Epoch: 13
tensor([[0.5126, 0.4786, 0.4786, 0.4786],
        [0.5067, 0.4786, 0.4786, 0.4786],
        [0.4933, 0.4786, 0.4786, 0.4786],
        [0.5371, 0.4733, 0.4786, 0.4786]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:32,511:INFO::its now!!!!!!!!5
2023-12-01 09:57:32,739:INFO::its now!!!!!!!!0
2023-12-01 09:57:32,740:INFO::its now!!!!!!!!3
2023-12-01 09:57:32,851:INFO::its now!!!!!!!!5
2023-12-01 09:57:33,085:INFO::its now!!!!!!!!
2023-12-01 09:57:33,085:INFO::its now!!!!!!!! on 
2023-12-01 09:57:33,205:INFO::its now!!!!!!!!5
2023-12-01 09:57:33,421:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:33,422:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 0.9891 | Train_Classification_Loss 1.0206 | Dmon_Loss -0.0630 | Val_Loss 0.8841 | Search Time(s) 0.6913 | Infer Time(s) 0.2224 | Time(s) 0.9137 
2023-12-01 09:57:33,472:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 2;	11: 3;	12: 3;	13: 0;	14: 3;	15: 2;	16: 2;	17: 2;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 1;	26: 3;	27: 1;	28: 2;	29: 1;	30: 3;	31: 2;	32: 1;	33: 0;	34: 2;	35: 2;	36: 3;	37: 0;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 2;	44
26098: 1;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 2;	26104: 1;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 2;	26120: 0;	26121: 3;	26122: 2;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 1;	
2023-12-01 09:57:33,473:INFO::Validation loss decreased (0.947733 --> 0.884088).  Saving model ...
2023-12-01 09:57:33,475:INFO::Epoch: 14
tensor([[0.5224, 0.4813, 0.4813, 0.4813],
        [0.5088, 0.4813, 0.4813, 0.4813],
        [0.4941, 0.4813, 0.4813, 0.4813],
        [0.5441, 0.4760, 0.4813, 0.4813]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:33,476:INFO::its now!!!!!!!!5
2023-12-01 09:57:33,663:INFO::its now!!!!!!!!0
2023-12-01 09:57:33,664:INFO::its now!!!!!!!!3
2023-12-01 09:57:33,775:INFO::its now!!!!!!!!5
2023-12-01 09:57:33,975:INFO::its now!!!!!!!!
2023-12-01 09:57:33,976:INFO::its now!!!!!!!! on 
2023-12-01 09:57:34,096:INFO::its now!!!!!!!!5
2023-12-01 09:57:34,355:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:34,357:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 0.9294 | Train_Classification_Loss 0.9610 | Dmon_Loss -0.0631 | Val_Loss 0.8170 | Search Time(s) 0.6165 | Infer Time(s) 0.2653 | Time(s) 0.8818 
2023-12-01 09:57:34,426:INFO::cluster info:
0: 3;	1: 1;	2: 3;	3: 3;	4: 3;	5: 3;	6: 2;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 0;	17: 0;	18: 3;	19: 0;	20: 0;	21: 3;	22: 3;	23: 0;	24: 0;	25: 3;	26: 0;	27: 3;	28: 2;	29: 3;	30: 0;	31: 0;	32: 3;	33: 2;	34: 3;	35: 1;	36: 2;	37: 0;	38: 3;	39: 2;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 1;	26099: 0;	26100: 1;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 2;	26106: 1;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 09:57:34,427:INFO::Validation loss decreased (0.884088 --> 0.817010).  Saving model ...
2023-12-01 09:57:34,430:INFO::Epoch: 15
tensor([[0.5300, 0.4823, 0.4823, 0.4823],
        [0.5120, 0.4823, 0.4823, 0.4823],
        [0.5013, 0.4823, 0.4823, 0.4823],
        [0.5515, 0.4771, 0.4823, 0.4823]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:34,431:INFO::its now!!!!!!!!5
2023-12-01 09:57:34,658:INFO::its now!!!!!!!!0
2023-12-01 09:57:34,658:INFO::its now!!!!!!!!3
2023-12-01 09:57:34,771:INFO::its now!!!!!!!!5
2023-12-01 09:57:34,999:INFO::its now!!!!!!!!
2023-12-01 09:57:34,999:INFO::its now!!!!!!!! on 
2023-12-01 09:57:35,121:INFO::its now!!!!!!!!5
2023-12-01 09:57:35,317:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:35,319:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 0.8862 | Train_Classification_Loss 0.9178 | Dmon_Loss -0.0633 | Val_Loss 0.7542 | Search Time(s) 0.6874 | Infer Time(s) 0.2015 | Time(s) 0.8888 
2023-12-01 09:57:35,358:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 3;	4: 0;	5: 2;	6: 3;	7: 0;	8: 3;	9: 0;	10: 1;	11: 1;	12: 1;	13: 2;	14: 0;	15: 3;	16: 3;	17: 3;	18: 0;	19: 3;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 3;	28: 2;	29: 0;	30: 3;	31: 1;	32: 3;	33: 2;	34: 2;	35: 3;	36: 0;	37: 3;	38: 2;	39: 0;	40: 3;	41: 3;	42: 3;	43: 0;	44
26098: 3;	26099: 3;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 3;	26106: 2;	26107: 0;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 09:57:35,359:INFO::Validation loss decreased (0.817010 --> 0.754214).  Saving model ...
2023-12-01 09:57:35,362:INFO::Epoch: 16
tensor([[0.5393, 0.4840, 0.4840, 0.4840],
        [0.5153, 0.4840, 0.4840, 0.4840],
        [0.5060, 0.4840, 0.4840, 0.4840],
        [0.5589, 0.4788, 0.4840, 0.4840]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:35,362:INFO::its now!!!!!!!!5
2023-12-01 09:57:35,576:INFO::its now!!!!!!!!0
2023-12-01 09:57:35,578:INFO::its now!!!!!!!!3
2023-12-01 09:57:35,690:INFO::its now!!!!!!!!5
2023-12-01 09:57:35,884:INFO::its now!!!!!!!!
2023-12-01 09:57:35,884:INFO::its now!!!!!!!! on 
2023-12-01 09:57:36,006:INFO::its now!!!!!!!!5
2023-12-01 09:57:36,203:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:36,205:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 0.8143 | Train_Classification_Loss 0.8460 | Dmon_Loss -0.0634 | Val_Loss 0.6936 | Search Time(s) 0.6395 | Infer Time(s) 0.2035 | Time(s) 0.8429 
2023-12-01 09:57:36,256:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 3;	4: 0;	5: 3;	6: 0;	7: 3;	8: 3;	9: 3;	10: 3;	11: 1;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 0;	18: 0;	19: 3;	20: 3;	21: 1;	22: 1;	23: 3;	24: 2;	25: 3;	26: 3;	27: 1;	28: 2;	29: 0;	30: 3;	31: 3;	32: 0;	33: 0;	34: 2;	35: 0;	36: 0;	37: 2;	38: 0;	39: 2;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 0;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 3;	26124: 3;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:36,257:INFO::Validation loss decreased (0.754214 --> 0.693583).  Saving model ...
2023-12-01 09:57:36,261:INFO::Epoch: 17
tensor([[0.5504, 0.4865, 0.4865, 0.4865],
        [0.5187, 0.4865, 0.4865, 0.4865],
        [0.5118, 0.4865, 0.4865, 0.4865],
        [0.5648, 0.4812, 0.4865, 0.4865]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:36,262:INFO::its now!!!!!!!!5
2023-12-01 09:57:36,468:INFO::its now!!!!!!!!0
2023-12-01 09:57:36,469:INFO::its now!!!!!!!!3
2023-12-01 09:57:36,581:INFO::its now!!!!!!!!5
2023-12-01 09:57:36,797:INFO::its now!!!!!!!!
2023-12-01 09:57:36,798:INFO::its now!!!!!!!! on 
2023-12-01 09:57:36,919:INFO::its now!!!!!!!!5
2023-12-01 09:57:37,143:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:37,145:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 0.7859 | Train_Classification_Loss 0.8177 | Dmon_Loss -0.0636 | Val_Loss 0.6352 | Search Time(s) 0.6544 | Infer Time(s) 0.2304 | Time(s) 0.8848 
2023-12-01 09:57:37,191:INFO::cluster info:
0: 1;	1: 0;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 0;	11: 3;	12: 1;	13: 2;	14: 3;	15: 3;	16: 1;	17: 2;	18: 1;	19: 0;	20: 1;	21: 3;	22: 0;	23: 0;	24: 0;	25: 3;	26: 3;	27: 2;	28: 2;	29: 3;	30: 0;	31: 1;	32: 3;	33: 3;	34: 2;	35: 3;	36: 0;	37: 3;	38: 3;	39: 3;	40: 0;	41: 3;	42: 3;	43: 0;	44
26098: 0;	26099: 0;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 0;	26105: 0;	26106: 0;	26107: 3;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 3;	26122: 0;	26123: 3;	26124: 2;	26125: 3;	26126: 3;	26127: 1;	
2023-12-01 09:57:37,192:INFO::Validation loss decreased (0.693583 --> 0.635225).  Saving model ...
2023-12-01 09:57:37,196:INFO::Epoch: 18
tensor([[0.5597, 0.4902, 0.4902, 0.4902],
        [0.5233, 0.4902, 0.4902, 0.4902],
        [0.5216, 0.4902, 0.4902, 0.4902],
        [0.5702, 0.4850, 0.4902, 0.4902]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:37,198:INFO::its now!!!!!!!!5
2023-12-01 09:57:37,412:INFO::its now!!!!!!!!0
2023-12-01 09:57:37,413:INFO::its now!!!!!!!!3
2023-12-01 09:57:37,525:INFO::its now!!!!!!!!5
2023-12-01 09:57:37,734:INFO::its now!!!!!!!!
2023-12-01 09:57:37,734:INFO::its now!!!!!!!! on 
2023-12-01 09:57:37,856:INFO::its now!!!!!!!!5
2023-12-01 09:57:38,049:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:38,050:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 0.7415 | Train_Classification_Loss 0.7734 | Dmon_Loss -0.0637 | Val_Loss 0.5807 | Search Time(s) 0.6554 | Infer Time(s) 0.1995 | Time(s) 0.8549 
2023-12-01 09:57:38,096:INFO::cluster info:
0: 3;	1: 0;	2: 3;	3: 3;	4: 2;	5: 0;	6: 3;	7: 1;	8: 2;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 0;	15: 3;	16: 3;	17: 2;	18: 0;	19: 3;	20: 3;	21: 1;	22: 3;	23: 0;	24: 2;	25: 0;	26: 0;	27: 3;	28: 0;	29: 0;	30: 2;	31: 1;	32: 2;	33: 3;	34: 3;	35: 3;	36: 0;	37: 1;	38: 2;	39: 2;	40: 3;	41: 3;	42: 3;	43: 0;	44
26098: 3;	26099: 0;	26100: 1;	26101: 1;	26102: 3;	26103: 2;	26104: 3;	26105: 0;	26106: 2;	26107: 2;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 3;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 2;	26121: 3;	26122: 0;	26123: 3;	26124: 2;	26125: 3;	26126: 3;	26127: 2;	
2023-12-01 09:57:38,097:INFO::Validation loss decreased (0.635225 --> 0.580712).  Saving model ...
2023-12-01 09:57:38,099:INFO::Epoch: 19
tensor([[0.5692, 0.4912, 0.4912, 0.4912],
        [0.5256, 0.4912, 0.4912, 0.4912],
        [0.5279, 0.4912, 0.4912, 0.4912],
        [0.5748, 0.4860, 0.4912, 0.4912]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:38,100:INFO::its now!!!!!!!!5
2023-12-01 09:57:38,316:INFO::its now!!!!!!!!0
2023-12-01 09:57:38,317:INFO::its now!!!!!!!!3
2023-12-01 09:57:38,429:INFO::its now!!!!!!!!5
2023-12-01 09:57:38,654:INFO::its now!!!!!!!!
2023-12-01 09:57:38,654:INFO::its now!!!!!!!! on 
2023-12-01 09:57:38,777:INFO::its now!!!!!!!!5
2023-12-01 09:57:38,981:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:38,983:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 0.7256 | Train_Classification_Loss 0.7575 | Dmon_Loss -0.0639 | Val_Loss 0.5280 | Search Time(s) 0.6733 | Infer Time(s) 0.2104 | Time(s) 0.8838 
2023-12-01 09:57:39,023:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 3;	8: 0;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 2;	17: 2;	18: 0;	19: 3;	20: 1;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 3;	28: 0;	29: 3;	30: 3;	31: 0;	32: 3;	33: 1;	34: 2;	35: 1;	36: 3;	37: 0;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 0;	44
26098: 0;	26099: 3;	26100: 2;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 2;	26106: 0;	26107: 3;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 2;	
2023-12-01 09:57:39,024:INFO::Validation loss decreased (0.580712 --> 0.528010).  Saving model ...
2023-12-01 09:57:39,027:INFO::Epoch: 20
tensor([[0.5801, 0.4855, 0.4855, 0.4855],
        [0.5286, 0.4855, 0.4855, 0.4855],
        [0.5306, 0.4855, 0.4855, 0.4855],
        [0.5792, 0.4803, 0.4855, 0.4855]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:39,028:INFO::its now!!!!!!!!5
2023-12-01 09:57:39,231:INFO::its now!!!!!!!!0
2023-12-01 09:57:39,232:INFO::its now!!!!!!!!3
2023-12-01 09:57:39,345:INFO::its now!!!!!!!!5
2023-12-01 09:57:39,558:INFO::its now!!!!!!!!
2023-12-01 09:57:39,558:INFO::its now!!!!!!!! on 
2023-12-01 09:57:39,680:INFO::its now!!!!!!!!5
2023-12-01 09:57:39,937:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:39,939:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 0.6550 | Train_Classification_Loss 0.6872 | Dmon_Loss -0.0644 | Val_Loss 0.4748 | Search Time(s) 0.6504 | Infer Time(s) 0.2623 | Time(s) 0.9127 
2023-12-01 09:57:39,995:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 1;	6: 2;	7: 0;	8: 3;	9: 3;	10: 3;	11: 3;	12: 2;	13: 2;	14: 3;	15: 3;	16: 1;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 1;	27: 2;	28: 2;	29: 3;	30: 0;	31: 0;	32: 3;	33: 0;	34: 3;	35: 1;	36: 3;	37: 2;	38: 3;	39: 0;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 2;	26099: 3;	26100: 0;	26101: 3;	26102: 2;	26103: 2;	26104: 3;	26105: 0;	26106: 2;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:39,996:INFO::Validation loss decreased (0.528010 --> 0.474765).  Saving model ...
2023-12-01 09:57:39,999:INFO::Epoch: 21
tensor([[0.5890, 0.4831, 0.4831, 0.4831],
        [0.5310, 0.4831, 0.4831, 0.4831],
        [0.5392, 0.4831, 0.4831, 0.4831],
        [0.5828, 0.4779, 0.4831, 0.4831]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:39,999:INFO::its now!!!!!!!!5
2023-12-01 09:57:40,222:INFO::its now!!!!!!!!0
2023-12-01 09:57:40,223:INFO::its now!!!!!!!!3
2023-12-01 09:57:40,336:INFO::its now!!!!!!!!5
2023-12-01 09:57:40,556:INFO::its now!!!!!!!!
2023-12-01 09:57:40,556:INFO::its now!!!!!!!! on 
2023-12-01 09:57:40,677:INFO::its now!!!!!!!!5
2023-12-01 09:57:40,895:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:40,896:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 0.6613 | Train_Classification_Loss 0.6937 | Dmon_Loss -0.0649 | Val_Loss 0.4262 | Search Time(s) 0.6745 | Infer Time(s) 0.2244 | Time(s) 0.8989 
2023-12-01 09:57:40,939:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 1;	8: 3;	9: 2;	10: 0;	11: 3;	12: 3;	13: 0;	14: 3;	15: 2;	16: 3;	17: 2;	18: 1;	19: 3;	20: 3;	21: 1;	22: 3;	23: 0;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 0;	30: 2;	31: 3;	32: 0;	33: 3;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 0;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:40,940:INFO::Validation loss decreased (0.474765 --> 0.426224).  Saving model ...
2023-12-01 09:57:40,943:INFO::Epoch: 22
tensor([[0.5947, 0.4769, 0.4769, 0.4769],
        [0.5329, 0.4769, 0.4769, 0.4769],
        [0.5494, 0.4769, 0.4769, 0.4769],
        [0.5878, 0.4716, 0.4769, 0.4769]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:40,944:INFO::its now!!!!!!!!5
2023-12-01 09:57:41,141:INFO::its now!!!!!!!!0
2023-12-01 09:57:41,142:INFO::its now!!!!!!!!3
2023-12-01 09:57:41,253:INFO::its now!!!!!!!!5
2023-12-01 09:57:41,469:INFO::its now!!!!!!!!
2023-12-01 09:57:41,469:INFO::its now!!!!!!!! on 
2023-12-01 09:57:41,590:INFO::its now!!!!!!!!5
2023-12-01 09:57:41,783:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:41,785:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 0.6175 | Train_Classification_Loss 0.6502 | Dmon_Loss -0.0653 | Val_Loss 0.3812 | Search Time(s) 0.6440 | Infer Time(s) 0.1991 | Time(s) 0.8431 
2023-12-01 09:57:41,836:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 2;	5: 0;	6: 3;	7: 3;	8: 3;	9: 2;	10: 1;	11: 3;	12: 3;	13: 2;	14: 0;	15: 3;	16: 3;	17: 2;	18: 1;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 3;	33: 3;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 1;	26099: 3;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 3;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:41,837:INFO::Validation loss decreased (0.426224 --> 0.381196).  Saving model ...
2023-12-01 09:57:41,840:INFO::Epoch: 23
tensor([[0.5991, 0.4753, 0.4753, 0.4753],
        [0.5351, 0.4753, 0.4753, 0.4753],
        [0.5600, 0.4753, 0.4753, 0.4753],
        [0.5927, 0.4700, 0.4753, 0.4753]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:41,840:INFO::its now!!!!!!!!5
2023-12-01 09:57:42,038:INFO::its now!!!!!!!!0
2023-12-01 09:57:42,039:INFO::its now!!!!!!!!3
2023-12-01 09:57:42,151:INFO::its now!!!!!!!!5
2023-12-01 09:57:42,370:INFO::its now!!!!!!!!
2023-12-01 09:57:42,370:INFO::its now!!!!!!!! on 
2023-12-01 09:57:42,491:INFO::its now!!!!!!!!5
2023-12-01 09:57:42,701:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:42,702:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 0.6021 | Train_Classification_Loss 0.6351 | Dmon_Loss -0.0660 | Val_Loss 0.3452 | Search Time(s) 0.6483 | Infer Time(s) 0.2156 | Time(s) 0.8639 
2023-12-01 09:57:42,750:INFO::cluster info:
0: 1;	1: 0;	2: 3;	3: 0;	4: 2;	5: 3;	6: 3;	7: 1;	8: 1;	9: 3;	10: 3;	11: 3;	12: 1;	13: 0;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 1;	22: 0;	23: 0;	24: 0;	25: 1;	26: 0;	27: 1;	28: 2;	29: 0;	30: 0;	31: 0;	32: 1;	33: 2;	34: 3;	35: 3;	36: 1;	37: 0;	38: 3;	39: 2;	40: 3;	41: 3;	42: 2;	43: 3;	44
26098: 3;	26099: 0;	26100: 2;	26101: 2;	26102: 2;	26103: 0;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 1;	
2023-12-01 09:57:42,752:INFO::Validation loss decreased (0.381196 --> 0.345207).  Saving model ...
2023-12-01 09:57:42,755:INFO::Epoch: 24
tensor([[0.6023, 0.4759, 0.4759, 0.4759],
        [0.5370, 0.4759, 0.4759, 0.4759],
        [0.5718, 0.4759, 0.4759, 0.4759],
        [0.5962, 0.4706, 0.4759, 0.4759]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:42,756:INFO::its now!!!!!!!!5
2023-12-01 09:57:42,956:INFO::its now!!!!!!!!0
2023-12-01 09:57:42,957:INFO::its now!!!!!!!!3
2023-12-01 09:57:43,070:INFO::its now!!!!!!!!5
2023-12-01 09:57:43,268:INFO::its now!!!!!!!!
2023-12-01 09:57:43,268:INFO::its now!!!!!!!! on 
2023-12-01 09:57:43,390:INFO::its now!!!!!!!!5
2023-12-01 09:57:43,599:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:43,601:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 0.5277 | Train_Classification_Loss 0.5616 | Dmon_Loss -0.0678 | Val_Loss 0.3159 | Search Time(s) 0.6323 | Infer Time(s) 0.2144 | Time(s) 0.8467 
2023-12-01 09:57:43,638:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 3;	6: 3;	7: 0;	8: 0;	9: 0;	10: 1;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 3;	17: 2;	18: 3;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 0;	32: 1;	33: 2;	34: 3;	35: 1;	36: 0;	37: 2;	38: 3;	39: 3;	40: 3;	41: 2;	42: 2;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 3;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:43,639:INFO::Validation loss decreased (0.345207 --> 0.315923).  Saving model ...
2023-12-01 09:57:43,643:INFO::Epoch: 25
tensor([[0.6000, 0.4787, 0.4787, 0.4787],
        [0.5389, 0.4787, 0.4787, 0.4787],
        [0.5836, 0.4787, 0.4787, 0.4787],
        [0.5983, 0.4734, 0.4787, 0.4787]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:43,644:INFO::its now!!!!!!!!5
2023-12-01 09:57:43,841:INFO::its now!!!!!!!!0
2023-12-01 09:57:43,842:INFO::its now!!!!!!!!3
2023-12-01 09:57:43,954:INFO::its now!!!!!!!!5
2023-12-01 09:57:44,156:INFO::its now!!!!!!!!
2023-12-01 09:57:44,156:INFO::its now!!!!!!!! on 
2023-12-01 09:57:44,277:INFO::its now!!!!!!!!5
2023-12-01 09:57:44,475:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:44,476:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 0.5454 | Train_Classification_Loss 0.5798 | Dmon_Loss -0.0688 | Val_Loss 0.2917 | Search Time(s) 0.6293 | Infer Time(s) 0.2055 | Time(s) 0.8348 
2023-12-01 09:57:44,516:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 1;	11: 3;	12: 3;	13: 0;	14: 0;	15: 3;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 3;	26: 0;	27: 1;	28: 2;	29: 0;	30: 0;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 1;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 1;	26101: 2;	26102: 2;	26103: 0;	26104: 3;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 3;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 1;	
2023-12-01 09:57:44,517:INFO::Validation loss decreased (0.315923 --> 0.291653).  Saving model ...
2023-12-01 09:57:44,520:INFO::Epoch: 26
tensor([[0.5966, 0.4806, 0.4806, 0.4806],
        [0.5408, 0.4806, 0.4806, 0.4806],
        [0.5953, 0.4806, 0.4806, 0.4806],
        [0.6007, 0.4753, 0.4806, 0.4806]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:44,521:INFO::its now!!!!!!!!5
2023-12-01 09:57:44,744:INFO::its now!!!!!!!!0
2023-12-01 09:57:44,745:INFO::its now!!!!!!!!3
2023-12-01 09:57:44,859:INFO::its now!!!!!!!!5
2023-12-01 09:57:45,066:INFO::its now!!!!!!!!
2023-12-01 09:57:45,066:INFO::its now!!!!!!!! on 
2023-12-01 09:57:45,188:INFO::its now!!!!!!!!5
2023-12-01 09:57:45,437:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:45,438:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 0.5453 | Train_Classification_Loss 0.5802 | Dmon_Loss -0.0699 | Val_Loss 0.2752 | Search Time(s) 0.6652 | Infer Time(s) 0.2543 | Time(s) 0.9195 
2023-12-01 09:57:45,482:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 3;	6: 3;	7: 0;	8: 1;	9: 1;	10: 3;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 1;	26: 1;	27: 1;	28: 2;	29: 0;	30: 0;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 3;	26099: 1;	26100: 2;	26101: 2;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 3;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 1;	
2023-12-01 09:57:45,483:INFO::Validation loss decreased (0.291653 --> 0.275198).  Saving model ...
2023-12-01 09:57:45,485:INFO::Epoch: 27
tensor([[0.5989, 0.4821, 0.4821, 0.4821],
        [0.5433, 0.4821, 0.4821, 0.4821],
        [0.6002, 0.4821, 0.4821, 0.4821],
        [0.6031, 0.4769, 0.4821, 0.4821]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:45,486:INFO::its now!!!!!!!!5
2023-12-01 09:57:45,674:INFO::its now!!!!!!!!0
2023-12-01 09:57:45,675:INFO::its now!!!!!!!!3
2023-12-01 09:57:45,788:INFO::its now!!!!!!!!5
2023-12-01 09:57:46,008:INFO::its now!!!!!!!!
2023-12-01 09:57:46,008:INFO::its now!!!!!!!! on 
2023-12-01 09:57:46,130:INFO::its now!!!!!!!!5
2023-12-01 09:57:46,325:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:46,327:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 0.4846 | Train_Classification_Loss 0.5212 | Dmon_Loss -0.0731 | Val_Loss 0.2666 | Search Time(s) 0.6403 | Infer Time(s) 0.2025 | Time(s) 0.8427 
2023-12-01 09:57:46,373:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 3;	6: 0;	7: 0;	8: 0;	9: 0;	10: 3;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 3;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 3;	26099: 1;	26100: 0;	26101: 1;	26102: 0;	26103: 2;	26104: 3;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 3;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:46,374:INFO::Validation loss decreased (0.275198 --> 0.266567).  Saving model ...
2023-12-01 09:57:46,377:INFO::Epoch: 28
tensor([[0.6005, 0.4805, 0.4805, 0.4805],
        [0.5445, 0.4805, 0.4805, 0.4805],
        [0.6050, 0.4805, 0.4805, 0.4805],
        [0.6053, 0.4752, 0.4805, 0.4805]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:46,378:INFO::its now!!!!!!!!5
2023-12-01 09:57:46,603:INFO::its now!!!!!!!!0
2023-12-01 09:57:46,604:INFO::its now!!!!!!!!3
2023-12-01 09:57:46,716:INFO::its now!!!!!!!!5
2023-12-01 09:57:46,945:INFO::its now!!!!!!!!
2023-12-01 09:57:46,945:INFO::its now!!!!!!!! on 
2023-12-01 09:57:47,066:INFO::its now!!!!!!!!5
2023-12-01 09:57:47,257:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:47,258:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 0.5102 | Train_Classification_Loss 0.5481 | Dmon_Loss -0.0758 | Val_Loss 0.2590 | Search Time(s) 0.6842 | Infer Time(s) 0.1972 | Time(s) 0.8814 
2023-12-01 09:57:47,312:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 1;	9: 2;	10: 0;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 3;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 3;	33: 2;	34: 2;	35: 3;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 2;	26104: 1;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:47,315:INFO::Validation loss decreased (0.266567 --> 0.258989).  Saving model ...
2023-12-01 09:57:47,322:INFO::Epoch: 29
tensor([[0.6019, 0.4750, 0.4750, 0.4750],
        [0.5465, 0.4750, 0.4750, 0.4750],
        [0.6088, 0.4750, 0.4750, 0.4750],
        [0.6075, 0.4697, 0.4750, 0.4750]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:47,323:INFO::its now!!!!!!!!5
2023-12-01 09:57:47,526:INFO::its now!!!!!!!!0
2023-12-01 09:57:47,527:INFO::its now!!!!!!!!3
2023-12-01 09:57:47,639:INFO::its now!!!!!!!!5
2023-12-01 09:57:47,852:INFO::its now!!!!!!!!
2023-12-01 09:57:47,852:INFO::its now!!!!!!!! on 
2023-12-01 09:57:47,975:INFO::its now!!!!!!!!5
2023-12-01 09:57:48,195:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:48,196:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 0.5009 | Train_Classification_Loss 0.5384 | Dmon_Loss -0.0751 | Val_Loss 0.2506 | Search Time(s) 0.6514 | Infer Time(s) 0.2271 | Time(s) 0.8785 
2023-12-01 09:57:48,232:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 1;	7: 0;	8: 0;	9: 0;	10: 0;	11: 3;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 1;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 0;	26109: 3;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 0;	26121: 2;	26122: 0;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:48,233:INFO::Validation loss decreased (0.258989 --> 0.250614).  Saving model ...
2023-12-01 09:57:48,236:INFO::Epoch: 30
tensor([[0.6055, 0.4696, 0.4696, 0.4696],
        [0.5478, 0.4696, 0.4696, 0.4696],
        [0.6104, 0.4696, 0.4696, 0.4696],
        [0.6098, 0.4643, 0.4696, 0.4696]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:48,236:INFO::its now!!!!!!!!5
2023-12-01 09:57:48,455:INFO::its now!!!!!!!!0
2023-12-01 09:57:48,456:INFO::its now!!!!!!!!3
2023-12-01 09:57:48,569:INFO::its now!!!!!!!!5
2023-12-01 09:57:48,782:INFO::its now!!!!!!!!
2023-12-01 09:57:48,782:INFO::its now!!!!!!!! on 
2023-12-01 09:57:48,902:INFO::its now!!!!!!!!5
2023-12-01 09:57:49,121:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:49,123:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 0.4620 | Train_Classification_Loss 0.5026 | Dmon_Loss -0.0810 | Val_Loss 0.2436 | Search Time(s) 0.6635 | Infer Time(s) 0.2244 | Time(s) 0.8879 
2023-12-01 09:57:49,163:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 1;	9: 0;	10: 0;	11: 0;	12: 3;	13: 2;	14: 0;	15: 3;	16: 1;	17: 2;	18: 0;	19: 0;	20: 3;	21: 1;	22: 0;	23: 0;	24: 0;	25: 3;	26: 0;	27: 2;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:49,164:INFO::Validation loss decreased (0.250614 --> 0.243632).  Saving model ...
2023-12-01 09:57:49,166:INFO::Epoch: 31
tensor([[0.6085, 0.4638, 0.4638, 0.4638],
        [0.5506, 0.4638, 0.4638, 0.4638],
        [0.6064, 0.4638, 0.4638, 0.4638],
        [0.6119, 0.4585, 0.4638, 0.4638]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:49,166:INFO::its now!!!!!!!!5
2023-12-01 09:57:49,377:INFO::its now!!!!!!!!0
2023-12-01 09:57:49,378:INFO::its now!!!!!!!!3
2023-12-01 09:57:49,490:INFO::its now!!!!!!!!5
2023-12-01 09:57:49,683:INFO::its now!!!!!!!!
2023-12-01 09:57:49,683:INFO::its now!!!!!!!! on 
2023-12-01 09:57:49,805:INFO::its now!!!!!!!!5
2023-12-01 09:57:50,015:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:50,016:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 0.4408 | Train_Classification_Loss 0.4839 | Dmon_Loss -0.0861 | Val_Loss 0.2356 | Search Time(s) 0.6355 | Infer Time(s) 0.2164 | Time(s) 0.8520 
2023-12-01 09:57:50,056:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 1;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 3;	22: 0;	23: 0;	24: 0;	25: 1;	26: 0;	27: 2;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 1;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:50,057:INFO::Validation loss decreased (0.243632 --> 0.235598).  Saving model ...
2023-12-01 09:57:50,059:INFO::Epoch: 32
tensor([[0.6074, 0.4540, 0.4540, 0.4540],
        [0.5528, 0.4540, 0.4540, 0.4540],
        [0.5995, 0.4540, 0.4540, 0.4540],
        [0.6144, 0.4486, 0.4540, 0.4540]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:50,060:INFO::its now!!!!!!!!5
2023-12-01 09:57:50,272:INFO::its now!!!!!!!!0
2023-12-01 09:57:50,273:INFO::its now!!!!!!!!3
2023-12-01 09:57:50,385:INFO::its now!!!!!!!!5
2023-12-01 09:57:50,594:INFO::its now!!!!!!!!
2023-12-01 09:57:50,595:INFO::its now!!!!!!!! on 
2023-12-01 09:57:50,718:INFO::its now!!!!!!!!5
2023-12-01 09:57:50,984:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:50,986:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 0.4343 | Train_Classification_Loss 0.4795 | Dmon_Loss -0.0905 | Val_Loss 0.2266 | Search Time(s) 0.6549 | Infer Time(s) 0.2713 | Time(s) 0.9261 
2023-12-01 09:57:51,036:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 3;	22: 0;	23: 0;	24: 0;	25: 3;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 3;	32: 1;	33: 2;	34: 2;	35: 3;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:51,037:INFO::Validation loss decreased (0.235598 --> 0.226599).  Saving model ...
2023-12-01 09:57:51,039:INFO::Epoch: 33
tensor([[0.6090, 0.4455, 0.4455, 0.4455],
        [0.5542, 0.4455, 0.4455, 0.4455],
        [0.5986, 0.4455, 0.4455, 0.4455],
        [0.6163, 0.4401, 0.4455, 0.4455]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:51,040:INFO::its now!!!!!!!!5
2023-12-01 09:57:51,240:INFO::its now!!!!!!!!0
2023-12-01 09:57:51,241:INFO::its now!!!!!!!!3
2023-12-01 09:57:51,354:INFO::its now!!!!!!!!5
2023-12-01 09:57:51,824:INFO::its now!!!!!!!!
2023-12-01 09:57:51,824:INFO::its now!!!!!!!! on 
2023-12-01 09:57:51,955:INFO::its now!!!!!!!!5
2023-12-01 09:57:52,190:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:52,192:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 0.4276 | Train_Classification_Loss 0.4737 | Dmon_Loss -0.0923 | Val_Loss 0.2189 | Search Time(s) 0.9134 | Infer Time(s) 0.2394 | Time(s) 1.1527 
2023-12-01 09:57:52,243:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 1;	6: 3;	7: 0;	8: 0;	9: 0;	10: 3;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 3;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 3;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 0;	32: 1;	33: 2;	34: 2;	35: 3;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 1;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:52,244:INFO::Validation loss decreased (0.226599 --> 0.218937).  Saving model ...
2023-12-01 09:57:52,247:INFO::Epoch: 34
tensor([[0.6128, 0.4365, 0.4365, 0.4365],
        [0.5556, 0.4365, 0.4365, 0.4365],
        [0.5993, 0.4365, 0.4365, 0.4365],
        [0.6172, 0.4311, 0.4365, 0.4365]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:52,248:INFO::its now!!!!!!!!5
2023-12-01 09:57:52,468:INFO::its now!!!!!!!!0
2023-12-01 09:57:52,469:INFO::its now!!!!!!!!3
2023-12-01 09:57:52,583:INFO::its now!!!!!!!!5
2023-12-01 09:57:52,805:INFO::its now!!!!!!!!
2023-12-01 09:57:52,805:INFO::its now!!!!!!!! on 
2023-12-01 09:57:52,926:INFO::its now!!!!!!!!5
2023-12-01 09:57:53,145:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:53,146:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 0.4324 | Train_Classification_Loss 0.4811 | Dmon_Loss -0.0972 | Val_Loss 0.2144 | Search Time(s) 0.6744 | Infer Time(s) 0.2254 | Time(s) 0.8998 
2023-12-01 09:57:53,194:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 3;	12: 3;	13: 2;	14: 0;	15: 3;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 2;	28: 2;	29: 0;	30: 2;	31: 0;	32: 3;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 1;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:53,196:INFO::Validation loss decreased (0.218937 --> 0.214356).  Saving model ...
2023-12-01 09:57:53,199:INFO::Epoch: 35
tensor([[0.6145, 0.4323, 0.4323, 0.4323],
        [0.5550, 0.4323, 0.4323, 0.4323],
        [0.6020, 0.4323, 0.4323, 0.4323],
        [0.6185, 0.4269, 0.4323, 0.4323]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:53,200:INFO::its now!!!!!!!!5
2023-12-01 09:57:53,429:INFO::its now!!!!!!!!0
2023-12-01 09:57:53,431:INFO::its now!!!!!!!!3
2023-12-01 09:57:53,542:INFO::its now!!!!!!!!5
2023-12-01 09:57:53,748:INFO::its now!!!!!!!!
2023-12-01 09:57:53,748:INFO::its now!!!!!!!! on 
2023-12-01 09:57:53,871:INFO::its now!!!!!!!!5
2023-12-01 09:57:54,071:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:54,072:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 0.3774 | Train_Classification_Loss 0.4304 | Dmon_Loss -0.1060 | Val_Loss 0.2097 | Search Time(s) 0.6705 | Infer Time(s) 0.2045 | Time(s) 0.8749 
2023-12-01 09:57:54,120:INFO::cluster info:
0: 3;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 1;	12: 3;	13: 2;	14: 0;	15: 2;	16: 1;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 3;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:54,121:INFO::Validation loss decreased (0.214356 --> 0.209724).  Saving model ...
2023-12-01 09:57:54,124:INFO::Epoch: 36
tensor([[0.6126, 0.4280, 0.4280, 0.4280],
        [0.5559, 0.4280, 0.4280, 0.4280],
        [0.6031, 0.4280, 0.4280, 0.4280],
        [0.6203, 0.4226, 0.4280, 0.4280]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:54,125:INFO::its now!!!!!!!!5
2023-12-01 09:57:54,356:INFO::its now!!!!!!!!0
2023-12-01 09:57:54,357:INFO::its now!!!!!!!!3
2023-12-01 09:57:54,470:INFO::its now!!!!!!!!5
2023-12-01 09:57:54,684:INFO::its now!!!!!!!!
2023-12-01 09:57:54,684:INFO::its now!!!!!!!! on 
2023-12-01 09:57:54,804:INFO::its now!!!!!!!!5
2023-12-01 09:57:55,001:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:55,002:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 0.3992 | Train_Classification_Loss 0.4532 | Dmon_Loss -0.1079 | Val_Loss 0.2094 | Search Time(s) 0.6760 | Infer Time(s) 0.2025 | Time(s) 0.8784 
2023-12-01 09:57:55,044:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 2;	10: 0;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 3;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 0;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 1;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:55,046:INFO::Validation loss decreased (0.209724 --> 0.209366).  Saving model ...
2023-12-01 09:57:55,048:INFO::Epoch: 37
tensor([[0.6160, 0.4215, 0.4215, 0.4215],
        [0.5577, 0.4215, 0.4215, 0.4215],
        [0.5984, 0.4215, 0.4215, 0.4215],
        [0.6205, 0.4161, 0.4215, 0.4215]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:55,049:INFO::its now!!!!!!!!5
2023-12-01 09:57:55,271:INFO::its now!!!!!!!!0
2023-12-01 09:57:55,272:INFO::its now!!!!!!!!3
2023-12-01 09:57:55,388:INFO::its now!!!!!!!!5
2023-12-01 09:57:55,627:INFO::its now!!!!!!!!
2023-12-01 09:57:55,627:INFO::its now!!!!!!!! on 
2023-12-01 09:57:55,749:INFO::its now!!!!!!!!5
2023-12-01 09:57:55,979:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 0.3572 | Train_Classification_Loss 0.4136 | Dmon_Loss -0.1127 | Val_Loss 0.2095 | Search Time(s) 0.6974 | Infer Time(s) 0.2364 | Time(s) 0.9337 
2023-12-01 09:57:56,028:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 3;	10: 3;	11: 1;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 0;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:56,029:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:57:56,031:INFO::Epoch: 38
tensor([[0.6175, 0.4187, 0.4187, 0.4187],
        [0.5586, 0.4187, 0.4187, 0.4187],
        [0.5936, 0.4187, 0.4187, 0.4187],
        [0.6213, 0.4133, 0.4187, 0.4187]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:56,032:INFO::its now!!!!!!!!5
2023-12-01 09:57:56,317:INFO::its now!!!!!!!!0
2023-12-01 09:57:56,318:INFO::its now!!!!!!!!3
2023-12-01 09:57:56,436:INFO::its now!!!!!!!!5
2023-12-01 09:57:56,648:INFO::its now!!!!!!!!
2023-12-01 09:57:56,649:INFO::its now!!!!!!!! on 
2023-12-01 09:57:56,772:INFO::its now!!!!!!!!5
2023-12-01 09:57:57,004:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 0.3910 | Train_Classification_Loss 0.4519 | Dmon_Loss -0.1219 | Val_Loss 0.2108 | Search Time(s) 0.7372 | Infer Time(s) 0.2374 | Time(s) 0.9745 
2023-12-01 09:57:57,054:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 1;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 1;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 1;	44
26098: 3;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:57,055:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:57:57,058:INFO::Epoch: 39
tensor([[0.6329, 0.4301, 0.4166, 0.4301],
        [0.5598, 0.4301, 0.4301, 0.4301],
        [0.6088, 0.4301, 0.4163, 0.4301],
        [0.6366, 0.4247, 0.4301, 0.4172]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:57,059:INFO::its now!!!!!!!!5
2023-12-01 09:57:57,272:INFO::its now!!!!!!!!0
2023-12-01 09:57:57,273:INFO::its now!!!!!!!!3
2023-12-01 09:57:57,386:INFO::its now!!!!!!!!5
2023-12-01 09:57:57,605:INFO::its now!!!!!!!!
2023-12-01 09:57:57,605:INFO::its now!!!!!!!! on 
2023-12-01 09:57:57,729:INFO::its now!!!!!!!!5
2023-12-01 09:57:57,939:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:57,940:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 0.3672 | Train_Classification_Loss 0.4294 | Dmon_Loss -0.1244 | Val_Loss 0.2070 | Search Time(s) 0.6695 | Infer Time(s) 0.2134 | Time(s) 0.8829 
2023-12-01 09:57:57,978:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 1;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:57,979:INFO::Validation loss decreased (0.209366 --> 0.207041).  Saving model ...
2023-12-01 09:57:57,981:INFO::Epoch: 40
tensor([[0.6399, 0.4349, 0.4140, 0.4349],
        [0.5608, 0.4349, 0.4349, 0.4349],
        [0.6170, 0.4349, 0.4135, 0.4349],
        [0.6446, 0.4295, 0.4349, 0.4149]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:57,981:INFO::its now!!!!!!!!5
2023-12-01 09:57:58,175:INFO::its now!!!!!!!!0
2023-12-01 09:57:58,176:INFO::its now!!!!!!!!3
2023-12-01 09:57:58,289:INFO::its now!!!!!!!!5
2023-12-01 09:57:58,516:INFO::its now!!!!!!!!
2023-12-01 09:57:58,516:INFO::its now!!!!!!!! on 
2023-12-01 09:57:58,638:INFO::its now!!!!!!!!5
2023-12-01 09:57:58,858:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:57:58,860:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 0.3541 | Train_Classification_Loss 0.4181 | Dmon_Loss -0.1281 | Val_Loss 0.2061 | Search Time(s) 0.6538 | Infer Time(s) 0.2258 | Time(s) 0.8796 
2023-12-01 09:57:58,909:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 3;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 0;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 1;	26099: 0;	26100: 0;	26101: 0;	26102: 1;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:58,910:INFO::Validation loss decreased (0.207041 --> 0.206074).  Saving model ...
2023-12-01 09:57:58,912:INFO::Epoch: 41
tensor([[0.6435, 0.4369, 0.4118, 0.4369],
        [0.5610, 0.4369, 0.4369, 0.4369],
        [0.6208, 0.4369, 0.4113, 0.4369],
        [0.6487, 0.4315, 0.4369, 0.4129]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:58,913:INFO::its now!!!!!!!!5
2023-12-01 09:57:59,109:INFO::its now!!!!!!!!0
2023-12-01 09:57:59,110:INFO::its now!!!!!!!!3
2023-12-01 09:57:59,245:INFO::its now!!!!!!!!5
2023-12-01 09:57:59,471:INFO::its now!!!!!!!!
2023-12-01 09:57:59,471:INFO::its now!!!!!!!! on 
2023-12-01 09:57:59,592:INFO::its now!!!!!!!!5
2023-12-01 09:57:59,801:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 0.3157 | Train_Classification_Loss 0.3853 | Dmon_Loss -0.1391 | Val_Loss 0.2095 | Search Time(s) 0.6758 | Infer Time(s) 0.2150 | Time(s) 0.8908 
2023-12-01 09:57:59,857:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 3;	11: 0;	12: 3;	13: 2;	14: 0;	15: 2;	16: 3;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 0;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:57:59,858:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:57:59,861:INFO::Epoch: 42
tensor([[0.6444, 0.4498, 0.4256, 0.4498],
        [0.5771, 0.4378, 0.4498, 0.4498],
        [0.6352, 0.4498, 0.4095, 0.4498],
        [0.6631, 0.4444, 0.4498, 0.4119]], device='cuda:0', requires_grad=True)
2023-12-01 09:57:59,862:INFO::its now!!!!!!!!5
2023-12-01 09:58:00,078:INFO::its now!!!!!!!!0
2023-12-01 09:58:00,079:INFO::its now!!!!!!!!3
2023-12-01 09:58:00,191:INFO::its now!!!!!!!!5
2023-12-01 09:58:00,426:INFO::its now!!!!!!!!
2023-12-01 09:58:00,426:INFO::its now!!!!!!!! on 
2023-12-01 09:58:00,550:INFO::its now!!!!!!!!5
2023-12-01 09:58:00,770:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 0.3354 | Train_Classification_Loss 0.4072 | Dmon_Loss -0.1436 | Val_Loss 0.2138 | Search Time(s) 0.6862 | Infer Time(s) 0.2247 | Time(s) 0.9109 
2023-12-01 09:58:00,818:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 1;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 3;	22: 0;	23: 0;	24: 0;	25: 3;	26: 2;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:58:00,819:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:58:00,821:INFO::Epoch: 43
tensor([[0.6450, 0.4537, 0.4295, 0.4537],
        [0.5852, 0.4344, 0.4537, 0.4537],
        [0.6420, 0.4537, 0.4026, 0.4537],
        [0.6706, 0.4483, 0.4537, 0.4054]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:00,822:INFO::its now!!!!!!!!5
2023-12-01 09:58:01,003:INFO::its now!!!!!!!!0
2023-12-01 09:58:01,004:INFO::its now!!!!!!!!3
2023-12-01 09:58:01,117:INFO::its now!!!!!!!!5
2023-12-01 09:58:01,448:INFO::its now!!!!!!!!
2023-12-01 09:58:01,448:INFO::its now!!!!!!!! on 
2023-12-01 09:58:01,571:INFO::its now!!!!!!!!5
2023-12-01 09:58:01,808:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 0.2889 | Train_Classification_Loss 0.3635 | Dmon_Loss -0.1492 | Val_Loss 0.2207 | Search Time(s) 0.7455 | Infer Time(s) 0.2429 | Time(s) 0.9885 
2023-12-01 09:58:01,875:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 1;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 0;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 3;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 1;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 0;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:58:01,876:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:58:01,878:INFO::Epoch: 44
tensor([[0.6455, 0.4548, 0.4305, 0.4548],
        [0.5893, 0.4314, 0.4548, 0.4548],
        [0.6452, 0.4548, 0.3971, 0.4548],
        [0.6745, 0.4494, 0.4548, 0.4000]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:01,879:INFO::its now!!!!!!!!5
2023-12-01 09:58:02,107:INFO::its now!!!!!!!!0
2023-12-01 09:58:02,108:INFO::its now!!!!!!!!3
2023-12-01 09:58:02,221:INFO::its now!!!!!!!!5
2023-12-01 09:58:02,459:INFO::its now!!!!!!!!
2023-12-01 09:58:02,459:INFO::its now!!!!!!!! on 
2023-12-01 09:58:02,580:INFO::its now!!!!!!!!5
2023-12-01 09:58:02,777:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 0.3130 | Train_Classification_Loss 0.3896 | Dmon_Loss -0.1532 | Val_Loss 0.2317 | Search Time(s) 0.6988 | Infer Time(s) 0.2021 | Time(s) 0.9008 
2023-12-01 09:58:02,835:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:58:02,836:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:58:02,839:INFO::Epoch: 45
tensor([[0.6459, 0.4539, 0.4293, 0.4539],
        [0.5914, 0.4276, 0.4539, 0.4539],
        [0.6465, 0.4539, 0.3909, 0.4539],
        [0.6764, 0.4485, 0.4539, 0.3939]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:02,840:INFO::its now!!!!!!!!5
2023-12-01 09:58:03,045:INFO::its now!!!!!!!!0
2023-12-01 09:58:03,046:INFO::its now!!!!!!!!3
2023-12-01 09:58:03,161:INFO::its now!!!!!!!!5
2023-12-01 09:58:03,371:INFO::its now!!!!!!!!
2023-12-01 09:58:03,372:INFO::its now!!!!!!!! on 
2023-12-01 09:58:03,495:INFO::its now!!!!!!!!5
2023-12-01 09:58:03,717:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 0.2811 | Train_Classification_Loss 0.3594 | Dmon_Loss -0.1565 | Val_Loss 0.2369 | Search Time(s) 0.6502 | Infer Time(s) 0.2296 | Time(s) 0.8799 
2023-12-01 09:58:03,756:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 2;	10: 2;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:58:03,757:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:58:03,760:INFO::Epoch: 46
tensor([[0.6462, 0.4491, 0.4237, 0.4491],
        [0.5924, 0.4196, 0.4491, 0.4491],
        [0.6468, 0.4491, 0.3794, 0.4491],
        [0.6774, 0.4437, 0.4491, 0.3825]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:03,761:INFO::its now!!!!!!!!5
2023-12-01 09:58:03,979:INFO::its now!!!!!!!!0
2023-12-01 09:58:03,980:INFO::its now!!!!!!!!3
2023-12-01 09:58:04,091:INFO::its now!!!!!!!!5
2023-12-01 09:58:04,315:INFO::its now!!!!!!!!
2023-12-01 09:58:04,315:INFO::its now!!!!!!!! on 
2023-12-01 09:58:04,441:INFO::its now!!!!!!!!5
2023-12-01 09:58:04,721:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 0.3040 | Train_Classification_Loss 0.3854 | Dmon_Loss -0.1628 | Val_Loss 0.2340 | Search Time(s) 0.6802 | Infer Time(s) 0.2836 | Time(s) 0.9638 
2023-12-01 09:58:04,778:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 2;	25: 3;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:58:04,780:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 09:58:04,783:INFO::Epoch: 47
tensor([[0.6466, 0.4451, 0.4191, 0.4451],
        [0.5929, 0.4131, 0.4451, 0.4451],
        [0.6467, 0.4451, 0.3704, 0.4451],
        [0.6777, 0.4397, 0.4451, 0.3735]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:04,784:INFO::its now!!!!!!!!5
2023-12-01 09:58:05,026:INFO::its now!!!!!!!!0
2023-12-01 09:58:05,027:INFO::its now!!!!!!!!3
2023-12-01 09:58:05,140:INFO::its now!!!!!!!!5
2023-12-01 09:58:05,349:INFO::its now!!!!!!!!
2023-12-01 09:58:05,349:INFO::its now!!!!!!!! on 
2023-12-01 09:58:05,473:INFO::its now!!!!!!!!5
2023-12-01 09:58:05,727:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 0.2723 | Train_Classification_Loss 0.3555 | Dmon_Loss -0.1663 | Val_Loss 0.2258 | Search Time(s) 0.6892 | Infer Time(s) 0.2585 | Time(s) 0.9477 
2023-12-01 09:58:05,779:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 3;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 2;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 3;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:58:05,780:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 09:58:05,782:INFO::Epoch: 48
tensor([[0.6471, 0.4396, 0.4129, 0.4396],
        [0.5932, 0.4051, 0.4396, 0.4396],
        [0.6464, 0.4396, 0.3596, 0.4396],
        [0.6779, 0.4342, 0.4396, 0.3627]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:05,783:INFO::its now!!!!!!!!5
2023-12-01 09:58:05,998:INFO::its now!!!!!!!!0
2023-12-01 09:58:05,999:INFO::its now!!!!!!!!3
2023-12-01 09:58:06,111:INFO::its now!!!!!!!!5
2023-12-01 09:58:06,315:INFO::its now!!!!!!!!
2023-12-01 09:58:06,315:INFO::its now!!!!!!!! on 
2023-12-01 09:58:06,438:INFO::its now!!!!!!!!5
2023-12-01 09:58:06,630:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 0.2454 | Train_Classification_Loss 0.3311 | Dmon_Loss -0.1713 | Val_Loss 0.2190 | Search Time(s) 0.6513 | Infer Time(s) 0.1980 | Time(s) 0.8493 
2023-12-01 09:58:06,689:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 0;	9: 3;	10: 0;	11: 0;	12: 3;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 3;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 0;	31: 0;	32: 0;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:58:06,701:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 09:58:06,702:INFO::Eearly stopping!
2023-12-01 09:58:06,816:INFO::############### Search Stage Ends! ###############
2023-12-01 09:58:06,843:INFO::=============== Retrain Stage Starts:
2023-12-01 09:58:06,843:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:06,856:INFO::node_assign_Counter:
Counter({-1: 14328, 2: 5008, 0: 4246, 3: 1969, 1: 577})
2023-12-01 09:58:06,856:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:07,248:INFO::============= repeat round: 1; seed: 666
2023-12-01 09:58:07,303:INFO::arch_weights:
[[0.64345956 0.4368587  0.41181415 0.4368587 ]
 [0.56101704 0.4368587  0.4368587  0.4368587 ]
 [0.6207988  0.4368587  0.4112857  0.4368587 ]
 [0.6486738  0.43146184 0.4368587  0.41285303]]
2023-12-01 09:58:07,304:INFO::arch_weights_softmax:
[[0.29240486 0.23782578 0.23194353 0.23782578]
 [0.2739936  0.24200213 0.24200213 0.24200213]
 [0.2877739  0.23942374 0.23337857 0.23942374]
 [0.29378963 0.23642997 0.2377094  0.23207095]]
2023-12-01 09:58:07,304:INFO::genotype choice:
['gcn', 'gcn', 'gcn', 'gcn']
2023-12-01 09:58:07,825:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.3962 | Val_Loss 1.3512 | Time(s) 0.4700
2023-12-01 09:58:08,198:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3744 | Val_Loss 1.3275 | Time(s) 0.3610
2023-12-01 09:58:08,210:INFO::Validation loss decreased (inf --> 1.327483).  Saving model ...
2023-12-01 09:58:08,574:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3481 | Val_Loss 1.3052 | Time(s) 0.3626
2023-12-01 09:58:08,592:INFO::Validation loss decreased (1.327483 --> 1.305214).  Saving model ...
2023-12-01 09:58:08,957:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.3353 | Val_Loss 1.2822 | Time(s) 0.3656
2023-12-01 09:58:08,968:INFO::Validation loss decreased (1.305214 --> 1.282176).  Saving model ...
2023-12-01 09:58:09,320:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.3041 | Val_Loss 1.2562 | Time(s) 0.3511
2023-12-01 09:58:09,331:INFO::Validation loss decreased (1.282176 --> 1.256178).  Saving model ...
2023-12-01 09:58:09,691:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.2826 | Val_Loss 1.2267 | Time(s) 0.3600
2023-12-01 09:58:09,704:INFO::Validation loss decreased (1.256178 --> 1.226706).  Saving model ...
2023-12-01 09:58:10,064:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.2683 | Val_Loss 1.1942 | Time(s) 0.3590
2023-12-01 09:58:10,074:INFO::Validation loss decreased (1.226706 --> 1.194175).  Saving model ...
2023-12-01 09:58:10,431:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.2346 | Val_Loss 1.1579 | Time(s) 0.3570
2023-12-01 09:58:10,441:INFO::Validation loss decreased (1.194175 --> 1.157906).  Saving model ...
2023-12-01 09:58:10,797:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.2026 | Val_Loss 1.1176 | Time(s) 0.3554
2023-12-01 09:58:10,808:INFO::Validation loss decreased (1.157906 --> 1.117650).  Saving model ...
2023-12-01 09:58:11,173:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.1512 | Val_Loss 1.0730 | Time(s) 0.3650
2023-12-01 09:58:11,184:INFO::Validation loss decreased (1.117650 --> 1.073001).  Saving model ...
2023-12-01 09:58:11,537:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.1388 | Val_Loss 1.0247 | Time(s) 0.3531
2023-12-01 09:58:11,555:INFO::Validation loss decreased (1.073001 --> 1.024720).  Saving model ...
2023-12-01 09:58:11,916:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.0844 | Val_Loss 0.9729 | Time(s) 0.3612
2023-12-01 09:58:11,933:INFO::Validation loss decreased (1.024720 --> 0.972853).  Saving model ...
2023-12-01 09:58:12,323:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 1.0490 | Val_Loss 0.9174 | Time(s) 0.3900
2023-12-01 09:58:12,333:INFO::Validation loss decreased (0.972853 --> 0.917357).  Saving model ...
2023-12-01 09:58:12,705:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 0.9883 | Val_Loss 0.8584 | Time(s) 0.3723
2023-12-01 09:58:12,722:INFO::Validation loss decreased (0.917357 --> 0.858411).  Saving model ...
2023-12-01 09:58:13,099:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 0.9229 | Val_Loss 0.7960 | Time(s) 0.3760
2023-12-01 09:58:13,109:INFO::Validation loss decreased (0.858411 --> 0.795999).  Saving model ...
2023-12-01 09:58:13,465:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 0.8874 | Val_Loss 0.7306 | Time(s) 0.3552
2023-12-01 09:58:13,478:INFO::Validation loss decreased (0.795999 --> 0.730626).  Saving model ...
2023-12-01 09:58:13,852:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 0.8548 | Val_Loss 0.6649 | Time(s) 0.3730
2023-12-01 09:58:13,867:INFO::Validation loss decreased (0.730626 --> 0.664895).  Saving model ...
2023-12-01 09:58:14,254:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 0.7593 | Val_Loss 0.6008 | Time(s) 0.3870
2023-12-01 09:58:14,265:INFO::Validation loss decreased (0.664895 --> 0.600815).  Saving model ...
2023-12-01 09:58:14,626:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 0.7225 | Val_Loss 0.5408 | Time(s) 0.3606
2023-12-01 09:58:14,639:INFO::Validation loss decreased (0.600815 --> 0.540799).  Saving model ...
2023-12-01 09:58:14,991:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 0.7325 | Val_Loss 0.4870 | Time(s) 0.3527
2023-12-01 09:58:15,003:INFO::Validation loss decreased (0.540799 --> 0.486954).  Saving model ...
2023-12-01 09:58:15,381:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 0.6754 | Val_Loss 0.4420 | Time(s) 0.3770
2023-12-01 09:58:15,398:INFO::Validation loss decreased (0.486954 --> 0.442005).  Saving model ...
2023-12-01 09:58:15,793:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 0.6437 | Val_Loss 0.4029 | Time(s) 0.3953
2023-12-01 09:58:15,805:INFO::Validation loss decreased (0.442005 --> 0.402880).  Saving model ...
2023-12-01 09:58:16,169:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 0.6359 | Val_Loss 0.3742 | Time(s) 0.3640
2023-12-01 09:58:16,187:INFO::Validation loss decreased (0.402880 --> 0.374154).  Saving model ...
2023-12-01 09:58:16,580:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 0.5830 | Val_Loss 0.3532 | Time(s) 0.3906
2023-12-01 09:58:16,591:INFO::Validation loss decreased (0.374154 --> 0.353181).  Saving model ...
2023-12-01 09:58:16,947:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 0.5749 | Val_Loss 0.3335 | Time(s) 0.3562
2023-12-01 09:58:16,957:INFO::Validation loss decreased (0.353181 --> 0.333466).  Saving model ...
2023-12-01 09:58:17,312:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 0.5652 | Val_Loss 0.3134 | Time(s) 0.3551
2023-12-01 09:58:17,491:INFO::Validation loss decreased (0.333466 --> 0.313384).  Saving model ...
2023-12-01 09:58:18,007:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 0.5053 | Val_Loss 0.2958 | Time(s) 0.5160
2023-12-01 09:58:18,018:INFO::Validation loss decreased (0.313384 --> 0.295784).  Saving model ...
2023-12-01 09:58:18,378:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 0.5093 | Val_Loss 0.2792 | Time(s) 0.3580
2023-12-01 09:58:18,388:INFO::Validation loss decreased (0.295784 --> 0.279222).  Saving model ...
2023-12-01 09:58:18,739:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 0.4806 | Val_Loss 0.2679 | Time(s) 0.3500
2023-12-01 09:58:18,749:INFO::Validation loss decreased (0.279222 --> 0.267891).  Saving model ...
2023-12-01 09:58:19,113:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 0.4801 | Val_Loss 0.2578 | Time(s) 0.3640
2023-12-01 09:58:19,123:INFO::Validation loss decreased (0.267891 --> 0.257769).  Saving model ...
2023-12-01 09:58:19,488:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 0.4662 | Val_Loss 0.2533 | Time(s) 0.3651
2023-12-01 09:58:19,498:INFO::Validation loss decreased (0.257769 --> 0.253289).  Saving model ...
2023-12-01 09:58:19,856:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 0.4408 | Val_Loss 0.2498 | Time(s) 0.3568
2023-12-01 09:58:19,865:INFO::Validation loss decreased (0.253289 --> 0.249832).  Saving model ...
2023-12-01 09:58:20,213:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 0.4347 | Val_Loss 0.2498 | Time(s) 0.3471
2023-12-01 09:58:20,222:INFO::Validation loss decreased (0.249832 --> 0.249809).  Saving model ...
2023-12-01 09:58:20,573:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 0.3708 | Val_Loss 0.2501 | Time(s) 0.3497
2023-12-01 09:58:20,573:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:58:20,924:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 0.4066 | Val_Loss 0.2524 | Time(s) 0.3508
2023-12-01 09:58:20,925:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:58:21,270:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 0.4064 | Val_Loss 0.2517 | Time(s) 0.3440
2023-12-01 09:58:21,270:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:58:21,624:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 0.4099 | Val_Loss 0.2486 | Time(s) 0.3537
2023-12-01 09:58:21,634:INFO::Validation loss decreased (0.249809 --> 0.248645).  Saving model ...
2023-12-01 09:58:21,981:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 0.4053 | Val_Loss 0.2442 | Time(s) 0.3467
2023-12-01 09:58:21,991:INFO::Validation loss decreased (0.248645 --> 0.244231).  Saving model ...
2023-12-01 09:58:22,340:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 0.3961 | Val_Loss 0.2393 | Time(s) 0.3471
2023-12-01 09:58:22,349:INFO::Validation loss decreased (0.244231 --> 0.239257).  Saving model ...
2023-12-01 09:58:22,699:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 0.4022 | Val_Loss 0.2314 | Time(s) 0.3489
2023-12-01 09:58:22,709:INFO::Validation loss decreased (0.239257 --> 0.231440).  Saving model ...
2023-12-01 09:58:23,059:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 0.3762 | Val_Loss 0.2257 | Time(s) 0.3501
2023-12-01 09:58:23,070:INFO::Validation loss decreased (0.231440 --> 0.225728).  Saving model ...
2023-12-01 09:58:23,439:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 0.3535 | Val_Loss 0.2234 | Time(s) 0.3680
2023-12-01 09:58:23,452:INFO::Validation loss decreased (0.225728 --> 0.223440).  Saving model ...
2023-12-01 09:58:23,820:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 0.3424 | Val_Loss 0.2221 | Time(s) 0.3683
2023-12-01 09:58:23,832:INFO::Validation loss decreased (0.223440 --> 0.222062).  Saving model ...
2023-12-01 09:58:24,186:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 0.3490 | Val_Loss 0.2205 | Time(s) 0.3541
2023-12-01 09:58:24,197:INFO::Validation loss decreased (0.222062 --> 0.220517).  Saving model ...
2023-12-01 09:58:24,549:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 0.3604 | Val_Loss 0.2205 | Time(s) 0.3515
2023-12-01 09:58:24,560:INFO::Validation loss decreased (0.220517 --> 0.220503).  Saving model ...
2023-12-01 09:58:24,922:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 0.3122 | Val_Loss 0.2211 | Time(s) 0.3616
2023-12-01 09:58:24,923:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:58:25,289:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 0.3110 | Val_Loss 0.2227 | Time(s) 0.3650
2023-12-01 09:58:25,290:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:58:25,665:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 0.3434 | Val_Loss 0.2244 | Time(s) 0.3742
2023-12-01 09:58:25,666:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:58:26,046:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 0.2938 | Val_Loss 0.2270 | Time(s) 0.3800
2023-12-01 09:58:26,047:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:58:26,406:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 0.2978 | Val_Loss 0.2316 | Time(s) 0.3590
2023-12-01 09:58:26,407:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:58:26,771:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 0.3335 | Val_Loss 0.2298 | Time(s) 0.3642
2023-12-01 09:58:26,772:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 09:58:27,138:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.3142 | Val_Loss 0.2251 | Time(s) 0.3654
2023-12-01 09:58:27,139:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 09:58:27,504:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.3100 | Val_Loss 0.2219 | Time(s) 0.3650
2023-12-01 09:58:27,504:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 09:58:27,505:INFO::Eearly stopping!
2023-12-01 09:58:27,505:INFO::
testing...
2023-12-01 09:58:27,523:INFO::submit dir: submit/submit_gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:27,654:INFO::{'micro-f1': 0.9323943661971831, 'macro-f1': 0.9272371808191437}
2023-12-01 09:58:27,783:INFO::############### Retrain Stage Ends! #################
2023-12-01 09:58:27,784:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gat', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-09-54-04', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=1233, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=2, last_hidden_dim=512, logger=<Logger log_output (INFO)>)
2023-12-01 09:58:43,965:INFO::node_type_num: 4
2023-12-01 09:58:44,007:INFO::=============== Prepare basic data stage finish, use 16.222925662994385 time.
2023-12-01 09:58:44,135:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:45,403:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:45,404:INFO::its now!!!!!!!!5
2023-12-01 09:58:45,654:INFO::its now!!!!!!!!0
2023-12-01 09:58:45,655:INFO::its now!!!!!!!!3
2023-12-01 09:58:45,771:INFO::its now!!!!!!!!5
2023-12-01 09:58:46,003:INFO::its now!!!!!!!!
2023-12-01 09:58:46,003:INFO::its now!!!!!!!! on 
2023-12-01 09:58:46,140:INFO::its now!!!!!!!!5
2023-12-01 09:58:46,359:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:46,361:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.4066 | Train_Classification_Loss 1.4373 | Dmon_Loss -0.0615 | Val_Loss 1.3614 | Search Time(s) 0.7211 | Infer Time(s) 0.2364 | Time(s) 0.9574 
2023-12-01 09:58:46,415:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 2;	5: 2;	6: 1;	7: 2;	8: 2;	9: 2;	10: 3;	11: 2;	12: 2;	13: 0;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 3;	38: 0;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 3;	26100: 2;	26101: 2;	26102: 0;	26103: 0;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:58:46,419:INFO::Epoch: 1
tensor([[0.5050, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:46,420:INFO::its now!!!!!!!!5
2023-12-01 09:58:46,623:INFO::its now!!!!!!!!0
2023-12-01 09:58:46,624:INFO::its now!!!!!!!!3
2023-12-01 09:58:46,753:INFO::its now!!!!!!!!5
2023-12-01 09:58:46,960:INFO::its now!!!!!!!!
2023-12-01 09:58:46,960:INFO::its now!!!!!!!! on 
2023-12-01 09:58:47,083:INFO::its now!!!!!!!!5
2023-12-01 09:58:47,282:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:47,284:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3522 | Train_Classification_Loss 1.3835 | Dmon_Loss -0.0626 | Val_Loss 1.3604 | Search Time(s) 0.6592 | Infer Time(s) 0.2064 | Time(s) 0.8657 
2023-12-01 09:58:47,326:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 0;	5: 1;	6: 2;	7: 1;	8: 0;	9: 3;	10: 1;	11: 0;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 3;	18: 1;	19: 1;	20: 2;	21: 1;	22: 1;	23: 1;	24: 2;	25: 1;	26: 3;	27: 3;	28: 1;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 3;	35: 1;	36: 3;	37: 1;	38: 1;	39: 0;	40: 1;	41: 1;	42: 1;	43: 1;	44
26098: 2;	26099: 1;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 2;	26105: 0;	26106: 1;	26107: 0;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 2;	
2023-12-01 09:58:47,328:INFO::Validation loss decreased (inf --> 1.360421).  Saving model ...
2023-12-01 09:58:47,330:INFO::Epoch: 2
tensor([[0.5097, 0.5073, 0.5085, 0.5085],
        [0.4995, 0.5074, 0.5085, 0.5085],
        [0.4996, 0.5072, 0.5085, 0.5085],
        [0.4990, 0.5073, 0.5085, 0.5085]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:47,331:INFO::its now!!!!!!!!5
2023-12-01 09:58:47,539:INFO::its now!!!!!!!!0
2023-12-01 09:58:47,540:INFO::its now!!!!!!!!3
2023-12-01 09:58:47,657:INFO::its now!!!!!!!!5
2023-12-01 09:58:47,871:INFO::its now!!!!!!!!
2023-12-01 09:58:47,871:INFO::its now!!!!!!!! on 
2023-12-01 09:58:47,993:INFO::its now!!!!!!!!5
2023-12-01 09:58:48,191:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:48,193:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3401 | Train_Classification_Loss 1.3714 | Dmon_Loss -0.0626 | Val_Loss 1.3524 | Search Time(s) 0.6574 | Infer Time(s) 0.2058 | Time(s) 0.8632 
2023-12-01 09:58:48,234:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 2;	9: 1;	10: 0;	11: 2;	12: 1;	13: 1;	14: 1;	15: 1;	16: 1;	17: 0;	18: 1;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 0;	25: 2;	26: 2;	27: 3;	28: 1;	29: 1;	30: 1;	31: 0;	32: 2;	33: 3;	34: 1;	35: 1;	36: 1;	37: 3;	38: 1;	39: 0;	40: 1;	41: 1;	42: 1;	43: 0;	44
26098: 2;	26099: 0;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 2;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 09:58:48,236:INFO::Validation loss decreased (1.360421 --> 1.352448).  Saving model ...
2023-12-01 09:58:48,239:INFO::Epoch: 3
tensor([[0.5122, 0.5079, 0.5097, 0.5097],
        [0.4996, 0.5080, 0.5103, 0.5097],
        [0.4997, 0.5077, 0.5103, 0.5097],
        [0.4989, 0.5079, 0.5103, 0.5097]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:48,240:INFO::its now!!!!!!!!5
2023-12-01 09:58:48,471:INFO::its now!!!!!!!!0
2023-12-01 09:58:48,472:INFO::its now!!!!!!!!3
2023-12-01 09:58:48,588:INFO::its now!!!!!!!!5
2023-12-01 09:58:48,831:INFO::its now!!!!!!!!
2023-12-01 09:58:48,831:INFO::its now!!!!!!!! on 
2023-12-01 09:58:48,955:INFO::its now!!!!!!!!5
2023-12-01 09:58:49,174:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:49,176:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3295 | Train_Classification_Loss 1.3608 | Dmon_Loss -0.0626 | Val_Loss 1.3415 | Search Time(s) 0.7121 | Infer Time(s) 0.2254 | Time(s) 0.9376 
2023-12-01 09:58:49,230:INFO::cluster info:
0: 1;	1: 2;	2: 1;	3: 2;	4: 2;	5: 2;	6: 0;	7: 1;	8: 1;	9: 1;	10: 2;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 0;	18: 1;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 1;	25: 1;	26: 0;	27: 2;	28: 1;	29: 2;	30: 2;	31: 0;	32: 3;	33: 0;	34: 2;	35: 3;	36: 1;	37: 0;	38: 1;	39: 3;	40: 2;	41: 1;	42: 1;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 1;	26102: 2;	26103: 1;	26104: 0;	26105: 0;	26106: 2;	26107: 2;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 09:58:49,232:INFO::Validation loss decreased (1.352448 --> 1.341495).  Saving model ...
2023-12-01 09:58:49,235:INFO::Epoch: 4
tensor([[0.5135, 0.5084, 0.5105, 0.5105],
        [0.5000, 0.5084, 0.5113, 0.5105],
        [0.5002, 0.5081, 0.5113, 0.5105],
        [0.4993, 0.5084, 0.5113, 0.5105]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:49,236:INFO::its now!!!!!!!!5
2023-12-01 09:58:49,458:INFO::its now!!!!!!!!0
2023-12-01 09:58:49,459:INFO::its now!!!!!!!!3
2023-12-01 09:58:49,574:INFO::its now!!!!!!!!5
2023-12-01 09:58:49,811:INFO::its now!!!!!!!!
2023-12-01 09:58:49,811:INFO::its now!!!!!!!! on 
2023-12-01 09:58:49,935:INFO::its now!!!!!!!!5
2023-12-01 09:58:50,133:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:50,136:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3145 | Train_Classification_Loss 1.3458 | Dmon_Loss -0.0626 | Val_Loss 1.3293 | Search Time(s) 0.6943 | Infer Time(s) 0.2064 | Time(s) 0.9008 
2023-12-01 09:58:50,182:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 1;	4: 2;	5: 1;	6: 0;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 1;	13: 1;	14: 1;	15: 2;	16: 2;	17: 2;	18: 1;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 1;	25: 3;	26: 1;	27: 2;	28: 0;	29: 2;	30: 2;	31: 1;	32: 1;	33: 1;	34: 1;	35: 1;	36: 1;	37: 1;	38: 2;	39: 3;	40: 1;	41: 1;	42: 1;	43: 1;	44
26098: 2;	26099: 1;	26100: 0;	26101: 3;	26102: 0;	26103: 3;	26104: 0;	26105: 2;	26106: 2;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 09:58:50,183:INFO::Validation loss decreased (1.341495 --> 1.329323).  Saving model ...
2023-12-01 09:58:50,186:INFO::Epoch: 5
tensor([[0.5143, 0.5071, 0.5094, 0.5094],
        [0.4962, 0.5071, 0.5117, 0.5094],
        [0.4964, 0.5067, 0.5118, 0.5094],
        [0.4955, 0.5071, 0.5118, 0.5094]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:50,186:INFO::its now!!!!!!!!5
2023-12-01 09:58:50,438:INFO::its now!!!!!!!!0
2023-12-01 09:58:50,439:INFO::its now!!!!!!!!3
2023-12-01 09:58:50,556:INFO::its now!!!!!!!!5
2023-12-01 09:58:50,779:INFO::its now!!!!!!!!
2023-12-01 09:58:50,779:INFO::its now!!!!!!!! on 
2023-12-01 09:58:50,905:INFO::its now!!!!!!!!5
2023-12-01 09:58:51,113:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3058 | Train_Classification_Loss 1.3371 | Dmon_Loss -0.0626 | Val_Loss 1.3340 | Search Time(s) 0.7213 | Infer Time(s) 0.2082 | Time(s) 0.9295 
2023-12-01 09:58:51,163:INFO::cluster info:
0: 1;	1: 2;	2: 1;	3: 2;	4: 1;	5: 2;	6: 1;	7: 3;	8: 3;	9: 0;	10: 0;	11: 1;	12: 1;	13: 1;	14: 3;	15: 2;	16: 2;	17: 1;	18: 0;	19: 2;	20: 3;	21: 0;	22: 1;	23: 1;	24: 1;	25: 3;	26: 2;	27: 3;	28: 1;	29: 1;	30: 2;	31: 3;	32: 3;	33: 1;	34: 3;	35: 2;	36: 0;	37: 1;	38: 1;	39: 0;	40: 2;	41: 1;	42: 1;	43: 3;	44
26098: 1;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 2;	26105: 2;	26106: 1;	26107: 0;	26108: 1;	26109: 1;	26110: 2;	26111: 2;	26112: 1;	26113: 0;	26114: 1;	26115: 1;	26116: 3;	26117: 2;	26118: 2;	26119: 3;	26120: 0;	26121: 1;	26122: 3;	26123: 2;	26124: 2;	26125: 1;	26126: 2;	26127: 1;	
2023-12-01 09:58:51,164:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:58:51,167:INFO::Epoch: 6
tensor([[0.5146, 0.5097, 0.5120, 0.5120],
        [0.5003, 0.5097, 0.5120, 0.5120],
        [0.5005, 0.5093, 0.5121, 0.5120],
        [0.4995, 0.5097, 0.5121, 0.5120]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:51,168:INFO::its now!!!!!!!!5
2023-12-01 09:58:51,397:INFO::its now!!!!!!!!0
2023-12-01 09:58:51,398:INFO::its now!!!!!!!!3
2023-12-01 09:58:51,513:INFO::its now!!!!!!!!5
2023-12-01 09:58:51,719:INFO::its now!!!!!!!!
2023-12-01 09:58:51,719:INFO::its now!!!!!!!! on 
2023-12-01 09:58:51,844:INFO::its now!!!!!!!!5
2023-12-01 09:58:52,073:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:52,075:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.2888 | Train_Classification_Loss 1.3201 | Dmon_Loss -0.0626 | Val_Loss 1.3129 | Search Time(s) 0.6762 | Infer Time(s) 0.2324 | Time(s) 0.9086 
2023-12-01 09:58:52,242:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 1;	4: 2;	5: 3;	6: 3;	7: 3;	8: 1;	9: 0;	10: 2;	11: 1;	12: 2;	13: 1;	14: 2;	15: 3;	16: 1;	17: 2;	18: 1;	19: 2;	20: 2;	21: 1;	22: 1;	23: 2;	24: 0;	25: 1;	26: 1;	27: 3;	28: 1;	29: 0;	30: 1;	31: 1;	32: 2;	33: 1;	34: 2;	35: 2;	36: 2;	37: 0;	38: 3;	39: 2;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 2;	26099: 2;	26100: 1;	26101: 1;	26102: 0;	26103: 3;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 1;	26109: 1;	26110: 0;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 1;	26121: 1;	26122: 2;	26123: 1;	26124: 2;	26125: 1;	26126: 2;	26127: 3;	
2023-12-01 09:58:52,243:INFO::Validation loss decreased (1.329323 --> 1.312856).  Saving model ...
2023-12-01 09:58:52,246:INFO::Epoch: 7
tensor([[0.5148, 0.5149, 0.5172, 0.5172],
        [0.5070, 0.5149, 0.5166, 0.5134],
        [0.5071, 0.5146, 0.5123, 0.5172],
        [0.5061, 0.5149, 0.5123, 0.5172]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:52,247:INFO::its now!!!!!!!!5
2023-12-01 09:58:52,636:INFO::its now!!!!!!!!0
2023-12-01 09:58:52,638:INFO::its now!!!!!!!!3
2023-12-01 09:58:52,755:INFO::its now!!!!!!!!5
2023-12-01 09:58:52,953:INFO::its now!!!!!!!!
2023-12-01 09:58:52,953:INFO::its now!!!!!!!! on 
2023-12-01 09:58:53,094:INFO::its now!!!!!!!!5
2023-12-01 09:58:53,305:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:53,306:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.3082 | Train_Classification_Loss 1.3397 | Dmon_Loss -0.0629 | Val_Loss 1.2915 | Search Time(s) 0.8465 | Infer Time(s) 0.2152 | Time(s) 1.0618 
2023-12-01 09:58:53,361:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 0;	5: 0;	6: 2;	7: 2;	8: 0;	9: 3;	10: 2;	11: 1;	12: 0;	13: 2;	14: 2;	15: 0;	16: 2;	17: 0;	18: 2;	19: 0;	20: 2;	21: 2;	22: 0;	23: 0;	24: 3;	25: 0;	26: 2;	27: 2;	28: 0;	29: 0;	30: 3;	31: 2;	32: 3;	33: 2;	34: 0;	35: 0;	36: 2;	37: 2;	38: 2;	39: 0;	40: 0;	41: 0;	42: 0;	43: 2;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 3;	26104: 1;	26105: 3;	26106: 2;	26107: 2;	26108: 2;	26109: 0;	26110: 2;	26111: 2;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 3;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 0;	26127: 2;	
2023-12-01 09:58:53,362:INFO::Validation loss decreased (1.312856 --> 1.291525).  Saving model ...
2023-12-01 09:58:53,365:INFO::Epoch: 8
tensor([[0.5217, 0.5213, 0.5200, 0.5235],
        [0.5143, 0.5213, 0.5192, 0.5186],
        [0.5144, 0.5209, 0.5175, 0.5200],
        [0.5135, 0.5213, 0.5176, 0.5200]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:53,366:INFO::its now!!!!!!!!5
2023-12-01 09:58:53,603:INFO::its now!!!!!!!!0
2023-12-01 09:58:53,604:INFO::its now!!!!!!!!3
2023-12-01 09:58:53,736:INFO::its now!!!!!!!!5
2023-12-01 09:58:53,961:INFO::its now!!!!!!!!
2023-12-01 09:58:53,961:INFO::its now!!!!!!!! on 
2023-12-01 09:58:54,103:INFO::its now!!!!!!!!5
2023-12-01 09:58:54,330:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:54,332:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.2984 | Train_Classification_Loss 1.3299 | Dmon_Loss -0.0631 | Val_Loss 1.2667 | Search Time(s) 0.7203 | Infer Time(s) 0.2473 | Time(s) 0.9676 
2023-12-01 09:58:54,374:INFO::cluster info:
0: 2;	1: 0;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 0;	8: 2;	9: 3;	10: 3;	11: 2;	12: 3;	13: 0;	14: 2;	15: 2;	16: 2;	17: 3;	18: 2;	19: 2;	20: 3;	21: 2;	22: 2;	23: 0;	24: 2;	25: 2;	26: 0;	27: 3;	28: 3;	29: 2;	30: 2;	31: 0;	32: 2;	33: 3;	34: 3;	35: 0;	36: 0;	37: 0;	38: 3;	39: 2;	40: 2;	41: 3;	42: 2;	43: 2;	44
26098: 1;	26099: 2;	26100: 0;	26101: 3;	26102: 2;	26103: 3;	26104: 3;	26105: 2;	26106: 1;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 2;	26112: 3;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 0;	26121: 2;	26122: 0;	26123: 2;	26124: 2;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:58:54,375:INFO::Validation loss decreased (1.291525 --> 1.266742).  Saving model ...
2023-12-01 09:58:54,378:INFO::Epoch: 9
tensor([[0.5275, 0.5260, 0.5231, 0.5269],
        [0.5197, 0.5247, 0.5223, 0.5229],
        [0.5199, 0.5238, 0.5220, 0.5231],
        [0.5189, 0.5247, 0.5220, 0.5231]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:54,379:INFO::its now!!!!!!!!5
2023-12-01 09:58:54,582:INFO::its now!!!!!!!!0
2023-12-01 09:58:54,583:INFO::its now!!!!!!!!3
2023-12-01 09:58:54,714:INFO::its now!!!!!!!!5
2023-12-01 09:58:54,928:INFO::its now!!!!!!!!
2023-12-01 09:58:54,928:INFO::its now!!!!!!!! on 
2023-12-01 09:58:55,050:INFO::its now!!!!!!!!5
2023-12-01 09:58:55,282:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.2617 | Train_Classification_Loss 1.2930 | Dmon_Loss -0.0626 | Val_Loss 1.2960 | Search Time(s) 0.6710 | Infer Time(s) 0.2352 | Time(s) 0.9061 
2023-12-01 09:58:55,347:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 3;	4: 1;	5: 3;	6: 1;	7: 1;	8: 0;	9: 1;	10: 0;	11: 1;	12: 1;	13: 1;	14: 3;	15: 2;	16: 1;	17: 0;	18: 3;	19: 2;	20: 0;	21: 2;	22: 0;	23: 2;	24: 1;	25: 1;	26: 2;	27: 3;	28: 1;	29: 2;	30: 1;	31: 3;	32: 1;	33: 2;	34: 1;	35: 2;	36: 0;	37: 1;	38: 0;	39: 3;	40: 1;	41: 2;	42: 1;	43: 0;	44
26098: 2;	26099: 2;	26100: 2;	26101: 1;	26102: 1;	26103: 2;	26104: 3;	26105: 0;	26106: 0;	26107: 2;	26108: 1;	26109: 1;	26110: 3;	26111: 2;	26112: 2;	26113: 2;	26114: 0;	26115: 1;	26116: 0;	26117: 0;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 3;	26125: 0;	26126: 3;	26127: 0;	
2023-12-01 09:58:55,348:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:58:55,350:INFO::Epoch: 10
tensor([[0.5302, 0.5312, 0.5280, 0.5314],
        [0.5256, 0.5264, 0.5275, 0.5283],
        [0.5258, 0.5253, 0.5277, 0.5280],
        [0.5248, 0.5263, 0.5277, 0.5280]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:55,351:INFO::its now!!!!!!!!5
2023-12-01 09:58:55,562:INFO::its now!!!!!!!!0
2023-12-01 09:58:55,563:INFO::its now!!!!!!!!3
2023-12-01 09:58:55,675:INFO::its now!!!!!!!!5
2023-12-01 09:58:55,962:INFO::its now!!!!!!!!
2023-12-01 09:58:55,962:INFO::its now!!!!!!!! on 
2023-12-01 09:58:56,102:INFO::its now!!!!!!!!5
2023-12-01 09:58:56,315:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:56,317:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.2564 | Train_Classification_Loss 1.2879 | Dmon_Loss -0.0629 | Val_Loss 1.2578 | Search Time(s) 0.7331 | Infer Time(s) 0.2344 | Time(s) 0.9674 
2023-12-01 09:58:56,366:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 1;	5: 0;	6: 3;	7: 2;	8: 2;	9: 3;	10: 1;	11: 1;	12: 2;	13: 2;	14: 3;	15: 3;	16: 0;	17: 3;	18: 2;	19: 2;	20: 3;	21: 2;	22: 3;	23: 2;	24: 1;	25: 2;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 1;	32: 3;	33: 0;	34: 0;	35: 3;	36: 2;	37: 2;	38: 0;	39: 0;	40: 1;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 3;	26100: 2;	26101: 1;	26102: 2;	26103: 1;	26104: 0;	26105: 3;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 09:58:56,367:INFO::Validation loss decreased (1.266742 --> 1.257809).  Saving model ...
2023-12-01 09:58:56,369:INFO::Epoch: 11
tensor([[0.5340, 0.5354, 0.5321, 0.5337],
        [0.5302, 0.5289, 0.5319, 0.5310],
        [0.5304, 0.5277, 0.5323, 0.5305],
        [0.5294, 0.5288, 0.5323, 0.5305]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:56,369:INFO::its now!!!!!!!!5
2023-12-01 09:58:56,564:INFO::its now!!!!!!!!0
2023-12-01 09:58:56,565:INFO::its now!!!!!!!!3
2023-12-01 09:58:56,695:INFO::its now!!!!!!!!5
2023-12-01 09:58:56,906:INFO::its now!!!!!!!!
2023-12-01 09:58:56,906:INFO::its now!!!!!!!! on 
2023-12-01 09:58:57,047:INFO::its now!!!!!!!!5
2023-12-01 09:58:57,255:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:57,257:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.2148 | Train_Classification_Loss 1.2462 | Dmon_Loss -0.0627 | Val_Loss 1.2366 | Search Time(s) 0.6600 | Infer Time(s) 0.2283 | Time(s) 0.8883 
2023-12-01 09:58:57,330:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 0;	7: 1;	8: 2;	9: 2;	10: 2;	11: 1;	12: 2;	13: 1;	14: 1;	15: 2;	16: 1;	17: 1;	18: 1;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 3;	28: 2;	29: 2;	30: 1;	31: 1;	32: 1;	33: 0;	34: 1;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 1;	41: 1;	42: 1;	43: 1;	44
26098: 1;	26099: 2;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 0;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 2;	26115: 1;	26116: 1;	26117: 2;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 09:58:57,330:INFO::Validation loss decreased (1.257809 --> 1.236572).  Saving model ...
2023-12-01 09:58:57,333:INFO::Epoch: 12
tensor([[0.5333, 0.5375, 0.5325, 0.5333],
        [0.5309, 0.5285, 0.5342, 0.5307],
        [0.5310, 0.5272, 0.5348, 0.5300],
        [0.5301, 0.5284, 0.5347, 0.5300]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:57,333:INFO::its now!!!!!!!!5
2023-12-01 09:58:57,543:INFO::its now!!!!!!!!0
2023-12-01 09:58:57,544:INFO::its now!!!!!!!!3
2023-12-01 09:58:57,673:INFO::its now!!!!!!!!5
2023-12-01 09:58:57,912:INFO::its now!!!!!!!!
2023-12-01 09:58:57,912:INFO::its now!!!!!!!! on 
2023-12-01 09:58:58,055:INFO::its now!!!!!!!!5
2023-12-01 09:58:58,300:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:58,302:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.2049 | Train_Classification_Loss 1.2362 | Dmon_Loss -0.0627 | Val_Loss 1.2204 | Search Time(s) 0.7068 | Infer Time(s) 0.2623 | Time(s) 0.9691 
2023-12-01 09:58:58,351:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 0;	6: 2;	7: 1;	8: 2;	9: 2;	10: 2;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 2;	17: 1;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 0;	25: 0;	26: 1;	27: 1;	28: 1;	29: 1;	30: 2;	31: 1;	32: 2;	33: 3;	34: 2;	35: 0;	36: 2;	37: 1;	38: 1;	39: 3;	40: 1;	41: 1;	42: 1;	43: 1;	44
26098: 3;	26099: 0;	26100: 1;	26101: 1;	26102: 0;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 2;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 2;	26118: 2;	26119: 1;	26120: 1;	26121: 2;	26122: 2;	26123: 1;	26124: 1;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 09:58:58,353:INFO::Validation loss decreased (1.236572 --> 1.220389).  Saving model ...
2023-12-01 09:58:58,355:INFO::Epoch: 13
tensor([[0.5288, 0.5387, 0.5296, 0.5303],
        [0.5282, 0.5254, 0.5355, 0.5274],
        [0.5284, 0.5240, 0.5360, 0.5266],
        [0.5274, 0.5252, 0.5359, 0.5266]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:58,356:INFO::its now!!!!!!!!5
2023-12-01 09:58:58,595:INFO::its now!!!!!!!!0
2023-12-01 09:58:58,597:INFO::its now!!!!!!!!3
2023-12-01 09:58:58,729:INFO::its now!!!!!!!!5
2023-12-01 09:58:58,974:INFO::its now!!!!!!!!
2023-12-01 09:58:58,975:INFO::its now!!!!!!!! on 
2023-12-01 09:58:59,116:INFO::its now!!!!!!!!5
2023-12-01 09:58:59,371:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:58:59,372:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.1907 | Train_Classification_Loss 1.2220 | Dmon_Loss -0.0627 | Val_Loss 1.1988 | Search Time(s) 0.7450 | Infer Time(s) 0.2723 | Time(s) 1.0172 
2023-12-01 09:58:59,436:INFO::cluster info:
0: 2;	1: 1;	2: 1;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 2;	13: 1;	14: 1;	15: 2;	16: 3;	17: 1;	18: 1;	19: 1;	20: 1;	21: 2;	22: 2;	23: 2;	24: 1;	25: 2;	26: 3;	27: 2;	28: 2;	29: 0;	30: 2;	31: 1;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 2;	40: 2;	41: 1;	42: 1;	43: 1;	44
26098: 2;	26099: 0;	26100: 1;	26101: 3;	26102: 0;	26103: 3;	26104: 2;	26105: 1;	26106: 1;	26107: 3;	26108: 2;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 09:58:59,436:INFO::Validation loss decreased (1.220389 --> 1.198846).  Saving model ...
2023-12-01 09:58:59,439:INFO::Epoch: 14
tensor([[0.5293, 0.5392, 0.5301, 0.5306],
        [0.5288, 0.5257, 0.5362, 0.5278],
        [0.5290, 0.5243, 0.5367, 0.5269],
        [0.5280, 0.5255, 0.5366, 0.5270]], device='cuda:0', requires_grad=True)
2023-12-01 09:58:59,440:INFO::its now!!!!!!!!5
2023-12-01 09:58:59,677:INFO::its now!!!!!!!!0
2023-12-01 09:58:59,677:INFO::its now!!!!!!!!3
2023-12-01 09:58:59,791:INFO::its now!!!!!!!!5
2023-12-01 09:58:59,998:INFO::its now!!!!!!!!
2023-12-01 09:58:59,998:INFO::its now!!!!!!!! on 
2023-12-01 09:59:00,139:INFO::its now!!!!!!!!5
2023-12-01 09:59:00,354:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:00,355:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.1598 | Train_Classification_Loss 1.1912 | Dmon_Loss -0.0627 | Val_Loss 1.1742 | Search Time(s) 0.6804 | Infer Time(s) 0.2364 | Time(s) 0.9168 
2023-12-01 09:59:00,392:INFO::cluster info:
0: 2;	1: 1;	2: 2;	3: 2;	4: 1;	5: 2;	6: 1;	7: 1;	8: 3;	9: 2;	10: 1;	11: 2;	12: 1;	13: 1;	14: 1;	15: 1;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 3;	25: 1;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 3;	33: 1;	34: 1;	35: 2;	36: 0;	37: 1;	38: 2;	39: 2;	40: 1;	41: 1;	42: 2;	43: 1;	44
26098: 1;	26099: 0;	26100: 2;	26101: 0;	26102: 2;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 1;	26110: 1;	26111: 1;	26112: 2;	26113: 2;	26114: 1;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 1;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 09:59:00,393:INFO::Validation loss decreased (1.198846 --> 1.174213).  Saving model ...
2023-12-01 09:59:00,395:INFO::Epoch: 15
tensor([[0.5287, 0.5389, 0.5304, 0.5302],
        [0.5290, 0.5253, 0.5359, 0.5274],
        [0.5287, 0.5239, 0.5370, 0.5265],
        [0.5277, 0.5251, 0.5369, 0.5265]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:00,396:INFO::its now!!!!!!!!5
2023-12-01 09:59:00,617:INFO::its now!!!!!!!!0
2023-12-01 09:59:00,618:INFO::its now!!!!!!!!3
2023-12-01 09:59:00,749:INFO::its now!!!!!!!!5
2023-12-01 09:59:00,971:INFO::its now!!!!!!!!
2023-12-01 09:59:00,971:INFO::its now!!!!!!!! on 
2023-12-01 09:59:01,111:INFO::its now!!!!!!!!5
2023-12-01 09:59:01,335:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:01,337:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.1299 | Train_Classification_Loss 1.1613 | Dmon_Loss -0.0627 | Val_Loss 1.1496 | Search Time(s) 0.6983 | Infer Time(s) 0.2433 | Time(s) 0.9417 
2023-12-01 09:59:01,391:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 2;	4: 1;	5: 2;	6: 3;	7: 1;	8: 1;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 1;	18: 1;	19: 1;	20: 2;	21: 1;	22: 2;	23: 1;	24: 2;	25: 3;	26: 1;	27: 0;	28: 2;	29: 1;	30: 2;	31: 2;	32: 1;	33: 1;	34: 0;	35: 1;	36: 2;	37: 0;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 0;	26102: 0;	26103: 0;	26104: 2;	26105: 3;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 2;	26111: 1;	26112: 1;	26113: 1;	26114: 2;	26115: 2;	26116: 2;	26117: 1;	26118: 2;	26119: 1;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 2;	
2023-12-01 09:59:01,392:INFO::Validation loss decreased (1.174213 --> 1.149628).  Saving model ...
2023-12-01 09:59:01,395:INFO::Epoch: 16
tensor([[0.5255, 0.5387, 0.5284, 0.5280],
        [0.5270, 0.5230, 0.5358, 0.5250],
        [0.5264, 0.5216, 0.5374, 0.5241],
        [0.5254, 0.5228, 0.5371, 0.5241]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:01,396:INFO::its now!!!!!!!!5
2023-12-01 09:59:01,648:INFO::its now!!!!!!!!0
2023-12-01 09:59:01,649:INFO::its now!!!!!!!!3
2023-12-01 09:59:01,781:INFO::its now!!!!!!!!5
2023-12-01 09:59:02,025:INFO::its now!!!!!!!!
2023-12-01 09:59:02,026:INFO::its now!!!!!!!! on 
2023-12-01 09:59:02,167:INFO::its now!!!!!!!!5
2023-12-01 09:59:02,373:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:02,374:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 1.1121 | Train_Classification_Loss 1.1434 | Dmon_Loss -0.0627 | Val_Loss 1.1237 | Search Time(s) 0.7532 | Infer Time(s) 0.2264 | Time(s) 0.9796 
2023-12-01 09:59:02,423:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 2;	4: 3;	5: 2;	6: 0;	7: 2;	8: 2;	9: 0;	10: 1;	11: 1;	12: 2;	13: 0;	14: 2;	15: 0;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 3;	22: 1;	23: 2;	24: 2;	25: 2;	26: 2;	27: 3;	28: 2;	29: 0;	30: 2;	31: 2;	32: 3;	33: 1;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 0;	42: 2;	43: 0;	44
26098: 2;	26099: 1;	26100: 1;	26101: 3;	26102: 3;	26103: 2;	26104: 1;	26105: 3;	26106: 3;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 09:59:02,424:INFO::Validation loss decreased (1.149628 --> 1.123706).  Saving model ...
2023-12-01 09:59:02,428:INFO::Epoch: 17
tensor([[0.5316, 0.5386, 0.5337, 0.5329],
        [0.5322, 0.5280, 0.5359, 0.5301],
        [0.5315, 0.5266, 0.5375, 0.5293],
        [0.5305, 0.5278, 0.5372, 0.5293]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:02,428:INFO::its now!!!!!!!!5
2023-12-01 09:59:02,628:INFO::its now!!!!!!!!0
2023-12-01 09:59:02,629:INFO::its now!!!!!!!!3
2023-12-01 09:59:02,759:INFO::its now!!!!!!!!5
2023-12-01 09:59:02,986:INFO::its now!!!!!!!!
2023-12-01 09:59:02,986:INFO::its now!!!!!!!! on 
2023-12-01 09:59:03,129:INFO::its now!!!!!!!!5
2023-12-01 09:59:03,370:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:03,372:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 1.0881 | Train_Classification_Loss 1.1195 | Dmon_Loss -0.0628 | Val_Loss 1.0989 | Search Time(s) 0.6814 | Infer Time(s) 0.2633 | Time(s) 0.9447 
2023-12-01 09:59:03,426:INFO::cluster info:
0: 0;	1: 1;	2: 0;	3: 2;	4: 2;	5: 1;	6: 0;	7: 3;	8: 1;	9: 1;	10: 1;	11: 1;	12: 2;	13: 1;	14: 2;	15: 0;	16: 0;	17: 1;	18: 2;	19: 0;	20: 1;	21: 1;	22: 2;	23: 1;	24: 2;	25: 2;	26: 0;	27: 3;	28: 2;	29: 0;	30: 3;	31: 0;	32: 2;	33: 2;	34: 2;	35: 0;	36: 2;	37: 2;	38: 2;	39: 0;	40: 0;	41: 2;	42: 1;	43: 0;	44
26098: 2;	26099: 0;	26100: 1;	26101: 3;	26102: 2;	26103: 1;	26104: 0;	26105: 1;	26106: 2;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:59:03,427:INFO::Validation loss decreased (1.123706 --> 1.098893).  Saving model ...
2023-12-01 09:59:03,431:INFO::Epoch: 18
tensor([[0.5370, 0.5386, 0.5385, 0.5373],
        [0.5369, 0.5326, 0.5362, 0.5348],
        [0.5362, 0.5312, 0.5378, 0.5340],
        [0.5352, 0.5324, 0.5373, 0.5340]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:03,432:INFO::its now!!!!!!!!5
2023-12-01 09:59:03,671:INFO::its now!!!!!!!!0
2023-12-01 09:59:03,672:INFO::its now!!!!!!!!3
2023-12-01 09:59:03,805:INFO::its now!!!!!!!!5
2023-12-01 09:59:04,033:INFO::its now!!!!!!!!
2023-12-01 09:59:04,033:INFO::its now!!!!!!!! on 
2023-12-01 09:59:04,159:INFO::its now!!!!!!!!5
2023-12-01 09:59:04,370:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:04,371:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 1.0801 | Train_Classification_Loss 1.1116 | Dmon_Loss -0.0630 | Val_Loss 1.0851 | Search Time(s) 0.7223 | Infer Time(s) 0.2184 | Time(s) 0.9407 
2023-12-01 09:59:04,423:INFO::cluster info:
0: 1;	1: 2;	2: 3;	3: 2;	4: 1;	5: 1;	6: 2;	7: 2;	8: 1;	9: 0;	10: 1;	11: 2;	12: 3;	13: 2;	14: 1;	15: 0;	16: 0;	17: 3;	18: 2;	19: 3;	20: 2;	21: 2;	22: 0;	23: 2;	24: 3;	25: 2;	26: 0;	27: 3;	28: 0;	29: 2;	30: 0;	31: 1;	32: 1;	33: 3;	34: 2;	35: 2;	36: 1;	37: 1;	38: 0;	39: 2;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 0;	26099: 3;	26100: 2;	26101: 2;	26102: 0;	26103: 2;	26104: 1;	26105: 1;	26106: 0;	26107: 3;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 1;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 1;	26124: 0;	26125: 0;	26126: 2;	26127: 1;	
2023-12-01 09:59:04,424:INFO::Validation loss decreased (1.098893 --> 1.085078).  Saving model ...
2023-12-01 09:59:04,426:INFO::Epoch: 19
tensor([[0.5453, 0.5388, 0.5459, 0.5444],
        [0.5393, 0.5399, 0.5434, 0.5422],
        [0.5435, 0.5385, 0.5383, 0.5415],
        [0.5425, 0.5397, 0.5374, 0.5415]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:04,427:INFO::its now!!!!!!!!5
2023-12-01 09:59:04,637:INFO::its now!!!!!!!!0
2023-12-01 09:59:04,638:INFO::its now!!!!!!!!3
2023-12-01 09:59:04,753:INFO::its now!!!!!!!!5
2023-12-01 09:59:05,006:INFO::its now!!!!!!!!
2023-12-01 09:59:05,007:INFO::its now!!!!!!!! on 
2023-12-01 09:59:05,130:INFO::its now!!!!!!!!5
2023-12-01 09:59:05,362:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:05,363:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 1.0355 | Train_Classification_Loss 1.0670 | Dmon_Loss -0.0630 | Val_Loss 1.0655 | Search Time(s) 0.7033 | Infer Time(s) 0.2344 | Time(s) 0.9377 
2023-12-01 09:59:05,404:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 2;	4: 3;	5: 0;	6: 1;	7: 1;	8: 2;	9: 2;	10: 0;	11: 0;	12: 1;	13: 3;	14: 1;	15: 3;	16: 2;	17: 0;	18: 2;	19: 2;	20: 0;	21: 2;	22: 0;	23: 3;	24: 3;	25: 3;	26: 3;	27: 2;	28: 1;	29: 0;	30: 2;	31: 0;	32: 2;	33: 2;	34: 0;	35: 2;	36: 1;	37: 0;	38: 2;	39: 2;	40: 0;	41: 2;	42: 2;	43: 0;	44
26098: 1;	26099: 0;	26100: 2;	26101: 2;	26102: 2;	26103: 3;	26104: 1;	26105: 1;	26106: 0;	26107: 2;	26108: 3;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 3;	26116: 2;	26117: 0;	26118: 1;	26119: 3;	26120: 1;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 09:59:05,405:INFO::Validation loss decreased (1.085078 --> 1.065500).  Saving model ...
2023-12-01 09:59:05,408:INFO::Epoch: 20
tensor([[0.5513, 0.5411, 0.5498, 0.5495],
        [0.5423, 0.5451, 0.5474, 0.5475],
        [0.5470, 0.5437, 0.5412, 0.5469],
        [0.5463, 0.5449, 0.5401, 0.5469]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:05,409:INFO::its now!!!!!!!!5
2023-12-01 09:59:05,596:INFO::its now!!!!!!!!0
2023-12-01 09:59:05,597:INFO::its now!!!!!!!!3
2023-12-01 09:59:05,715:INFO::its now!!!!!!!!5
2023-12-01 09:59:05,950:INFO::its now!!!!!!!!
2023-12-01 09:59:05,950:INFO::its now!!!!!!!! on 
2023-12-01 09:59:06,077:INFO::its now!!!!!!!!5
2023-12-01 09:59:06,289:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:06,291:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 0.9784 | Train_Classification_Loss 1.0099 | Dmon_Loss -0.0629 | Val_Loss 1.0123 | Search Time(s) 0.6684 | Infer Time(s) 0.2154 | Time(s) 0.8838 
2023-12-01 09:59:06,348:INFO::cluster info:
0: 2;	1: 0;	2: 3;	3: 0;	4: 2;	5: 3;	6: 0;	7: 3;	8: 0;	9: 1;	10: 0;	11: 2;	12: 1;	13: 3;	14: 2;	15: 0;	16: 2;	17: 3;	18: 3;	19: 3;	20: 3;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 0;	27: 2;	28: 2;	29: 0;	30: 0;	31: 3;	32: 2;	33: 2;	34: 2;	35: 1;	36: 3;	37: 1;	38: 0;	39: 3;	40: 3;	41: 0;	42: 2;	43: 3;	44
26098: 2;	26099: 1;	26100: 1;	26101: 3;	26102: 1;	26103: 2;	26104: 2;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 0;	26110: 2;	26111: 2;	26112: 0;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 0;	26118: 2;	26119: 2;	26120: 3;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:06,349:INFO::Validation loss decreased (1.065500 --> 1.012319).  Saving model ...
2023-12-01 09:59:06,352:INFO::Epoch: 21
tensor([[0.5543, 0.5451, 0.5538, 0.5539],
        [0.5461, 0.5497, 0.5521, 0.5502],
        [0.5489, 0.5483, 0.5459, 0.5516],
        [0.5502, 0.5495, 0.5448, 0.5497]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:06,353:INFO::its now!!!!!!!!5
2023-12-01 09:59:06,553:INFO::its now!!!!!!!!0
2023-12-01 09:59:06,554:INFO::its now!!!!!!!!3
2023-12-01 09:59:06,675:INFO::its now!!!!!!!!5
2023-12-01 09:59:06,904:INFO::its now!!!!!!!!
2023-12-01 09:59:06,904:INFO::its now!!!!!!!! on 
2023-12-01 09:59:07,048:INFO::its now!!!!!!!!5
2023-12-01 09:59:07,260:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:07,261:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 0.9734 | Train_Classification_Loss 1.0049 | Dmon_Loss -0.0630 | Val_Loss 0.9741 | Search Time(s) 0.6954 | Infer Time(s) 0.2154 | Time(s) 0.9109 
2023-12-01 09:59:07,312:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 1;	7: 3;	8: 3;	9: 3;	10: 2;	11: 1;	12: 3;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 0;	19: 3;	20: 3;	21: 3;	22: 3;	23: 2;	24: 0;	25: 2;	26: 2;	27: 3;	28: 3;	29: 2;	30: 3;	31: 2;	32: 2;	33: 2;	34: 3;	35: 3;	36: 3;	37: 0;	38: 2;	39: 3;	40: 0;	41: 3;	42: 2;	43: 2;	44
26098: 2;	26099: 0;	26100: 0;	26101: 2;	26102: 2;	26103: 0;	26104: 3;	26105: 3;	26106: 0;	26107: 3;	26108: 3;	26109: 3;	26110: 2;	26111: 3;	26112: 2;	26113: 0;	26114: 2;	26115: 3;	26116: 3;	26117: 2;	26118: 2;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 2;	26124: 2;	26125: 0;	26126: 3;	26127: 2;	
2023-12-01 09:59:07,313:INFO::Validation loss decreased (1.012319 --> 0.974090).  Saving model ...
2023-12-01 09:59:07,315:INFO::Epoch: 22
tensor([[0.5559, 0.5550, 0.5625, 0.5627],
        [0.5551, 0.5586, 0.5545, 0.5584],
        [0.5568, 0.5572, 0.5566, 0.5539],
        [0.5522, 0.5584, 0.5554, 0.5580]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:07,316:INFO::its now!!!!!!!!5
2023-12-01 09:59:07,520:INFO::its now!!!!!!!!0
2023-12-01 09:59:07,521:INFO::its now!!!!!!!!3
2023-12-01 09:59:07,655:INFO::its now!!!!!!!!5
2023-12-01 09:59:07,901:INFO::its now!!!!!!!!
2023-12-01 09:59:07,902:INFO::its now!!!!!!!! on 
2023-12-01 09:59:08,046:INFO::its now!!!!!!!!5
2023-12-01 09:59:08,271:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:08,272:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 0.9428 | Train_Classification_Loss 0.9745 | Dmon_Loss -0.0632 | Val_Loss 0.9386 | Search Time(s) 0.7322 | Infer Time(s) 0.2254 | Time(s) 0.9576 
2023-12-01 09:59:08,318:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 1;	5: 2;	6: 3;	7: 3;	8: 2;	9: 2;	10: 0;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 1;	17: 3;	18: 2;	19: 3;	20: 2;	21: 3;	22: 3;	23: 0;	24: 2;	25: 2;	26: 3;	27: 3;	28: 2;	29: 0;	30: 2;	31: 1;	32: 3;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 3;	39: 2;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 2;	26099: 2;	26100: 1;	26101: 0;	26102: 1;	26103: 3;	26104: 0;	26105: 2;	26106: 2;	26107: 1;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 2;	26113: 3;	26114: 0;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 3;	26120: 3;	26121: 3;	26122: 2;	26123: 2;	26124: 2;	26125: 3;	26126: 2;	26127: 3;	
2023-12-01 09:59:08,320:INFO::Validation loss decreased (0.974090 --> 0.938585).  Saving model ...
2023-12-01 09:59:08,323:INFO::Epoch: 23
tensor([[0.5506, 0.5542, 0.5621, 0.5671],
        [0.5546, 0.5631, 0.5487, 0.5578],
        [0.5559, 0.5614, 0.5558, 0.5495],
        [0.5476, 0.5629, 0.5546, 0.5573]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:08,324:INFO::its now!!!!!!!!5
2023-12-01 09:59:08,544:INFO::its now!!!!!!!!0
2023-12-01 09:59:08,545:INFO::its now!!!!!!!!3
2023-12-01 09:59:08,675:INFO::its now!!!!!!!!5
2023-12-01 09:59:08,882:INFO::its now!!!!!!!!
2023-12-01 09:59:08,882:INFO::its now!!!!!!!! on 
2023-12-01 09:59:09,024:INFO::its now!!!!!!!!5
2023-12-01 09:59:09,238:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:09,239:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 0.9233 | Train_Classification_Loss 0.9549 | Dmon_Loss -0.0633 | Val_Loss 0.8970 | Search Time(s) 0.7007 | Infer Time(s) 0.2164 | Time(s) 0.9171 
2023-12-01 09:59:09,276:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 3;	4: 2;	5: 2;	6: 2;	7: 2;	8: 1;	9: 3;	10: 2;	11: 3;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 3;	26: 2;	27: 3;	28: 3;	29: 3;	30: 1;	31: 3;	32: 3;	33: 3;	34: 2;	35: 2;	36: 2;	37: 2;	38: 0;	39: 3;	40: 0;	41: 3;	42: 3;	43: 0;	44
26098: 3;	26099: 0;	26100: 2;	26101: 3;	26102: 2;	26103: 1;	26104: 3;	26105: 2;	26106: 0;	26107: 3;	26108: 3;	26109: 2;	26110: 2;	26111: 3;	26112: 3;	26113: 3;	26114: 2;	26115: 3;	26116: 2;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:59:09,277:INFO::Validation loss decreased (0.938585 --> 0.896968).  Saving model ...
2023-12-01 09:59:09,279:INFO::Epoch: 24
tensor([[0.5484, 0.5544, 0.5623, 0.5694],
        [0.5547, 0.5655, 0.5464, 0.5578],
        [0.5559, 0.5636, 0.5559, 0.5477],
        [0.5458, 0.5651, 0.5547, 0.5574]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:09,280:INFO::its now!!!!!!!!5
2023-12-01 09:59:09,486:INFO::its now!!!!!!!!0
2023-12-01 09:59:09,488:INFO::its now!!!!!!!!3
2023-12-01 09:59:09,619:INFO::its now!!!!!!!!5
2023-12-01 09:59:09,827:INFO::its now!!!!!!!!
2023-12-01 09:59:09,827:INFO::its now!!!!!!!! on 
2023-12-01 09:59:09,969:INFO::its now!!!!!!!!5
2023-12-01 09:59:10,205:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:10,208:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 0.8991 | Train_Classification_Loss 0.9310 | Dmon_Loss -0.0638 | Val_Loss 0.8580 | Search Time(s) 0.6884 | Infer Time(s) 0.2393 | Time(s) 0.9277 
2023-12-01 09:59:10,265:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 2;	8: 2;	9: 2;	10: 0;	11: 1;	12: 0;	13: 3;	14: 3;	15: 1;	16: 0;	17: 0;	18: 3;	19: 0;	20: 2;	21: 3;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 3;	33: 1;	34: 0;	35: 2;	36: 2;	37: 2;	38: 3;	39: 2;	40: 2;	41: 2;	42: 3;	43: 0;	44
26098: 3;	26099: 2;	26100: 0;	26101: 2;	26102: 3;	26103: 1;	26104: 2;	26105: 0;	26106: 2;	26107: 2;	26108: 2;	26109: 3;	26110: 2;	26111: 3;	26112: 2;	26113: 0;	26114: 0;	26115: 3;	26116: 2;	26117: 0;	26118: 3;	26119: 2;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 2;	
2023-12-01 09:59:10,266:INFO::Validation loss decreased (0.896968 --> 0.857974).  Saving model ...
2023-12-01 09:59:10,268:INFO::Epoch: 25
tensor([[0.5482, 0.5552, 0.5631, 0.5705],
        [0.5555, 0.5667, 0.5462, 0.5585],
        [0.5566, 0.5644, 0.5568, 0.5476],
        [0.5456, 0.5661, 0.5556, 0.5581]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:10,269:INFO::its now!!!!!!!!5
2023-12-01 09:59:10,481:INFO::its now!!!!!!!!0
2023-12-01 09:59:10,482:INFO::its now!!!!!!!!3
2023-12-01 09:59:10,613:INFO::its now!!!!!!!!5
2023-12-01 09:59:10,819:INFO::its now!!!!!!!!
2023-12-01 09:59:10,819:INFO::its now!!!!!!!! on 
2023-12-01 09:59:10,958:INFO::its now!!!!!!!!5
2023-12-01 09:59:11,187:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:11,189:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 0.8587 | Train_Classification_Loss 0.8904 | Dmon_Loss -0.0634 | Val_Loss 0.8225 | Search Time(s) 0.6893 | Infer Time(s) 0.2314 | Time(s) 0.9207 
2023-12-01 09:59:11,237:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 0;	4: 0;	5: 3;	6: 2;	7: 3;	8: 2;	9: 1;	10: 0;	11: 0;	12: 3;	13: 2;	14: 2;	15: 1;	16: 2;	17: 2;	18: 2;	19: 3;	20: 3;	21: 3;	22: 3;	23: 2;	24: 0;	25: 1;	26: 0;	27: 3;	28: 0;	29: 0;	30: 3;	31: 1;	32: 3;	33: 3;	34: 0;	35: 0;	36: 2;	37: 1;	38: 0;	39: 0;	40: 2;	41: 2;	42: 2;	43: 3;	44
26098: 2;	26099: 1;	26100: 3;	26101: 0;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 3;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 09:59:11,238:INFO::Validation loss decreased (0.857974 --> 0.822519).  Saving model ...
2023-12-01 09:59:11,241:INFO::Epoch: 26
tensor([[0.5479, 0.5555, 0.5633, 0.5711],
        [0.5558, 0.5673, 0.5459, 0.5588],
        [0.5568, 0.5648, 0.5571, 0.5474],
        [0.5454, 0.5663, 0.5559, 0.5584]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:11,242:INFO::its now!!!!!!!!5
2023-12-01 09:59:11,501:INFO::its now!!!!!!!!0
2023-12-01 09:59:11,503:INFO::its now!!!!!!!!3
2023-12-01 09:59:11,634:INFO::its now!!!!!!!!5
2023-12-01 09:59:11,876:INFO::its now!!!!!!!!
2023-12-01 09:59:11,877:INFO::its now!!!!!!!! on 
2023-12-01 09:59:12,018:INFO::its now!!!!!!!!5
2023-12-01 09:59:12,261:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:12,263:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 0.8286 | Train_Classification_Loss 0.8603 | Dmon_Loss -0.0634 | Val_Loss 0.7885 | Search Time(s) 0.7743 | Infer Time(s) 0.2473 | Time(s) 1.0216 
2023-12-01 09:59:12,335:INFO::cluster info:
0: 1;	1: 3;	2: 3;	3: 2;	4: 0;	5: 3;	6: 3;	7: 3;	8: 2;	9: 3;	10: 3;	11: 1;	12: 3;	13: 3;	14: 3;	15: 2;	16: 3;	17: 2;	18: 2;	19: 3;	20: 0;	21: 1;	22: 3;	23: 3;	24: 2;	25: 0;	26: 1;	27: 1;	28: 0;	29: 2;	30: 3;	31: 3;	32: 0;	33: 2;	34: 0;	35: 0;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 0;	42: 2;	43: 3;	44
26098: 2;	26099: 0;	26100: 2;	26101: 3;	26102: 2;	26103: 0;	26104: 3;	26105: 1;	26106: 2;	26107: 3;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 09:59:12,336:INFO::Validation loss decreased (0.822519 --> 0.788521).  Saving model ...
2023-12-01 09:59:12,339:INFO::Epoch: 27
tensor([[0.5536, 0.5608, 0.5681, 0.5715],
        [0.5607, 0.5676, 0.5522, 0.5635],
        [0.5615, 0.5648, 0.5627, 0.5527],
        [0.5507, 0.5664, 0.5615, 0.5631]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:12,340:INFO::its now!!!!!!!!5
2023-12-01 09:59:12,555:INFO::its now!!!!!!!!0
2023-12-01 09:59:12,557:INFO::its now!!!!!!!!3
2023-12-01 09:59:12,689:INFO::its now!!!!!!!!5
2023-12-01 09:59:12,904:INFO::its now!!!!!!!!
2023-12-01 09:59:12,904:INFO::its now!!!!!!!! on 
2023-12-01 09:59:13,027:INFO::its now!!!!!!!!5
2023-12-01 09:59:13,236:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:13,237:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 0.8025 | Train_Classification_Loss 0.8339 | Dmon_Loss -0.0628 | Val_Loss 0.7735 | Search Time(s) 0.6875 | Infer Time(s) 0.2114 | Time(s) 0.8989 
2023-12-01 09:59:13,288:INFO::cluster info:
0: 2;	1: 3;	2: 3;	3: 2;	4: 2;	5: 3;	6: 2;	7: 3;	8: 1;	9: 2;	10: 2;	11: 1;	12: 1;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 0;	19: 2;	20: 0;	21: 2;	22: 2;	23: 2;	24: 0;	25: 1;	26: 2;	27: 2;	28: 2;	29: 0;	30: 0;	31: 1;	32: 1;	33: 0;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 3;	44
26098: 2;	26099: 3;	26100: 2;	26101: 2;	26102: 0;	26103: 1;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 09:59:13,289:INFO::Validation loss decreased (0.788521 --> 0.773540).  Saving model ...
2023-12-01 09:59:13,293:INFO::Epoch: 28
tensor([[0.5619, 0.5685, 0.5750, 0.5716],
        [0.5679, 0.5677, 0.5611, 0.5704],
        [0.5685, 0.5646, 0.5707, 0.5606],
        [0.5585, 0.5664, 0.5695, 0.5701]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:13,295:INFO::its now!!!!!!!!5
2023-12-01 09:59:13,529:INFO::its now!!!!!!!!0
2023-12-01 09:59:13,530:INFO::its now!!!!!!!!3
2023-12-01 09:59:13,644:INFO::its now!!!!!!!!5
2023-12-01 09:59:13,877:INFO::its now!!!!!!!!
2023-12-01 09:59:13,877:INFO::its now!!!!!!!! on 
2023-12-01 09:59:14,003:INFO::its now!!!!!!!!5
2023-12-01 09:59:14,214:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:14,216:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 0.6965 | Train_Classification_Loss 0.7284 | Dmon_Loss -0.0638 | Val_Loss 0.6754 | Search Time(s) 0.7113 | Infer Time(s) 0.2144 | Time(s) 0.9257 
2023-12-01 09:59:14,268:INFO::cluster info:
0: 2;	1: 0;	2: 2;	3: 0;	4: 2;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 3;	11: 0;	12: 3;	13: 2;	14: 2;	15: 2;	16: 2;	17: 0;	18: 2;	19: 0;	20: 2;	21: 2;	22: 2;	23: 2;	24: 1;	25: 1;	26: 0;	27: 1;	28: 2;	29: 0;	30: 1;	31: 0;	32: 0;	33: 0;	34: 0;	35: 2;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 3;	44
26098: 2;	26099: 0;	26100: 0;	26101: 3;	26102: 2;	26103: 3;	26104: 2;	26105: 3;	26106: 2;	26107: 3;	26108: 3;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:14,269:INFO::Validation loss decreased (0.773540 --> 0.675412).  Saving model ...
2023-12-01 09:59:14,273:INFO::Epoch: 29
tensor([[0.5733, 0.5794, 0.5784, 0.5797],
        [0.5782, 0.5759, 0.5731, 0.5739],
        [0.5785, 0.5726, 0.5748, 0.5715],
        [0.5695, 0.5745, 0.5806, 0.5736]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:14,274:INFO::its now!!!!!!!!5
2023-12-01 09:59:14,512:INFO::its now!!!!!!!!0
2023-12-01 09:59:14,513:INFO::its now!!!!!!!!3
2023-12-01 09:59:14,631:INFO::its now!!!!!!!!5
2023-12-01 09:59:14,859:INFO::its now!!!!!!!!
2023-12-01 09:59:14,859:INFO::its now!!!!!!!! on 
2023-12-01 09:59:15,002:INFO::its now!!!!!!!!5
2023-12-01 09:59:15,218:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 0.7484 | Train_Classification_Loss 0.7802 | Dmon_Loss -0.0635 | Val_Loss 0.6807 | Search Time(s) 0.7113 | Infer Time(s) 0.2373 | Time(s) 0.9486 
2023-12-01 09:59:15,258:INFO::cluster info:
0: 2;	1: 0;	2: 2;	3: 2;	4: 2;	5: 2;	6: 1;	7: 1;	8: 0;	9: 2;	10: 2;	11: 2;	12: 2;	13: 1;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 1;	26: 0;	27: 2;	28: 2;	29: 2;	30: 3;	31: 1;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 0;	39: 1;	40: 2;	41: 3;	42: 2;	43: 0;	44
26098: 2;	26099: 2;	26100: 3;	26101: 3;	26102: 2;	26103: 1;	26104: 2;	26105: 1;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:59:15,259:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:15,261:INFO::Epoch: 30
tensor([[0.5796, 0.5853, 0.5807, 0.5838],
        [0.5835, 0.5805, 0.5797, 0.5762],
        [0.5836, 0.5772, 0.5774, 0.5776],
        [0.5755, 0.5791, 0.5862, 0.5759]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:15,262:INFO::its now!!!!!!!!5
2023-12-01 09:59:15,479:INFO::its now!!!!!!!!0
2023-12-01 09:59:15,480:INFO::its now!!!!!!!!3
2023-12-01 09:59:15,613:INFO::its now!!!!!!!!5
2023-12-01 09:59:15,857:INFO::its now!!!!!!!!
2023-12-01 09:59:15,857:INFO::its now!!!!!!!! on 
2023-12-01 09:59:15,983:INFO::its now!!!!!!!!5
2023-12-01 09:59:16,182:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:16,183:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 0.6624 | Train_Classification_Loss 0.6945 | Dmon_Loss -0.0642 | Val_Loss 0.6035 | Search Time(s) 0.7212 | Infer Time(s) 0.2025 | Time(s) 0.9237 
2023-12-01 09:59:16,228:INFO::cluster info:
0: 3;	1: 0;	2: 1;	3: 0;	4: 2;	5: 0;	6: 1;	7: 2;	8: 2;	9: 2;	10: 0;	11: 0;	12: 2;	13: 2;	14: 2;	15: 3;	16: 2;	17: 0;	18: 1;	19: 2;	20: 2;	21: 2;	22: 1;	23: 2;	24: 3;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 0;	32: 2;	33: 3;	34: 0;	35: 2;	36: 2;	37: 3;	38: 0;	39: 2;	40: 3;	41: 0;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 2;	26104: 0;	26105: 1;	26106: 3;	26107: 2;	26108: 0;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:16,229:INFO::Validation loss decreased (0.675412 --> 0.603491).  Saving model ...
2023-12-01 09:59:16,233:INFO::Epoch: 31
tensor([[0.5863, 0.5884, 0.5855, 0.5893],
        [0.5862, 0.5863, 0.5867, 0.5810],
        [0.5862, 0.5830, 0.5829, 0.5841],
        [0.5819, 0.5849, 0.5891, 0.5808]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:16,234:INFO::its now!!!!!!!!5
2023-12-01 09:59:16,469:INFO::its now!!!!!!!!0
2023-12-01 09:59:16,469:INFO::its now!!!!!!!!3
2023-12-01 09:59:16,585:INFO::its now!!!!!!!!5
2023-12-01 09:59:16,807:INFO::its now!!!!!!!!
2023-12-01 09:59:16,807:INFO::its now!!!!!!!! on 
2023-12-01 09:59:16,934:INFO::its now!!!!!!!!5
2023-12-01 09:59:17,150:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 0.6593 | Train_Classification_Loss 0.6910 | Dmon_Loss -0.0634 | Val_Loss 0.6371 | Search Time(s) 0.7013 | Infer Time(s) 0.2184 | Time(s) 0.9197 
2023-12-01 09:59:17,196:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 3;	5: 1;	6: 0;	7: 2;	8: 1;	9: 1;	10: 1;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 0;	18: 0;	19: 1;	20: 2;	21: 2;	22: 2;	23: 1;	24: 3;	25: 2;	26: 0;	27: 2;	28: 2;	29: 0;	30: 2;	31: 0;	32: 1;	33: 0;	34: 2;	35: 2;	36: 0;	37: 0;	38: 0;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 1;	26101: 1;	26102: 3;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 2;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:59:17,197:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:17,200:INFO::Epoch: 32
tensor([[0.5869, 0.5872, 0.5851, 0.5920],
        [0.5850, 0.5866, 0.5902, 0.5807],
        [0.5876, 0.5832, 0.5825, 0.5847],
        [0.5826, 0.5851, 0.5905, 0.5804]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:17,201:INFO::its now!!!!!!!!5
2023-12-01 09:59:17,423:INFO::its now!!!!!!!!0
2023-12-01 09:59:17,425:INFO::its now!!!!!!!!3
2023-12-01 09:59:17,542:INFO::its now!!!!!!!!5
2023-12-01 09:59:17,795:INFO::its now!!!!!!!!
2023-12-01 09:59:17,795:INFO::its now!!!!!!!! on 
2023-12-01 09:59:17,922:INFO::its now!!!!!!!!5
2023-12-01 09:59:18,118:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:18,120:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 0.6394 | Train_Classification_Loss 0.6715 | Dmon_Loss -0.0643 | Val_Loss 0.5450 | Search Time(s) 0.7212 | Infer Time(s) 0.1994 | Time(s) 0.9207 
2023-12-01 09:59:18,169:INFO::cluster info:
0: 1;	1: 0;	2: 2;	3: 2;	4: 2;	5: 2;	6: 1;	7: 1;	8: 1;	9: 0;	10: 0;	11: 2;	12: 1;	13: 3;	14: 2;	15: 1;	16: 2;	17: 0;	18: 1;	19: 2;	20: 2;	21: 2;	22: 2;	23: 1;	24: 1;	25: 2;	26: 0;	27: 2;	28: 0;	29: 2;	30: 2;	31: 3;	32: 2;	33: 3;	34: 3;	35: 2;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 0;	42: 2;	43: 2;	44
26098: 1;	26099: 3;	26100: 3;	26101: 3;	26102: 0;	26103: 3;	26104: 0;	26105: 0;	26106: 1;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 0;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 1;	
2023-12-01 09:59:18,170:INFO::Validation loss decreased (0.603491 --> 0.545035).  Saving model ...
2023-12-01 09:59:18,172:INFO::Epoch: 33
tensor([[0.5870, 0.5865, 0.5847, 0.5934],
        [0.5842, 0.5865, 0.5920, 0.5803],
        [0.5883, 0.5831, 0.5820, 0.5848],
        [0.5827, 0.5850, 0.5912, 0.5800]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:18,173:INFO::its now!!!!!!!!5
2023-12-01 09:59:18,380:INFO::its now!!!!!!!!0
2023-12-01 09:59:18,381:INFO::its now!!!!!!!!3
2023-12-01 09:59:18,515:INFO::its now!!!!!!!!5
2023-12-01 09:59:18,747:INFO::its now!!!!!!!!
2023-12-01 09:59:18,747:INFO::its now!!!!!!!! on 
2023-12-01 09:59:18,873:INFO::its now!!!!!!!!5
2023-12-01 09:59:19,094:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 0.5995 | Train_Classification_Loss 0.6315 | Dmon_Loss -0.0640 | Val_Loss 0.5545 | Search Time(s) 0.6993 | Infer Time(s) 0.2244 | Time(s) 0.9237 
2023-12-01 09:59:19,131:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 2;	4: 2;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 0;	20: 2;	21: 2;	22: 3;	23: 2;	24: 2;	25: 1;	26: 1;	27: 1;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 2;	26102: 2;	26103: 3;	26104: 2;	26105: 1;	26106: 1;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:59:19,132:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:19,135:INFO::Epoch: 34
tensor([[0.5871, 0.5834, 0.5818, 0.5914],
        [0.5838, 0.5837, 0.5900, 0.5773],
        [0.5862, 0.5828, 0.5787, 0.5822],
        [0.5801, 0.5823, 0.5916, 0.5770]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:19,136:INFO::its now!!!!!!!!5
2023-12-01 09:59:19,329:INFO::its now!!!!!!!!0
2023-12-01 09:59:19,330:INFO::its now!!!!!!!!3
2023-12-01 09:59:19,447:INFO::its now!!!!!!!!5
2023-12-01 09:59:19,668:INFO::its now!!!!!!!!
2023-12-01 09:59:19,668:INFO::its now!!!!!!!! on 
2023-12-01 09:59:19,796:INFO::its now!!!!!!!!5
2023-12-01 09:59:19,988:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:19,990:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 0.5807 | Train_Classification_Loss 0.6132 | Dmon_Loss -0.0650 | Val_Loss 0.4894 | Search Time(s) 0.6603 | Infer Time(s) 0.1945 | Time(s) 0.8548 
2023-12-01 09:59:20,032:INFO::cluster info:
0: 1;	1: 2;	2: 1;	3: 1;	4: 1;	5: 2;	6: 0;	7: 3;	8: 0;	9: 2;	10: 3;	11: 2;	12: 2;	13: 2;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 0;	20: 2;	21: 2;	22: 2;	23: 1;	24: 1;	25: 2;	26: 2;	27: 2;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 0;	34: 2;	35: 2;	36: 2;	37: 3;	38: 0;	39: 2;	40: 0;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 0;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 1;	
2023-12-01 09:59:20,033:INFO::Validation loss decreased (0.545035 --> 0.489390).  Saving model ...
2023-12-01 09:59:20,037:INFO::Epoch: 35
tensor([[0.5837, 0.5786, 0.5768, 0.5903],
        [0.5804, 0.5790, 0.5890, 0.5724],
        [0.5852, 0.5792, 0.5731, 0.5777],
        [0.5756, 0.5775, 0.5917, 0.5721]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:20,038:INFO::its now!!!!!!!!5
2023-12-01 09:59:20,244:INFO::its now!!!!!!!!0
2023-12-01 09:59:20,245:INFO::its now!!!!!!!!3
2023-12-01 09:59:20,362:INFO::its now!!!!!!!!5
2023-12-01 09:59:20,573:INFO::its now!!!!!!!!
2023-12-01 09:59:20,573:INFO::its now!!!!!!!! on 
2023-12-01 09:59:20,697:INFO::its now!!!!!!!!5
2023-12-01 09:59:20,926:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 0.6002 | Train_Classification_Loss 0.6323 | Dmon_Loss -0.0642 | Val_Loss 0.5270 | Search Time(s) 0.6604 | Infer Time(s) 0.2314 | Time(s) 0.8918 
2023-12-01 09:59:20,978:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 1;	10: 2;	11: 2;	12: 2;	13: 3;	14: 2;	15: 1;	16: 2;	17: 2;	18: 1;	19: 3;	20: 2;	21: 2;	22: 0;	23: 2;	24: 2;	25: 2;	26: 1;	27: 2;	28: 1;	29: 2;	30: 2;	31: 3;	32: 2;	33: 3;	34: 2;	35: 2;	36: 1;	37: 3;	38: 1;	39: 2;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 1;	26099: 1;	26100: 1;	26101: 2;	26102: 2;	26103: 3;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:59:20,979:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:20,981:INFO::Epoch: 36
tensor([[0.5776, 0.5719, 0.5699, 0.5896],
        [0.5745, 0.5722, 0.5884, 0.5655],
        [0.5849, 0.5730, 0.5655, 0.5712],
        [0.5691, 0.5708, 0.5918, 0.5652]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:20,982:INFO::its now!!!!!!!!5
2023-12-01 09:59:21,177:INFO::its now!!!!!!!!0
2023-12-01 09:59:21,178:INFO::its now!!!!!!!!3
2023-12-01 09:59:21,295:INFO::its now!!!!!!!!5
2023-12-01 09:59:21,553:INFO::its now!!!!!!!!
2023-12-01 09:59:21,553:INFO::its now!!!!!!!! on 
2023-12-01 09:59:21,680:INFO::its now!!!!!!!!5
2023-12-01 09:59:21,904:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:21,906:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 0.5092 | Train_Classification_Loss 0.5425 | Dmon_Loss -0.0664 | Val_Loss 0.4529 | Search Time(s) 0.6973 | Infer Time(s) 0.2274 | Time(s) 0.9247 
2023-12-01 09:59:21,969:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 0;	7: 2;	8: 2;	9: 1;	10: 0;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 1;	17: 0;	18: 2;	19: 2;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 1;	26: 1;	27: 2;	28: 3;	29: 2;	30: 2;	31: 3;	32: 1;	33: 0;	34: 0;	35: 2;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 0;	42: 2;	43: 2;	44
26098: 1;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 3;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:21,970:INFO::Validation loss decreased (0.489390 --> 0.452930).  Saving model ...
2023-12-01 09:59:21,972:INFO::Epoch: 37
tensor([[0.5707, 0.5649, 0.5626, 0.5893],
        [0.5679, 0.5651, 0.5880, 0.5582],
        [0.5846, 0.5660, 0.5575, 0.5643],
        [0.5622, 0.5637, 0.5918, 0.5578]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:21,973:INFO::its now!!!!!!!!5
2023-12-01 09:59:22,162:INFO::its now!!!!!!!!0
2023-12-01 09:59:22,163:INFO::its now!!!!!!!!3
2023-12-01 09:59:22,282:INFO::its now!!!!!!!!5
2023-12-01 09:59:22,490:INFO::its now!!!!!!!!
2023-12-01 09:59:22,490:INFO::its now!!!!!!!! on 
2023-12-01 09:59:22,619:INFO::its now!!!!!!!!5
2023-12-01 09:59:22,821:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 0.5375 | Train_Classification_Loss 0.5698 | Dmon_Loss -0.0646 | Val_Loss 0.4906 | Search Time(s) 0.6449 | Infer Time(s) 0.2061 | Time(s) 0.8510 
2023-12-01 09:59:22,875:INFO::cluster info:
0: 2;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 0;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 1;	16: 1;	17: 1;	18: 2;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 2;	32: 2;	33: 3;	34: 0;	35: 1;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 1;	42: 2;	43: 1;	44
26098: 1;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:59:22,876:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:22,880:INFO::Epoch: 38
tensor([[0.5608, 0.5551, 0.5526, 0.5889],
        [0.5584, 0.5552, 0.5876, 0.5481],
        [0.5844, 0.5561, 0.5466, 0.5546],
        [0.5525, 0.5538, 0.5918, 0.5477]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:22,881:INFO::its now!!!!!!!!5
2023-12-01 09:59:23,093:INFO::its now!!!!!!!!0
2023-12-01 09:59:23,094:INFO::its now!!!!!!!!3
2023-12-01 09:59:23,213:INFO::its now!!!!!!!!5
2023-12-01 09:59:23,459:INFO::its now!!!!!!!!
2023-12-01 09:59:23,460:INFO::its now!!!!!!!! on 
2023-12-01 09:59:23,586:INFO::its now!!!!!!!!5
2023-12-01 09:59:23,796:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:23,798:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 0.4797 | Train_Classification_Loss 0.5142 | Dmon_Loss -0.0690 | Val_Loss 0.3875 | Search Time(s) 0.7086 | Infer Time(s) 0.2120 | Time(s) 0.9206 
2023-12-01 09:59:23,837:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 1;	5: 2;	6: 0;	7: 2;	8: 1;	9: 1;	10: 0;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 2;	17: 0;	18: 0;	19: 2;	20: 2;	21: 2;	22: 2;	23: 1;	24: 2;	25: 1;	26: 1;	27: 2;	28: 2;	29: 0;	30: 0;	31: 0;	32: 1;	33: 0;	34: 0;	35: 2;	36: 2;	37: 3;	38: 0;	39: 2;	40: 0;	41: 0;	42: 2;	43: 0;	44
26098: 3;	26099: 0;	26100: 1;	26101: 1;	26102: 2;	26103: 3;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:23,838:INFO::Validation loss decreased (0.452930 --> 0.387538).  Saving model ...
2023-12-01 09:59:23,841:INFO::Epoch: 39
tensor([[0.5556, 0.5500, 0.5473, 0.5887],
        [0.5535, 0.5500, 0.5874, 0.5428],
        [0.5845, 0.5510, 0.5409, 0.5495],
        [0.5474, 0.5485, 0.5917, 0.5424]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:23,842:INFO::its now!!!!!!!!5
2023-12-01 09:59:24,060:INFO::its now!!!!!!!!0
2023-12-01 09:59:24,061:INFO::its now!!!!!!!!3
2023-12-01 09:59:24,177:INFO::its now!!!!!!!!5
2023-12-01 09:59:24,404:INFO::its now!!!!!!!!
2023-12-01 09:59:24,404:INFO::its now!!!!!!!! on 
2023-12-01 09:59:24,530:INFO::its now!!!!!!!!5
2023-12-01 09:59:24,720:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 0.5224 | Train_Classification_Loss 0.5551 | Dmon_Loss -0.0654 | Val_Loss 0.4572 | Search Time(s) 0.6891 | Infer Time(s) 0.1927 | Time(s) 0.8818 
2023-12-01 09:59:24,759:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 2;	13: 2;	14: 1;	15: 1;	16: 1;	17: 3;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 2;	26: 1;	27: 2;	28: 3;	29: 1;	30: 1;	31: 1;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 0;	39: 2;	40: 1;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 2;	26100: 2;	26101: 0;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 1;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 1;	26121: 1;	26122: 2;	26123: 2;	26124: 2;	26125: 1;	26126: 2;	26127: 2;	
2023-12-01 09:59:24,760:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:24,763:INFO::Epoch: 40
tensor([[0.5465, 0.5410, 0.5381, 0.5886],
        [0.5446, 0.5409, 0.5872, 0.5336],
        [0.5846, 0.5418, 0.5311, 0.5406],
        [0.5385, 0.5395, 0.5917, 0.5332]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:24,763:INFO::its now!!!!!!!!5
2023-12-01 09:59:24,988:INFO::its now!!!!!!!!0
2023-12-01 09:59:24,988:INFO::its now!!!!!!!!3
2023-12-01 09:59:25,109:INFO::its now!!!!!!!!5
2023-12-01 09:59:25,328:INFO::its now!!!!!!!!
2023-12-01 09:59:25,329:INFO::its now!!!!!!!! on 
2023-12-01 09:59:25,456:INFO::its now!!!!!!!!5
2023-12-01 09:59:25,678:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 0.4544 | Train_Classification_Loss 0.4882 | Dmon_Loss -0.0677 | Val_Loss 0.4222 | Search Time(s) 0.6933 | Infer Time(s) 0.2244 | Time(s) 0.9177 
2023-12-01 09:59:25,722:INFO::cluster info:
0: 1;	1: 2;	2: 1;	3: 2;	4: 1;	5: 2;	6: 0;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 0;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 1;	24: 3;	25: 2;	26: 0;	27: 1;	28: 2;	29: 0;	30: 0;	31: 3;	32: 1;	33: 0;	34: 0;	35: 2;	36: 0;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:25,723:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:59:25,726:INFO::Epoch: 41
tensor([[0.5400, 0.5346, 0.5316, 0.5886],
        [0.5384, 0.5345, 0.5868, 0.5271],
        [0.5847, 0.5353, 0.5242, 0.5343],
        [0.5322, 0.5330, 0.5916, 0.5267]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:25,727:INFO::its now!!!!!!!!5
2023-12-01 09:59:25,943:INFO::its now!!!!!!!!0
2023-12-01 09:59:25,944:INFO::its now!!!!!!!!3
2023-12-01 09:59:26,061:INFO::its now!!!!!!!!5
2023-12-01 09:59:26,276:INFO::its now!!!!!!!!
2023-12-01 09:59:26,276:INFO::its now!!!!!!!! on 
2023-12-01 09:59:26,404:INFO::its now!!!!!!!!5
2023-12-01 09:59:26,611:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 0.4118 | Train_Classification_Loss 0.4456 | Dmon_Loss -0.0676 | Val_Loss 0.3878 | Search Time(s) 0.6752 | Infer Time(s) 0.2114 | Time(s) 0.8866 
2023-12-01 09:59:26,648:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 0;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 2;	13: 2;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 0;	30: 3;	31: 1;	32: 1;	33: 3;	34: 2;	35: 2;	36: 1;	37: 2;	38: 0;	39: 2;	40: 2;	41: 0;	42: 2;	43: 2;	44
26098: 1;	26099: 2;	26100: 3;	26101: 2;	26102: 3;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:59:26,649:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:59:26,652:INFO::Epoch: 42
tensor([[0.5288, 0.5235, 0.5203, 0.5881],
        [0.5274, 0.5233, 0.5866, 0.5158],
        [0.5847, 0.5241, 0.5124, 0.5232],
        [0.5212, 0.5218, 0.5916, 0.5154]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:26,653:INFO::its now!!!!!!!!5
2023-12-01 09:59:26,887:INFO::its now!!!!!!!!0
2023-12-01 09:59:26,887:INFO::its now!!!!!!!!3
2023-12-01 09:59:27,003:INFO::its now!!!!!!!!5
2023-12-01 09:59:27,221:INFO::its now!!!!!!!!
2023-12-01 09:59:27,221:INFO::its now!!!!!!!! on 
2023-12-01 09:59:27,350:INFO::its now!!!!!!!!5
2023-12-01 09:59:27,558:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:27,560:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 0.4457 | Train_Classification_Loss 0.4818 | Dmon_Loss -0.0722 | Val_Loss 0.3730 | Search Time(s) 0.6982 | Infer Time(s) 0.2104 | Time(s) 0.9086 
2023-12-01 09:59:27,598:INFO::cluster info:
0: 1;	1: 0;	2: 2;	3: 2;	4: 1;	5: 0;	6: 0;	7: 1;	8: 1;	9: 2;	10: 2;	11: 1;	12: 2;	13: 3;	14: 2;	15: 2;	16: 2;	17: 0;	18: 1;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 1;	26: 1;	27: 2;	28: 2;	29: 0;	30: 0;	31: 1;	32: 1;	33: 2;	34: 0;	35: 2;	36: 2;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:27,599:INFO::Validation loss decreased (0.387538 --> 0.373005).  Saving model ...
2023-12-01 09:59:27,602:INFO::Epoch: 43
tensor([[0.5287, 0.5235, 0.5202, 0.5879],
        [0.5274, 0.5232, 0.5862, 0.5158],
        [0.5846, 0.5241, 0.5124, 0.5232],
        [0.5212, 0.5218, 0.5916, 0.5154]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:27,603:INFO::its now!!!!!!!!5
2023-12-01 09:59:27,822:INFO::its now!!!!!!!!0
2023-12-01 09:59:27,823:INFO::its now!!!!!!!!3
2023-12-01 09:59:27,940:INFO::its now!!!!!!!!5
2023-12-01 09:59:28,148:INFO::its now!!!!!!!!
2023-12-01 09:59:28,148:INFO::its now!!!!!!!! on 
2023-12-01 09:59:28,275:INFO::its now!!!!!!!!5
2023-12-01 09:59:28,487:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:28,489:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 0.3972 | Train_Classification_Loss 0.4315 | Dmon_Loss -0.0687 | Val_Loss 0.3660 | Search Time(s) 0.6722 | Infer Time(s) 0.2154 | Time(s) 0.8876 
2023-12-01 09:59:28,549:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 0;	5: 1;	6: 0;	7: 1;	8: 1;	9: 1;	10: 2;	11: 0;	12: 2;	13: 3;	14: 1;	15: 2;	16: 1;	17: 0;	18: 1;	19: 0;	20: 1;	21: 2;	22: 0;	23: 2;	24: 2;	25: 1;	26: 0;	27: 2;	28: 0;	29: 0;	30: 1;	31: 0;	32: 1;	33: 3;	34: 2;	35: 2;	36: 1;	37: 2;	38: 0;	39: 1;	40: 2;	41: 0;	42: 2;	43: 3;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 3;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 2;	26115: 2;	26116: 1;	26117: 0;	26118: 3;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 09:59:28,551:INFO::Validation loss decreased (0.373005 --> 0.365950).  Saving model ...
2023-12-01 09:59:28,554:INFO::Epoch: 44
tensor([[0.5220, 0.5168, 0.5135, 0.5877],
        [0.5208, 0.5165, 0.5860, 0.5090],
        [0.5841, 0.5173, 0.5054, 0.5165],
        [0.5145, 0.5151, 0.5916, 0.5086]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:28,554:INFO::its now!!!!!!!!5
2023-12-01 09:59:28,796:INFO::its now!!!!!!!!0
2023-12-01 09:59:28,797:INFO::its now!!!!!!!!3
2023-12-01 09:59:28,915:INFO::its now!!!!!!!!5
2023-12-01 09:59:29,134:INFO::its now!!!!!!!!
2023-12-01 09:59:29,134:INFO::its now!!!!!!!! on 
2023-12-01 09:59:29,261:INFO::its now!!!!!!!!5
2023-12-01 09:59:29,478:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:29,479:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 0.4277 | Train_Classification_Loss 0.4650 | Dmon_Loss -0.0745 | Val_Loss 0.3603 | Search Time(s) 0.7061 | Infer Time(s) 0.2204 | Time(s) 0.9265 
2023-12-01 09:59:29,520:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 2;	4: 3;	5: 1;	6: 1;	7: 1;	8: 2;	9: 1;	10: 2;	11: 1;	12: 2;	13: 3;	14: 2;	15: 0;	16: 2;	17: 0;	18: 2;	19: 2;	20: 2;	21: 2;	22: 0;	23: 1;	24: 2;	25: 1;	26: 2;	27: 2;	28: 0;	29: 0;	30: 0;	31: 1;	32: 2;	33: 0;	34: 0;	35: 2;	36: 3;	37: 3;	38: 0;	39: 2;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 0;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:29,521:INFO::Validation loss decreased (0.365950 --> 0.360330).  Saving model ...
2023-12-01 09:59:29,525:INFO::Epoch: 45
tensor([[0.5237, 0.5184, 0.5151, 0.5875],
        [0.5224, 0.5182, 0.5857, 0.5107],
        [0.5838, 0.5190, 0.5071, 0.5182],
        [0.5161, 0.5167, 0.5915, 0.5102]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:29,526:INFO::its now!!!!!!!!5
2023-12-01 09:59:29,764:INFO::its now!!!!!!!!0
2023-12-01 09:59:29,765:INFO::its now!!!!!!!!3
2023-12-01 09:59:29,881:INFO::its now!!!!!!!!5
2023-12-01 09:59:30,115:INFO::its now!!!!!!!!
2023-12-01 09:59:30,115:INFO::its now!!!!!!!! on 
2023-12-01 09:59:30,242:INFO::its now!!!!!!!!5
2023-12-01 09:59:30,462:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 0.4168 | Train_Classification_Loss 0.4517 | Dmon_Loss -0.0697 | Val_Loss 0.3762 | Search Time(s) 0.7191 | Infer Time(s) 0.2204 | Time(s) 0.9395 
2023-12-01 09:59:30,512:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 1;	13: 3;	14: 1;	15: 2;	16: 1;	17: 0;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 0;	34: 2;	35: 2;	36: 1;	37: 3;	38: 0;	39: 2;	40: 2;	41: 0;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 3;	26102: 3;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 1;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 2;	26124: 2;	26125: 1;	26126: 2;	26127: 2;	
2023-12-01 09:59:30,513:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:30,516:INFO::Epoch: 46
tensor([[0.5208, 0.5156, 0.5123, 0.5872],
        [0.5196, 0.5153, 0.5855, 0.5078],
        [0.5834, 0.5161, 0.5042, 0.5153],
        [0.5133, 0.5139, 0.5915, 0.5074]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:30,517:INFO::its now!!!!!!!!5
2023-12-01 09:59:30,735:INFO::its now!!!!!!!!0
2023-12-01 09:59:30,736:INFO::its now!!!!!!!!3
2023-12-01 09:59:30,852:INFO::its now!!!!!!!!5
2023-12-01 09:59:31,065:INFO::its now!!!!!!!!
2023-12-01 09:59:31,065:INFO::its now!!!!!!!! on 
2023-12-01 09:59:31,192:INFO::its now!!!!!!!!5
2023-12-01 09:59:31,407:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 0.4140 | Train_Classification_Loss 0.4532 | Dmon_Loss -0.0784 | Val_Loss 0.3673 | Search Time(s) 0.6762 | Infer Time(s) 0.2184 | Time(s) 0.8946 
2023-12-01 09:59:31,457:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 0;	5: 1;	6: 0;	7: 1;	8: 0;	9: 1;	10: 0;	11: 1;	12: 2;	13: 2;	14: 1;	15: 0;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 2;	23: 1;	24: 0;	25: 1;	26: 1;	27: 1;	28: 2;	29: 0;	30: 2;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 2;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 2;	26099: 2;	26100: 3;	26101: 3;	26102: 2;	26103: 3;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 2;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:31,458:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:59:31,461:INFO::Epoch: 47
tensor([[0.5212, 0.5161, 0.5127, 0.5870],
        [0.5200, 0.5158, 0.5852, 0.5083],
        [0.5832, 0.5165, 0.5047, 0.5158],
        [0.5138, 0.5143, 0.5915, 0.5078]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:31,461:INFO::its now!!!!!!!!5
2023-12-01 09:59:31,658:INFO::its now!!!!!!!!0
2023-12-01 09:59:31,659:INFO::its now!!!!!!!!3
2023-12-01 09:59:31,775:INFO::its now!!!!!!!!5
2023-12-01 09:59:32,011:INFO::its now!!!!!!!!
2023-12-01 09:59:32,011:INFO::its now!!!!!!!! on 
2023-12-01 09:59:32,138:INFO::its now!!!!!!!!5
2023-12-01 09:59:32,374:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 0.3874 | Train_Classification_Loss 0.4240 | Dmon_Loss -0.0732 | Val_Loss 0.3783 | Search Time(s) 0.6752 | Infer Time(s) 0.2393 | Time(s) 0.9146 
2023-12-01 09:59:32,420:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 1;	13: 1;	14: 1;	15: 2;	16: 1;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 1;	26: 1;	27: 1;	28: 3;	29: 1;	30: 1;	31: 1;	32: 1;	33: 3;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 3;	26105: 3;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 1;	26122: 2;	26123: 2;	26124: 2;	26125: 1;	26126: 2;	26127: 1;	
2023-12-01 09:59:32,421:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:59:32,424:INFO::Epoch: 48
tensor([[0.5166, 0.5115, 0.5081, 0.5865],
        [0.5155, 0.5112, 0.5850, 0.5037],
        [0.5829, 0.5119, 0.4999, 0.5112],
        [0.5092, 0.5097, 0.5914, 0.5032]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:32,424:INFO::its now!!!!!!!!5
2023-12-01 09:59:32,624:INFO::its now!!!!!!!!0
2023-12-01 09:59:32,625:INFO::its now!!!!!!!!3
2023-12-01 09:59:32,741:INFO::its now!!!!!!!!5
2023-12-01 09:59:32,962:INFO::its now!!!!!!!!
2023-12-01 09:59:32,962:INFO::its now!!!!!!!! on 
2023-12-01 09:59:33,089:INFO::its now!!!!!!!!5
2023-12-01 09:59:33,289:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 0.4343 | Train_Classification_Loss 0.4722 | Dmon_Loss -0.0758 | Val_Loss 0.3615 | Search Time(s) 0.6652 | Infer Time(s) 0.2034 | Time(s) 0.8687 
2023-12-01 09:59:33,343:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 2;	9: 1;	10: 2;	11: 2;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 2;	20: 2;	21: 2;	22: 1;	23: 2;	24: 1;	25: 2;	26: 1;	27: 2;	28: 3;	29: 2;	30: 1;	31: 0;	32: 1;	33: 0;	34: 0;	35: 2;	36: 2;	37: 0;	38: 2;	39: 1;	40: 2;	41: 0;	42: 2;	43: 2;	44
26098: 2;	26099: 1;	26100: 1;	26101: 3;	26102: 3;	26103: 2;	26104: 1;	26105: 3;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:33,344:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:59:33,346:INFO::Epoch: 49
tensor([[0.5137, 0.5086, 0.5052, 0.5862],
        [0.5126, 0.5083, 0.5848, 0.5008],
        [0.5826, 0.5090, 0.4970, 0.5084],
        [0.5063, 0.5069, 0.5914, 0.5003]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:33,347:INFO::its now!!!!!!!!5
2023-12-01 09:59:33,554:INFO::its now!!!!!!!!0
2023-12-01 09:59:33,555:INFO::its now!!!!!!!!3
2023-12-01 09:59:33,672:INFO::its now!!!!!!!!5
2023-12-01 09:59:33,894:INFO::its now!!!!!!!!
2023-12-01 09:59:33,894:INFO::its now!!!!!!!! on 
2023-12-01 09:59:34,019:INFO::its now!!!!!!!!5
2023-12-01 09:59:34,257:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:34,259:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 0.4054 | Train_Classification_Loss 0.4439 | Dmon_Loss -0.0771 | Val_Loss 0.3406 | Search Time(s) 0.6722 | Infer Time(s) 0.2404 | Time(s) 0.9126 
2023-12-01 09:59:34,309:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 2;	11: 1;	12: 2;	13: 2;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 0;	30: 3;	31: 1;	32: 2;	33: 0;	34: 0;	35: 2;	36: 0;	37: 3;	38: 0;	39: 2;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 3;	26100: 3;	26101: 3;	26102: 2;	26103: 2;	26104: 1;	26105: 3;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 2;	26125: 1;	26126: 2;	26127: 2;	
2023-12-01 09:59:34,310:INFO::Validation loss decreased (0.360330 --> 0.340628).  Saving model ...
2023-12-01 09:59:34,314:INFO::Epoch: 50
tensor([[0.5061, 0.5010, 0.4975, 0.5863],
        [0.5051, 0.5007, 0.5847, 0.4931],
        [0.5818, 0.5014, 0.4891, 0.5008],
        [0.4988, 0.4992, 0.5914, 0.4926]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:34,315:INFO::its now!!!!!!!!5
2023-12-01 09:59:34,521:INFO::its now!!!!!!!!0
2023-12-01 09:59:34,523:INFO::its now!!!!!!!!3
2023-12-01 09:59:34,639:INFO::its now!!!!!!!!5
2023-12-01 09:59:34,853:INFO::its now!!!!!!!!
2023-12-01 09:59:34,853:INFO::its now!!!!!!!! on 
2023-12-01 09:59:34,980:INFO::its now!!!!!!!!5
2023-12-01 09:59:35,175:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:35,177:INFO::Epoch 00050 | lr 0.00050 | Train_Loss 0.3253 | Train_Classification_Loss 0.3659 | Dmon_Loss -0.0811 | Val_Loss 0.3370 | Search Time(s) 0.6653 | Infer Time(s) 0.1984 | Time(s) 0.8637 
2023-12-01 09:59:35,215:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 0;	7: 1;	8: 0;	9: 1;	10: 0;	11: 1;	12: 2;	13: 2;	14: 1;	15: 0;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 1;	26: 1;	27: 1;	28: 2;	29: 0;	30: 3;	31: 0;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 2;	38: 0;	39: 2;	40: 0;	41: 0;	42: 2;	43: 2;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 3;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:35,216:INFO::Validation loss decreased (0.340628 --> 0.336972).  Saving model ...
2023-12-01 09:59:35,218:INFO::Epoch: 51
tensor([[0.4996, 0.4946, 0.4911, 0.5864],
        [0.4987, 0.4942, 0.5845, 0.4866],
        [0.5810, 0.4949, 0.4825, 0.4944],
        [0.4924, 0.4928, 0.5914, 0.4862]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:35,219:INFO::its now!!!!!!!!5
2023-12-01 09:59:35,425:INFO::its now!!!!!!!!0
2023-12-01 09:59:35,426:INFO::its now!!!!!!!!3
2023-12-01 09:59:35,543:INFO::its now!!!!!!!!5
2023-12-01 09:59:35,779:INFO::its now!!!!!!!!
2023-12-01 09:59:35,779:INFO::its now!!!!!!!! on 
2023-12-01 09:59:35,904:INFO::its now!!!!!!!!5
2023-12-01 09:59:36,104:INFO::Epoch 00051 | lr 0.00050 | Train_Loss 0.3773 | Train_Classification_Loss 0.4173 | Dmon_Loss -0.0800 | Val_Loss 0.3502 | Search Time(s) 0.6842 | Infer Time(s) 0.2024 | Time(s) 0.8866 
2023-12-01 09:59:36,141:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 0;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 1;	26: 1;	27: 2;	28: 3;	29: 0;	30: 3;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 3;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 2;	26102: 1;	26103: 3;	26104: 1;	26105: 2;	26106: 3;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 3;	26120: 3;	26121: 1;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:36,143:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:36,146:INFO::Epoch: 52
tensor([[0.4909, 0.4860, 0.4824, 0.5861],
        [0.4901, 0.4855, 0.5845, 0.4779],
        [0.5806, 0.4862, 0.4737, 0.4858],
        [0.4838, 0.4841, 0.5912, 0.4774]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:36,147:INFO::its now!!!!!!!!5
2023-12-01 09:59:36,368:INFO::its now!!!!!!!!0
2023-12-01 09:59:36,369:INFO::its now!!!!!!!!3
2023-12-01 09:59:36,488:INFO::its now!!!!!!!!5
2023-12-01 09:59:36,705:INFO::its now!!!!!!!!
2023-12-01 09:59:36,706:INFO::its now!!!!!!!! on 
2023-12-01 09:59:36,833:INFO::its now!!!!!!!!5
2023-12-01 09:59:37,039:INFO::Epoch 00052 | lr 0.00050 | Train_Loss 0.3526 | Train_Classification_Loss 0.3946 | Dmon_Loss -0.0838 | Val_Loss 0.3589 | Search Time(s) 0.6862 | Infer Time(s) 0.2094 | Time(s) 0.8956 
2023-12-01 09:59:37,078:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 2;	11: 1;	12: 2;	13: 2;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 2;	23: 1;	24: 2;	25: 2;	26: 1;	27: 2;	28: 0;	29: 0;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:37,079:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:59:37,082:INFO::Epoch: 53
tensor([[0.4844, 0.4794, 0.4758, 0.5857],
        [0.4836, 0.4790, 0.5843, 0.4713],
        [0.5803, 0.4797, 0.4670, 0.4792],
        [0.4772, 0.4776, 0.5910, 0.4709]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:37,083:INFO::its now!!!!!!!!5
2023-12-01 09:59:37,279:INFO::its now!!!!!!!!0
2023-12-01 09:59:37,280:INFO::its now!!!!!!!!3
2023-12-01 09:59:37,396:INFO::its now!!!!!!!!5
2023-12-01 09:59:37,622:INFO::its now!!!!!!!!
2023-12-01 09:59:37,622:INFO::its now!!!!!!!! on 
2023-12-01 09:59:37,749:INFO::its now!!!!!!!!5
2023-12-01 09:59:37,956:INFO::Epoch 00053 | lr 0.00050 | Train_Loss 0.3650 | Train_Classification_Loss 0.4058 | Dmon_Loss -0.0816 | Val_Loss 0.3381 | Search Time(s) 0.6652 | Infer Time(s) 0.2104 | Time(s) 0.8756 
2023-12-01 09:59:38,006:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 1;	12: 2;	13: 2;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 1;	28: 3;	29: 0;	30: 0;	31: 1;	32: 1;	33: 3;	34: 0;	35: 2;	36: 3;	37: 2;	38: 2;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 2;	26102: 1;	26103: 3;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 1;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 2;	26124: 2;	26125: 3;	26126: 2;	26127: 2;	
2023-12-01 09:59:38,007:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:59:38,009:INFO::Epoch: 54
tensor([[0.4806, 0.4757, 0.4720, 0.5854],
        [0.4799, 0.4752, 0.5842, 0.4676],
        [0.5799, 0.4759, 0.4631, 0.4755],
        [0.4735, 0.4738, 0.5908, 0.4671]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:38,010:INFO::its now!!!!!!!!5
2023-12-01 09:59:38,216:INFO::its now!!!!!!!!0
2023-12-01 09:59:38,217:INFO::its now!!!!!!!!3
2023-12-01 09:59:38,333:INFO::its now!!!!!!!!5
2023-12-01 09:59:38,559:INFO::its now!!!!!!!!
2023-12-01 09:59:38,560:INFO::its now!!!!!!!! on 
2023-12-01 09:59:38,687:INFO::its now!!!!!!!!5
2023-12-01 09:59:38,894:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:38,895:INFO::Epoch 00054 | lr 0.00050 | Train_Loss 0.3120 | Train_Classification_Loss 0.3617 | Dmon_Loss -0.0994 | Val_Loss 0.3191 | Search Time(s) 0.6772 | Infer Time(s) 0.2104 | Time(s) 0.8876 
2023-12-01 09:59:38,944:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 0;	7: 2;	8: 1;	9: 1;	10: 2;	11: 1;	12: 2;	13: 3;	14: 1;	15: 0;	16: 2;	17: 0;	18: 0;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 2;	26: 1;	27: 2;	28: 3;	29: 0;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 3;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 3;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:38,945:INFO::Validation loss decreased (0.336972 --> 0.319073).  Saving model ...
2023-12-01 09:59:38,947:INFO::Epoch: 55
tensor([[0.4796, 0.4748, 0.4711, 0.5853],
        [0.4790, 0.4743, 0.5839, 0.4666],
        [0.5798, 0.4749, 0.4622, 0.4746],
        [0.4726, 0.4729, 0.5907, 0.4661]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:38,948:INFO::its now!!!!!!!!5
2023-12-01 09:59:39,175:INFO::its now!!!!!!!!0
2023-12-01 09:59:39,176:INFO::its now!!!!!!!!3
2023-12-01 09:59:39,293:INFO::its now!!!!!!!!5
2023-12-01 09:59:39,556:INFO::its now!!!!!!!!
2023-12-01 09:59:39,556:INFO::its now!!!!!!!! on 
2023-12-01 09:59:39,683:INFO::its now!!!!!!!!5
2023-12-01 09:59:39,909:INFO::Epoch 00055 | lr 0.00050 | Train_Loss 0.3149 | Train_Classification_Loss 0.3571 | Dmon_Loss -0.0844 | Val_Loss 0.3509 | Search Time(s) 0.7351 | Infer Time(s) 0.2284 | Time(s) 0.9634 
2023-12-01 09:59:39,957:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 2;	13: 1;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 1;	26: 1;	27: 1;	28: 3;	29: 1;	30: 0;	31: 1;	32: 1;	33: 3;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 1;	26102: 1;	26103: 3;	26104: 1;	26105: 2;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 1;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:39,958:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:39,963:INFO::Epoch: 56
tensor([[0.4736, 0.4688, 0.4650, 0.5849],
        [0.4730, 0.4683, 0.5837, 0.4606],
        [0.5795, 0.4689, 0.4560, 0.4686],
        [0.4666, 0.4669, 0.5907, 0.4601]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:39,964:INFO::its now!!!!!!!!5
2023-12-01 09:59:40,177:INFO::its now!!!!!!!!0
2023-12-01 09:59:40,178:INFO::its now!!!!!!!!3
2023-12-01 09:59:40,295:INFO::its now!!!!!!!!5
2023-12-01 09:59:40,523:INFO::its now!!!!!!!!
2023-12-01 09:59:40,523:INFO::its now!!!!!!!! on 
2023-12-01 09:59:40,650:INFO::its now!!!!!!!!5
2023-12-01 09:59:40,859:INFO::Epoch 00056 | lr 0.00050 | Train_Loss 0.3063 | Train_Classification_Loss 0.3561 | Dmon_Loss -0.0995 | Val_Loss 0.3455 | Search Time(s) 0.6882 | Infer Time(s) 0.2125 | Time(s) 0.9006 
2023-12-01 09:59:40,902:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 2;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 0;	26106: 2;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:40,903:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:59:40,905:INFO::Epoch: 57
tensor([[0.4724, 0.4676, 0.4638, 0.5848],
        [0.4718, 0.4671, 0.5836, 0.4594],
        [0.5792, 0.4677, 0.4548, 0.4674],
        [0.4654, 0.4656, 0.5907, 0.4589]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:40,906:INFO::its now!!!!!!!!5
2023-12-01 09:59:41,115:INFO::its now!!!!!!!!0
2023-12-01 09:59:41,116:INFO::its now!!!!!!!!3
2023-12-01 09:59:41,250:INFO::its now!!!!!!!!5
2023-12-01 09:59:41,473:INFO::its now!!!!!!!!
2023-12-01 09:59:41,473:INFO::its now!!!!!!!! on 
2023-12-01 09:59:41,599:INFO::its now!!!!!!!!5
2023-12-01 09:59:41,802:INFO::Epoch 00057 | lr 0.00050 | Train_Loss 0.3142 | Train_Classification_Loss 0.3607 | Dmon_Loss -0.0929 | Val_Loss 0.3401 | Search Time(s) 0.6932 | Infer Time(s) 0.2064 | Time(s) 0.8996 
2023-12-01 09:59:41,853:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 0;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 1;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 0;	38: 0;	39: 1;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:41,854:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:59:41,858:INFO::Epoch: 58
tensor([[0.4713, 0.4766, 0.4729, 0.6005],
        [0.4808, 0.4664, 0.5995, 0.4685],
        [0.5944, 0.4768, 0.4640, 0.4667],
        [0.4744, 0.4747, 0.6066, 0.4583]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:41,859:INFO::its now!!!!!!!!5
2023-12-01 09:59:42,070:INFO::its now!!!!!!!!0
2023-12-01 09:59:42,071:INFO::its now!!!!!!!!3
2023-12-01 09:59:42,204:INFO::its now!!!!!!!!5
2023-12-01 09:59:42,446:INFO::its now!!!!!!!!
2023-12-01 09:59:42,446:INFO::its now!!!!!!!! on 
2023-12-01 09:59:42,573:INFO::its now!!!!!!!!5
2023-12-01 09:59:42,791:INFO::Epoch 00058 | lr 0.00050 | Train_Loss 0.2632 | Train_Classification_Loss 0.3172 | Dmon_Loss -0.1081 | Val_Loss 0.3230 | Search Time(s) 0.7161 | Infer Time(s) 0.2194 | Time(s) 0.9355 
2023-12-01 09:59:42,830:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 0;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 1;	11: 0;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 2;	26: 1;	27: 2;	28: 3;	29: 0;	30: 0;	31: 0;	32: 1;	33: 0;	34: 0;	35: 2;	36: 0;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 2;	26100: 2;	26101: 2;	26102: 1;	26103: 3;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 3;	26116: 1;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:42,832:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:59:42,835:INFO::Epoch: 59
tensor([[0.4706, 0.4879, 0.4842, 0.6175],
        [0.4921, 0.4658, 0.6167, 0.4798],
        [0.6110, 0.4881, 0.4754, 0.4663],
        [0.4790, 0.4860, 0.6237, 0.4660]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:42,836:INFO::its now!!!!!!!!5
2023-12-01 09:59:43,045:INFO::its now!!!!!!!!0
2023-12-01 09:59:43,046:INFO::its now!!!!!!!!3
2023-12-01 09:59:43,179:INFO::its now!!!!!!!!5
2023-12-01 09:59:43,406:INFO::its now!!!!!!!!
2023-12-01 09:59:43,407:INFO::its now!!!!!!!! on 
2023-12-01 09:59:43,534:INFO::its now!!!!!!!!5
2023-12-01 09:59:43,741:INFO::Epoch 00059 | lr 0.00050 | Train_Loss 0.3011 | Train_Classification_Loss 0.3495 | Dmon_Loss -0.0968 | Val_Loss 0.3410 | Search Time(s) 0.6981 | Infer Time(s) 0.2104 | Time(s) 0.9086 
2023-12-01 09:59:43,797:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 0;	7: 1;	8: 2;	9: 1;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 1;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 2;	31: 1;	32: 1;	33: 0;	34: 2;	35: 2;	36: 1;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 1;	26115: 2;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:43,798:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:59:43,801:INFO::Epoch: 60
tensor([[0.4726, 0.4955, 0.4919, 0.6260],
        [0.4996, 0.4653, 0.6281, 0.4874],
        [0.6222, 0.4935, 0.4831, 0.4685],
        [0.4833, 0.4936, 0.6323, 0.4721]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:43,802:INFO::its now!!!!!!!!5
2023-12-01 09:59:43,993:INFO::its now!!!!!!!!0
2023-12-01 09:59:43,994:INFO::its now!!!!!!!!3
2023-12-01 09:59:44,109:INFO::its now!!!!!!!!5
2023-12-01 09:59:44,324:INFO::its now!!!!!!!!
2023-12-01 09:59:44,324:INFO::its now!!!!!!!! on 
2023-12-01 09:59:44,451:INFO::its now!!!!!!!!5
2023-12-01 09:59:44,675:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:44,677:INFO::Epoch 00060 | lr 0.00050 | Train_Loss 0.3180 | Train_Classification_Loss 0.3744 | Dmon_Loss -0.1128 | Val_Loss 0.3159 | Search Time(s) 0.6483 | Infer Time(s) 0.2274 | Time(s) 0.8757 
2023-12-01 09:59:44,722:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 2;	12: 2;	13: 3;	14: 1;	15: 0;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 3;	29: 0;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 0;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 3;	26116: 1;	26117: 1;	26118: 3;	26119: 3;	26120: 2;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:44,723:INFO::Validation loss decreased (0.319073 --> 0.315888).  Saving model ...
2023-12-01 09:59:44,726:INFO::Epoch: 61
tensor([[0.4739, 0.4995, 0.4959, 0.6302],
        [0.5036, 0.4653, 0.6339, 0.4915],
        [0.6274, 0.4964, 0.4872, 0.4699],
        [0.4858, 0.4977, 0.6367, 0.4754]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:44,728:INFO::its now!!!!!!!!5
2023-12-01 09:59:44,991:INFO::its now!!!!!!!!0
2023-12-01 09:59:44,993:INFO::its now!!!!!!!!3
2023-12-01 09:59:45,127:INFO::its now!!!!!!!!5
2023-12-01 09:59:45,332:INFO::its now!!!!!!!!
2023-12-01 09:59:45,332:INFO::its now!!!!!!!! on 
2023-12-01 09:59:45,458:INFO::its now!!!!!!!!5
2023-12-01 09:59:45,690:INFO::Epoch 00061 | lr 0.00050 | Train_Loss 0.2940 | Train_Classification_Loss 0.3475 | Dmon_Loss -0.1070 | Val_Loss 0.3304 | Search Time(s) 0.7321 | Infer Time(s) 0.2353 | Time(s) 0.9674 
2023-12-01 09:59:45,729:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:45,730:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:45,733:INFO::Epoch: 62
tensor([[0.4731, 0.5014, 0.4967, 0.6305],
        [0.5045, 0.4638, 0.6351, 0.4935],
        [0.6299, 0.4967, 0.4881, 0.4691],
        [0.4857, 0.4985, 0.6371, 0.4771]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:45,734:INFO::its now!!!!!!!!5
2023-12-01 09:59:45,938:INFO::its now!!!!!!!!0
2023-12-01 09:59:45,939:INFO::its now!!!!!!!!3
2023-12-01 09:59:46,056:INFO::its now!!!!!!!!5
2023-12-01 09:59:46,291:INFO::its now!!!!!!!!
2023-12-01 09:59:46,291:INFO::its now!!!!!!!! on 
2023-12-01 09:59:46,434:INFO::its now!!!!!!!!5
2023-12-01 09:59:46,633:INFO::Epoch 00062 | lr 0.00050 | Train_Loss 0.2831 | Train_Classification_Loss 0.3443 | Dmon_Loss -0.1223 | Val_Loss 0.3174 | Search Time(s) 0.7011 | Infer Time(s) 0.2014 | Time(s) 0.9026 
2023-12-01 09:59:46,678:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 0;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 3;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 3;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 3;	26116: 1;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:46,679:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:59:46,682:INFO::Epoch: 63
tensor([[0.4726, 0.5022, 0.4971, 0.6306],
        [0.5048, 0.4630, 0.6357, 0.4945],
        [0.6310, 0.4967, 0.4884, 0.4686],
        [0.4856, 0.4988, 0.6373, 0.4778]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:46,682:INFO::its now!!!!!!!!5
2023-12-01 09:59:46,886:INFO::its now!!!!!!!!0
2023-12-01 09:59:46,887:INFO::its now!!!!!!!!3
2023-12-01 09:59:47,006:INFO::its now!!!!!!!!5
2023-12-01 09:59:47,254:INFO::its now!!!!!!!!
2023-12-01 09:59:47,254:INFO::its now!!!!!!!! on 
2023-12-01 09:59:47,382:INFO::its now!!!!!!!!5
2023-12-01 09:59:47,618:INFO::Epoch 00063 | lr 0.00050 | Train_Loss 0.2788 | Train_Classification_Loss 0.3347 | Dmon_Loss -0.1118 | Val_Loss 0.3309 | Search Time(s) 0.6972 | Infer Time(s) 0.2404 | Time(s) 0.9375 
2023-12-01 09:59:47,656:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 3;	26102: 1;	26103: 3;	26104: 1;	26105: 0;	26106: 1;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:47,657:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:59:47,659:INFO::Epoch: 64
tensor([[0.4745, 0.5044, 0.4990, 0.6306],
        [0.5067, 0.4648, 0.6360, 0.4967],
        [0.6316, 0.4985, 0.4904, 0.4705],
        [0.4874, 0.5008, 0.6374, 0.4802]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:47,660:INFO::its now!!!!!!!!5
2023-12-01 09:59:47,875:INFO::its now!!!!!!!!0
2023-12-01 09:59:47,876:INFO::its now!!!!!!!!3
2023-12-01 09:59:47,995:INFO::its now!!!!!!!!5
2023-12-01 09:59:48,204:INFO::its now!!!!!!!!
2023-12-01 09:59:48,204:INFO::its now!!!!!!!! on 
2023-12-01 09:59:48,335:INFO::its now!!!!!!!!5
2023-12-01 09:59:48,555:INFO::Epoch 00064 | lr 0.00050 | Train_Loss 0.2568 | Train_Classification_Loss 0.3238 | Dmon_Loss -0.1340 | Val_Loss 0.3224 | Search Time(s) 0.6732 | Infer Time(s) 0.2244 | Time(s) 0.8976 
2023-12-01 09:59:48,612:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 1;	11: 0;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 3;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 0;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 3;	26116: 1;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:48,613:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:59:48,616:INFO::Epoch: 65
tensor([[0.4725, 0.5031, 0.4976, 0.6304],
        [0.5053, 0.4627, 0.6363, 0.4954],
        [0.6309, 0.4970, 0.4889, 0.4685],
        [0.4858, 0.4993, 0.6374, 0.4787]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:48,617:INFO::its now!!!!!!!!5
2023-12-01 09:59:48,820:INFO::its now!!!!!!!!0
2023-12-01 09:59:48,822:INFO::its now!!!!!!!!3
2023-12-01 09:59:48,939:INFO::its now!!!!!!!!5
2023-12-01 09:59:49,152:INFO::its now!!!!!!!!
2023-12-01 09:59:49,152:INFO::its now!!!!!!!! on 
2023-12-01 09:59:49,278:INFO::its now!!!!!!!!5
2023-12-01 09:59:49,497:INFO::Epoch 00065 | lr 0.00050 | Train_Loss 0.2642 | Train_Classification_Loss 0.3256 | Dmon_Loss -0.1228 | Val_Loss 0.3267 | Search Time(s) 0.6613 | Infer Time(s) 0.2214 | Time(s) 0.8826 
2023-12-01 09:59:49,543:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 2;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 1;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 2;	26099: 1;	26100: 3;	26101: 2;	26102: 1;	26103: 3;	26104: 1;	26105: 0;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:49,544:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:59:49,547:INFO::Epoch: 66
tensor([[0.4726, 0.5034, 0.4978, 0.6302],
        [0.5055, 0.4627, 0.6365, 0.4957],
        [0.6304, 0.4972, 0.4891, 0.4686],
        [0.4859, 0.4995, 0.6375, 0.4789]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:49,547:INFO::its now!!!!!!!!5
2023-12-01 09:59:49,766:INFO::its now!!!!!!!!0
2023-12-01 09:59:49,767:INFO::its now!!!!!!!!3
2023-12-01 09:59:49,885:INFO::its now!!!!!!!!5
2023-12-01 09:59:50,093:INFO::its now!!!!!!!!
2023-12-01 09:59:50,093:INFO::its now!!!!!!!! on 
2023-12-01 09:59:50,220:INFO::its now!!!!!!!!5
2023-12-01 09:59:50,467:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:50,468:INFO::Epoch 00066 | lr 0.00050 | Train_Loss 0.2419 | Train_Classification_Loss 0.3126 | Dmon_Loss -0.1413 | Val_Loss 0.3150 | Search Time(s) 0.6732 | Infer Time(s) 0.2503 | Time(s) 0.9235 
2023-12-01 09:59:50,511:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 2;	11: 0;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 2;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 0;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 3;	26116: 1;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:50,512:INFO::Validation loss decreased (0.315888 --> 0.314985).  Saving model ...
2023-12-01 09:59:50,515:INFO::Epoch: 67
tensor([[0.4739, 0.5045, 0.4989, 0.6301],
        [0.5066, 0.4640, 0.6365, 0.4968],
        [0.6301, 0.4982, 0.4902, 0.4699],
        [0.4870, 0.5006, 0.6375, 0.4802]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:50,516:INFO::its now!!!!!!!!5
2023-12-01 09:59:50,736:INFO::its now!!!!!!!!0
2023-12-01 09:59:50,738:INFO::its now!!!!!!!!3
2023-12-01 09:59:50,855:INFO::its now!!!!!!!!5
2023-12-01 09:59:51,086:INFO::its now!!!!!!!!
2023-12-01 09:59:51,086:INFO::its now!!!!!!!! on 
2023-12-01 09:59:51,214:INFO::its now!!!!!!!!5
2023-12-01 09:59:51,458:INFO::Epoch 00067 | lr 0.00050 | Train_Loss 0.2571 | Train_Classification_Loss 0.3239 | Dmon_Loss -0.1336 | Val_Loss 0.3261 | Search Time(s) 0.6992 | Infer Time(s) 0.2463 | Time(s) 0.9455 
2023-12-01 09:59:51,500:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 1;	26: 1;	27: 2;	28: 0;	29: 1;	30: 1;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 3;	26104: 1;	26105: 0;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 1;	26126: 2;	26127: 2;	
2023-12-01 09:59:51,501:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 09:59:51,503:INFO::Epoch: 68
tensor([[0.4711, 0.5023, 0.4966, 0.6300],
        [0.5044, 0.4612, 0.6363, 0.4946],
        [0.6300, 0.4960, 0.4880, 0.4671],
        [0.4846, 0.4984, 0.6375, 0.4777]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:51,503:INFO::its now!!!!!!!!5
2023-12-01 09:59:51,719:INFO::its now!!!!!!!!0
2023-12-01 09:59:51,720:INFO::its now!!!!!!!!3
2023-12-01 09:59:51,839:INFO::its now!!!!!!!!5
2023-12-01 09:59:52,072:INFO::its now!!!!!!!!
2023-12-01 09:59:52,072:INFO::its now!!!!!!!! on 
2023-12-01 09:59:52,199:INFO::its now!!!!!!!!5
2023-12-01 09:59:52,411:INFO::Epoch 00068 | lr 0.00050 | Train_Loss 0.2104 | Train_Classification_Loss 0.2842 | Dmon_Loss -0.1475 | Val_Loss 0.3242 | Search Time(s) 0.6944 | Infer Time(s) 0.2147 | Time(s) 0.9090 
2023-12-01 09:59:52,458:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 0;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 0;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 3;	26104: 1;	26105: 0;	26106: 1;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:52,459:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 09:59:52,462:INFO::Epoch: 69
tensor([[0.4712, 0.5024, 0.4968, 0.6300],
        [0.5045, 0.4613, 0.6363, 0.4947],
        [0.6300, 0.4961, 0.4881, 0.4673],
        [0.4847, 0.4985, 0.6375, 0.4778]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:52,463:INFO::its now!!!!!!!!5
2023-12-01 09:59:52,692:INFO::its now!!!!!!!!0
2023-12-01 09:59:52,693:INFO::its now!!!!!!!!3
2023-12-01 09:59:52,809:INFO::its now!!!!!!!!5
2023-12-01 09:59:53,023:INFO::its now!!!!!!!!
2023-12-01 09:59:53,023:INFO::its now!!!!!!!! on 
2023-12-01 09:59:53,150:INFO::its now!!!!!!!!5
2023-12-01 09:59:53,351:INFO::Epoch 00069 | lr 0.00050 | Train_Loss 0.2313 | Train_Classification_Loss 0.3046 | Dmon_Loss -0.1466 | Val_Loss 0.3269 | Search Time(s) 0.6874 | Infer Time(s) 0.2045 | Time(s) 0.8918 
2023-12-01 09:59:53,392:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 0;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 3;	26120: 1;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:53,394:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 09:59:53,397:INFO::Epoch: 70
tensor([[0.4705, 0.5018, 0.4962, 0.6300],
        [0.5039, 0.4606, 0.6362, 0.4941],
        [0.6299, 0.4955, 0.4875, 0.4665],
        [0.4841, 0.4979, 0.6375, 0.4772]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:53,398:INFO::its now!!!!!!!!5
2023-12-01 09:59:53,637:INFO::its now!!!!!!!!0
2023-12-01 09:59:53,639:INFO::its now!!!!!!!!3
2023-12-01 09:59:53,759:INFO::its now!!!!!!!!5
2023-12-01 09:59:53,980:INFO::its now!!!!!!!!
2023-12-01 09:59:53,980:INFO::its now!!!!!!!! on 
2023-12-01 09:59:54,108:INFO::its now!!!!!!!!5
2023-12-01 09:59:54,307:INFO::Epoch 00070 | lr 0.00050 | Train_Loss 0.1963 | Train_Classification_Loss 0.2742 | Dmon_Loss -0.1559 | Val_Loss 0.3190 | Search Time(s) 0.7105 | Infer Time(s) 0.2024 | Time(s) 0.9130 
2023-12-01 09:59:54,359:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 2;	11: 1;	12: 2;	13: 3;	14: 1;	15: 0;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 1;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 3;	26102: 1;	26103: 3;	26104: 1;	26105: 0;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:54,360:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 09:59:54,362:INFO::Epoch: 71
tensor([[0.4658, 0.4980, 0.4923, 0.6301],
        [0.5001, 0.4558, 0.6362, 0.4903],
        [0.6295, 0.4917, 0.4836, 0.4619],
        [0.4800, 0.4941, 0.6375, 0.4728]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:54,362:INFO::its now!!!!!!!!5
2023-12-01 09:59:54,565:INFO::its now!!!!!!!!0
2023-12-01 09:59:54,566:INFO::its now!!!!!!!!3
2023-12-01 09:59:54,680:INFO::its now!!!!!!!!5
2023-12-01 09:59:54,893:INFO::its now!!!!!!!!
2023-12-01 09:59:54,893:INFO::its now!!!!!!!! on 
2023-12-01 09:59:55,020:INFO::its now!!!!!!!!5
2023-12-01 09:59:55,228:INFO::Epoch 00071 | lr 0.00050 | Train_Loss 0.2077 | Train_Classification_Loss 0.2861 | Dmon_Loss -0.1569 | Val_Loss 0.3209 | Search Time(s) 0.6575 | Infer Time(s) 0.2094 | Time(s) 0.8669 
2023-12-01 09:59:55,279:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 0;	12: 2;	13: 3;	14: 1;	15: 0;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 1;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 3;	26104: 1;	26105: 0;	26106: 3;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 3;	26116: 1;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:55,280:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 09:59:55,285:INFO::Epoch: 72
tensor([[0.4558, 0.4896, 0.4840, 0.6302],
        [0.4918, 0.4458, 0.6361, 0.4819],
        [0.6284, 0.4833, 0.4752, 0.4519],
        [0.4712, 0.4857, 0.6375, 0.4636]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:55,286:INFO::its now!!!!!!!!5
2023-12-01 09:59:55,495:INFO::its now!!!!!!!!0
2023-12-01 09:59:55,496:INFO::its now!!!!!!!!3
2023-12-01 09:59:55,611:INFO::its now!!!!!!!!5
2023-12-01 09:59:55,843:INFO::its now!!!!!!!!
2023-12-01 09:59:55,843:INFO::its now!!!!!!!! on 
2023-12-01 09:59:55,970:INFO::its now!!!!!!!!5
2023-12-01 09:59:56,193:INFO::Epoch 00072 | lr 0.00050 | Train_Loss 0.2203 | Train_Classification_Loss 0.3032 | Dmon_Loss -0.1656 | Val_Loss 0.3234 | Search Time(s) 0.6873 | Infer Time(s) 0.2264 | Time(s) 0.9137 
2023-12-01 09:59:56,243:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 0;	37: 3;	38: 0;	39: 1;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 3;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 0;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:56,244:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 09:59:56,246:INFO::Epoch: 73
tensor([[0.4515, 0.4860, 0.4803, 0.6301],
        [0.4881, 0.4414, 0.6359, 0.4783],
        [0.6279, 0.4796, 0.4715, 0.4476],
        [0.4673, 0.4821, 0.6375, 0.4595]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:56,247:INFO::its now!!!!!!!!5
2023-12-01 09:59:56,462:INFO::its now!!!!!!!!0
2023-12-01 09:59:56,463:INFO::its now!!!!!!!!3
2023-12-01 09:59:56,580:INFO::its now!!!!!!!!5
2023-12-01 09:59:56,817:INFO::its now!!!!!!!!
2023-12-01 09:59:56,817:INFO::its now!!!!!!!! on 
2023-12-01 09:59:56,943:INFO::its now!!!!!!!!5
2023-12-01 09:59:57,163:INFO::Epoch 00073 | lr 0.00050 | Train_Loss 0.2120 | Train_Classification_Loss 0.2960 | Dmon_Loss -0.1680 | Val_Loss 0.3207 | Search Time(s) 0.6954 | Infer Time(s) 0.2234 | Time(s) 0.9188 
2023-12-01 09:59:57,205:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 2;	26: 1;	27: 2;	28: 3;	29: 1;	30: 0;	31: 1;	32: 2;	33: 0;	34: 0;	35: 2;	36: 1;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 3;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 3;	26119: 3;	26120: 2;	26121: 1;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:57,206:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 09:59:57,209:INFO::Epoch: 74
tensor([[0.4455, 0.4810, 0.4753, 0.6301],
        [0.4831, 0.4354, 0.6358, 0.4732],
        [0.6274, 0.4745, 0.4664, 0.4416],
        [0.4620, 0.4770, 0.6375, 0.4539]], device='cuda:0', requires_grad=True)
2023-12-01 09:59:57,209:INFO::its now!!!!!!!!5
2023-12-01 09:59:57,422:INFO::its now!!!!!!!!0
2023-12-01 09:59:57,423:INFO::its now!!!!!!!!3
2023-12-01 09:59:57,556:INFO::its now!!!!!!!!5
2023-12-01 09:59:57,779:INFO::its now!!!!!!!!
2023-12-01 09:59:57,779:INFO::its now!!!!!!!! on 
2023-12-01 09:59:57,906:INFO::its now!!!!!!!!5
2023-12-01 09:59:58,101:INFO::Epoch 00074 | lr 0.00050 | Train_Loss 0.1621 | Train_Classification_Loss 0.2511 | Dmon_Loss -0.1781 | Val_Loss 0.3171 | Search Time(s) 0.6964 | Infer Time(s) 0.1974 | Time(s) 0.8938 
2023-12-01 09:59:58,156:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 1;	12: 2;	13: 3;	14: 1;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 0;	29: 1;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 2;	36: 1;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 3;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 0;	26114: 0;	26115: 2;	26116: 1;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 09:59:58,157:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 09:59:58,157:INFO::Eearly stopping!
2023-12-01 09:59:58,264:INFO::############### Search Stage Ends! ###############
2023-12-01 09:59:58,331:INFO::=============== Retrain Stage Starts:
2023-12-01 09:59:58,331:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:58,365:INFO::node_assign_Counter:
Counter({-1: 14328, 0: 3934, 1: 3931, 2: 3455, 3: 480})
2023-12-01 09:59:58,365:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 09:59:58,752:INFO::============= repeat round: 2; seed: 1233
2023-12-01 09:59:58,778:INFO::arch_weights:
[[0.47386712 0.5044836  0.4988584  0.6300781 ]
 [0.50657535 0.46397886 0.63652754 0.49680427]
 [0.630121   0.49824145 0.4902037  0.46988085]
 [0.48700297 0.5005954  0.6374682  0.48019615]]
2023-12-01 09:59:58,778:INFO::arch_weights_softmax:
[[0.23666012 0.24401785 0.24264908 0.2766729 ]
 [0.24465738 0.23445468 0.27860945 0.24227847]
 [0.2779464  0.24360518 0.24165499 0.23679343]
 [0.23984978 0.24313217 0.27879536 0.23822272]]
2023-12-01 09:59:58,778:INFO::genotype choice:
['one-hot', 'mean', 'gcn', 'mean']
2023-12-01 09:59:59,369:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.4021 | Val_Loss 1.3434 | Time(s) 0.5509
2023-12-01 09:59:59,752:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3436 | Val_Loss 1.2986 | Time(s) 0.3682
2023-12-01 09:59:59,766:INFO::Validation loss decreased (inf --> 1.298568).  Saving model ...
2023-12-01 10:00:00,147:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3267 | Val_Loss 1.2569 | Time(s) 0.3800
2023-12-01 10:00:00,161:INFO::Validation loss decreased (1.298568 --> 1.256889).  Saving model ...
2023-12-01 10:00:00,562:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.2825 | Val_Loss 1.2166 | Time(s) 0.4009
2023-12-01 10:00:00,575:INFO::Validation loss decreased (1.256889 --> 1.216601).  Saving model ...
2023-12-01 10:00:00,958:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.2432 | Val_Loss 1.1765 | Time(s) 0.3826
2023-12-01 10:00:00,973:INFO::Validation loss decreased (1.216601 --> 1.176510).  Saving model ...
2023-12-01 10:00:01,361:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.2266 | Val_Loss 1.1359 | Time(s) 0.3870
2023-12-01 10:00:01,372:INFO::Validation loss decreased (1.176510 --> 1.135936).  Saving model ...
2023-12-01 10:00:01,755:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.1657 | Val_Loss 1.0942 | Time(s) 0.3822
2023-12-01 10:00:01,769:INFO::Validation loss decreased (1.135936 --> 1.094175).  Saving model ...
2023-12-01 10:00:02,168:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.1269 | Val_Loss 1.0510 | Time(s) 0.3989
2023-12-01 10:00:02,181:INFO::Validation loss decreased (1.094175 --> 1.050997).  Saving model ...
2023-12-01 10:00:02,562:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.0568 | Val_Loss 1.0067 | Time(s) 0.3796
2023-12-01 10:00:02,573:INFO::Validation loss decreased (1.050997 --> 1.006726).  Saving model ...
2023-12-01 10:00:02,945:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.0404 | Val_Loss 0.9619 | Time(s) 0.3725
2023-12-01 10:00:02,959:INFO::Validation loss decreased (1.006726 --> 0.961867).  Saving model ...
2023-12-01 10:00:03,327:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.0336 | Val_Loss 0.9171 | Time(s) 0.3680
2023-12-01 10:00:03,338:INFO::Validation loss decreased (0.961867 --> 0.917078).  Saving model ...
2023-12-01 10:00:03,719:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 0.9601 | Val_Loss 0.8726 | Time(s) 0.3812
2023-12-01 10:00:03,731:INFO::Validation loss decreased (0.917078 --> 0.872585).  Saving model ...
2023-12-01 10:00:04,106:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 0.9448 | Val_Loss 0.8293 | Time(s) 0.3750
2023-12-01 10:00:04,118:INFO::Validation loss decreased (0.872585 --> 0.829282).  Saving model ...
2023-12-01 10:00:04,480:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 0.9049 | Val_Loss 0.7872 | Time(s) 0.3620
2023-12-01 10:00:04,491:INFO::Validation loss decreased (0.829282 --> 0.787203).  Saving model ...
2023-12-01 10:00:04,868:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 0.8658 | Val_Loss 0.7471 | Time(s) 0.3772
2023-12-01 10:00:04,880:INFO::Validation loss decreased (0.787203 --> 0.747101).  Saving model ...
2023-12-01 10:00:05,254:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 0.8357 | Val_Loss 0.7093 | Time(s) 0.3740
2023-12-01 10:00:05,264:INFO::Validation loss decreased (0.747101 --> 0.709329).  Saving model ...
2023-12-01 10:00:05,643:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 0.8178 | Val_Loss 0.6736 | Time(s) 0.3786
2023-12-01 10:00:05,655:INFO::Validation loss decreased (0.709329 --> 0.673635).  Saving model ...
2023-12-01 10:00:06,017:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 0.7437 | Val_Loss 0.6397 | Time(s) 0.3617
2023-12-01 10:00:06,027:INFO::Validation loss decreased (0.673635 --> 0.639742).  Saving model ...
2023-12-01 10:00:06,420:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 0.7268 | Val_Loss 0.6076 | Time(s) 0.3920
2023-12-01 10:00:06,431:INFO::Validation loss decreased (0.639742 --> 0.607618).  Saving model ...
2023-12-01 10:00:06,810:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 0.6915 | Val_Loss 0.5762 | Time(s) 0.3782
2023-12-01 10:00:06,821:INFO::Validation loss decreased (0.607618 --> 0.576189).  Saving model ...
2023-12-01 10:00:07,216:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 0.6848 | Val_Loss 0.5455 | Time(s) 0.3949
2023-12-01 10:00:07,229:INFO::Validation loss decreased (0.576189 --> 0.545471).  Saving model ...
2023-12-01 10:00:07,626:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 0.6536 | Val_Loss 0.5180 | Time(s) 0.3955
2023-12-01 10:00:07,637:INFO::Validation loss decreased (0.545471 --> 0.518029).  Saving model ...
2023-12-01 10:00:08,026:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 0.6198 | Val_Loss 0.4936 | Time(s) 0.3885
2023-12-01 10:00:08,037:INFO::Validation loss decreased (0.518029 --> 0.493630).  Saving model ...
2023-12-01 10:00:08,419:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 0.6255 | Val_Loss 0.4707 | Time(s) 0.3820
2023-12-01 10:00:08,431:INFO::Validation loss decreased (0.493630 --> 0.470673).  Saving model ...
2023-12-01 10:00:08,794:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 0.5912 | Val_Loss 0.4509 | Time(s) 0.3623
2023-12-01 10:00:08,822:INFO::Validation loss decreased (0.470673 --> 0.450884).  Saving model ...
2023-12-01 10:00:09,209:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 0.5551 | Val_Loss 0.4355 | Time(s) 0.3850
2023-12-01 10:00:09,221:INFO::Validation loss decreased (0.450884 --> 0.435518).  Saving model ...
2023-12-01 10:00:09,613:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 0.5638 | Val_Loss 0.4200 | Time(s) 0.3926
2023-12-01 10:00:09,629:INFO::Validation loss decreased (0.435518 --> 0.420034).  Saving model ...
2023-12-01 10:00:10,002:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 0.4841 | Val_Loss 0.4033 | Time(s) 0.3726
2023-12-01 10:00:10,012:INFO::Validation loss decreased (0.420034 --> 0.403313).  Saving model ...
2023-12-01 10:00:10,398:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 0.5000 | Val_Loss 0.3876 | Time(s) 0.3850
2023-12-01 10:00:10,412:INFO::Validation loss decreased (0.403313 --> 0.387580).  Saving model ...
2023-12-01 10:00:10,787:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 0.4575 | Val_Loss 0.3737 | Time(s) 0.3755
2023-12-01 10:00:10,797:INFO::Validation loss decreased (0.387580 --> 0.373716).  Saving model ...
2023-12-01 10:00:11,159:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 0.4390 | Val_Loss 0.3627 | Time(s) 0.3611
2023-12-01 10:00:11,172:INFO::Validation loss decreased (0.373716 --> 0.362741).  Saving model ...
2023-12-01 10:00:11,559:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 0.4571 | Val_Loss 0.3537 | Time(s) 0.3866
2023-12-01 10:00:11,571:INFO::Validation loss decreased (0.362741 --> 0.353696).  Saving model ...
2023-12-01 10:00:11,957:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 0.4001 | Val_Loss 0.3467 | Time(s) 0.3865
2023-12-01 10:00:11,971:INFO::Validation loss decreased (0.353696 --> 0.346720).  Saving model ...
2023-12-01 10:00:12,395:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 0.4263 | Val_Loss 0.3410 | Time(s) 0.4229
2023-12-01 10:00:12,406:INFO::Validation loss decreased (0.346720 --> 0.340969).  Saving model ...
2023-12-01 10:00:12,789:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 0.4085 | Val_Loss 0.3349 | Time(s) 0.3832
2023-12-01 10:00:12,803:INFO::Validation loss decreased (0.340969 --> 0.334852).  Saving model ...
2023-12-01 10:00:13,184:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 0.4051 | Val_Loss 0.3295 | Time(s) 0.3810
2023-12-01 10:00:13,197:INFO::Validation loss decreased (0.334852 --> 0.329504).  Saving model ...
2023-12-01 10:00:13,565:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 0.3503 | Val_Loss 0.3254 | Time(s) 0.3676
2023-12-01 10:00:13,592:INFO::Validation loss decreased (0.329504 --> 0.325441).  Saving model ...
2023-12-01 10:00:13,964:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 0.4103 | Val_Loss 0.3222 | Time(s) 0.3710
2023-12-01 10:00:13,976:INFO::Validation loss decreased (0.325441 --> 0.322181).  Saving model ...
2023-12-01 10:00:14,352:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 0.3347 | Val_Loss 0.3195 | Time(s) 0.3740
2023-12-01 10:00:14,363:INFO::Validation loss decreased (0.322181 --> 0.319493).  Saving model ...
2023-12-01 10:00:14,744:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 0.3543 | Val_Loss 0.3174 | Time(s) 0.3801
2023-12-01 10:00:14,756:INFO::Validation loss decreased (0.319493 --> 0.317445).  Saving model ...
2023-12-01 10:00:15,115:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 0.3122 | Val_Loss 0.3159 | Time(s) 0.3590
2023-12-01 10:00:15,125:INFO::Validation loss decreased (0.317445 --> 0.315896).  Saving model ...
2023-12-01 10:00:15,489:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 0.3160 | Val_Loss 0.3144 | Time(s) 0.3640
2023-12-01 10:00:15,501:INFO::Validation loss decreased (0.315896 --> 0.314399).  Saving model ...
2023-12-01 10:00:15,883:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 0.3346 | Val_Loss 0.3133 | Time(s) 0.3822
2023-12-01 10:00:15,895:INFO::Validation loss decreased (0.314399 --> 0.313276).  Saving model ...
2023-12-01 10:00:16,266:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 0.3250 | Val_Loss 0.3119 | Time(s) 0.3710
2023-12-01 10:00:16,277:INFO::Validation loss decreased (0.313276 --> 0.311899).  Saving model ...
2023-12-01 10:00:16,665:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 0.3017 | Val_Loss 0.3097 | Time(s) 0.3865
2023-12-01 10:00:16,677:INFO::Validation loss decreased (0.311899 --> 0.309739).  Saving model ...
2023-12-01 10:00:17,040:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 0.3086 | Val_Loss 0.3080 | Time(s) 0.3630
2023-12-01 10:00:17,052:INFO::Validation loss decreased (0.309739 --> 0.308043).  Saving model ...
2023-12-01 10:00:17,415:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 0.2930 | Val_Loss 0.3073 | Time(s) 0.3630
2023-12-01 10:00:17,432:INFO::Validation loss decreased (0.308043 --> 0.307261).  Saving model ...
2023-12-01 10:00:17,837:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 0.3034 | Val_Loss 0.3058 | Time(s) 0.4051
2023-12-01 10:00:17,849:INFO::Validation loss decreased (0.307261 --> 0.305784).  Saving model ...
2023-12-01 10:00:18,226:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 0.2968 | Val_Loss 0.3057 | Time(s) 0.3770
2023-12-01 10:00:18,239:INFO::Validation loss decreased (0.305784 --> 0.305660).  Saving model ...
2023-12-01 10:00:18,618:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 0.2749 | Val_Loss 0.3061 | Time(s) 0.3795
2023-12-01 10:00:18,619:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:00:19,005:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 0.2699 | Val_Loss 0.3070 | Time(s) 0.3856
2023-12-01 10:00:19,006:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:00:19,386:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.2717 | Val_Loss 0.3087 | Time(s) 0.3800
2023-12-01 10:00:19,387:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 10:00:19,763:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.2467 | Val_Loss 0.3103 | Time(s) 0.3763
2023-12-01 10:00:19,764:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 10:00:20,147:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 0.2723 | Val_Loss 0.3115 | Time(s) 0.3820
2023-12-01 10:00:20,148:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 10:00:20,517:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.2667 | Val_Loss 0.3138 | Time(s) 0.3690
2023-12-01 10:00:20,518:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 10:00:20,909:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.2847 | Val_Loss 0.3162 | Time(s) 0.3911
2023-12-01 10:00:20,910:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 10:00:21,311:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.2510 | Val_Loss 0.3194 | Time(s) 0.4009
2023-12-01 10:00:21,312:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 10:00:21,312:INFO::Eearly stopping!
2023-12-01 10:00:21,312:INFO::
testing...
2023-12-01 10:00:21,333:INFO::submit dir: submit/submit_gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:21,491:INFO::{'micro-f1': 0.9137323943661971, 'macro-f1': 0.9082840726370998}
2023-12-01 10:00:21,612:INFO::############### Retrain Stage Ends! #################
2023-12-01 10:00:21,613:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gat', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-09-54-04', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=1024, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=3, last_hidden_dim=512, logger=<Logger log_output (INFO)>)
2023-12-01 10:00:37,597:INFO::node_type_num: 4
2023-12-01 10:00:37,614:INFO::=============== Prepare basic data stage finish, use 16.000778198242188 time.
2023-12-01 10:00:37,734:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:39,056:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:39,057:INFO::its now!!!!!!!!5
2023-12-01 10:00:39,348:INFO::its now!!!!!!!!0
2023-12-01 10:00:39,349:INFO::its now!!!!!!!!3
2023-12-01 10:00:39,471:INFO::its now!!!!!!!!5
2023-12-01 10:00:39,681:INFO::its now!!!!!!!!
2023-12-01 10:00:39,681:INFO::its now!!!!!!!! on 
2023-12-01 10:00:39,820:INFO::its now!!!!!!!!5
2023-12-01 10:00:40,025:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:40,048:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.4426 | Train_Classification_Loss 1.4743 | Dmon_Loss -0.0634 | Val_Loss 1.3879 | Search Time(s) 0.7500 | Infer Time(s) 0.2214 | Time(s) 0.9714 
2023-12-01 10:00:40,088:INFO::cluster info:
0: 3;	1: 2;	2: 3;	3: 2;	4: 0;	5: 0;	6: 3;	7: 0;	8: 0;	9: 3;	10: 2;	11: 0;	12: 2;	13: 0;	14: 2;	15: 2;	16: 0;	17: 0;	18: 0;	19: 0;	20: 2;	21: 1;	22: 3;	23: 0;	24: 3;	25: 3;	26: 0;	27: 0;	28: 0;	29: 3;	30: 3;	31: 2;	32: 0;	33: 0;	34: 0;	35: 0;	36: 2;	37: 3;	38: 0;	39: 0;	40: 0;	41: 0;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 1;	26101: 2;	26102: 2;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 0;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 2;	26121: 2;	26122: 0;	26123: 3;	26124: 0;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:00:40,091:INFO::Epoch: 1
tensor([[0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:40,092:INFO::its now!!!!!!!!5
2023-12-01 10:00:40,296:INFO::its now!!!!!!!!0
2023-12-01 10:00:40,297:INFO::its now!!!!!!!!3
2023-12-01 10:00:40,426:INFO::its now!!!!!!!!5
2023-12-01 10:00:40,640:INFO::its now!!!!!!!!
2023-12-01 10:00:40,640:INFO::its now!!!!!!!! on 
2023-12-01 10:00:40,781:INFO::its now!!!!!!!!5
2023-12-01 10:00:40,986:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:40,988:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3673 | Train_Classification_Loss 1.3988 | Dmon_Loss -0.0628 | Val_Loss 1.3634 | Search Time(s) 0.6702 | Infer Time(s) 0.2264 | Time(s) 0.8966 
2023-12-01 10:00:41,034:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 3;	4: 0;	5: 1;	6: 2;	7: 2;	8: 2;	9: 0;	10: 2;	11: 2;	12: 3;	13: 0;	14: 2;	15: 1;	16: 3;	17: 2;	18: 2;	19: 3;	20: 2;	21: 2;	22: 2;	23: 3;	24: 1;	25: 2;	26: 3;	27: 0;	28: 3;	29: 3;	30: 2;	31: 3;	32: 2;	33: 3;	34: 3;	35: 2;	36: 3;	37: 3;	38: 2;	39: 3;	40: 3;	41: 0;	42: 3;	43: 2;	44
26098: 0;	26099: 3;	26100: 0;	26101: 2;	26102: 0;	26103: 1;	26104: 3;	26105: 2;	26106: 0;	26107: 0;	26108: 2;	26109: 3;	26110: 2;	26111: 2;	26112: 2;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 2;	26119: 3;	26120: 3;	26121: 2;	26122: 3;	26123: 2;	26124: 3;	26125: 3;	26126: 3;	26127: 2;	
2023-12-01 10:00:41,035:INFO::Validation loss decreased (inf --> 1.363388).  Saving model ...
2023-12-01 10:00:41,038:INFO::Epoch: 2
tensor([[0.4898, 0.5068, 0.5068, 0.5068],
        [0.4897, 0.5074, 0.5068, 0.5068],
        [0.4899, 0.5065, 0.5068, 0.5068],
        [0.4898, 0.5071, 0.5068, 0.5068]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:41,039:INFO::its now!!!!!!!!5
2023-12-01 10:00:41,260:INFO::its now!!!!!!!!0
2023-12-01 10:00:41,261:INFO::its now!!!!!!!!3
2023-12-01 10:00:41,392:INFO::its now!!!!!!!!5
2023-12-01 10:00:41,614:INFO::its now!!!!!!!!
2023-12-01 10:00:41,614:INFO::its now!!!!!!!! on 
2023-12-01 10:00:41,755:INFO::its now!!!!!!!!5
2023-12-01 10:00:41,999:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3874 | Train_Classification_Loss 1.4191 | Dmon_Loss -0.0633 | Val_Loss 1.3917 | Search Time(s) 0.7011 | Infer Time(s) 0.2633 | Time(s) 0.9644 
2023-12-01 10:00:42,042:INFO::cluster info:
0: 2;	1: 3;	2: 0;	3: 2;	4: 0;	5: 3;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 0;	16: 0;	17: 0;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 2;	28: 3;	29: 0;	30: 2;	31: 2;	32: 0;	33: 0;	34: 2;	35: 2;	36: 3;	37: 0;	38: 0;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 3;	26100: 1;	26101: 0;	26102: 3;	26103: 3;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:00:42,045:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:00:42,048:INFO::Epoch: 3
tensor([[0.4844, 0.5051, 0.5078, 0.5051],
        [0.4843, 0.5086, 0.5051, 0.5051],
        [0.4846, 0.5047, 0.5078, 0.5051],
        [0.4844, 0.5069, 0.5051, 0.5051]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:42,049:INFO::its now!!!!!!!!5
2023-12-01 10:00:42,257:INFO::its now!!!!!!!!0
2023-12-01 10:00:42,259:INFO::its now!!!!!!!!3
2023-12-01 10:00:42,392:INFO::its now!!!!!!!!5
2023-12-01 10:00:42,618:INFO::its now!!!!!!!!
2023-12-01 10:00:42,618:INFO::its now!!!!!!!! on 
2023-12-01 10:00:42,758:INFO::its now!!!!!!!!5
2023-12-01 10:00:42,976:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:42,978:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3399 | Train_Classification_Loss 1.3712 | Dmon_Loss -0.0627 | Val_Loss 1.3625 | Search Time(s) 0.6941 | Infer Time(s) 0.2364 | Time(s) 0.9305 
2023-12-01 10:00:43,041:INFO::cluster info:
0: 3;	1: 2;	2: 3;	3: 3;	4: 2;	5: 3;	6: 2;	7: 0;	8: 2;	9: 2;	10: 3;	11: 2;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 2;	22: 3;	23: 3;	24: 2;	25: 3;	26: 2;	27: 3;	28: 3;	29: 3;	30: 2;	31: 2;	32: 2;	33: 3;	34: 3;	35: 2;	36: 3;	37: 3;	38: 3;	39: 1;	40: 3;	41: 2;	42: 2;	43: 2;	44
26098: 1;	26099: 2;	26100: 0;	26101: 2;	26102: 2;	26103: 0;	26104: 0;	26105: 3;	26106: 2;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 2;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 2;	26127: 3;	
2023-12-01 10:00:43,041:INFO::Validation loss decreased (1.363388 --> 1.362545).  Saving model ...
2023-12-01 10:00:43,043:INFO::Epoch: 4
tensor([[0.4858, 0.5065, 0.5084, 0.5066],
        [0.4858, 0.5093, 0.5066, 0.5066],
        [0.4860, 0.5061, 0.5085, 0.5066],
        [0.4858, 0.5068, 0.5066, 0.5066]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:43,044:INFO::its now!!!!!!!!5
2023-12-01 10:00:43,261:INFO::its now!!!!!!!!0
2023-12-01 10:00:43,262:INFO::its now!!!!!!!!3
2023-12-01 10:00:43,395:INFO::its now!!!!!!!!5
2023-12-01 10:00:43,602:INFO::its now!!!!!!!!
2023-12-01 10:00:43,602:INFO::its now!!!!!!!! on 
2023-12-01 10:00:43,743:INFO::its now!!!!!!!!5
2023-12-01 10:00:43,953:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3458 | Train_Classification_Loss 1.3777 | Dmon_Loss -0.0637 | Val_Loss 1.3774 | Search Time(s) 0.6802 | Infer Time(s) 0.2314 | Time(s) 0.9116 
2023-12-01 10:00:43,990:INFO::cluster info:
0: 2;	1: 2;	2: 3;	3: 2;	4: 2;	5: 2;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 0;	13: 2;	14: 0;	15: 3;	16: 0;	17: 0;	18: 0;	19: 0;	20: 2;	21: 0;	22: 2;	23: 0;	24: 0;	25: 3;	26: 0;	27: 0;	28: 2;	29: 3;	30: 2;	31: 2;	32: 0;	33: 0;	34: 2;	35: 2;	36: 3;	37: 1;	38: 2;	39: 2;	40: 0;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 1;	26100: 2;	26101: 2;	26102: 3;	26103: 1;	26104: 2;	26105: 2;	26106: 1;	26107: 3;	26108: 0;	26109: 0;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 10:00:43,991:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:00:43,993:INFO::Epoch: 5
tensor([[0.4806, 0.5019, 0.5087, 0.5019],
        [0.4806, 0.5097, 0.5019, 0.5019],
        [0.4809, 0.5014, 0.5089, 0.5019],
        [0.4806, 0.5039, 0.5019, 0.5019]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:43,994:INFO::its now!!!!!!!!5
2023-12-01 10:00:44,194:INFO::its now!!!!!!!!0
2023-12-01 10:00:44,195:INFO::its now!!!!!!!!3
2023-12-01 10:00:44,330:INFO::its now!!!!!!!!5
2023-12-01 10:00:44,595:INFO::its now!!!!!!!!
2023-12-01 10:00:44,595:INFO::its now!!!!!!!! on 
2023-12-01 10:00:44,737:INFO::its now!!!!!!!!5
2023-12-01 10:00:44,948:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:44,950:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3200 | Train_Classification_Loss 1.3514 | Dmon_Loss -0.0627 | Val_Loss 1.3490 | Search Time(s) 0.7251 | Infer Time(s) 0.2324 | Time(s) 0.9574 
2023-12-01 10:00:45,000:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 3;	4: 2;	5: 3;	6: 3;	7: 2;	8: 2;	9: 3;	10: 3;	11: 1;	12: 0;	13: 0;	14: 3;	15: 3;	16: 2;	17: 2;	18: 2;	19: 3;	20: 2;	21: 0;	22: 3;	23: 3;	24: 3;	25: 3;	26: 0;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 3;	34: 2;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 2;	44
26098: 2;	26099: 0;	26100: 0;	26101: 3;	26102: 2;	26103: 1;	26104: 0;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 10:00:45,001:INFO::Validation loss decreased (1.362545 --> 1.349019).  Saving model ...
2023-12-01 10:00:45,003:INFO::Epoch: 6
tensor([[0.4761, 0.4977, 0.5085, 0.4977],
        [0.4760, 0.5098, 0.4977, 0.4977],
        [0.4763, 0.4972, 0.5089, 0.4977],
        [0.4761, 0.5024, 0.4977, 0.4977]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:45,003:INFO::its now!!!!!!!!5
2023-12-01 10:00:45,219:INFO::its now!!!!!!!!0
2023-12-01 10:00:45,220:INFO::its now!!!!!!!!3
2023-12-01 10:00:45,350:INFO::its now!!!!!!!!5
2023-12-01 10:00:45,572:INFO::its now!!!!!!!!
2023-12-01 10:00:45,572:INFO::its now!!!!!!!! on 
2023-12-01 10:00:45,710:INFO::its now!!!!!!!!5
2023-12-01 10:00:45,926:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.3456 | Train_Classification_Loss 1.3775 | Dmon_Loss -0.0637 | Val_Loss 1.3575 | Search Time(s) 0.6892 | Infer Time(s) 0.2356 | Time(s) 0.9248 
2023-12-01 10:00:45,978:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 0;	4: 2;	5: 3;	6: 0;	7: 2;	8: 2;	9: 0;	10: 2;	11: 0;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 0;	23: 2;	24: 1;	25: 0;	26: 0;	27: 3;	28: 2;	29: 0;	30: 2;	31: 2;	32: 2;	33: 1;	34: 0;	35: 0;	36: 2;	37: 2;	38: 3;	39: 0;	40: 0;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 0;	26100: 0;	26101: 2;	26102: 1;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 0;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 0;	26125: 2;	26126: 0;	26127: 2;	
2023-12-01 10:00:45,980:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:00:45,982:INFO::Epoch: 7
tensor([[0.4697, 0.4915, 0.5083, 0.4916],
        [0.4696, 0.5099, 0.4916, 0.4916],
        [0.4699, 0.4911, 0.5089, 0.4916],
        [0.4697, 0.5005, 0.4916, 0.4916]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:45,983:INFO::its now!!!!!!!!5
2023-12-01 10:00:46,187:INFO::its now!!!!!!!!0
2023-12-01 10:00:46,189:INFO::its now!!!!!!!!3
2023-12-01 10:00:46,323:INFO::its now!!!!!!!!5
2023-12-01 10:00:46,549:INFO::its now!!!!!!!!
2023-12-01 10:00:46,549:INFO::its now!!!!!!!! on 
2023-12-01 10:00:46,689:INFO::its now!!!!!!!!5
2023-12-01 10:00:46,898:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:46,900:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.3122 | Train_Classification_Loss 1.3436 | Dmon_Loss -0.0627 | Val_Loss 1.3306 | Search Time(s) 0.6877 | Infer Time(s) 0.2300 | Time(s) 0.9177 
2023-12-01 10:00:46,942:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 2;	4: 0;	5: 3;	6: 0;	7: 3;	8: 2;	9: 2;	10: 2;	11: 2;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 2;	18: 3;	19: 3;	20: 2;	21: 1;	22: 3;	23: 3;	24: 0;	25: 2;	26: 0;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 2;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 0;	39: 0;	40: 2;	41: 3;	42: 2;	43: 2;	44
26098: 0;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 1;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 2;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 10:00:46,943:INFO::Validation loss decreased (1.349019 --> 1.330639).  Saving model ...
2023-12-01 10:00:46,945:INFO::Epoch: 8
tensor([[0.4636, 0.4856, 0.5082, 0.4857],
        [0.4635, 0.5099, 0.4857, 0.4857],
        [0.4638, 0.4852, 0.5086, 0.4857],
        [0.4636, 0.4995, 0.4857, 0.4857]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:46,946:INFO::its now!!!!!!!!5
2023-12-01 10:00:47,171:INFO::its now!!!!!!!!0
2023-12-01 10:00:47,172:INFO::its now!!!!!!!!3
2023-12-01 10:00:47,303:INFO::its now!!!!!!!!5
2023-12-01 10:00:47,526:INFO::its now!!!!!!!!
2023-12-01 10:00:47,526:INFO::its now!!!!!!!! on 
2023-12-01 10:00:47,666:INFO::its now!!!!!!!!5
2023-12-01 10:00:47,870:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:47,871:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.3606 | Train_Classification_Loss 1.3924 | Dmon_Loss -0.0636 | Val_Loss 1.3296 | Search Time(s) 0.7015 | Infer Time(s) 0.2240 | Time(s) 0.9256 
2023-12-01 10:00:47,921:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 2;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 2;	22: 2;	23: 0;	24: 2;	25: 2;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 2;	34: 0;	35: 2;	36: 0;	37: 2;	38: 0;	39: 2;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 3;	26106: 2;	26107: 3;	26108: 0;	26109: 2;	26110: 0;	26111: 0;	26112: 0;	26113: 0;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 0;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 0;	
2023-12-01 10:00:47,922:INFO::Validation loss decreased (1.330639 --> 1.329603).  Saving model ...
2023-12-01 10:00:47,924:INFO::Epoch: 9
tensor([[0.4566, 0.4788, 0.5081, 0.4789],
        [0.4566, 0.5099, 0.4789, 0.4789],
        [0.4568, 0.4783, 0.5084, 0.4789],
        [0.4566, 0.4976, 0.4789, 0.4789]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:47,925:INFO::its now!!!!!!!!5
2023-12-01 10:00:48,149:INFO::its now!!!!!!!!0
2023-12-01 10:00:48,150:INFO::its now!!!!!!!!3
2023-12-01 10:00:48,283:INFO::its now!!!!!!!!5
2023-12-01 10:00:48,520:INFO::its now!!!!!!!!
2023-12-01 10:00:48,520:INFO::its now!!!!!!!! on 
2023-12-01 10:00:48,661:INFO::its now!!!!!!!!5
2023-12-01 10:00:48,872:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:48,874:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.2980 | Train_Classification_Loss 1.3293 | Dmon_Loss -0.0627 | Val_Loss 1.3110 | Search Time(s) 0.7186 | Infer Time(s) 0.2310 | Time(s) 0.9496 
2023-12-01 10:00:48,926:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 0;	9: 0;	10: 2;	11: 3;	12: 3;	13: 0;	14: 3;	15: 3;	16: 3;	17: 3;	18: 0;	19: 2;	20: 3;	21: 0;	22: 0;	23: 2;	24: 3;	25: 0;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 3;	32: 3;	33: 3;	34: 1;	35: 3;	36: 3;	37: 2;	38: 2;	39: 3;	40: 2;	41: 0;	42: 3;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 3;	26102: 3;	26103: 0;	26104: 2;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 2;	26113: 3;	26114: 3;	26115: 3;	26116: 2;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 2;	
2023-12-01 10:00:48,927:INFO::Validation loss decreased (1.329603 --> 1.311048).  Saving model ...
2023-12-01 10:00:48,930:INFO::Epoch: 10
tensor([[0.4507, 0.4729, 0.5077, 0.4730],
        [0.4506, 0.5099, 0.4730, 0.4730],
        [0.4509, 0.4725, 0.5080, 0.4730],
        [0.4507, 0.4966, 0.4730, 0.4730]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:48,930:INFO::its now!!!!!!!!5
2023-12-01 10:00:49,154:INFO::its now!!!!!!!!0
2023-12-01 10:00:49,155:INFO::its now!!!!!!!!3
2023-12-01 10:00:49,287:INFO::its now!!!!!!!!5
2023-12-01 10:00:49,513:INFO::its now!!!!!!!!
2023-12-01 10:00:49,513:INFO::its now!!!!!!!! on 
2023-12-01 10:00:49,653:INFO::its now!!!!!!!!5
2023-12-01 10:00:49,864:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:49,866:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.3170 | Train_Classification_Loss 1.3488 | Dmon_Loss -0.0636 | Val_Loss 1.3040 | Search Time(s) 0.7056 | Infer Time(s) 0.2310 | Time(s) 0.9366 
2023-12-01 10:00:49,921:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 3;	5: 2;	6: 1;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 0;	23: 2;	24: 1;	25: 0;	26: 2;	27: 2;	28: 2;	29: 2;	30: 0;	31: 2;	32: 2;	33: 2;	34: 0;	35: 0;	36: 2;	37: 2;	38: 3;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 2;	26099: 3;	26100: 0;	26101: 3;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 0;	26119: 2;	26120: 0;	26121: 0;	26122: 2;	26123: 0;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:00:49,922:INFO::Validation loss decreased (1.311048 --> 1.303950).  Saving model ...
2023-12-01 10:00:49,925:INFO::Epoch: 11
tensor([[0.4455, 0.4679, 0.5073, 0.4680],
        [0.4455, 0.5099, 0.4680, 0.4680],
        [0.4458, 0.4675, 0.5079, 0.4680],
        [0.4455, 0.4951, 0.4680, 0.4680]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:49,927:INFO::its now!!!!!!!!5
2023-12-01 10:00:50,182:INFO::its now!!!!!!!!0
2023-12-01 10:00:50,183:INFO::its now!!!!!!!!3
2023-12-01 10:00:50,318:INFO::its now!!!!!!!!5
2023-12-01 10:00:50,544:INFO::its now!!!!!!!!
2023-12-01 10:00:50,544:INFO::its now!!!!!!!! on 
2023-12-01 10:00:50,685:INFO::its now!!!!!!!!5
2023-12-01 10:00:50,891:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:50,892:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.2653 | Train_Classification_Loss 1.2967 | Dmon_Loss -0.0627 | Val_Loss 1.2901 | Search Time(s) 0.7432 | Infer Time(s) 0.2264 | Time(s) 0.9696 
2023-12-01 10:00:50,943:INFO::cluster info:
0: 3;	1: 3;	2: 2;	3: 3;	4: 2;	5: 3;	6: 1;	7: 3;	8: 2;	9: 2;	10: 3;	11: 2;	12: 2;	13: 2;	14: 2;	15: 3;	16: 0;	17: 2;	18: 3;	19: 3;	20: 3;	21: 2;	22: 3;	23: 0;	24: 1;	25: 3;	26: 2;	27: 1;	28: 3;	29: 2;	30: 2;	31: 2;	32: 3;	33: 0;	34: 3;	35: 0;	36: 2;	37: 2;	38: 3;	39: 2;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 0;	26099: 3;	26100: 3;	26101: 3;	26102: 2;	26103: 3;	26104: 3;	26105: 2;	26106: 1;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 2;	26112: 2;	26113: 3;	26114: 3;	26115: 2;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 2;	26123: 3;	26124: 2;	26125: 3;	26126: 3;	26127: 2;	
2023-12-01 10:00:50,944:INFO::Validation loss decreased (1.303950 --> 1.290091).  Saving model ...
2023-12-01 10:00:50,947:INFO::Epoch: 12
tensor([[0.4419, 0.4644, 0.5070, 0.4644],
        [0.4419, 0.5099, 0.4644, 0.4644],
        [0.4422, 0.4639, 0.5078, 0.4644],
        [0.4419, 0.4944, 0.4644, 0.4644]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:50,947:INFO::its now!!!!!!!!5
2023-12-01 10:00:51,152:INFO::its now!!!!!!!!0
2023-12-01 10:00:51,153:INFO::its now!!!!!!!!3
2023-12-01 10:00:51,286:INFO::its now!!!!!!!!5
2023-12-01 10:00:51,507:INFO::its now!!!!!!!!
2023-12-01 10:00:51,507:INFO::its now!!!!!!!! on 
2023-12-01 10:00:51,648:INFO::its now!!!!!!!!5
2023-12-01 10:00:51,866:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:51,867:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.2653 | Train_Classification_Loss 1.2972 | Dmon_Loss -0.0637 | Val_Loss 1.2781 | Search Time(s) 0.6817 | Infer Time(s) 0.2390 | Time(s) 0.9207 
2023-12-01 10:00:51,905:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 0;	9: 2;	10: 2;	11: 2;	12: 0;	13: 2;	14: 0;	15: 0;	16: 0;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 0;	23: 0;	24: 0;	25: 2;	26: 2;	27: 0;	28: 0;	29: 2;	30: 2;	31: 3;	32: 2;	33: 0;	34: 0;	35: 2;	36: 0;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 3;	26100: 1;	26101: 0;	26102: 3;	26103: 0;	26104: 1;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 0;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 0;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:00:51,905:INFO::Validation loss decreased (1.290091 --> 1.278053).  Saving model ...
2023-12-01 10:00:51,908:INFO::Epoch: 13
tensor([[0.4379, 0.4604, 0.5069, 0.4604],
        [0.4378, 0.5098, 0.4604, 0.4604],
        [0.4381, 0.4599, 0.5075, 0.4604],
        [0.4379, 0.4921, 0.4604, 0.4604]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:51,908:INFO::its now!!!!!!!!5
2023-12-01 10:00:52,126:INFO::its now!!!!!!!!0
2023-12-01 10:00:52,127:INFO::its now!!!!!!!!3
2023-12-01 10:00:52,259:INFO::its now!!!!!!!!5
2023-12-01 10:00:52,486:INFO::its now!!!!!!!!
2023-12-01 10:00:52,486:INFO::its now!!!!!!!! on 
2023-12-01 10:00:52,627:INFO::its now!!!!!!!!5
2023-12-01 10:00:52,854:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:52,856:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.2440 | Train_Classification_Loss 1.2754 | Dmon_Loss -0.0627 | Val_Loss 1.2639 | Search Time(s) 0.7027 | Infer Time(s) 0.2449 | Time(s) 0.9476 
2023-12-01 10:00:52,901:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 2;	4: 3;	5: 2;	6: 3;	7: 2;	8: 2;	9: 2;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 0;	18: 3;	19: 3;	20: 2;	21: 0;	22: 2;	23: 2;	24: 3;	25: 3;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 0;	34: 3;	35: 3;	36: 2;	37: 3;	38: 3;	39: 2;	40: 2;	41: 2;	42: 2;	43: 3;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 3;	26103: 0;	26104: 2;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 3;	26111: 3;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 3;	26118: 2;	26119: 3;	26120: 3;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 3;	26126: 2;	26127: 3;	
2023-12-01 10:00:52,903:INFO::Validation loss decreased (1.278053 --> 1.263863).  Saving model ...
2023-12-01 10:00:52,907:INFO::Epoch: 14
tensor([[0.4333, 0.4559, 0.5066, 0.4559],
        [0.4332, 0.5098, 0.4559, 0.4559],
        [0.4335, 0.4554, 0.5068, 0.4559],
        [0.4333, 0.4909, 0.4559, 0.4559]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:52,908:INFO::its now!!!!!!!!5
2023-12-01 10:00:53,106:INFO::its now!!!!!!!!0
2023-12-01 10:00:53,107:INFO::its now!!!!!!!!3
2023-12-01 10:00:53,238:INFO::its now!!!!!!!!5
2023-12-01 10:00:53,458:INFO::its now!!!!!!!!
2023-12-01 10:00:53,458:INFO::its now!!!!!!!! on 
2023-12-01 10:00:53,598:INFO::its now!!!!!!!!5
2023-12-01 10:00:53,808:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:53,810:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.2527 | Train_Classification_Loss 1.2844 | Dmon_Loss -0.0634 | Val_Loss 1.2538 | Search Time(s) 0.6737 | Infer Time(s) 0.2310 | Time(s) 0.9047 
2023-12-01 10:00:53,850:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 0;	7: 0;	8: 2;	9: 2;	10: 0;	11: 2;	12: 3;	13: 2;	14: 0;	15: 3;	16: 0;	17: 3;	18: 0;	19: 2;	20: 0;	21: 2;	22: 2;	23: 0;	24: 0;	25: 2;	26: 2;	27: 3;	28: 0;	29: 2;	30: 2;	31: 1;	32: 0;	33: 2;	34: 3;	35: 0;	36: 2;	37: 2;	38: 0;	39: 2;	40: 0;	41: 0;	42: 0;	43: 2;	44
26098: 0;	26099: 0;	26100: 0;	26101: 2;	26102: 0;	26103: 0;	26104: 2;	26105: 3;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 0;	26124: 2;	26125: 0;	26126: 2;	26127: 0;	
2023-12-01 10:00:53,852:INFO::Validation loss decreased (1.263863 --> 1.253775).  Saving model ...
2023-12-01 10:00:53,854:INFO::Epoch: 15
tensor([[0.4300, 0.4526, 0.5062, 0.4527],
        [0.4299, 0.5098, 0.4527, 0.4527],
        [0.4302, 0.4522, 0.5058, 0.4527],
        [0.4300, 0.4899, 0.4527, 0.4527]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:53,855:INFO::its now!!!!!!!!5
2023-12-01 10:00:54,079:INFO::its now!!!!!!!!0
2023-12-01 10:00:54,081:INFO::its now!!!!!!!!3
2023-12-01 10:00:54,214:INFO::its now!!!!!!!!5
2023-12-01 10:00:54,447:INFO::its now!!!!!!!!
2023-12-01 10:00:54,447:INFO::its now!!!!!!!! on 
2023-12-01 10:00:54,587:INFO::its now!!!!!!!!5
2023-12-01 10:00:54,794:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:54,796:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.2250 | Train_Classification_Loss 1.2563 | Dmon_Loss -0.0627 | Val_Loss 1.2307 | Search Time(s) 0.7147 | Infer Time(s) 0.2270 | Time(s) 0.9417 
2023-12-01 10:00:54,844:INFO::cluster info:
0: 1;	1: 2;	2: 1;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 3;	11: 0;	12: 3;	13: 3;	14: 3;	15: 2;	16: 2;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 2;	24: 3;	25: 2;	26: 2;	27: 3;	28: 3;	29: 2;	30: 2;	31: 0;	32: 2;	33: 3;	34: 0;	35: 2;	36: 3;	37: 0;	38: 3;	39: 0;	40: 2;	41: 2;	42: 3;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 0;	26108: 2;	26109: 3;	26110: 3;	26111: 2;	26112: 2;	26113: 3;	26114: 3;	26115: 3;	26116: 2;	26117: 3;	26118: 3;	26119: 2;	26120: 2;	26121: 3;	26122: 3;	26123: 2;	26124: 3;	26125: 2;	26126: 3;	26127: 0;	
2023-12-01 10:00:54,845:INFO::Validation loss decreased (1.253775 --> 1.230671).  Saving model ...
2023-12-01 10:00:54,848:INFO::Epoch: 16
tensor([[0.4295, 0.4521, 0.5060, 0.4522],
        [0.4295, 0.5098, 0.4522, 0.4522],
        [0.4297, 0.4517, 0.5048, 0.4522],
        [0.4295, 0.4894, 0.4522, 0.4522]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:54,849:INFO::its now!!!!!!!!5
2023-12-01 10:00:55,056:INFO::its now!!!!!!!!0
2023-12-01 10:00:55,057:INFO::its now!!!!!!!!3
2023-12-01 10:00:55,190:INFO::its now!!!!!!!!5
2023-12-01 10:00:55,407:INFO::its now!!!!!!!!
2023-12-01 10:00:55,407:INFO::its now!!!!!!!! on 
2023-12-01 10:00:55,548:INFO::its now!!!!!!!!5
2023-12-01 10:00:55,772:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:55,774:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 1.1920 | Train_Classification_Loss 1.2239 | Dmon_Loss -0.0637 | Val_Loss 1.2080 | Search Time(s) 0.6812 | Infer Time(s) 0.2449 | Time(s) 0.9261 
2023-12-01 10:00:55,819:INFO::cluster info:
0: 3;	1: 0;	2: 0;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 0;	9: 2;	10: 2;	11: 2;	12: 2;	13: 0;	14: 2;	15: 2;	16: 2;	17: 2;	18: 0;	19: 0;	20: 2;	21: 2;	22: 2;	23: 2;	24: 0;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 0;	31: 3;	32: 2;	33: 0;	34: 3;	35: 2;	36: 2;	37: 3;	38: 2;	39: 2;	40: 2;	41: 0;	42: 2;	43: 0;	44
26098: 2;	26099: 2;	26100: 0;	26101: 2;	26102: 0;	26103: 1;	26104: 2;	26105: 2;	26106: 0;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 0;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:00:55,820:INFO::Validation loss decreased (1.230671 --> 1.208039).  Saving model ...
2023-12-01 10:00:55,821:INFO::Epoch: 17
tensor([[0.4268, 0.4495, 0.5057, 0.4495],
        [0.4268, 0.5099, 0.4495, 0.4495],
        [0.4270, 0.4490, 0.5041, 0.4495],
        [0.4268, 0.4889, 0.4495, 0.4495]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:55,822:INFO::its now!!!!!!!!5
2023-12-01 10:00:56,043:INFO::its now!!!!!!!!0
2023-12-01 10:00:56,044:INFO::its now!!!!!!!!3
2023-12-01 10:00:56,177:INFO::its now!!!!!!!!5
2023-12-01 10:00:56,438:INFO::its now!!!!!!!!
2023-12-01 10:00:56,438:INFO::its now!!!!!!!! on 
2023-12-01 10:00:56,578:INFO::its now!!!!!!!!5
2023-12-01 10:00:56,789:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:56,791:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 1.1919 | Train_Classification_Loss 1.2232 | Dmon_Loss -0.0628 | Val_Loss 1.1904 | Search Time(s) 0.7380 | Infer Time(s) 0.2316 | Time(s) 0.9696 
2023-12-01 10:00:56,834:INFO::cluster info:
0: 0;	1: 0;	2: 3;	3: 3;	4: 3;	5: 3;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 2;	17: 2;	18: 3;	19: 3;	20: 3;	21: 2;	22: 2;	23: 3;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 0;	30: 2;	31: 3;	32: 2;	33: 0;	34: 2;	35: 1;	36: 0;	37: 0;	38: 0;	39: 2;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 3;	26101: 3;	26102: 2;	26103: 3;	26104: 2;	26105: 3;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 3;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 3;	26127: 2;	
2023-12-01 10:00:56,835:INFO::Validation loss decreased (1.208039 --> 1.190358).  Saving model ...
2023-12-01 10:00:56,838:INFO::Epoch: 18
tensor([[0.4245, 0.4472, 0.5056, 0.4472],
        [0.4244, 0.5098, 0.4472, 0.4472],
        [0.4247, 0.4468, 0.5039, 0.4472],
        [0.4245, 0.4885, 0.4472, 0.4472]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:56,839:INFO::its now!!!!!!!!5
2023-12-01 10:00:57,051:INFO::its now!!!!!!!!0
2023-12-01 10:00:57,053:INFO::its now!!!!!!!!3
2023-12-01 10:00:57,184:INFO::its now!!!!!!!!5
2023-12-01 10:00:57,404:INFO::its now!!!!!!!!
2023-12-01 10:00:57,404:INFO::its now!!!!!!!! on 
2023-12-01 10:00:57,543:INFO::its now!!!!!!!!5
2023-12-01 10:00:57,772:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:57,774:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 1.1620 | Train_Classification_Loss 1.1935 | Dmon_Loss -0.0629 | Val_Loss 1.1673 | Search Time(s) 0.6882 | Infer Time(s) 0.2486 | Time(s) 0.9367 
2023-12-01 10:00:57,817:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 2;	5: 0;	6: 2;	7: 2;	8: 0;	9: 2;	10: 0;	11: 2;	12: 0;	13: 2;	14: 0;	15: 2;	16: 2;	17: 2;	18: 0;	19: 2;	20: 2;	21: 2;	22: 0;	23: 0;	24: 1;	25: 2;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 0;	34: 2;	35: 0;	36: 2;	37: 3;	38: 2;	39: 2;	40: 0;	41: 0;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 1;	26101: 2;	26102: 0;	26103: 3;	26104: 2;	26105: 3;	26106: 3;	26107: 2;	26108: 2;	26109: 2;	26110: 0;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:00:57,818:INFO::Validation loss decreased (1.190358 --> 1.167257).  Saving model ...
2023-12-01 10:00:57,820:INFO::Epoch: 19
tensor([[0.4229, 0.4456, 0.5056, 0.4457],
        [0.4228, 0.5098, 0.4457, 0.4457],
        [0.4231, 0.4452, 0.5033, 0.4457],
        [0.4229, 0.4881, 0.4457, 0.4457]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:57,821:INFO::its now!!!!!!!!5
2023-12-01 10:00:58,046:INFO::its now!!!!!!!!0
2023-12-01 10:00:58,047:INFO::its now!!!!!!!!3
2023-12-01 10:00:58,179:INFO::its now!!!!!!!!5
2023-12-01 10:00:58,421:INFO::its now!!!!!!!!
2023-12-01 10:00:58,421:INFO::its now!!!!!!!! on 
2023-12-01 10:00:58,563:INFO::its now!!!!!!!!5
2023-12-01 10:00:58,795:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:58,797:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 1.1465 | Train_Classification_Loss 1.1779 | Dmon_Loss -0.0627 | Val_Loss 1.1422 | Search Time(s) 0.7271 | Infer Time(s) 0.2506 | Time(s) 0.9777 
2023-12-01 10:00:58,836:INFO::cluster info:
0: 0;	1: 3;	2: 2;	3: 2;	4: 2;	5: 3;	6: 0;	7: 2;	8: 3;	9: 2;	10: 1;	11: 0;	12: 1;	13: 3;	14: 2;	15: 1;	16: 2;	17: 2;	18: 2;	19: 3;	20: 3;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 1;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 0;	35: 0;	36: 3;	37: 2;	38: 2;	39: 0;	40: 3;	41: 2;	42: 3;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 0;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:00:58,837:INFO::Validation loss decreased (1.167257 --> 1.142245).  Saving model ...
2023-12-01 10:00:58,841:INFO::Epoch: 20
tensor([[0.4223, 0.4450, 0.5053, 0.4450],
        [0.4222, 0.5099, 0.4450, 0.4450],
        [0.4225, 0.4445, 0.5024, 0.4450],
        [0.4223, 0.4879, 0.4450, 0.4450]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:58,841:INFO::its now!!!!!!!!5
2023-12-01 10:00:59,062:INFO::its now!!!!!!!!0
2023-12-01 10:00:59,063:INFO::its now!!!!!!!!3
2023-12-01 10:00:59,194:INFO::its now!!!!!!!!5
2023-12-01 10:00:59,427:INFO::its now!!!!!!!!
2023-12-01 10:00:59,427:INFO::its now!!!!!!!! on 
2023-12-01 10:00:59,566:INFO::its now!!!!!!!!5
2023-12-01 10:00:59,776:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:00:59,778:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 1.1097 | Train_Classification_Loss 1.1412 | Dmon_Loss -0.0629 | Val_Loss 1.1132 | Search Time(s) 0.7073 | Infer Time(s) 0.2316 | Time(s) 0.9389 
2023-12-01 10:00:59,830:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 0;	10: 2;	11: 0;	12: 0;	13: 2;	14: 2;	15: 3;	16: 2;	17: 2;	18: 2;	19: 2;	20: 0;	21: 2;	22: 3;	23: 2;	24: 0;	25: 2;	26: 1;	27: 2;	28: 0;	29: 0;	30: 2;	31: 0;	32: 2;	33: 2;	34: 0;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 0;	42: 2;	43: 2;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 0;	26103: 3;	26104: 2;	26105: 2;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:00:59,831:INFO::Validation loss decreased (1.142245 --> 1.113217).  Saving model ...
2023-12-01 10:00:59,834:INFO::Epoch: 21
tensor([[0.4172, 0.4399, 0.5051, 0.4400],
        [0.4171, 0.5099, 0.4400, 0.4400],
        [0.4174, 0.4395, 0.5020, 0.4400],
        [0.4172, 0.4877, 0.4400, 0.4400]], device='cuda:0', requires_grad=True)
2023-12-01 10:00:59,835:INFO::its now!!!!!!!!5
2023-12-01 10:01:00,051:INFO::its now!!!!!!!!0
2023-12-01 10:01:00,053:INFO::its now!!!!!!!!3
2023-12-01 10:01:00,183:INFO::its now!!!!!!!!5
2023-12-01 10:01:00,412:INFO::its now!!!!!!!!
2023-12-01 10:01:00,412:INFO::its now!!!!!!!! on 
2023-12-01 10:01:00,553:INFO::its now!!!!!!!!5
2023-12-01 10:01:00,785:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:00,787:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 1.0865 | Train_Classification_Loss 1.1179 | Dmon_Loss -0.0628 | Val_Loss 1.0844 | Search Time(s) 0.7011 | Infer Time(s) 0.2527 | Time(s) 0.9538 
2023-12-01 10:01:00,851:INFO::cluster info:
0: 2;	1: 3;	2: 0;	3: 2;	4: 0;	5: 3;	6: 2;	7: 2;	8: 0;	9: 2;	10: 3;	11: 2;	12: 3;	13: 2;	14: 0;	15: 2;	16: 3;	17: 3;	18: 2;	19: 3;	20: 0;	21: 1;	22: 3;	23: 2;	24: 3;	25: 0;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 3;	32: 2;	33: 0;	34: 2;	35: 0;	36: 2;	37: 0;	38: 3;	39: 2;	40: 2;	41: 0;	42: 3;	43: 2;	44
26098: 3;	26099: 1;	26100: 0;	26101: 3;	26102: 3;	26103: 0;	26104: 1;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 10:01:00,852:INFO::Validation loss decreased (1.113217 --> 1.084377).  Saving model ...
2023-12-01 10:01:00,855:INFO::Epoch: 22
tensor([[0.4122, 0.4351, 0.5050, 0.4351],
        [0.4122, 0.5098, 0.4351, 0.4351],
        [0.4125, 0.4346, 0.5015, 0.4351],
        [0.4122, 0.4876, 0.4351, 0.4351]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:00,856:INFO::its now!!!!!!!!5
2023-12-01 10:01:01,137:INFO::its now!!!!!!!!0
2023-12-01 10:01:01,138:INFO::its now!!!!!!!!3
2023-12-01 10:01:01,268:INFO::its now!!!!!!!!5
2023-12-01 10:01:01,486:INFO::its now!!!!!!!!
2023-12-01 10:01:01,486:INFO::its now!!!!!!!! on 
2023-12-01 10:01:01,626:INFO::its now!!!!!!!!5
2023-12-01 10:01:01,841:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:01,843:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 1.0660 | Train_Classification_Loss 1.0974 | Dmon_Loss -0.0629 | Val_Loss 1.0535 | Search Time(s) 0.7545 | Infer Time(s) 0.2350 | Time(s) 0.9895 
2023-12-01 10:01:01,890:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 0;	5: 0;	6: 3;	7: 2;	8: 3;	9: 0;	10: 0;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 3;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 3;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 0;	34: 2;	35: 2;	36: 0;	37: 0;	38: 0;	39: 2;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 2;	26099: 3;	26100: 0;	26101: 2;	26102: 2;	26103: 3;	26104: 2;	26105: 1;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 10:01:01,891:INFO::Validation loss decreased (1.084377 --> 1.053536).  Saving model ...
2023-12-01 10:01:01,893:INFO::Epoch: 23
tensor([[0.4067, 0.4296, 0.5050, 0.4296],
        [0.4066, 0.5099, 0.4296, 0.4296],
        [0.4069, 0.4291, 0.5011, 0.4296],
        [0.4067, 0.4875, 0.4296, 0.4296]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:01,894:INFO::its now!!!!!!!!5
2023-12-01 10:01:02,113:INFO::its now!!!!!!!!0
2023-12-01 10:01:02,114:INFO::its now!!!!!!!!3
2023-12-01 10:01:02,248:INFO::its now!!!!!!!!5
2023-12-01 10:01:02,476:INFO::its now!!!!!!!!
2023-12-01 10:01:02,476:INFO::its now!!!!!!!! on 
2023-12-01 10:01:02,616:INFO::its now!!!!!!!!5
2023-12-01 10:01:02,846:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:02,848:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 1.0401 | Train_Classification_Loss 1.0716 | Dmon_Loss -0.0629 | Val_Loss 1.0200 | Search Time(s) 0.7048 | Infer Time(s) 0.2500 | Time(s) 0.9548 
2023-12-01 10:01:02,887:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 3;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 3;	14: 2;	15: 2;	16: 2;	17: 2;	18: 0;	19: 2;	20: 2;	21: 2;	22: 0;	23: 2;	24: 3;	25: 2;	26: 2;	27: 2;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 0;	35: 3;	36: 0;	37: 2;	38: 0;	39: 2;	40: 0;	41: 3;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 3;	26103: 3;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 10:01:02,888:INFO::Validation loss decreased (1.053536 --> 1.020019).  Saving model ...
2023-12-01 10:01:02,892:INFO::Epoch: 24
tensor([[0.4010, 0.4240, 0.5050, 0.4240],
        [0.4010, 0.5099, 0.4240, 0.4240],
        [0.4013, 0.4235, 0.5015, 0.4240],
        [0.4010, 0.4874, 0.4240, 0.4240]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:02,892:INFO::its now!!!!!!!!5
2023-12-01 10:01:03,114:INFO::its now!!!!!!!!0
2023-12-01 10:01:03,116:INFO::its now!!!!!!!!3
2023-12-01 10:01:03,231:INFO::its now!!!!!!!!5
2023-12-01 10:01:03,467:INFO::its now!!!!!!!!
2023-12-01 10:01:03,467:INFO::its now!!!!!!!! on 
2023-12-01 10:01:03,609:INFO::its now!!!!!!!!5
2023-12-01 10:01:03,838:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:03,840:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 0.9882 | Train_Classification_Loss 1.0197 | Dmon_Loss -0.0629 | Val_Loss 0.9870 | Search Time(s) 0.7017 | Infer Time(s) 0.2489 | Time(s) 0.9506 
2023-12-01 10:01:03,888:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 0;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 0;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 3;	26: 0;	27: 2;	28: 2;	29: 2;	30: 2;	31: 0;	32: 2;	33: 0;	34: 3;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 3;	42: 2;	43: 2;	44
26098: 3;	26099: 1;	26100: 3;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 3;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:03,889:INFO::Validation loss decreased (1.020019 --> 0.987022).  Saving model ...
2023-12-01 10:01:03,891:INFO::Epoch: 25
tensor([[0.3913, 0.4143, 0.5051, 0.4144],
        [0.3913, 0.4977, 0.4144, 0.4212],
        [0.3916, 0.4139, 0.5016, 0.4144],
        [0.3913, 0.4753, 0.4144, 0.4212]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:03,892:INFO::its now!!!!!!!!5
2023-12-01 10:01:04,103:INFO::its now!!!!!!!!0
2023-12-01 10:01:04,104:INFO::its now!!!!!!!!3
2023-12-01 10:01:04,235:INFO::its now!!!!!!!!5
2023-12-01 10:01:04,468:INFO::its now!!!!!!!!
2023-12-01 10:01:04,468:INFO::its now!!!!!!!! on 
2023-12-01 10:01:04,608:INFO::its now!!!!!!!!5
2023-12-01 10:01:04,816:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:04,818:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 0.9518 | Train_Classification_Loss 0.9833 | Dmon_Loss -0.0630 | Val_Loss 0.9417 | Search Time(s) 0.6967 | Infer Time(s) 0.2290 | Time(s) 0.9257 
2023-12-01 10:01:04,876:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 0;	7: 0;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 0;	14: 2;	15: 3;	16: 2;	17: 0;	18: 2;	19: 3;	20: 2;	21: 0;	22: 0;	23: 2;	24: 0;	25: 2;	26: 2;	27: 2;	28: 3;	29: 2;	30: 0;	31: 2;	32: 0;	33: 3;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:04,877:INFO::Validation loss decreased (0.987022 --> 0.941749).  Saving model ...
2023-12-01 10:01:04,879:INFO::Epoch: 26
tensor([[0.3842, 0.4072, 0.5048, 0.4073],
        [0.3841, 0.4915, 0.4073, 0.4169],
        [0.3844, 0.4068, 0.5016, 0.4073],
        [0.3842, 0.4691, 0.4073, 0.4169]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:04,880:INFO::its now!!!!!!!!5
2023-12-01 10:01:05,092:INFO::its now!!!!!!!!0
2023-12-01 10:01:05,093:INFO::its now!!!!!!!!3
2023-12-01 10:01:05,224:INFO::its now!!!!!!!!5
2023-12-01 10:01:05,460:INFO::its now!!!!!!!!
2023-12-01 10:01:05,460:INFO::its now!!!!!!!! on 
2023-12-01 10:01:05,600:INFO::its now!!!!!!!!5
2023-12-01 10:01:05,818:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:05,819:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 0.9204 | Train_Classification_Loss 0.9519 | Dmon_Loss -0.0630 | Val_Loss 0.9050 | Search Time(s) 0.7037 | Infer Time(s) 0.2379 | Time(s) 0.9416 
2023-12-01 10:01:05,859:INFO::cluster info:
0: 2;	1: 0;	2: 1;	3: 2;	4: 3;	5: 3;	6: 2;	7: 2;	8: 2;	9: 0;	10: 2;	11: 3;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 0;	23: 2;	24: 0;	25: 2;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 3;	33: 0;	34: 0;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 3;	26103: 2;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:05,860:INFO::Validation loss decreased (0.941749 --> 0.905022).  Saving model ...
2023-12-01 10:01:05,862:INFO::Epoch: 27
tensor([[0.3771, 0.4001, 0.5048, 0.4002],
        [0.3770, 0.4883, 0.4002, 0.4106],
        [0.3773, 0.3997, 0.5022, 0.4002],
        [0.3771, 0.4659, 0.4002, 0.4106]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:05,863:INFO::its now!!!!!!!!5
2023-12-01 10:01:06,096:INFO::its now!!!!!!!!0
2023-12-01 10:01:06,097:INFO::its now!!!!!!!!3
2023-12-01 10:01:06,229:INFO::its now!!!!!!!!5
2023-12-01 10:01:06,471:INFO::its now!!!!!!!!
2023-12-01 10:01:06,472:INFO::its now!!!!!!!! on 
2023-12-01 10:01:06,612:INFO::its now!!!!!!!!5
2023-12-01 10:01:06,825:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:06,826:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 0.8870 | Train_Classification_Loss 0.9185 | Dmon_Loss -0.0630 | Val_Loss 0.8659 | Search Time(s) 0.7316 | Infer Time(s) 0.2331 | Time(s) 0.9647 
2023-12-01 10:01:06,870:INFO::cluster info:
0: 0;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 0;	34: 0;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 0;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 0;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 2;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:06,872:INFO::Validation loss decreased (0.905022 --> 0.865857).  Saving model ...
2023-12-01 10:01:06,874:INFO::Epoch: 28
tensor([[0.3695, 0.3926, 0.5048, 0.3927],
        [0.3695, 0.4867, 0.3927, 0.4028],
        [0.3697, 0.3922, 0.5028, 0.3927],
        [0.3695, 0.4643, 0.3927, 0.4028]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:06,874:INFO::its now!!!!!!!!5
2023-12-01 10:01:07,102:INFO::its now!!!!!!!!0
2023-12-01 10:01:07,103:INFO::its now!!!!!!!!3
2023-12-01 10:01:07,235:INFO::its now!!!!!!!!5
2023-12-01 10:01:07,480:INFO::its now!!!!!!!!
2023-12-01 10:01:07,480:INFO::its now!!!!!!!! on 
2023-12-01 10:01:07,620:INFO::its now!!!!!!!!5
2023-12-01 10:01:07,852:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:07,854:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 0.8511 | Train_Classification_Loss 0.8826 | Dmon_Loss -0.0630 | Val_Loss 0.8236 | Search Time(s) 0.7276 | Infer Time(s) 0.2530 | Time(s) 0.9806 
2023-12-01 10:01:07,908:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 3;	5: 0;	6: 2;	7: 2;	8: 3;	9: 0;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 0;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 3;	25: 2;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 3;	35: 3;	36: 0;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 3;	44
26098: 3;	26099: 2;	26100: 2;	26101: 0;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:07,909:INFO::Validation loss decreased (0.865857 --> 0.823613).  Saving model ...
2023-12-01 10:01:07,912:INFO::Epoch: 29
tensor([[0.3631, 0.3862, 0.5048, 0.3862],
        [0.3630, 0.4859, 0.3862, 0.3957],
        [0.3633, 0.3858, 0.5040, 0.3862],
        [0.3631, 0.4635, 0.3862, 0.3957]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:07,913:INFO::its now!!!!!!!!5
2023-12-01 10:01:08,119:INFO::its now!!!!!!!!0
2023-12-01 10:01:08,120:INFO::its now!!!!!!!!3
2023-12-01 10:01:08,253:INFO::its now!!!!!!!!5
2023-12-01 10:01:08,482:INFO::its now!!!!!!!!
2023-12-01 10:01:08,482:INFO::its now!!!!!!!! on 
2023-12-01 10:01:08,623:INFO::its now!!!!!!!!5
2023-12-01 10:01:08,832:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:08,834:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 0.8265 | Train_Classification_Loss 0.8580 | Dmon_Loss -0.0631 | Val_Loss 0.7792 | Search Time(s) 0.6947 | Infer Time(s) 0.2280 | Time(s) 0.9227 
2023-12-01 10:01:08,891:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 0;	13: 2;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 2;	25: 2;	26: 0;	27: 2;	28: 0;	29: 2;	30: 2;	31: 2;	32: 3;	33: 0;	34: 2;	35: 2;	36: 2;	37: 0;	38: 0;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 2;	26101: 0;	26102: 2;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:08,892:INFO::Validation loss decreased (0.823613 --> 0.779190).  Saving model ...
2023-12-01 10:01:08,895:INFO::Epoch: 30
tensor([[0.3557, 0.3789, 0.4918, 0.3830],
        [0.3556, 0.4855, 0.3789, 0.3875],
        [0.3596, 0.3784, 0.4911, 0.3789],
        [0.3598, 0.4560, 0.3789, 0.3875]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:08,895:INFO::its now!!!!!!!!5
2023-12-01 10:01:09,109:INFO::its now!!!!!!!!0
2023-12-01 10:01:09,111:INFO::its now!!!!!!!!3
2023-12-01 10:01:09,241:INFO::its now!!!!!!!!5
2023-12-01 10:01:09,472:INFO::its now!!!!!!!!
2023-12-01 10:01:09,472:INFO::its now!!!!!!!! on 
2023-12-01 10:01:09,615:INFO::its now!!!!!!!!5
2023-12-01 10:01:09,831:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:09,832:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 0.7891 | Train_Classification_Loss 0.8207 | Dmon_Loss -0.0631 | Val_Loss 0.7426 | Search Time(s) 0.7027 | Infer Time(s) 0.2370 | Time(s) 0.9397 
2023-12-01 10:01:09,883:INFO::cluster info:
0: 2;	1: 0;	2: 3;	3: 2;	4: 2;	5: 2;	6: 0;	7: 2;	8: 0;	9: 0;	10: 0;	11: 1;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 3;	31: 2;	32: 0;	33: 3;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 0;	40: 0;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 1;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 3;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:09,885:INFO::Validation loss decreased (0.779190 --> 0.742621).  Saving model ...
2023-12-01 10:01:09,887:INFO::Epoch: 31
tensor([[0.3493, 0.3725, 0.4852, 0.3785],
        [0.3492, 0.4852, 0.3725, 0.3804],
        [0.3549, 0.3720, 0.4845, 0.3725],
        [0.3552, 0.4522, 0.3725, 0.3804]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:09,888:INFO::its now!!!!!!!!5
2023-12-01 10:01:10,114:INFO::its now!!!!!!!!0
2023-12-01 10:01:10,115:INFO::its now!!!!!!!!3
2023-12-01 10:01:10,247:INFO::its now!!!!!!!!5
2023-12-01 10:01:10,473:INFO::its now!!!!!!!!
2023-12-01 10:01:10,474:INFO::its now!!!!!!!! on 
2023-12-01 10:01:10,613:INFO::its now!!!!!!!!5
2023-12-01 10:01:10,817:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:10,819:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 0.7455 | Train_Classification_Loss 0.7771 | Dmon_Loss -0.0631 | Val_Loss 0.7007 | Search Time(s) 0.7077 | Infer Time(s) 0.2240 | Time(s) 0.9317 
2023-12-01 10:01:10,873:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 0;	9: 3;	10: 2;	11: 0;	12: 2;	13: 0;	14: 2;	15: 1;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 0;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 0;	31: 2;	32: 2;	33: 0;	34: 3;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 2;	26101: 0;	26102: 3;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 10:01:10,874:INFO::Validation loss decreased (0.742621 --> 0.700659).  Saving model ...
2023-12-01 10:01:10,876:INFO::Epoch: 32
tensor([[0.3420, 0.3652, 0.4818, 0.3719],
        [0.3419, 0.4851, 0.3652, 0.3722],
        [0.3482, 0.3647, 0.4812, 0.3652],
        [0.3487, 0.4503, 0.3652, 0.3722]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:10,877:INFO::its now!!!!!!!!5
2023-12-01 10:01:11,077:INFO::its now!!!!!!!!0
2023-12-01 10:01:11,078:INFO::its now!!!!!!!!3
2023-12-01 10:01:11,209:INFO::its now!!!!!!!!5
2023-12-01 10:01:11,427:INFO::its now!!!!!!!!
2023-12-01 10:01:11,427:INFO::its now!!!!!!!! on 
2023-12-01 10:01:11,569:INFO::its now!!!!!!!!5
2023-12-01 10:01:11,799:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:11,801:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 0.7081 | Train_Classification_Loss 0.7397 | Dmon_Loss -0.0631 | Val_Loss 0.6602 | Search Time(s) 0.6742 | Infer Time(s) 0.2505 | Time(s) 0.9247 
2023-12-01 10:01:11,845:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 0;	7: 2;	8: 2;	9: 2;	10: 3;	11: 2;	12: 2;	13: 2;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 3;	33: 0;	34: 2;	35: 2;	36: 2;	37: 3;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 1;	26099: 0;	26100: 3;	26101: 0;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:11,847:INFO::Validation loss decreased (0.700659 --> 0.660178).  Saving model ...
2023-12-01 10:01:11,850:INFO::Epoch: 33
tensor([[0.3374, 0.3607, 0.4800, 0.3677],
        [0.3374, 0.4850, 0.3607, 0.3671],
        [0.3440, 0.3602, 0.4795, 0.3607],
        [0.3445, 0.4493, 0.3607, 0.3671]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:11,851:INFO::its now!!!!!!!!5
2023-12-01 10:01:12,095:INFO::its now!!!!!!!!0
2023-12-01 10:01:12,096:INFO::its now!!!!!!!!3
2023-12-01 10:01:12,228:INFO::its now!!!!!!!!5
2023-12-01 10:01:12,450:INFO::its now!!!!!!!!
2023-12-01 10:01:12,450:INFO::its now!!!!!!!! on 
2023-12-01 10:01:12,595:INFO::its now!!!!!!!!5
2023-12-01 10:01:12,818:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:12,819:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 0.6784 | Train_Classification_Loss 0.7100 | Dmon_Loss -0.0632 | Val_Loss 0.6161 | Search Time(s) 0.7246 | Infer Time(s) 0.2460 | Time(s) 0.9706 
2023-12-01 10:01:12,855:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 0;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 1;	25: 2;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 2;	35: 3;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 0;	26100: 3;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 2;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:12,856:INFO::Validation loss decreased (0.660178 --> 0.616116).  Saving model ...
2023-12-01 10:01:12,859:INFO::Epoch: 34
tensor([[0.3327, 0.3559, 0.4791, 0.3631],
        [0.3326, 0.4850, 0.3560, 0.3618],
        [0.3392, 0.3555, 0.4786, 0.3560],
        [0.3398, 0.4488, 0.3560, 0.3618]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:12,860:INFO::its now!!!!!!!!5
2023-12-01 10:01:13,095:INFO::its now!!!!!!!!0
2023-12-01 10:01:13,096:INFO::its now!!!!!!!!3
2023-12-01 10:01:13,228:INFO::its now!!!!!!!!5
2023-12-01 10:01:13,453:INFO::its now!!!!!!!!
2023-12-01 10:01:13,453:INFO::its now!!!!!!!! on 
2023-12-01 10:01:13,594:INFO::its now!!!!!!!!5
2023-12-01 10:01:13,832:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:13,834:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 0.6419 | Train_Classification_Loss 0.6735 | Dmon_Loss -0.0632 | Val_Loss 0.5853 | Search Time(s) 0.7167 | Infer Time(s) 0.2580 | Time(s) 0.9746 
2023-12-01 10:01:13,870:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 3;	7: 2;	8: 2;	9: 3;	10: 2;	11: 3;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 0;	25: 3;	26: 2;	27: 2;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 0;	26101: 3;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:13,871:INFO::Validation loss decreased (0.616116 --> 0.585345).  Saving model ...
2023-12-01 10:01:13,874:INFO::Epoch: 35
tensor([[0.3295, 0.3528, 0.4786, 0.3599],
        [0.3294, 0.4850, 0.3528, 0.3583],
        [0.3361, 0.3523, 0.4781, 0.3528],
        [0.3366, 0.4485, 0.3528, 0.3583]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:13,875:INFO::its now!!!!!!!!5
2023-12-01 10:01:14,107:INFO::its now!!!!!!!!0
2023-12-01 10:01:14,108:INFO::its now!!!!!!!!3
2023-12-01 10:01:14,239:INFO::its now!!!!!!!!5
2023-12-01 10:01:14,474:INFO::its now!!!!!!!!
2023-12-01 10:01:14,474:INFO::its now!!!!!!!! on 
2023-12-01 10:01:14,615:INFO::its now!!!!!!!!5
2023-12-01 10:01:14,835:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:14,837:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 0.6201 | Train_Classification_Loss 0.6518 | Dmon_Loss -0.0633 | Val_Loss 0.5519 | Search Time(s) 0.7227 | Infer Time(s) 0.2410 | Time(s) 0.9637 
2023-12-01 10:01:14,878:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 3;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 0;	13: 2;	14: 2;	15: 1;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 3;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 0;	36: 2;	37: 2;	38: 0;	39: 2;	40: 0;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:14,878:INFO::Validation loss decreased (0.585345 --> 0.551918).  Saving model ...
2023-12-01 10:01:14,880:INFO::Epoch: 36
tensor([[0.3285, 0.3518, 0.4781, 0.3589],
        [0.3285, 0.4850, 0.3518, 0.3572],
        [0.3351, 0.3513, 0.4777, 0.3518],
        [0.3357, 0.4484, 0.3518, 0.3572]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:14,881:INFO::its now!!!!!!!!5
2023-12-01 10:01:15,090:INFO::its now!!!!!!!!0
2023-12-01 10:01:15,092:INFO::its now!!!!!!!!3
2023-12-01 10:01:15,223:INFO::its now!!!!!!!!5
2023-12-01 10:01:15,453:INFO::its now!!!!!!!!
2023-12-01 10:01:15,453:INFO::its now!!!!!!!! on 
2023-12-01 10:01:15,594:INFO::its now!!!!!!!!5
2023-12-01 10:01:15,820:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:15,821:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 0.5925 | Train_Classification_Loss 0.6242 | Dmon_Loss -0.0634 | Val_Loss 0.5216 | Search Time(s) 0.6937 | Infer Time(s) 0.2469 | Time(s) 0.9406 
2023-12-01 10:01:15,860:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 0;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 3;	33: 3;	34: 0;	35: 0;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 2;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:15,862:INFO::Validation loss decreased (0.551918 --> 0.521587).  Saving model ...
2023-12-01 10:01:15,864:INFO::Epoch: 37
tensor([[0.3292, 0.3525, 0.4778, 0.3597],
        [0.3292, 0.4850, 0.3525, 0.3580],
        [0.3358, 0.3520, 0.4777, 0.3525],
        [0.3364, 0.4483, 0.3525, 0.3580]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:15,865:INFO::its now!!!!!!!!5
2023-12-01 10:01:16,097:INFO::its now!!!!!!!!0
2023-12-01 10:01:16,098:INFO::its now!!!!!!!!3
2023-12-01 10:01:16,229:INFO::its now!!!!!!!!5
2023-12-01 10:01:16,476:INFO::its now!!!!!!!!
2023-12-01 10:01:16,477:INFO::its now!!!!!!!! on 
2023-12-01 10:01:16,617:INFO::its now!!!!!!!!5
2023-12-01 10:01:16,827:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:16,829:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 0.5489 | Train_Classification_Loss 0.5806 | Dmon_Loss -0.0635 | Val_Loss 0.4900 | Search Time(s) 0.7349 | Infer Time(s) 0.2300 | Time(s) 0.9649 
2023-12-01 10:01:16,867:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 3;	13: 0;	14: 2;	15: 0;	16: 3;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 0;	25: 0;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 3;	34: 2;	35: 3;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 0;	26103: 3;	26104: 2;	26105: 0;	26106: 3;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:16,868:INFO::Validation loss decreased (0.521587 --> 0.490043).  Saving model ...
2023-12-01 10:01:16,871:INFO::Epoch: 38
tensor([[0.3274, 0.3507, 0.4776, 0.3579],
        [0.3274, 0.4850, 0.3508, 0.3560],
        [0.3340, 0.3503, 0.4777, 0.3508],
        [0.3346, 0.4483, 0.3508, 0.3560]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:16,872:INFO::its now!!!!!!!!5
2023-12-01 10:01:17,074:INFO::its now!!!!!!!!0
2023-12-01 10:01:17,075:INFO::its now!!!!!!!!3
2023-12-01 10:01:17,205:INFO::its now!!!!!!!!5
2023-12-01 10:01:17,458:INFO::its now!!!!!!!!
2023-12-01 10:01:17,459:INFO::its now!!!!!!!! on 
2023-12-01 10:01:17,600:INFO::its now!!!!!!!!5
2023-12-01 10:01:17,813:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:17,815:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 0.5503 | Train_Classification_Loss 0.5821 | Dmon_Loss -0.0636 | Val_Loss 0.4669 | Search Time(s) 0.7127 | Infer Time(s) 0.2320 | Time(s) 0.9447 
2023-12-01 10:01:17,876:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 2;	9: 3;	10: 2;	11: 3;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 0;	35: 3;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 1;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:17,877:INFO::Validation loss decreased (0.490043 --> 0.466920).  Saving model ...
2023-12-01 10:01:17,879:INFO::Epoch: 39
tensor([[0.3239, 0.3472, 0.4775, 0.3542],
        [0.3239, 0.4850, 0.3472, 0.3521],
        [0.3303, 0.3468, 0.4775, 0.3472],
        [0.3309, 0.4482, 0.3472, 0.3521]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:17,880:INFO::its now!!!!!!!!5
2023-12-01 10:01:18,101:INFO::its now!!!!!!!!0
2023-12-01 10:01:18,102:INFO::its now!!!!!!!!3
2023-12-01 10:01:18,233:INFO::its now!!!!!!!!5
2023-12-01 10:01:18,483:INFO::its now!!!!!!!!
2023-12-01 10:01:18,483:INFO::its now!!!!!!!! on 
2023-12-01 10:01:18,625:INFO::its now!!!!!!!!5
2023-12-01 10:01:18,846:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:18,848:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 0.5263 | Train_Classification_Loss 0.5582 | Dmon_Loss -0.0638 | Val_Loss 0.4424 | Search Time(s) 0.7287 | Infer Time(s) 0.2409 | Time(s) 0.9696 
2023-12-01 10:01:18,900:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 2;	9: 1;	10: 2;	11: 2;	12: 2;	13: 0;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 0;	25: 3;	26: 2;	27: 2;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 1;	26102: 2;	26103: 0;	26104: 3;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:18,901:INFO::Validation loss decreased (0.466920 --> 0.442357).  Saving model ...
2023-12-01 10:01:18,903:INFO::Epoch: 40
tensor([[0.3186, 0.3419, 0.4774, 0.3488],
        [0.3186, 0.4850, 0.3420, 0.3463],
        [0.3249, 0.3415, 0.4775, 0.3420],
        [0.3255, 0.4482, 0.3420, 0.3463]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:18,904:INFO::its now!!!!!!!!5
2023-12-01 10:01:19,101:INFO::its now!!!!!!!!0
2023-12-01 10:01:19,102:INFO::its now!!!!!!!!3
2023-12-01 10:01:19,232:INFO::its now!!!!!!!!5
2023-12-01 10:01:19,471:INFO::its now!!!!!!!!
2023-12-01 10:01:19,472:INFO::its now!!!!!!!! on 
2023-12-01 10:01:19,612:INFO::its now!!!!!!!!5
2023-12-01 10:01:19,815:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:19,816:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 0.5054 | Train_Classification_Loss 0.5374 | Dmon_Loss -0.0640 | Val_Loss 0.4255 | Search Time(s) 0.6898 | Infer Time(s) 0.2230 | Time(s) 0.9128 
2023-12-01 10:01:19,866:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 0;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 3;	34: 0;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:19,868:INFO::Validation loss decreased (0.442357 --> 0.425511).  Saving model ...
2023-12-01 10:01:19,870:INFO::Epoch: 41
tensor([[0.3133, 0.3366, 0.4773, 0.3433],
        [0.3133, 0.4850, 0.3367, 0.3404],
        [0.3194, 0.3362, 0.4777, 0.3367],
        [0.3199, 0.4482, 0.3367, 0.3404]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:19,871:INFO::its now!!!!!!!!5
2023-12-01 10:01:20,091:INFO::its now!!!!!!!!0
2023-12-01 10:01:20,092:INFO::its now!!!!!!!!3
2023-12-01 10:01:20,224:INFO::its now!!!!!!!!5
2023-12-01 10:01:20,452:INFO::its now!!!!!!!!
2023-12-01 10:01:20,452:INFO::its now!!!!!!!! on 
2023-12-01 10:01:20,594:INFO::its now!!!!!!!!5
2023-12-01 10:01:20,823:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:20,825:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 0.4950 | Train_Classification_Loss 0.5271 | Dmon_Loss -0.0642 | Val_Loss 0.4025 | Search Time(s) 0.7047 | Infer Time(s) 0.2500 | Time(s) 0.9547 
2023-12-01 10:01:20,867:INFO::cluster info:
0: 2;	1: 2;	2: 3;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 3;	13: 0;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 3;	25: 3;	26: 2;	27: 2;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:20,868:INFO::Validation loss decreased (0.425511 --> 0.402511).  Saving model ...
2023-12-01 10:01:20,871:INFO::Epoch: 42
tensor([[0.3105, 0.3338, 0.4772, 0.3404],
        [0.3105, 0.4849, 0.3339, 0.3373],
        [0.3165, 0.3334, 0.4779, 0.3339],
        [0.3170, 0.4482, 0.3339, 0.3373]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:20,872:INFO::its now!!!!!!!!5
2023-12-01 10:01:21,085:INFO::its now!!!!!!!!0
2023-12-01 10:01:21,086:INFO::its now!!!!!!!!3
2023-12-01 10:01:21,216:INFO::its now!!!!!!!!5
2023-12-01 10:01:21,455:INFO::its now!!!!!!!!
2023-12-01 10:01:21,455:INFO::its now!!!!!!!! on 
2023-12-01 10:01:21,596:INFO::its now!!!!!!!!5
2023-12-01 10:01:21,804:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:21,805:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 0.4549 | Train_Classification_Loss 0.4871 | Dmon_Loss -0.0644 | Val_Loss 0.3902 | Search Time(s) 0.7068 | Infer Time(s) 0.2290 | Time(s) 0.9357 
2023-12-01 10:01:21,846:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 3;	8: 2;	9: 3;	10: 2;	11: 2;	12: 3;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 1;	25: 0;	26: 2;	27: 0;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 0;	35: 2;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 0;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 1;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:21,847:INFO::Validation loss decreased (0.402511 --> 0.390178).  Saving model ...
2023-12-01 10:01:21,849:INFO::Epoch: 43
tensor([[0.3036, 0.3269, 0.4772, 0.3333],
        [0.3035, 0.4849, 0.3270, 0.3298],
        [0.3093, 0.3265, 0.4780, 0.3270],
        [0.3099, 0.4482, 0.3270, 0.3298]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:21,850:INFO::its now!!!!!!!!5
2023-12-01 10:01:22,062:INFO::its now!!!!!!!!0
2023-12-01 10:01:22,064:INFO::its now!!!!!!!!3
2023-12-01 10:01:22,196:INFO::its now!!!!!!!!5
2023-12-01 10:01:22,423:INFO::its now!!!!!!!!
2023-12-01 10:01:22,423:INFO::its now!!!!!!!! on 
2023-12-01 10:01:22,563:INFO::its now!!!!!!!!5
2023-12-01 10:01:22,805:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:22,806:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 0.4363 | Train_Classification_Loss 0.4687 | Dmon_Loss -0.0648 | Val_Loss 0.3788 | Search Time(s) 0.6952 | Infer Time(s) 0.2625 | Time(s) 0.9577 
2023-12-01 10:01:22,864:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 1;	10: 3;	11: 2;	12: 1;	13: 0;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 0;	25: 2;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 2;	34: 2;	35: 0;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 3;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:22,866:INFO::Validation loss decreased (0.390178 --> 0.378767).  Saving model ...
2023-12-01 10:01:22,870:INFO::Epoch: 44
tensor([[0.2980, 0.3214, 0.4770, 0.3275],
        [0.2979, 0.4849, 0.3214, 0.3237],
        [0.3035, 0.3209, 0.4782, 0.3214],
        [0.3041, 0.4482, 0.3214, 0.3237]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:22,871:INFO::its now!!!!!!!!5
2023-12-01 10:01:23,108:INFO::its now!!!!!!!!0
2023-12-01 10:01:23,109:INFO::its now!!!!!!!!3
2023-12-01 10:01:23,244:INFO::its now!!!!!!!!5
2023-12-01 10:01:23,470:INFO::its now!!!!!!!!
2023-12-01 10:01:23,470:INFO::its now!!!!!!!! on 
2023-12-01 10:01:23,611:INFO::its now!!!!!!!!5
2023-12-01 10:01:23,835:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:23,837:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 0.4260 | Train_Classification_Loss 0.4587 | Dmon_Loss -0.0653 | Val_Loss 0.3592 | Search Time(s) 0.7257 | Infer Time(s) 0.2440 | Time(s) 0.9696 
2023-12-01 10:01:23,885:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 1;	25: 2;	26: 2;	27: 2;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 0;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:23,887:INFO::Validation loss decreased (0.378767 --> 0.359194).  Saving model ...
2023-12-01 10:01:23,889:INFO::Epoch: 45
tensor([[0.2928, 0.3161, 0.4687, 0.3246],
        [0.2927, 0.4792, 0.3162, 0.3206],
        [0.2981, 0.3157, 0.4785, 0.3162],
        [0.2987, 0.4481, 0.3162, 0.3181]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:23,890:INFO::its now!!!!!!!!5
2023-12-01 10:01:24,109:INFO::its now!!!!!!!!0
2023-12-01 10:01:24,110:INFO::its now!!!!!!!!3
2023-12-01 10:01:24,240:INFO::its now!!!!!!!!5
2023-12-01 10:01:24,470:INFO::its now!!!!!!!!
2023-12-01 10:01:24,470:INFO::its now!!!!!!!! on 
2023-12-01 10:01:24,611:INFO::its now!!!!!!!!5
2023-12-01 10:01:24,835:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:24,836:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 0.4172 | Train_Classification_Loss 0.4502 | Dmon_Loss -0.0658 | Val_Loss 0.3460 | Search Time(s) 0.7047 | Infer Time(s) 0.2429 | Time(s) 0.9476 
2023-12-01 10:01:24,877:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 3;	7: 2;	8: 2;	9: 0;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 3;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 2;	35: 3;	36: 2;	37: 0;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 3;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:24,878:INFO::Validation loss decreased (0.359194 --> 0.346034).  Saving model ...
2023-12-01 10:01:24,880:INFO::Epoch: 46
tensor([[0.2897, 0.3131, 0.4643, 0.3227],
        [0.2897, 0.4763, 0.3132, 0.3186],
        [0.2950, 0.3127, 0.4790, 0.3132],
        [0.2956, 0.4481, 0.3132, 0.3148]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:24,880:INFO::its now!!!!!!!!5
2023-12-01 10:01:25,088:INFO::its now!!!!!!!!0
2023-12-01 10:01:25,089:INFO::its now!!!!!!!!3
2023-12-01 10:01:25,221:INFO::its now!!!!!!!!5
2023-12-01 10:01:25,444:INFO::its now!!!!!!!!
2023-12-01 10:01:25,444:INFO::its now!!!!!!!! on 
2023-12-01 10:01:25,584:INFO::its now!!!!!!!!5
2023-12-01 10:01:25,807:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:25,809:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 0.4271 | Train_Classification_Loss 0.4602 | Dmon_Loss -0.0664 | Val_Loss 0.3347 | Search Time(s) 0.6868 | Infer Time(s) 0.2430 | Time(s) 0.9298 
2023-12-01 10:01:25,850:INFO::cluster info:
0: 3;	1: 2;	2: 1;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 1;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 0;	25: 3;	26: 2;	27: 2;	28: 0;	29: 2;	30: 2;	31: 2;	32: 3;	33: 2;	34: 0;	35: 1;	36: 2;	37: 3;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 3;	26105: 0;	26106: 1;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 0;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 0;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:01:25,851:INFO::Validation loss decreased (0.346034 --> 0.334701).  Saving model ...
2023-12-01 10:01:25,854:INFO::Epoch: 47
tensor([[0.2880, 0.3114, 0.4619, 0.3215],
        [0.2880, 0.4749, 0.3115, 0.3174],
        [0.2932, 0.3110, 0.4796, 0.3115],
        [0.2938, 0.4481, 0.3115, 0.3129]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:25,855:INFO::its now!!!!!!!!5
2023-12-01 10:01:26,073:INFO::its now!!!!!!!!0
2023-12-01 10:01:26,074:INFO::its now!!!!!!!!3
2023-12-01 10:01:26,205:INFO::its now!!!!!!!!5
2023-12-01 10:01:26,431:INFO::its now!!!!!!!!
2023-12-01 10:01:26,432:INFO::its now!!!!!!!! on 
2023-12-01 10:01:26,572:INFO::its now!!!!!!!!5
2023-12-01 10:01:26,775:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:26,776:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 0.4148 | Train_Classification_Loss 0.4483 | Dmon_Loss -0.0670 | Val_Loss 0.3285 | Search Time(s) 0.6995 | Infer Time(s) 0.2226 | Time(s) 0.9221 
2023-12-01 10:01:26,813:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 1;	5: 2;	6: 2;	7: 3;	8: 3;	9: 3;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 3;	24: 1;	25: 0;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 3;	26100: 0;	26101: 0;	26102: 2;	26103: 3;	26104: 2;	26105: 0;	26106: 1;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 0;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 0;	26121: 2;	26122: 0;	26123: 0;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:01:26,814:INFO::Validation loss decreased (0.334701 --> 0.328497).  Saving model ...
2023-12-01 10:01:26,817:INFO::Epoch: 48
tensor([[0.2863, 0.3097, 0.4608, 0.3201],
        [0.2863, 0.4741, 0.3098, 0.3159],
        [0.2915, 0.3093, 0.4802, 0.3098],
        [0.2921, 0.4479, 0.3098, 0.3111]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:26,817:INFO::its now!!!!!!!!5
2023-12-01 10:01:27,052:INFO::its now!!!!!!!!0
2023-12-01 10:01:27,053:INFO::its now!!!!!!!!3
2023-12-01 10:01:27,185:INFO::its now!!!!!!!!5
2023-12-01 10:01:27,408:INFO::its now!!!!!!!!
2023-12-01 10:01:27,408:INFO::its now!!!!!!!! on 
2023-12-01 10:01:27,548:INFO::its now!!!!!!!!5
2023-12-01 10:01:27,746:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:27,747:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 0.3705 | Train_Classification_Loss 0.4045 | Dmon_Loss -0.0681 | Val_Loss 0.3160 | Search Time(s) 0.7131 | Infer Time(s) 0.2189 | Time(s) 0.9320 
2023-12-01 10:01:27,795:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 2;	9: 1;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 0;	16: 3;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 1;	25: 0;	26: 2;	27: 3;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 0;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 3;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 2;	26121: 2;	26122: 0;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:01:27,797:INFO::Validation loss decreased (0.328497 --> 0.315971).  Saving model ...
2023-12-01 10:01:27,800:INFO::Epoch: 49
tensor([[0.2843, 0.3077, 0.4605, 0.3182],
        [0.2843, 0.4736, 0.3078, 0.3139],
        [0.2894, 0.3073, 0.4804, 0.3078],
        [0.2900, 0.4477, 0.3078, 0.3089]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:27,801:INFO::its now!!!!!!!!5
2023-12-01 10:01:28,024:INFO::its now!!!!!!!!0
2023-12-01 10:01:28,025:INFO::its now!!!!!!!!3
2023-12-01 10:01:28,162:INFO::its now!!!!!!!!5
2023-12-01 10:01:28,450:INFO::its now!!!!!!!!
2023-12-01 10:01:28,450:INFO::its now!!!!!!!! on 
2023-12-01 10:01:28,591:INFO::its now!!!!!!!!5
2023-12-01 10:01:28,794:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:28,796:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 0.3664 | Train_Classification_Loss 0.4009 | Dmon_Loss -0.0690 | Val_Loss 0.3151 | Search Time(s) 0.7745 | Infer Time(s) 0.2220 | Time(s) 0.9965 
2023-12-01 10:01:28,832:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 3;	8: 3;	9: 3;	10: 2;	11: 2;	12: 0;	13: 0;	14: 2;	15: 0;	16: 3;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 3;	28: 0;	29: 2;	30: 2;	31: 3;	32: 2;	33: 0;	34: 0;	35: 0;	36: 2;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 3;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 2;	26124: 0;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:01:28,833:INFO::Validation loss decreased (0.315971 --> 0.315143).  Saving model ...
2023-12-01 10:01:28,835:INFO::Epoch: 50
tensor([[0.2825, 0.3065, 0.4577, 0.3164],
        [0.2825, 0.4716, 0.3068, 0.3120],
        [0.2876, 0.3055, 0.4775, 0.3066],
        [0.2881, 0.4460, 0.3068, 0.3070]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:28,835:INFO::its now!!!!!!!!5
2023-12-01 10:01:29,072:INFO::its now!!!!!!!!0
2023-12-01 10:01:29,073:INFO::its now!!!!!!!!3
2023-12-01 10:01:29,204:INFO::its now!!!!!!!!5
2023-12-01 10:01:29,435:INFO::its now!!!!!!!!
2023-12-01 10:01:29,435:INFO::its now!!!!!!!! on 
2023-12-01 10:01:29,576:INFO::its now!!!!!!!!5
2023-12-01 10:01:29,787:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:29,789:INFO::Epoch 00050 | lr 0.00050 | Train_Loss 0.3549 | Train_Classification_Loss 0.3900 | Dmon_Loss -0.0703 | Val_Loss 0.3070 | Search Time(s) 0.7211 | Infer Time(s) 0.2326 | Time(s) 0.9537 
2023-12-01 10:01:29,838:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 2;	9: 0;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 2;	16: 3;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 0;	25: 2;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 2;	32: 3;	33: 0;	34: 0;	35: 2;	36: 2;	37: 0;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 1;	26101: 3;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 3;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 3;	26124: 0;	26125: 0;	26126: 2;	26127: 0;	
2023-12-01 10:01:29,839:INFO::Validation loss decreased (0.315143 --> 0.307020).  Saving model ...
2023-12-01 10:01:29,842:INFO::Epoch: 51
tensor([[0.2794, 0.3036, 0.4563, 0.3132],
        [0.2793, 0.4706, 0.3040, 0.3086],
        [0.2844, 0.3024, 0.4762, 0.3038],
        [0.2849, 0.4451, 0.3041, 0.3036]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:29,842:INFO::its now!!!!!!!!5
2023-12-01 10:01:30,051:INFO::its now!!!!!!!!0
2023-12-01 10:01:30,053:INFO::its now!!!!!!!!3
2023-12-01 10:01:30,185:INFO::its now!!!!!!!!5
2023-12-01 10:01:30,414:INFO::its now!!!!!!!!
2023-12-01 10:01:30,414:INFO::its now!!!!!!!! on 
2023-12-01 10:01:30,556:INFO::its now!!!!!!!!5
2023-12-01 10:01:30,778:INFO::Epoch 00051 | lr 0.00050 | Train_Loss 0.3400 | Train_Classification_Loss 0.3758 | Dmon_Loss -0.0716 | Val_Loss 0.3077 | Search Time(s) 0.6961 | Infer Time(s) 0.2415 | Time(s) 0.9376 
2023-12-01 10:01:30,818:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 0;	16: 1;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 0;	25: 2;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 2;	37: 0;	38: 2;	39: 3;	40: 2;	41: 0;	42: 0;	43: 2;	44
26098: 3;	26099: 2;	26100: 3;	26101: 0;	26102: 2;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 2;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 10:01:30,819:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:01:30,822:INFO::Epoch: 52
tensor([[0.2744, 0.2988, 0.4558, 0.3080],
        [0.2743, 0.4700, 0.2992, 0.3032],
        [0.2792, 0.2973, 0.4755, 0.2989],
        [0.2797, 0.4448, 0.2992, 0.2981]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:30,822:INFO::its now!!!!!!!!5
2023-12-01 10:01:31,030:INFO::its now!!!!!!!!0
2023-12-01 10:01:31,031:INFO::its now!!!!!!!!3
2023-12-01 10:01:31,162:INFO::its now!!!!!!!!5
2023-12-01 10:01:31,413:INFO::its now!!!!!!!!
2023-12-01 10:01:31,413:INFO::its now!!!!!!!! on 
2023-12-01 10:01:31,554:INFO::its now!!!!!!!!5
2023-12-01 10:01:31,772:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:31,774:INFO::Epoch 00052 | lr 0.00050 | Train_Loss 0.3249 | Train_Classification_Loss 0.3620 | Dmon_Loss -0.0740 | Val_Loss 0.2928 | Search Time(s) 0.7141 | Infer Time(s) 0.2388 | Time(s) 0.9529 
2023-12-01 10:01:31,824:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 0;	16: 3;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 1;	25: 2;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 2;	35: 1;	36: 2;	37: 0;	38: 0;	39: 2;	40: 0;	41: 0;	42: 0;	43: 2;	44
26098: 1;	26099: 2;	26100: 1;	26101: 3;	26102: 0;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 3;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 10:01:31,826:INFO::Validation loss decreased (0.307020 --> 0.292829).  Saving model ...
2023-12-01 10:01:31,828:INFO::Epoch: 53
tensor([[0.2773, 0.3017, 0.4555, 0.3110],
        [0.2772, 0.4698, 0.3022, 0.3063],
        [0.2822, 0.3003, 0.4754, 0.3019],
        [0.2827, 0.4446, 0.3023, 0.3013]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:31,829:INFO::its now!!!!!!!!5
2023-12-01 10:01:32,027:INFO::its now!!!!!!!!0
2023-12-01 10:01:32,028:INFO::its now!!!!!!!!3
2023-12-01 10:01:32,160:INFO::its now!!!!!!!!5
2023-12-01 10:01:32,409:INFO::its now!!!!!!!!
2023-12-01 10:01:32,409:INFO::its now!!!!!!!! on 
2023-12-01 10:01:32,547:INFO::its now!!!!!!!!5
2023-12-01 10:01:32,778:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:32,780:INFO::Epoch 00053 | lr 0.00050 | Train_Loss 0.3132 | Train_Classification_Loss 0.3502 | Dmon_Loss -0.0740 | Val_Loss 0.2909 | Search Time(s) 0.7011 | Infer Time(s) 0.2506 | Time(s) 0.9517 
2023-12-01 10:01:32,817:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 0;	16: 2;	17: 2;	18: 2;	19: 2;	20: 0;	21: 0;	22: 2;	23: 2;	24: 1;	25: 2;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 2;	32: 2;	33: 0;	34: 0;	35: 3;	36: 2;	37: 0;	38: 2;	39: 3;	40: 0;	41: 0;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 3;	26108: 2;	26109: 0;	26110: 2;	26111: 0;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 10:01:32,818:INFO::Validation loss decreased (0.292829 --> 0.290851).  Saving model ...
2023-12-01 10:01:32,821:INFO::Epoch: 54
tensor([[0.2769, 0.3014, 0.4551, 0.3106],
        [0.2768, 0.4696, 0.3018, 0.3059],
        [0.2817, 0.2999, 0.4756, 0.3016],
        [0.2823, 0.4444, 0.3019, 0.3008]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:32,821:INFO::its now!!!!!!!!5
2023-12-01 10:01:33,016:INFO::its now!!!!!!!!0
2023-12-01 10:01:33,017:INFO::its now!!!!!!!!3
2023-12-01 10:01:33,149:INFO::its now!!!!!!!!5
2023-12-01 10:01:33,369:INFO::its now!!!!!!!!
2023-12-01 10:01:33,369:INFO::its now!!!!!!!! on 
2023-12-01 10:01:33,510:INFO::its now!!!!!!!!5
2023-12-01 10:01:33,775:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:33,777:INFO::Epoch 00054 | lr 0.00050 | Train_Loss 0.3068 | Train_Classification_Loss 0.3458 | Dmon_Loss -0.0779 | Val_Loss 0.2853 | Search Time(s) 0.6712 | Infer Time(s) 0.2864 | Time(s) 0.9576 
2023-12-01 10:01:33,833:INFO::cluster info:
0: 3;	1: 2;	2: 3;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 2;	9: 0;	10: 3;	11: 2;	12: 0;	13: 0;	14: 2;	15: 0;	16: 3;	17: 2;	18: 2;	19: 2;	20: 2;	21: 0;	22: 2;	23: 3;	24: 0;	25: 3;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 2;	32: 3;	33: 0;	34: 0;	35: 1;	36: 2;	37: 0;	38: 2;	39: 3;	40: 2;	41: 0;	42: 3;	43: 2;	44
26098: 3;	26099: 2;	26100: 1;	26101: 0;	26102: 3;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 1;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 2;	
2023-12-01 10:01:33,834:INFO::Validation loss decreased (0.290851 --> 0.285258).  Saving model ...
2023-12-01 10:01:33,836:INFO::Epoch: 55
tensor([[0.2808, 0.3053, 0.4547, 0.3147],
        [0.2808, 0.4696, 0.3058, 0.3102],
        [0.2858, 0.3038, 0.4759, 0.3055],
        [0.2863, 0.4442, 0.3059, 0.3050]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:33,837:INFO::its now!!!!!!!!5
2023-12-01 10:01:34,053:INFO::its now!!!!!!!!0
2023-12-01 10:01:34,054:INFO::its now!!!!!!!!3
2023-12-01 10:01:34,184:INFO::its now!!!!!!!!5
2023-12-01 10:01:34,396:INFO::its now!!!!!!!!
2023-12-01 10:01:34,396:INFO::its now!!!!!!!! on 
2023-12-01 10:01:34,538:INFO::its now!!!!!!!!5
2023-12-01 10:01:34,775:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:34,777:INFO::Epoch 00055 | lr 0.00050 | Train_Loss 0.3025 | Train_Classification_Loss 0.3422 | Dmon_Loss -0.0794 | Val_Loss 0.2820 | Search Time(s) 0.6842 | Infer Time(s) 0.2566 | Time(s) 0.9407 
2023-12-01 10:01:34,821:INFO::cluster info:
0: 3;	1: 2;	2: 1;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 3;	13: 0;	14: 2;	15: 0;	16: 1;	17: 0;	18: 2;	19: 3;	20: 0;	21: 1;	22: 2;	23: 2;	24: 1;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 2;	40: 2;	41: 0;	42: 0;	43: 3;	44
26098: 3;	26099: 2;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 0;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 0;	26127: 0;	
2023-12-01 10:01:34,822:INFO::Validation loss decreased (0.285258 --> 0.282032).  Saving model ...
2023-12-01 10:01:34,824:INFO::Epoch: 56
tensor([[0.2822, 0.3067, 0.4544, 0.3161],
        [0.2822, 0.4695, 0.3072, 0.3117],
        [0.2872, 0.3052, 0.4758, 0.3069],
        [0.2878, 0.4443, 0.3073, 0.3065]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:34,825:INFO::its now!!!!!!!!5
2023-12-01 10:01:35,057:INFO::its now!!!!!!!!0
2023-12-01 10:01:35,058:INFO::its now!!!!!!!!3
2023-12-01 10:01:35,188:INFO::its now!!!!!!!!5
2023-12-01 10:01:35,407:INFO::its now!!!!!!!!
2023-12-01 10:01:35,407:INFO::its now!!!!!!!! on 
2023-12-01 10:01:35,547:INFO::its now!!!!!!!!5
2023-12-01 10:01:35,775:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:35,777:INFO::Epoch 00056 | lr 0.00050 | Train_Loss 0.3054 | Train_Classification_Loss 0.3455 | Dmon_Loss -0.0802 | Val_Loss 0.2741 | Search Time(s) 0.7041 | Infer Time(s) 0.2485 | Time(s) 0.9527 
2023-12-01 10:01:35,818:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 3;	11: 2;	12: 3;	13: 0;	14: 2;	15: 0;	16: 2;	17: 2;	18: 3;	19: 2;	20: 0;	21: 0;	22: 2;	23: 3;	24: 0;	25: 3;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 3;	32: 2;	33: 0;	34: 0;	35: 2;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 2;	43: 2;	44
26098: 1;	26099: 3;	26100: 0;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 1;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 2;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 10:01:35,820:INFO::Validation loss decreased (0.282032 --> 0.274060).  Saving model ...
2023-12-01 10:01:35,823:INFO::Epoch: 57
tensor([[0.2832, 0.3077, 0.4546, 0.3171],
        [0.2831, 0.4694, 0.3081, 0.3127],
        [0.2882, 0.3061, 0.4758, 0.3079],
        [0.2887, 0.4442, 0.3082, 0.3075]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:35,824:INFO::its now!!!!!!!!5
2023-12-01 10:01:36,058:INFO::its now!!!!!!!!0
2023-12-01 10:01:36,059:INFO::its now!!!!!!!!3
2023-12-01 10:01:36,189:INFO::its now!!!!!!!!5
2023-12-01 10:01:36,407:INFO::its now!!!!!!!!
2023-12-01 10:01:36,407:INFO::its now!!!!!!!! on 
2023-12-01 10:01:36,548:INFO::its now!!!!!!!!5
2023-12-01 10:01:36,750:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:36,751:INFO::Epoch 00057 | lr 0.00050 | Train_Loss 0.2948 | Train_Classification_Loss 0.3373 | Dmon_Loss -0.0850 | Val_Loss 0.2704 | Search Time(s) 0.7071 | Infer Time(s) 0.2226 | Time(s) 0.9297 
2023-12-01 10:01:36,805:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 3;	8: 3;	9: 3;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 0;	16: 3;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 0;	25: 3;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 2;	32: 2;	33: 0;	34: 0;	35: 1;	36: 2;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 2;	26099: 3;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 1;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 1;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:36,806:INFO::Validation loss decreased (0.274060 --> 0.270395).  Saving model ...
2023-12-01 10:01:36,808:INFO::Epoch: 58
tensor([[0.2844, 0.3089, 0.4547, 0.3184],
        [0.2844, 0.4694, 0.3094, 0.3140],
        [0.2895, 0.3074, 0.4757, 0.3091],
        [0.2900, 0.4442, 0.3095, 0.3089]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:36,808:INFO::its now!!!!!!!!5
2023-12-01 10:01:37,015:INFO::its now!!!!!!!!0
2023-12-01 10:01:37,016:INFO::its now!!!!!!!!3
2023-12-01 10:01:37,148:INFO::its now!!!!!!!!5
2023-12-01 10:01:37,385:INFO::its now!!!!!!!!
2023-12-01 10:01:37,385:INFO::its now!!!!!!!! on 
2023-12-01 10:01:37,526:INFO::its now!!!!!!!!5
2023-12-01 10:01:37,735:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:37,737:INFO::Epoch 00058 | lr 0.00050 | Train_Loss 0.3121 | Train_Classification_Loss 0.3550 | Dmon_Loss -0.0858 | Val_Loss 0.2703 | Search Time(s) 0.7011 | Infer Time(s) 0.2276 | Time(s) 0.9287 
2023-12-01 10:01:37,788:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 2;	9: 1;	10: 2;	11: 2;	12: 1;	13: 0;	14: 2;	15: 0;	16: 1;	17: 0;	18: 2;	19: 2;	20: 0;	21: 1;	22: 2;	23: 3;	24: 0;	25: 0;	26: 2;	27: 0;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 2;	43: 3;	44
26098: 3;	26099: 2;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 2;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 2;	26124: 0;	26125: 0;	26126: 0;	26127: 0;	
2023-12-01 10:01:37,789:INFO::Validation loss decreased (0.270395 --> 0.270263).  Saving model ...
2023-12-01 10:01:37,791:INFO::Epoch: 59
tensor([[0.2880, 0.3125, 0.4550, 0.3220],
        [0.2879, 0.4693, 0.3129, 0.3178],
        [0.2931, 0.3109, 0.4755, 0.3127],
        [0.2937, 0.4442, 0.3130, 0.3126]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:37,792:INFO::its now!!!!!!!!5
2023-12-01 10:01:38,014:INFO::its now!!!!!!!!0
2023-12-01 10:01:38,015:INFO::its now!!!!!!!!3
2023-12-01 10:01:38,148:INFO::its now!!!!!!!!5
2023-12-01 10:01:38,380:INFO::its now!!!!!!!!
2023-12-01 10:01:38,380:INFO::its now!!!!!!!! on 
2023-12-01 10:01:38,522:INFO::its now!!!!!!!!5
2023-12-01 10:01:38,762:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:38,763:INFO::Epoch 00059 | lr 0.00050 | Train_Loss 0.3046 | Train_Classification_Loss 0.3502 | Dmon_Loss -0.0911 | Val_Loss 0.2669 | Search Time(s) 0.7141 | Infer Time(s) 0.2595 | Time(s) 0.9736 
2023-12-01 10:01:38,829:INFO::cluster info:
0: 3;	1: 2;	2: 1;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 3;	9: 3;	10: 2;	11: 2;	12: 3;	13: 0;	14: 3;	15: 0;	16: 3;	17: 2;	18: 2;	19: 3;	20: 0;	21: 1;	22: 2;	23: 2;	24: 0;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 3;	32: 2;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 2;	39: 2;	40: 0;	41: 0;	42: 1;	43: 2;	44
26098: 1;	26099: 3;	26100: 0;	26101: 1;	26102: 2;	26103: 1;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 1;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 3;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:38,830:INFO::Validation loss decreased (0.270263 --> 0.266856).  Saving model ...
2023-12-01 10:01:38,833:INFO::Epoch: 60
tensor([[0.2918, 0.3163, 0.4552, 0.3260],
        [0.2918, 0.4693, 0.3168, 0.3220],
        [0.2971, 0.3148, 0.4756, 0.3165],
        [0.2976, 0.4441, 0.3169, 0.3167]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:38,833:INFO::its now!!!!!!!!5
2023-12-01 10:01:39,063:INFO::its now!!!!!!!!0
2023-12-01 10:01:39,064:INFO::its now!!!!!!!!3
2023-12-01 10:01:39,195:INFO::its now!!!!!!!!5
2023-12-01 10:01:39,452:INFO::its now!!!!!!!!
2023-12-01 10:01:39,452:INFO::its now!!!!!!!! on 
2023-12-01 10:01:39,593:INFO::its now!!!!!!!!5
2023-12-01 10:01:39,823:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:39,825:INFO::Epoch 00060 | lr 0.00050 | Train_Loss 0.2790 | Train_Classification_Loss 0.3256 | Dmon_Loss -0.0932 | Val_Loss 0.2635 | Search Time(s) 0.7426 | Infer Time(s) 0.2510 | Time(s) 0.9936 
2023-12-01 10:01:39,871:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 2;	12: 1;	13: 0;	14: 3;	15: 0;	16: 3;	17: 0;	18: 2;	19: 2;	20: 0;	21: 1;	22: 2;	23: 3;	24: 0;	25: 1;	26: 2;	27: 0;	28: 0;	29: 2;	30: 0;	31: 2;	32: 2;	33: 0;	34: 0;	35: 2;	36: 0;	37: 0;	38: 0;	39: 2;	40: 0;	41: 0;	42: 0;	43: 2;	44
26098: 3;	26099: 2;	26100: 0;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 0;	26110: 2;	26111: 1;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:39,872:INFO::Validation loss decreased (0.266856 --> 0.263533).  Saving model ...
2023-12-01 10:01:39,874:INFO::Epoch: 61
tensor([[0.2987, 0.3232, 0.4549, 0.3331],
        [0.2987, 0.4692, 0.3237, 0.3293],
        [0.3041, 0.3217, 0.4759, 0.3234],
        [0.3047, 0.4440, 0.3238, 0.3241]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:39,875:INFO::its now!!!!!!!!5
2023-12-01 10:01:40,121:INFO::its now!!!!!!!!0
2023-12-01 10:01:40,122:INFO::its now!!!!!!!!3
2023-12-01 10:01:40,239:INFO::its now!!!!!!!!5
2023-12-01 10:01:40,478:INFO::its now!!!!!!!!
2023-12-01 10:01:40,478:INFO::its now!!!!!!!! on 
2023-12-01 10:01:40,619:INFO::its now!!!!!!!!5
2023-12-01 10:01:40,895:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:40,896:INFO::Epoch 00061 | lr 0.00050 | Train_Loss 0.2557 | Train_Classification_Loss 0.3046 | Dmon_Loss -0.0980 | Val_Loss 0.2561 | Search Time(s) 0.7287 | Infer Time(s) 0.2940 | Time(s) 1.0226 
2023-12-01 10:01:40,938:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 2;	12: 0;	13: 0;	14: 3;	15: 0;	16: 1;	17: 0;	18: 2;	19: 2;	20: 0;	21: 1;	22: 2;	23: 3;	24: 3;	25: 1;	26: 2;	27: 0;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 0;	26110: 2;	26111: 0;	26112: 3;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 2;	
2023-12-01 10:01:40,939:INFO::Validation loss decreased (0.263533 --> 0.256121).  Saving model ...
2023-12-01 10:01:40,941:INFO::Epoch: 62
tensor([[0.3002, 0.3247, 0.4473, 0.3367],
        [0.3020, 0.4637, 0.3251, 0.3309],
        [0.3074, 0.3231, 0.4677, 0.3249],
        [0.3062, 0.4390, 0.3273, 0.3256]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:40,941:INFO::its now!!!!!!!!5
2023-12-01 10:01:41,169:INFO::its now!!!!!!!!0
2023-12-01 10:01:41,170:INFO::its now!!!!!!!!3
2023-12-01 10:01:41,311:INFO::its now!!!!!!!!5
2023-12-01 10:01:41,563:INFO::its now!!!!!!!!
2023-12-01 10:01:41,564:INFO::its now!!!!!!!! on 
2023-12-01 10:01:41,704:INFO::its now!!!!!!!!5
2023-12-01 10:01:41,924:INFO::Epoch 00062 | lr 0.00050 | Train_Loss 0.2376 | Train_Classification_Loss 0.2896 | Dmon_Loss -0.1038 | Val_Loss 0.2606 | Search Time(s) 0.7470 | Infer Time(s) 0.2383 | Time(s) 0.9854 
2023-12-01 10:01:41,967:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 2;	4: 0;	5: 2;	6: 2;	7: 2;	8: 2;	9: 0;	10: 3;	11: 2;	12: 1;	13: 0;	14: 2;	15: 0;	16: 3;	17: 0;	18: 2;	19: 2;	20: 0;	21: 1;	22: 2;	23: 3;	24: 3;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 2;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 1;	26112: 3;	26113: 0;	26114: 0;	26115: 0;	26116: 3;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:41,969:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:01:41,971:INFO::Epoch: 63
tensor([[0.3083, 0.3327, 0.4433, 0.3460],
        [0.3110, 0.4609, 0.3332, 0.3394],
        [0.3166, 0.3312, 0.4824, 0.3255],
        [0.3069, 0.4510, 0.3363, 0.3341]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:41,972:INFO::its now!!!!!!!!5
2023-12-01 10:01:42,212:INFO::its now!!!!!!!!0
2023-12-01 10:01:42,214:INFO::its now!!!!!!!!3
2023-12-01 10:01:42,346:INFO::its now!!!!!!!!5
2023-12-01 10:01:42,593:INFO::its now!!!!!!!!
2023-12-01 10:01:42,593:INFO::its now!!!!!!!! on 
2023-12-01 10:01:42,735:INFO::its now!!!!!!!!5
2023-12-01 10:01:42,948:INFO::Epoch 00063 | lr 0.00050 | Train_Loss 0.2563 | Train_Classification_Loss 0.3108 | Dmon_Loss -0.1089 | Val_Loss 0.2584 | Search Time(s) 0.7459 | Infer Time(s) 0.2334 | Time(s) 0.9793 
2023-12-01 10:01:42,994:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 2;	4: 0;	5: 2;	6: 2;	7: 3;	8: 3;	9: 3;	10: 2;	11: 3;	12: 1;	13: 0;	14: 3;	15: 0;	16: 1;	17: 0;	18: 2;	19: 3;	20: 0;	21: 0;	22: 2;	23: 3;	24: 0;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 2;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 3;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 2;	26111: 1;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 1;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:42,995:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:01:42,998:INFO::Epoch: 64
tensor([[0.3122, 0.3366, 0.4412, 0.3505],
        [0.3154, 0.4590, 0.3371, 0.3435],
        [0.3210, 0.3351, 0.4899, 0.3257],
        [0.3071, 0.4571, 0.3407, 0.3382]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:42,998:INFO::its now!!!!!!!!5
2023-12-01 10:01:43,236:INFO::its now!!!!!!!!0
2023-12-01 10:01:43,237:INFO::its now!!!!!!!!3
2023-12-01 10:01:43,368:INFO::its now!!!!!!!!5
2023-12-01 10:01:43,588:INFO::its now!!!!!!!!
2023-12-01 10:01:43,588:INFO::its now!!!!!!!! on 
2023-12-01 10:01:43,730:INFO::its now!!!!!!!!5
2023-12-01 10:01:43,959:INFO::Epoch 00064 | lr 0.00050 | Train_Loss 0.2484 | Train_Classification_Loss 0.3030 | Dmon_Loss -0.1093 | Val_Loss 0.2574 | Search Time(s) 0.7143 | Infer Time(s) 0.2493 | Time(s) 0.9636 
2023-12-01 10:01:44,012:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 3;	4: 0;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 0;	12: 0;	13: 0;	14: 2;	15: 0;	16: 0;	17: 0;	18: 2;	19: 3;	20: 0;	21: 1;	22: 2;	23: 3;	24: 1;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 0;	43: 2;	44
26098: 3;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 0;	26110: 2;	26111: 1;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 0;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:44,014:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 10:01:44,016:INFO::Epoch: 65
tensor([[0.3183, 0.3428, 0.4398, 0.3571],
        [0.3218, 0.4580, 0.3433, 0.3500],
        [0.3275, 0.3412, 0.4938, 0.3303],
        [0.3118, 0.4600, 0.3472, 0.3446]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:44,016:INFO::its now!!!!!!!!5
2023-12-01 10:01:44,208:INFO::its now!!!!!!!!0
2023-12-01 10:01:44,209:INFO::its now!!!!!!!!3
2023-12-01 10:01:44,342:INFO::its now!!!!!!!!5
2023-12-01 10:01:44,613:INFO::its now!!!!!!!!
2023-12-01 10:01:44,614:INFO::its now!!!!!!!! on 
2023-12-01 10:01:44,755:INFO::its now!!!!!!!!5
2023-12-01 10:01:44,977:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:44,980:INFO::Epoch 00065 | lr 0.00050 | Train_Loss 0.2182 | Train_Classification_Loss 0.2778 | Dmon_Loss -0.1193 | Val_Loss 0.2548 | Search Time(s) 0.7213 | Infer Time(s) 0.2424 | Time(s) 0.9636 
2023-12-01 10:01:45,023:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 3;	11: 2;	12: 1;	13: 0;	14: 3;	15: 0;	16: 1;	17: 0;	18: 2;	19: 2;	20: 0;	21: 0;	22: 2;	23: 3;	24: 1;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 2;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 2;	44
26098: 2;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 0;	26110: 3;	26111: 1;	26112: 3;	26113: 0;	26114: 0;	26115: 0;	26116: 3;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:45,024:INFO::Validation loss decreased (0.256121 --> 0.254833).  Saving model ...
2023-12-01 10:01:45,026:INFO::Epoch: 66
tensor([[0.3214, 0.3459, 0.4394, 0.3603],
        [0.3249, 0.4575, 0.3463, 0.3533],
        [0.3307, 0.3443, 0.4959, 0.3326],
        [0.3142, 0.4615, 0.3503, 0.3478]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:45,027:INFO::its now!!!!!!!!5
2023-12-01 10:01:45,243:INFO::its now!!!!!!!!0
2023-12-01 10:01:45,244:INFO::its now!!!!!!!!3
2023-12-01 10:01:45,376:INFO::its now!!!!!!!!5
2023-12-01 10:01:45,587:INFO::its now!!!!!!!!
2023-12-01 10:01:45,587:INFO::its now!!!!!!!! on 
2023-12-01 10:01:45,727:INFO::its now!!!!!!!!5
2023-12-01 10:01:45,968:INFO::Epoch 00066 | lr 0.00050 | Train_Loss 0.1952 | Train_Classification_Loss 0.2550 | Dmon_Loss -0.1196 | Val_Loss 0.2560 | Search Time(s) 0.6827 | Infer Time(s) 0.2613 | Time(s) 0.9440 
2023-12-01 10:01:46,015:INFO::cluster info:
0: 3;	1: 2;	2: 0;	3: 3;	4: 3;	5: 2;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 3;	12: 0;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 2;	19: 2;	20: 0;	21: 1;	22: 3;	23: 3;	24: 0;	25: 1;	26: 3;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 0;	43: 2;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 0;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 3;	26111: 1;	26112: 2;	26113: 0;	26114: 0;	26115: 0;	26116: 0;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:46,016:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:01:46,018:INFO::Epoch: 67
tensor([[0.3249, 0.3494, 0.4392, 0.3640],
        [0.3286, 0.4572, 0.3499, 0.3570],
        [0.3344, 0.3478, 0.4970, 0.3359],
        [0.3176, 0.4619, 0.3540, 0.3515]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:46,018:INFO::its now!!!!!!!!5
2023-12-01 10:01:46,244:INFO::its now!!!!!!!!0
2023-12-01 10:01:46,245:INFO::its now!!!!!!!!3
2023-12-01 10:01:46,377:INFO::its now!!!!!!!!5
2023-12-01 10:01:46,595:INFO::its now!!!!!!!!
2023-12-01 10:01:46,595:INFO::its now!!!!!!!! on 
2023-12-01 10:01:46,736:INFO::its now!!!!!!!!5
2023-12-01 10:01:46,963:INFO::Epoch 00067 | lr 0.00050 | Train_Loss 0.2042 | Train_Classification_Loss 0.2684 | Dmon_Loss -0.1283 | Val_Loss 0.2561 | Search Time(s) 0.6993 | Infer Time(s) 0.2473 | Time(s) 0.9466 
2023-12-01 10:01:47,014:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 0;	5: 2;	6: 2;	7: 1;	8: 3;	9: 3;	10: 2;	11: 3;	12: 1;	13: 0;	14: 3;	15: 0;	16: 3;	17: 0;	18: 2;	19: 2;	20: 0;	21: 1;	22: 3;	23: 3;	24: 1;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 0;	26110: 3;	26111: 1;	26112: 3;	26113: 0;	26114: 0;	26115: 0;	26116: 3;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 0;	26127: 1;	
2023-12-01 10:01:47,015:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:01:47,018:INFO::Epoch: 68
tensor([[0.3203, 0.3447, 0.4390, 0.3593],
        [0.3239, 0.4570, 0.3452, 0.3521],
        [0.3297, 0.3432, 0.4977, 0.3306],
        [0.3122, 0.4621, 0.3493, 0.3466]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:47,019:INFO::its now!!!!!!!!5
2023-12-01 10:01:47,218:INFO::its now!!!!!!!!0
2023-12-01 10:01:47,220:INFO::its now!!!!!!!!3
2023-12-01 10:01:47,352:INFO::its now!!!!!!!!5
2023-12-01 10:01:47,583:INFO::its now!!!!!!!!
2023-12-01 10:01:47,583:INFO::its now!!!!!!!! on 
2023-12-01 10:01:47,725:INFO::its now!!!!!!!!5
2023-12-01 10:01:47,939:INFO::Epoch 00068 | lr 0.00050 | Train_Loss 0.1990 | Train_Classification_Loss 0.2685 | Dmon_Loss -0.1389 | Val_Loss 0.2630 | Search Time(s) 0.6900 | Infer Time(s) 0.2344 | Time(s) 0.9243 
2023-12-01 10:01:47,993:INFO::cluster info:
0: 3;	1: 2;	2: 1;	3: 3;	4: 0;	5: 3;	6: 2;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 3;	19: 2;	20: 1;	21: 1;	22: 2;	23: 3;	24: 0;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 0;	26110: 3;	26111: 1;	26112: 0;	26113: 0;	26114: 0;	26115: 0;	26116: 1;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:47,995:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 10:01:47,998:INFO::Epoch: 69
tensor([[0.3139, 0.3384, 0.4389, 0.3528],
        [0.3175, 0.4567, 0.3388, 0.3454],
        [0.3232, 0.3368, 0.4982, 0.3238],
        [0.3052, 0.4620, 0.3429, 0.3400]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:47,999:INFO::its now!!!!!!!!5
2023-12-01 10:01:48,232:INFO::its now!!!!!!!!0
2023-12-01 10:01:48,232:INFO::its now!!!!!!!!3
2023-12-01 10:01:48,364:INFO::its now!!!!!!!!5
2023-12-01 10:01:48,746:INFO::its now!!!!!!!!
2023-12-01 10:01:48,746:INFO::its now!!!!!!!! on 
2023-12-01 10:01:48,890:INFO::its now!!!!!!!!5
2023-12-01 10:01:49,117:INFO::Epoch 00069 | lr 0.00050 | Train_Loss 0.2083 | Train_Classification_Loss 0.2791 | Dmon_Loss -0.1416 | Val_Loss 0.2673 | Search Time(s) 0.8769 | Infer Time(s) 0.2453 | Time(s) 1.1222 
2023-12-01 10:01:49,155:INFO::cluster info:
0: 1;	1: 2;	2: 1;	3: 1;	4: 0;	5: 1;	6: 2;	7: 1;	8: 3;	9: 3;	10: 1;	11: 3;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 2;	19: 3;	20: 0;	21: 1;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 3;	26100: 1;	26101: 0;	26102: 2;	26103: 0;	26104: 3;	26105: 0;	26106: 1;	26107: 0;	26108: 2;	26109: 0;	26110: 1;	26111: 1;	26112: 3;	26113: 0;	26114: 0;	26115: 0;	26116: 1;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:49,156:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 10:01:49,158:INFO::Epoch: 70
tensor([[0.3096, 0.3340, 0.4385, 0.3483],
        [0.3132, 0.4562, 0.3345, 0.3409],
        [0.3188, 0.3325, 0.4986, 0.3191],
        [0.3005, 0.4618, 0.3386, 0.3355]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:49,159:INFO::its now!!!!!!!!5
2023-12-01 10:01:49,391:INFO::its now!!!!!!!!0
2023-12-01 10:01:49,392:INFO::its now!!!!!!!!3
2023-12-01 10:01:49,524:INFO::its now!!!!!!!!5
2023-12-01 10:01:49,754:INFO::its now!!!!!!!!
2023-12-01 10:01:49,754:INFO::its now!!!!!!!! on 
2023-12-01 10:01:49,894:INFO::its now!!!!!!!!5
2023-12-01 10:01:50,137:INFO::Epoch 00070 | lr 0.00050 | Train_Loss 0.2528 | Train_Classification_Loss 0.3219 | Dmon_Loss -0.1381 | Val_Loss 0.2689 | Search Time(s) 0.7183 | Infer Time(s) 0.2623 | Time(s) 0.9806 
2023-12-01 10:01:50,198:INFO::cluster info:
0: 3;	1: 1;	2: 1;	3: 1;	4: 0;	5: 1;	6: 2;	7: 1;	8: 3;	9: 1;	10: 1;	11: 2;	12: 0;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 3;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 1;	25: 1;	26: 2;	27: 1;	28: 0;	29: 3;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 1;	26100: 1;	26101: 3;	26102: 2;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 1;	26108: 3;	26109: 0;	26110: 1;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 0;	26116: 0;	26117: 1;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:50,200:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 10:01:50,203:INFO::Epoch: 71
tensor([[0.3035, 0.3279, 0.4378, 0.3421],
        [0.3071, 0.4556, 0.3284, 0.3345],
        [0.3126, 0.3264, 0.4989, 0.3126],
        [0.2939, 0.4618, 0.3325, 0.3292]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:50,204:INFO::its now!!!!!!!!5
2023-12-01 10:01:50,467:INFO::its now!!!!!!!!0
2023-12-01 10:01:50,468:INFO::its now!!!!!!!!3
2023-12-01 10:01:50,599:INFO::its now!!!!!!!!5
2023-12-01 10:01:50,831:INFO::its now!!!!!!!!
2023-12-01 10:01:50,831:INFO::its now!!!!!!!! on 
2023-12-01 10:01:50,972:INFO::its now!!!!!!!!5
2023-12-01 10:01:51,193:INFO::Epoch 00071 | lr 0.00050 | Train_Loss 0.1985 | Train_Classification_Loss 0.2715 | Dmon_Loss -0.1461 | Val_Loss 0.2588 | Search Time(s) 0.7502 | Infer Time(s) 0.2424 | Time(s) 0.9926 
2023-12-01 10:01:51,246:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 1;	4: 0;	5: 1;	6: 2;	7: 1;	8: 3;	9: 1;	10: 3;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 2;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 0;	25: 1;	26: 2;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 1;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 1;	26107: 1;	26108: 1;	26109: 0;	26110: 1;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:51,247:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 10:01:51,250:INFO::Epoch: 72
tensor([[0.2978, 0.3223, 0.4378, 0.3363],
        [0.3014, 0.4548, 0.3228, 0.3287],
        [0.3068, 0.3208, 0.4990, 0.3066],
        [0.2878, 0.4615, 0.3268, 0.3233]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:51,251:INFO::its now!!!!!!!!5
2023-12-01 10:01:51,470:INFO::its now!!!!!!!!0
2023-12-01 10:01:51,470:INFO::its now!!!!!!!!3
2023-12-01 10:01:51,602:INFO::its now!!!!!!!!5
2023-12-01 10:01:51,850:INFO::its now!!!!!!!!
2023-12-01 10:01:51,850:INFO::its now!!!!!!!! on 
2023-12-01 10:01:51,990:INFO::its now!!!!!!!!5
2023-12-01 10:01:52,213:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:52,215:INFO::Epoch 00072 | lr 0.00050 | Train_Loss 0.2089 | Train_Classification_Loss 0.2823 | Dmon_Loss -0.1467 | Val_Loss 0.2541 | Search Time(s) 0.7229 | Infer Time(s) 0.2424 | Time(s) 0.9653 
2023-12-01 10:01:52,275:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 1;	4: 0;	5: 3;	6: 2;	7: 1;	8: 3;	9: 1;	10: 1;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 2;	19: 1;	20: 1;	21: 1;	22: 1;	23: 1;	24: 0;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 1;	32: 1;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 3;	26108: 1;	26109: 1;	26110: 3;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:52,276:INFO::Validation loss decreased (0.254833 --> 0.254136).  Saving model ...
2023-12-01 10:01:52,280:INFO::Epoch: 73
tensor([[0.2950, 0.3195, 0.4380, 0.3334],
        [0.2985, 0.4536, 0.3199, 0.3257],
        [0.3039, 0.3179, 0.4990, 0.3036],
        [0.2847, 0.4614, 0.3240, 0.3204]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:52,281:INFO::its now!!!!!!!!5
2023-12-01 10:01:52,516:INFO::its now!!!!!!!!0
2023-12-01 10:01:52,517:INFO::its now!!!!!!!!3
2023-12-01 10:01:52,647:INFO::its now!!!!!!!!5
2023-12-01 10:01:52,870:INFO::its now!!!!!!!!
2023-12-01 10:01:52,870:INFO::its now!!!!!!!! on 
2023-12-01 10:01:53,011:INFO::its now!!!!!!!!5
2023-12-01 10:01:53,226:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:01:53,227:INFO::Epoch 00073 | lr 0.00050 | Train_Loss 0.2132 | Train_Classification_Loss 0.2867 | Dmon_Loss -0.1471 | Val_Loss 0.2528 | Search Time(s) 0.7143 | Infer Time(s) 0.2354 | Time(s) 0.9497 
2023-12-01 10:01:53,280:INFO::cluster info:
0: 3;	1: 1;	2: 1;	3: 1;	4: 0;	5: 1;	6: 3;	7: 1;	8: 1;	9: 3;	10: 1;	11: 3;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 3;	19: 1;	20: 1;	21: 1;	22: 3;	23: 1;	24: 0;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 1;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 1;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:53,281:INFO::Validation loss decreased (0.254136 --> 0.252827).  Saving model ...
2023-12-01 10:01:53,285:INFO::Epoch: 74
tensor([[0.2885, 0.3130, 0.4379, 0.3269],
        [0.2921, 0.4522, 0.3135, 0.3190],
        [0.2974, 0.3115, 0.4991, 0.2968],
        [0.2778, 0.4614, 0.3175, 0.3137]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:53,286:INFO::its now!!!!!!!!5
2023-12-01 10:01:53,510:INFO::its now!!!!!!!!0
2023-12-01 10:01:53,511:INFO::its now!!!!!!!!3
2023-12-01 10:01:53,644:INFO::its now!!!!!!!!5
2023-12-01 10:01:53,902:INFO::its now!!!!!!!!
2023-12-01 10:01:53,903:INFO::its now!!!!!!!! on 
2023-12-01 10:01:54,044:INFO::its now!!!!!!!!5
2023-12-01 10:01:54,265:INFO::Epoch 00074 | lr 0.00050 | Train_Loss 0.1798 | Train_Classification_Loss 0.2572 | Dmon_Loss -0.1549 | Val_Loss 0.2625 | Search Time(s) 0.7412 | Infer Time(s) 0.2424 | Time(s) 0.9835 
2023-12-01 10:01:54,312:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 0;	5: 3;	6: 2;	7: 1;	8: 1;	9: 1;	10: 3;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 3;	19: 3;	20: 1;	21: 1;	22: 3;	23: 1;	24: 0;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 1;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 1;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 3;	26118: 1;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:54,314:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:01:54,317:INFO::Epoch: 75
tensor([[0.2843, 0.3088, 0.4377, 0.3225],
        [0.2878, 0.4511, 0.3093, 0.3146],
        [0.2931, 0.3072, 0.4991, 0.2923],
        [0.2732, 0.4613, 0.3133, 0.3093]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:54,318:INFO::its now!!!!!!!!5
2023-12-01 10:01:54,565:INFO::its now!!!!!!!!0
2023-12-01 10:01:54,566:INFO::its now!!!!!!!!3
2023-12-01 10:01:54,695:INFO::its now!!!!!!!!5
2023-12-01 10:01:54,952:INFO::its now!!!!!!!!
2023-12-01 10:01:54,952:INFO::its now!!!!!!!! on 
2023-12-01 10:01:55,095:INFO::its now!!!!!!!!5
2023-12-01 10:01:55,325:INFO::Epoch 00075 | lr 0.00050 | Train_Loss 0.1988 | Train_Classification_Loss 0.2785 | Dmon_Loss -0.1594 | Val_Loss 0.2692 | Search Time(s) 0.7612 | Infer Time(s) 0.2503 | Time(s) 1.0115 
2023-12-01 10:01:55,365:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 0;	5: 3;	6: 2;	7: 1;	8: 3;	9: 1;	10: 2;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 3;	19: 3;	20: 1;	21: 1;	22: 3;	23: 1;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 2;	30: 0;	31: 3;	32: 1;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 2;	26118: 1;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:55,366:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:01:55,369:INFO::Epoch: 76
tensor([[0.2833, 0.3078, 0.4371, 0.3215],
        [0.2868, 0.4499, 0.3083, 0.3136],
        [0.2921, 0.3063, 0.4992, 0.2913],
        [0.2722, 0.4612, 0.3123, 0.3083]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:55,370:INFO::its now!!!!!!!!5
2023-12-01 10:01:55,635:INFO::its now!!!!!!!!0
2023-12-01 10:01:55,636:INFO::its now!!!!!!!!3
2023-12-01 10:01:55,769:INFO::its now!!!!!!!!5
2023-12-01 10:01:55,982:INFO::its now!!!!!!!!
2023-12-01 10:01:55,982:INFO::its now!!!!!!!! on 
2023-12-01 10:01:56,122:INFO::its now!!!!!!!!5
2023-12-01 10:01:56,340:INFO::Epoch 00076 | lr 0.00050 | Train_Loss 0.1916 | Train_Classification_Loss 0.2743 | Dmon_Loss -0.1653 | Val_Loss 0.2785 | Search Time(s) 0.7342 | Infer Time(s) 0.2374 | Time(s) 0.9716 
2023-12-01 10:01:56,378:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 0;	5: 3;	6: 2;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 1;	13: 0;	14: 1;	15: 1;	16: 1;	17: 0;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 1;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 2;	30: 0;	31: 2;	32: 1;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 3;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:56,379:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 10:01:56,381:INFO::Epoch: 77
tensor([[0.2757, 0.3002, 0.4365, 0.3138],
        [0.2792, 0.4491, 0.3007, 0.3057],
        [0.2844, 0.2987, 0.4993, 0.2833],
        [0.2641, 0.4611, 0.3047, 0.3005]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:56,382:INFO::its now!!!!!!!!5
2023-12-01 10:01:56,598:INFO::its now!!!!!!!!0
2023-12-01 10:01:56,599:INFO::its now!!!!!!!!3
2023-12-01 10:01:56,731:INFO::its now!!!!!!!!5
2023-12-01 10:01:56,944:INFO::its now!!!!!!!!
2023-12-01 10:01:56,945:INFO::its now!!!!!!!! on 
2023-12-01 10:01:57,086:INFO::its now!!!!!!!!5
2023-12-01 10:01:57,327:INFO::Epoch 00077 | lr 0.00050 | Train_Loss 0.1610 | Train_Classification_Loss 0.2457 | Dmon_Loss -0.1695 | Val_Loss 0.2669 | Search Time(s) 0.6864 | Infer Time(s) 0.2623 | Time(s) 0.9487 
2023-12-01 10:01:57,367:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 3;	5: 1;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 3;	19: 3;	20: 0;	21: 1;	22: 3;	23: 3;	24: 0;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 2;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 2;	44
26098: 1;	26099: 3;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 1;	26105: 0;	26106: 1;	26107: 0;	26108: 1;	26109: 0;	26110: 3;	26111: 1;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:57,368:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 10:01:57,371:INFO::Epoch: 78
tensor([[0.2753, 0.2998, 0.4363, 0.3133],
        [0.2788, 0.4483, 0.3002, 0.3052],
        [0.2839, 0.2982, 0.4994, 0.2828],
        [0.2636, 0.4609, 0.3042, 0.3000]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:57,372:INFO::its now!!!!!!!!5
2023-12-01 10:01:57,574:INFO::its now!!!!!!!!0
2023-12-01 10:01:57,575:INFO::its now!!!!!!!!3
2023-12-01 10:01:57,709:INFO::its now!!!!!!!!5
2023-12-01 10:01:57,916:INFO::its now!!!!!!!!
2023-12-01 10:01:57,917:INFO::its now!!!!!!!! on 
2023-12-01 10:01:58,057:INFO::its now!!!!!!!!5
2023-12-01 10:01:58,267:INFO::Epoch 00078 | lr 0.00050 | Train_Loss 0.1591 | Train_Classification_Loss 0.2489 | Dmon_Loss -0.1795 | Val_Loss 0.2604 | Search Time(s) 0.6676 | Infer Time(s) 0.2303 | Time(s) 0.8979 
2023-12-01 10:01:58,322:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 0;	5: 3;	6: 2;	7: 3;	8: 3;	9: 1;	10: 2;	11: 1;	12: 1;	13: 0;	14: 3;	15: 0;	16: 1;	17: 0;	18: 3;	19: 3;	20: 1;	21: 1;	22: 3;	23: 3;	24: 0;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 2;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 1;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:58,323:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 10:01:58,325:INFO::Epoch: 79
tensor([[0.2720, 0.2965, 0.4354, 0.3100],
        [0.2755, 0.4478, 0.2969, 0.3018],
        [0.2805, 0.2949, 0.4995, 0.2794],
        [0.2601, 0.4609, 0.3009, 0.2966]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:58,326:INFO::its now!!!!!!!!5
2023-12-01 10:01:58,574:INFO::its now!!!!!!!!0
2023-12-01 10:01:58,575:INFO::its now!!!!!!!!3
2023-12-01 10:01:58,707:INFO::its now!!!!!!!!5
2023-12-01 10:01:58,923:INFO::its now!!!!!!!!
2023-12-01 10:01:58,923:INFO::its now!!!!!!!! on 
2023-12-01 10:01:59,064:INFO::its now!!!!!!!!5
2023-12-01 10:01:59,269:INFO::Epoch 00079 | lr 0.00050 | Train_Loss 0.1476 | Train_Classification_Loss 0.2369 | Dmon_Loss -0.1784 | Val_Loss 0.2604 | Search Time(s) 0.7208 | Infer Time(s) 0.2254 | Time(s) 0.9462 
2023-12-01 10:01:59,332:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 3;	19: 3;	20: 1;	21: 1;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 0;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 3;	26100: 1;	26101: 1;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 1;	26108: 3;	26109: 0;	26110: 1;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:01:59,333:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 10:01:59,337:INFO::Epoch: 80
tensor([[0.2790, 0.3035, 0.4339, 0.3171],
        [0.2825, 0.4477, 0.3040, 0.3091],
        [0.2877, 0.3020, 0.4994, 0.2867],
        [0.2675, 0.4609, 0.3080, 0.3039]], device='cuda:0', requires_grad=True)
2023-12-01 10:01:59,338:INFO::its now!!!!!!!!5
2023-12-01 10:01:59,566:INFO::its now!!!!!!!!0
2023-12-01 10:01:59,567:INFO::its now!!!!!!!!3
2023-12-01 10:01:59,698:INFO::its now!!!!!!!!5
2023-12-01 10:01:59,924:INFO::its now!!!!!!!!
2023-12-01 10:01:59,924:INFO::its now!!!!!!!! on 
2023-12-01 10:02:00,065:INFO::its now!!!!!!!!5
2023-12-01 10:02:00,297:INFO::Epoch 00080 | lr 0.00050 | Train_Loss 0.1755 | Train_Classification_Loss 0.2639 | Dmon_Loss -0.1769 | Val_Loss 0.2564 | Search Time(s) 0.7123 | Infer Time(s) 0.2503 | Time(s) 0.9627 
2023-12-01 10:02:00,340:INFO::cluster info:
0: 3;	1: 2;	2: 1;	3: 3;	4: 0;	5: 3;	6: 3;	7: 1;	8: 3;	9: 1;	10: 3;	11: 1;	12: 1;	13: 0;	14: 3;	15: 0;	16: 1;	17: 0;	18: 2;	19: 3;	20: 1;	21: 1;	22: 3;	23: 1;	24: 0;	25: 1;	26: 2;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 1;	26109: 0;	26110: 3;	26111: 1;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 1;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:02:00,341:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 10:02:00,343:INFO::Epoch: 81
tensor([[0.2878, 0.3123, 0.4327, 0.3260],
        [0.2913, 0.4473, 0.3128, 0.3181],
        [0.2966, 0.3108, 0.4994, 0.2958],
        [0.2767, 0.4611, 0.3168, 0.3129]], device='cuda:0', requires_grad=True)
2023-12-01 10:02:00,344:INFO::its now!!!!!!!!5
2023-12-01 10:02:00,566:INFO::its now!!!!!!!!0
2023-12-01 10:02:00,567:INFO::its now!!!!!!!!3
2023-12-01 10:02:00,698:INFO::its now!!!!!!!!5
2023-12-01 10:02:00,943:INFO::its now!!!!!!!!
2023-12-01 10:02:00,943:INFO::its now!!!!!!!! on 
2023-12-01 10:02:01,086:INFO::its now!!!!!!!!5
2023-12-01 10:02:01,317:INFO::Epoch 00081 | lr 0.00050 | Train_Loss 0.1741 | Train_Classification_Loss 0.2650 | Dmon_Loss -0.1818 | Val_Loss 0.2563 | Search Time(s) 0.7252 | Infer Time(s) 0.2503 | Time(s) 0.9756 
2023-12-01 10:02:01,358:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 0;	5: 3;	6: 2;	7: 1;	8: 3;	9: 1;	10: 3;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 0;	18: 3;	19: 3;	20: 1;	21: 1;	22: 3;	23: 1;	24: 0;	25: 1;	26: 3;	27: 1;	28: 0;	29: 0;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 1;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 1;	26107: 0;	26108: 1;	26109: 0;	26110: 3;	26111: 1;	26112: 1;	26113: 0;	26114: 0;	26115: 1;	26116: 1;	26117: 3;	26118: 0;	26119: 0;	26120: 1;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:02:01,359:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 10:02:01,360:INFO::Eearly stopping!
2023-12-01 10:02:01,473:INFO::############### Search Stage Ends! ###############
2023-12-01 10:02:01,554:INFO::=============== Retrain Stage Starts:
2023-12-01 10:02:01,554:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:02:01,565:INFO::node_assign_Counter:
Counter({-1: 14328, 0: 5069, 1: 4345, 3: 1592, 2: 794})
2023-12-01 10:02:01,565:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:02:01,974:INFO::============= repeat round: 3; seed: 1024
2023-12-01 10:02:02,013:INFO::arch_weights:
[[0.28854918 0.3130397  0.43791837 0.32686386]
 [0.29209217 0.4522337  0.3135179  0.31901744]
 [0.29739293 0.3114872  0.499096   0.29679054]
 [0.27778304 0.46137476 0.3175285  0.31374064]]
2023-12-01 10:02:02,014:INFO::arch_weights_softmax:
[[0.23668906 0.24255726 0.27482003 0.2459337 ]
 [0.23681952 0.2779496  0.24194828 0.24328254]
 [0.2360118  0.23936176 0.2887568  0.23586968]
 [0.23371679 0.28081658 0.243193   0.24227358]]
2023-12-01 10:02:02,014:INFO::genotype choice:
['mean', 'ppnp', 'mean', 'ppnp']
2023-12-01 10:02:02,990:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.4086 | Val_Loss 1.3424 | Time(s) 0.9337
2023-12-01 10:02:03,763:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3488 | Val_Loss 1.3010 | Time(s) 0.7591
2023-12-01 10:02:03,778:INFO::Validation loss decreased (inf --> 1.300966).  Saving model ...
2023-12-01 10:02:04,507:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.2997 | Val_Loss 1.2651 | Time(s) 0.7290
2023-12-01 10:02:04,522:INFO::Validation loss decreased (1.300966 --> 1.265069).  Saving model ...
2023-12-01 10:02:05,283:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.2721 | Val_Loss 1.2325 | Time(s) 0.7613
2023-12-01 10:02:05,297:INFO::Validation loss decreased (1.265069 --> 1.232507).  Saving model ...
2023-12-01 10:02:06,028:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.2416 | Val_Loss 1.2012 | Time(s) 0.7292
2023-12-01 10:02:06,038:INFO::Validation loss decreased (1.232507 --> 1.201227).  Saving model ...
2023-12-01 10:02:06,771:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.2169 | Val_Loss 1.1699 | Time(s) 0.7333
2023-12-01 10:02:06,784:INFO::Validation loss decreased (1.201227 --> 1.169889).  Saving model ...
2023-12-01 10:02:07,537:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.1815 | Val_Loss 1.1378 | Time(s) 0.7530
2023-12-01 10:02:07,549:INFO::Validation loss decreased (1.169889 --> 1.137840).  Saving model ...
2023-12-01 10:02:08,243:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.1502 | Val_Loss 1.1055 | Time(s) 0.6943
2023-12-01 10:02:08,255:INFO::Validation loss decreased (1.137840 --> 1.105461).  Saving model ...
2023-12-01 10:02:09,030:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.1197 | Val_Loss 1.0737 | Time(s) 0.7751
2023-12-01 10:02:09,042:INFO::Validation loss decreased (1.105461 --> 1.073696).  Saving model ...
2023-12-01 10:02:09,762:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.0753 | Val_Loss 1.0415 | Time(s) 0.7192
2023-12-01 10:02:09,773:INFO::Validation loss decreased (1.073696 --> 1.041482).  Saving model ...
2023-12-01 10:02:10,505:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.0685 | Val_Loss 1.0093 | Time(s) 0.7320
2023-12-01 10:02:10,516:INFO::Validation loss decreased (1.041482 --> 1.009281).  Saving model ...
2023-12-01 10:02:11,310:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.0236 | Val_Loss 0.9773 | Time(s) 0.7941
2023-12-01 10:02:11,323:INFO::Validation loss decreased (1.009281 --> 0.977268).  Saving model ...
2023-12-01 10:02:12,112:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 0.9972 | Val_Loss 0.9459 | Time(s) 0.7885
2023-12-01 10:02:12,128:INFO::Validation loss decreased (0.977268 --> 0.945862).  Saving model ...
2023-12-01 10:02:12,878:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 1.0038 | Val_Loss 0.9150 | Time(s) 0.7503
2023-12-01 10:02:12,890:INFO::Validation loss decreased (0.945862 --> 0.915015).  Saving model ...
2023-12-01 10:02:13,619:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 0.9799 | Val_Loss 0.8847 | Time(s) 0.7286
2023-12-01 10:02:13,631:INFO::Validation loss decreased (0.915015 --> 0.884663).  Saving model ...
2023-12-01 10:02:14,370:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 0.9478 | Val_Loss 0.8551 | Time(s) 0.7397
2023-12-01 10:02:14,382:INFO::Validation loss decreased (0.884663 --> 0.855143).  Saving model ...
2023-12-01 10:02:15,090:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 0.9280 | Val_Loss 0.8260 | Time(s) 0.7063
2023-12-01 10:02:15,101:INFO::Validation loss decreased (0.855143 --> 0.825954).  Saving model ...
2023-12-01 10:02:15,814:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 0.8844 | Val_Loss 0.7978 | Time(s) 0.7133
2023-12-01 10:02:15,825:INFO::Validation loss decreased (0.825954 --> 0.797773).  Saving model ...
2023-12-01 10:02:16,615:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 0.8433 | Val_Loss 0.7706 | Time(s) 0.7884
2023-12-01 10:02:16,627:INFO::Validation loss decreased (0.797773 --> 0.770595).  Saving model ...
2023-12-01 10:02:17,331:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 0.8839 | Val_Loss 0.7448 | Time(s) 0.7027
2023-12-01 10:02:17,343:INFO::Validation loss decreased (0.770595 --> 0.744780).  Saving model ...
2023-12-01 10:02:18,158:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 0.8527 | Val_Loss 0.7196 | Time(s) 0.8149
2023-12-01 10:02:18,172:INFO::Validation loss decreased (0.744780 --> 0.719618).  Saving model ...
2023-12-01 10:02:18,913:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 0.8264 | Val_Loss 0.6954 | Time(s) 0.7412
2023-12-01 10:02:18,924:INFO::Validation loss decreased (0.719618 --> 0.695416).  Saving model ...
2023-12-01 10:02:19,654:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 0.7871 | Val_Loss 0.6723 | Time(s) 0.7286
2023-12-01 10:02:19,666:INFO::Validation loss decreased (0.695416 --> 0.672251).  Saving model ...
2023-12-01 10:02:20,401:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 0.7724 | Val_Loss 0.6497 | Time(s) 0.7345
2023-12-01 10:02:20,412:INFO::Validation loss decreased (0.672251 --> 0.649700).  Saving model ...
2023-12-01 10:02:21,148:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 0.7252 | Val_Loss 0.6277 | Time(s) 0.7346
2023-12-01 10:02:21,159:INFO::Validation loss decreased (0.649700 --> 0.627688).  Saving model ...
2023-12-01 10:02:21,913:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 0.7279 | Val_Loss 0.6061 | Time(s) 0.7542
2023-12-01 10:02:21,924:INFO::Validation loss decreased (0.627688 --> 0.606106).  Saving model ...
2023-12-01 10:02:22,633:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 0.7337 | Val_Loss 0.5856 | Time(s) 0.7087
2023-12-01 10:02:22,642:INFO::Validation loss decreased (0.606106 --> 0.585603).  Saving model ...
2023-12-01 10:02:23,430:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 0.6812 | Val_Loss 0.5656 | Time(s) 0.7855
2023-12-01 10:02:23,442:INFO::Validation loss decreased (0.585603 --> 0.565597).  Saving model ...
2023-12-01 10:02:24,172:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 0.6803 | Val_Loss 0.5463 | Time(s) 0.7292
2023-12-01 10:02:24,183:INFO::Validation loss decreased (0.565597 --> 0.546255).  Saving model ...
2023-12-01 10:02:24,936:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 0.6607 | Val_Loss 0.5275 | Time(s) 0.7525
2023-12-01 10:02:24,950:INFO::Validation loss decreased (0.546255 --> 0.527538).  Saving model ...
2023-12-01 10:02:25,655:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 0.6362 | Val_Loss 0.5085 | Time(s) 0.7058
2023-12-01 10:02:25,669:INFO::Validation loss decreased (0.527538 --> 0.508543).  Saving model ...
2023-12-01 10:02:26,421:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 0.6248 | Val_Loss 0.4894 | Time(s) 0.7510
2023-12-01 10:02:26,433:INFO::Validation loss decreased (0.508543 --> 0.489420).  Saving model ...
2023-12-01 10:02:27,193:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 0.6268 | Val_Loss 0.4714 | Time(s) 0.7601
2023-12-01 10:02:27,205:INFO::Validation loss decreased (0.489420 --> 0.471417).  Saving model ...
2023-12-01 10:02:27,956:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 0.6113 | Val_Loss 0.4549 | Time(s) 0.7502
2023-12-01 10:02:27,970:INFO::Validation loss decreased (0.471417 --> 0.454947).  Saving model ...
2023-12-01 10:02:28,734:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 0.5622 | Val_Loss 0.4395 | Time(s) 0.7642
2023-12-01 10:02:28,748:INFO::Validation loss decreased (0.454947 --> 0.439518).  Saving model ...
2023-12-01 10:02:29,521:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 0.5539 | Val_Loss 0.4251 | Time(s) 0.7729
2023-12-01 10:02:29,533:INFO::Validation loss decreased (0.439518 --> 0.425110).  Saving model ...
2023-12-01 10:02:30,312:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 0.5312 | Val_Loss 0.4118 | Time(s) 0.7779
2023-12-01 10:02:30,327:INFO::Validation loss decreased (0.425110 --> 0.411785).  Saving model ...
2023-12-01 10:02:31,080:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 0.5242 | Val_Loss 0.3998 | Time(s) 0.7527
2023-12-01 10:02:31,091:INFO::Validation loss decreased (0.411785 --> 0.399753).  Saving model ...
2023-12-01 10:02:31,834:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 0.4906 | Val_Loss 0.3877 | Time(s) 0.7432
2023-12-01 10:02:31,847:INFO::Validation loss decreased (0.399753 --> 0.387742).  Saving model ...
2023-12-01 10:02:32,593:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 0.4702 | Val_Loss 0.3759 | Time(s) 0.7466
2023-12-01 10:02:32,608:INFO::Validation loss decreased (0.387742 --> 0.375931).  Saving model ...
2023-12-01 10:02:33,332:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 0.4612 | Val_Loss 0.3651 | Time(s) 0.7227
2023-12-01 10:02:33,342:INFO::Validation loss decreased (0.375931 --> 0.365149).  Saving model ...
2023-12-01 10:02:34,147:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 0.4435 | Val_Loss 0.3539 | Time(s) 0.8041
2023-12-01 10:02:34,159:INFO::Validation loss decreased (0.365149 --> 0.353927).  Saving model ...
2023-12-01 10:02:34,900:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 0.4498 | Val_Loss 0.3431 | Time(s) 0.7403
2023-12-01 10:02:34,912:INFO::Validation loss decreased (0.353927 --> 0.343140).  Saving model ...
2023-12-01 10:02:35,648:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 0.4274 | Val_Loss 0.3333 | Time(s) 0.7356
2023-12-01 10:02:35,659:INFO::Validation loss decreased (0.343140 --> 0.333297).  Saving model ...
2023-12-01 10:02:36,364:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 0.4105 | Val_Loss 0.3239 | Time(s) 0.7038
2023-12-01 10:02:36,393:INFO::Validation loss decreased (0.333297 --> 0.323943).  Saving model ...
2023-12-01 10:02:37,109:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 0.3992 | Val_Loss 0.3158 | Time(s) 0.7152
2023-12-01 10:02:37,121:INFO::Validation loss decreased (0.323943 --> 0.315751).  Saving model ...
2023-12-01 10:02:37,885:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 0.4076 | Val_Loss 0.3083 | Time(s) 0.7642
2023-12-01 10:02:37,901:INFO::Validation loss decreased (0.315751 --> 0.308315).  Saving model ...
2023-12-01 10:02:38,726:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 0.3562 | Val_Loss 0.3011 | Time(s) 0.8239
2023-12-01 10:02:38,737:INFO::Validation loss decreased (0.308315 --> 0.301150).  Saving model ...
2023-12-01 10:02:39,602:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 0.3763 | Val_Loss 0.2931 | Time(s) 0.8643
2023-12-01 10:02:39,619:INFO::Validation loss decreased (0.301150 --> 0.293133).  Saving model ...
2023-12-01 10:02:40,466:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 0.3872 | Val_Loss 0.2858 | Time(s) 0.8469
2023-12-01 10:02:40,480:INFO::Validation loss decreased (0.293133 --> 0.285755).  Saving model ...
2023-12-01 10:02:41,191:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 0.3479 | Val_Loss 0.2792 | Time(s) 0.7103
2023-12-01 10:02:41,205:INFO::Validation loss decreased (0.285755 --> 0.279212).  Saving model ...
2023-12-01 10:02:41,928:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.3543 | Val_Loss 0.2737 | Time(s) 0.7223
2023-12-01 10:02:41,993:INFO::Validation loss decreased (0.279212 --> 0.273732).  Saving model ...
2023-12-01 10:02:42,971:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.3746 | Val_Loss 0.2700 | Time(s) 0.9004
2023-12-01 10:02:42,987:INFO::Validation loss decreased (0.273732 --> 0.270028).  Saving model ...
2023-12-01 10:02:43,738:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 0.3588 | Val_Loss 0.2660 | Time(s) 0.7514
2023-12-01 10:02:43,753:INFO::Validation loss decreased (0.270028 --> 0.265992).  Saving model ...
2023-12-01 10:02:44,507:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.3379 | Val_Loss 0.2602 | Time(s) 0.7536
2023-12-01 10:02:44,519:INFO::Validation loss decreased (0.265992 --> 0.260238).  Saving model ...
2023-12-01 10:02:45,331:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.3214 | Val_Loss 0.2560 | Time(s) 0.8120
2023-12-01 10:02:45,343:INFO::Validation loss decreased (0.260238 --> 0.255995).  Saving model ...
2023-12-01 10:02:46,083:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.3163 | Val_Loss 0.2537 | Time(s) 0.7392
2023-12-01 10:02:46,094:INFO::Validation loss decreased (0.255995 --> 0.253730).  Saving model ...
2023-12-01 10:02:46,821:INFO::Epoch 00057 | lr 0.00050 |Train_Loss 0.3133 | Val_Loss 0.2522 | Time(s) 0.7269
2023-12-01 10:02:46,831:INFO::Validation loss decreased (0.253730 --> 0.252211).  Saving model ...
2023-12-01 10:02:47,576:INFO::Epoch 00058 | lr 0.00050 |Train_Loss 0.2855 | Val_Loss 0.2512 | Time(s) 0.7456
2023-12-01 10:02:47,588:INFO::Validation loss decreased (0.252211 --> 0.251198).  Saving model ...
2023-12-01 10:02:48,371:INFO::Epoch 00059 | lr 0.00050 |Train_Loss 0.3196 | Val_Loss 0.2512 | Time(s) 0.7825
2023-12-01 10:02:48,372:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:02:49,119:INFO::Epoch 00060 | lr 0.00050 |Train_Loss 0.2906 | Val_Loss 0.2518 | Time(s) 0.7472
2023-12-01 10:02:49,120:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:02:49,900:INFO::Epoch 00061 | lr 0.00050 |Train_Loss 0.3145 | Val_Loss 0.2537 | Time(s) 0.7801
2023-12-01 10:02:49,900:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 10:02:50,765:INFO::Epoch 00062 | lr 0.00050 |Train_Loss 0.2854 | Val_Loss 0.2558 | Time(s) 0.8636
2023-12-01 10:02:50,766:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 10:02:51,538:INFO::Epoch 00063 | lr 0.00050 |Train_Loss 0.3078 | Val_Loss 0.2581 | Time(s) 0.7729
2023-12-01 10:02:51,539:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 10:02:52,296:INFO::Epoch 00064 | lr 0.00050 |Train_Loss 0.2902 | Val_Loss 0.2598 | Time(s) 0.7562
2023-12-01 10:02:52,297:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 10:02:53,184:INFO::Epoch 00065 | lr 0.00050 |Train_Loss 0.2791 | Val_Loss 0.2594 | Time(s) 0.8859
2023-12-01 10:02:53,184:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 10:02:54,062:INFO::Epoch 00066 | lr 0.00050 |Train_Loss 0.2806 | Val_Loss 0.2556 | Time(s) 0.8777
2023-12-01 10:02:54,063:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 10:02:54,063:INFO::Eearly stopping!
2023-12-01 10:02:54,064:INFO::
testing...
2023-12-01 10:02:54,083:INFO::submit dir: submit/submit_gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:02:54,575:INFO::{'micro-f1': 0.9091549295774648, 'macro-f1': 0.9030549669318251}
2023-12-01 10:02:54,768:INFO::############### Retrain Stage Ends! #################
2023-12-01 10:02:54,768:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gat', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-09-54-04', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=2022, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=4, last_hidden_dim=512, logger=<Logger log_output (INFO)>)
2023-12-01 10:03:13,679:INFO::node_type_num: 4
2023-12-01 10:03:13,702:INFO::=============== Prepare basic data stage finish, use 18.933921337127686 time.
2023-12-01 10:03:13,824:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:16,828:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:16,829:INFO::its now!!!!!!!!5
2023-12-01 10:03:17,185:INFO::its now!!!!!!!!0
2023-12-01 10:03:17,186:INFO::its now!!!!!!!!3
2023-12-01 10:03:17,309:INFO::its now!!!!!!!!5
2023-12-01 10:03:17,532:INFO::its now!!!!!!!!
2023-12-01 10:03:17,532:INFO::its now!!!!!!!! on 
2023-12-01 10:03:17,675:INFO::its now!!!!!!!!5
2023-12-01 10:03:17,900:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:17,997:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.4257 | Train_Classification_Loss 1.4568 | Dmon_Loss -0.0623 | Val_Loss 1.3865 | Search Time(s) 0.8378 | Infer Time(s) 0.2393 | Time(s) 1.0771 
2023-12-01 10:03:18,036:INFO::cluster info:
0: 0;	1: 1;	2: 2;	3: 1;	4: 0;	5: 1;	6: 1;	7: 1;	8: 0;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 2;	17: 2;	18: 0;	19: 2;	20: 1;	21: 2;	22: 2;	23: 1;	24: 2;	25: 1;	26: 0;	27: 2;	28: 2;	29: 2;	30: 1;	31: 2;	32: 2;	33: 0;	34: 1;	35: 2;	36: 2;	37: 2;	38: 1;	39: 3;	40: 0;	41: 2;	42: 2;	43: 1;	44
26098: 2;	26099: 1;	26100: 2;	26101: 1;	26102: 2;	26103: 1;	26104: 0;	26105: 1;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 10:03:18,040:INFO::Epoch: 1
tensor([[0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:18,041:INFO::its now!!!!!!!!5
2023-12-01 10:03:18,346:INFO::its now!!!!!!!!0
2023-12-01 10:03:18,348:INFO::its now!!!!!!!!3
2023-12-01 10:03:18,478:INFO::its now!!!!!!!!5
2023-12-01 10:03:18,699:INFO::its now!!!!!!!!
2023-12-01 10:03:18,699:INFO::its now!!!!!!!! on 
2023-12-01 10:03:18,821:INFO::its now!!!!!!!!5
2023-12-01 10:03:19,037:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:19,038:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3551 | Train_Classification_Loss 1.3864 | Dmon_Loss -0.0627 | Val_Loss 1.3771 | Search Time(s) 0.7785 | Infer Time(s) 0.2214 | Time(s) 0.9999 
2023-12-01 10:03:19,083:INFO::cluster info:
0: 2;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 3;	7: 0;	8: 2;	9: 0;	10: 0;	11: 3;	12: 2;	13: 0;	14: 2;	15: 3;	16: 3;	17: 0;	18: 2;	19: 3;	20: 2;	21: 2;	22: 0;	23: 0;	24: 3;	25: 2;	26: 3;	27: 3;	28: 2;	29: 2;	30: 3;	31: 2;	32: 3;	33: 0;	34: 3;	35: 3;	36: 2;	37: 1;	38: 2;	39: 2;	40: 3;	41: 2;	42: 2;	43: 0;	44
26098: 1;	26099: 0;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:19,084:INFO::Validation loss decreased (inf --> 1.377081).  Saving model ...
2023-12-01 10:03:19,088:INFO::Epoch: 2
tensor([[0.4997, 0.5074, 0.5101, 0.5101],
        [0.4997, 0.5064, 0.5101, 0.5101],
        [0.4996, 0.5073, 0.5101, 0.5101],
        [0.4997, 0.5073, 0.5101, 0.5101]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:19,089:INFO::its now!!!!!!!!5
2023-12-01 10:03:19,310:INFO::its now!!!!!!!!0
2023-12-01 10:03:19,312:INFO::its now!!!!!!!!3
2023-12-01 10:03:19,453:INFO::its now!!!!!!!!5
2023-12-01 10:03:19,685:INFO::its now!!!!!!!!
2023-12-01 10:03:19,685:INFO::its now!!!!!!!! on 
2023-12-01 10:03:19,810:INFO::its now!!!!!!!!5
2023-12-01 10:03:20,014:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:20,016:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3548 | Train_Classification_Loss 1.3861 | Dmon_Loss -0.0627 | Val_Loss 1.3683 | Search Time(s) 0.7221 | Infer Time(s) 0.2074 | Time(s) 0.9295 
2023-12-01 10:03:20,054:INFO::cluster info:
0: 1;	1: 0;	2: 0;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 2;	9: 1;	10: 1;	11: 0;	12: 3;	13: 2;	14: 0;	15: 3;	16: 2;	17: 2;	18: 0;	19: 2;	20: 2;	21: 0;	22: 2;	23: 1;	24: 2;	25: 0;	26: 1;	27: 2;	28: 0;	29: 0;	30: 2;	31: 2;	32: 0;	33: 1;	34: 1;	35: 2;	36: 2;	37: 1;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 2;	26102: 1;	26103: 0;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 0;	26127: 2;	
2023-12-01 10:03:20,056:INFO::Validation loss decreased (1.377081 --> 1.368301).  Saving model ...
2023-12-01 10:03:20,058:INFO::Epoch: 3
tensor([[0.5052, 0.5123, 0.5127, 0.5156],
        [0.5052, 0.5111, 0.5156, 0.5128],
        [0.5051, 0.5068, 0.5156, 0.5156],
        [0.5052, 0.5086, 0.5156, 0.5156]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:20,058:INFO::its now!!!!!!!!5
2023-12-01 10:03:20,268:INFO::its now!!!!!!!!0
2023-12-01 10:03:20,269:INFO::its now!!!!!!!!3
2023-12-01 10:03:20,385:INFO::its now!!!!!!!!5
2023-12-01 10:03:20,592:INFO::its now!!!!!!!!
2023-12-01 10:03:20,592:INFO::its now!!!!!!!! on 
2023-12-01 10:03:20,716:INFO::its now!!!!!!!!5
2023-12-01 10:03:20,927:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:20,928:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3403 | Train_Classification_Loss 1.3717 | Dmon_Loss -0.0627 | Val_Loss 1.3606 | Search Time(s) 0.6572 | Infer Time(s) 0.2124 | Time(s) 0.8697 
2023-12-01 10:03:20,969:INFO::cluster info:
0: 3;	1: 1;	2: 0;	3: 0;	4: 0;	5: 2;	6: 1;	7: 2;	8: 1;	9: 2;	10: 0;	11: 2;	12: 0;	13: 0;	14: 2;	15: 2;	16: 2;	17: 2;	18: 0;	19: 2;	20: 2;	21: 3;	22: 3;	23: 2;	24: 1;	25: 3;	26: 0;	27: 0;	28: 2;	29: 0;	30: 0;	31: 0;	32: 3;	33: 0;	34: 1;	35: 2;	36: 2;	37: 0;	38: 2;	39: 0;	40: 0;	41: 1;	42: 0;	43: 1;	44
26098: 1;	26099: 0;	26100: 3;	26101: 3;	26102: 2;	26103: 3;	26104: 0;	26105: 1;	26106: 1;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 0;	26112: 0;	26113: 0;	26114: 2;	26115: 0;	26116: 2;	26117: 2;	26118: 2;	26119: 0;	26120: 2;	26121: 0;	26122: 0;	26123: 2;	26124: 2;	26125: 2;	26126: 1;	26127: 2;	
2023-12-01 10:03:20,970:INFO::Validation loss decreased (1.368301 --> 1.360557).  Saving model ...
2023-12-01 10:03:20,973:INFO::Epoch: 4
tensor([[0.5081, 0.5175, 0.5175, 0.5209],
        [0.5106, 0.5162, 0.5209, 0.5142],
        [0.5105, 0.5109, 0.5209, 0.5186],
        [0.5106, 0.5134, 0.5186, 0.5209]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:20,973:INFO::its now!!!!!!!!5
2023-12-01 10:03:21,168:INFO::its now!!!!!!!!0
2023-12-01 10:03:21,170:INFO::its now!!!!!!!!3
2023-12-01 10:03:21,284:INFO::its now!!!!!!!!5
2023-12-01 10:03:21,523:INFO::its now!!!!!!!!
2023-12-01 10:03:21,523:INFO::its now!!!!!!!! on 
2023-12-01 10:03:21,646:INFO::its now!!!!!!!!5
2023-12-01 10:03:21,854:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:21,857:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3425 | Train_Classification_Loss 1.3738 | Dmon_Loss -0.0627 | Val_Loss 1.3531 | Search Time(s) 0.6732 | Infer Time(s) 0.2114 | Time(s) 0.8846 
2023-12-01 10:03:21,908:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 0;	4: 2;	5: 0;	6: 1;	7: 0;	8: 0;	9: 0;	10: 2;	11: 3;	12: 1;	13: 2;	14: 0;	15: 1;	16: 0;	17: 0;	18: 3;	19: 0;	20: 2;	21: 1;	22: 3;	23: 0;	24: 2;	25: 1;	26: 0;	27: 1;	28: 0;	29: 0;	30: 0;	31: 1;	32: 0;	33: 1;	34: 0;	35: 2;	36: 2;	37: 0;	38: 2;	39: 0;	40: 3;	41: 2;	42: 3;	43: 0;	44
26098: 0;	26099: 3;	26100: 3;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 1;	26106: 2;	26107: 0;	26108: 0;	26109: 0;	26110: 2;	26111: 1;	26112: 0;	26113: 2;	26114: 0;	26115: 2;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 1;	26123: 2;	26124: 0;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:21,909:INFO::Validation loss decreased (1.360557 --> 1.353113).  Saving model ...
2023-12-01 10:03:21,912:INFO::Epoch: 5
tensor([[0.5077, 0.5185, 0.5179, 0.5237],
        [0.5118, 0.5172, 0.5238, 0.5123],
        [0.5117, 0.5107, 0.5237, 0.5184],
        [0.5118, 0.5134, 0.5184, 0.5238]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:21,913:INFO::its now!!!!!!!!5
2023-12-01 10:03:22,116:INFO::its now!!!!!!!!0
2023-12-01 10:03:22,116:INFO::its now!!!!!!!!3
2023-12-01 10:03:22,231:INFO::its now!!!!!!!!5
2023-12-01 10:03:22,481:INFO::its now!!!!!!!!
2023-12-01 10:03:22,481:INFO::its now!!!!!!!! on 
2023-12-01 10:03:22,605:INFO::its now!!!!!!!!5
2023-12-01 10:03:22,836:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:22,838:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3291 | Train_Classification_Loss 1.3604 | Dmon_Loss -0.0627 | Val_Loss 1.3380 | Search Time(s) 0.6951 | Infer Time(s) 0.2314 | Time(s) 0.9265 
2023-12-01 10:03:22,879:INFO::cluster info:
0: 2;	1: 2;	2: 3;	3: 2;	4: 0;	5: 0;	6: 3;	7: 2;	8: 3;	9: 3;	10: 0;	11: 3;	12: 0;	13: 3;	14: 2;	15: 3;	16: 0;	17: 1;	18: 2;	19: 3;	20: 2;	21: 1;	22: 2;	23: 2;	24: 1;	25: 2;	26: 3;	27: 0;	28: 2;	29: 2;	30: 0;	31: 0;	32: 2;	33: 0;	34: 0;	35: 2;	36: 3;	37: 2;	38: 0;	39: 2;	40: 2;	41: 2;	42: 3;	43: 0;	44
26098: 1;	26099: 1;	26100: 1;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 2;	26110: 2;	26111: 0;	26112: 1;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 3;	26118: 0;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 0;	26124: 2;	26125: 0;	26126: 2;	26127: 0;	
2023-12-01 10:03:22,880:INFO::Validation loss decreased (1.353113 --> 1.338011).  Saving model ...
2023-12-01 10:03:22,882:INFO::Epoch: 6
tensor([[0.5068, 0.5185, 0.5174, 0.5252],
        [0.5118, 0.5172, 0.5253, 0.5103],
        [0.5118, 0.5098, 0.5253, 0.5177],
        [0.5119, 0.5127, 0.5177, 0.5253]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:22,883:INFO::its now!!!!!!!!5
2023-12-01 10:03:23,101:INFO::its now!!!!!!!!0
2023-12-01 10:03:23,102:INFO::its now!!!!!!!!3
2023-12-01 10:03:23,220:INFO::its now!!!!!!!!5
2023-12-01 10:03:23,480:INFO::its now!!!!!!!!
2023-12-01 10:03:23,480:INFO::its now!!!!!!!! on 
2023-12-01 10:03:23,603:INFO::its now!!!!!!!!5
2023-12-01 10:03:23,813:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:23,814:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.3091 | Train_Classification_Loss 1.3404 | Dmon_Loss -0.0627 | Val_Loss 1.3228 | Search Time(s) 0.7181 | Infer Time(s) 0.2134 | Time(s) 0.9315 
2023-12-01 10:03:23,852:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 0;	4: 0;	5: 3;	6: 2;	7: 2;	8: 1;	9: 3;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 3;	17: 2;	18: 2;	19: 1;	20: 0;	21: 3;	22: 0;	23: 0;	24: 3;	25: 2;	26: 1;	27: 3;	28: 2;	29: 0;	30: 0;	31: 2;	32: 1;	33: 1;	34: 3;	35: 2;	36: 0;	37: 3;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 3;	26099: 0;	26100: 3;	26101: 1;	26102: 0;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 1;	26109: 0;	26110: 0;	26111: 2;	26112: 0;	26113: 0;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 3;	26122: 0;	26123: 0;	26124: 2;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 10:03:23,854:INFO::Validation loss decreased (1.338011 --> 1.322794).  Saving model ...
2023-12-01 10:03:23,856:INFO::Epoch: 7
tensor([[0.5099, 0.5217, 0.5208, 0.5260],
        [0.5150, 0.5203, 0.5261, 0.5139],
        [0.5149, 0.5134, 0.5260, 0.5207],
        [0.5151, 0.5163, 0.5207, 0.5263]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:23,857:INFO::its now!!!!!!!!5
2023-12-01 10:03:24,077:INFO::its now!!!!!!!!0
2023-12-01 10:03:24,078:INFO::its now!!!!!!!!3
2023-12-01 10:03:24,193:INFO::its now!!!!!!!!5
2023-12-01 10:03:24,432:INFO::its now!!!!!!!!
2023-12-01 10:03:24,432:INFO::its now!!!!!!!! on 
2023-12-01 10:03:24,559:INFO::its now!!!!!!!!5
2023-12-01 10:03:24,765:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:24,767:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.2984 | Train_Classification_Loss 1.3298 | Dmon_Loss -0.0627 | Val_Loss 1.3151 | Search Time(s) 0.7011 | Infer Time(s) 0.2104 | Time(s) 0.9116 
2023-12-01 10:03:24,808:INFO::cluster info:
0: 1;	1: 0;	2: 1;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 0;	9: 3;	10: 2;	11: 1;	12: 3;	13: 2;	14: 0;	15: 3;	16: 3;	17: 0;	18: 0;	19: 0;	20: 2;	21: 3;	22: 1;	23: 0;	24: 2;	25: 3;	26: 0;	27: 2;	28: 0;	29: 1;	30: 2;	31: 0;	32: 2;	33: 2;	34: 0;	35: 1;	36: 0;	37: 2;	38: 0;	39: 0;	40: 0;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 3;	26102: 0;	26103: 2;	26104: 0;	26105: 0;	26106: 0;	26107: 3;	26108: 0;	26109: 1;	26110: 0;	26111: 0;	26112: 3;	26113: 1;	26114: 0;	26115: 0;	26116: 2;	26117: 1;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 10:03:24,809:INFO::Validation loss decreased (1.322794 --> 1.315074).  Saving model ...
2023-12-01 10:03:24,812:INFO::Epoch: 8
tensor([[0.5092, 0.5212, 0.5202, 0.5264],
        [0.5146, 0.5198, 0.5265, 0.5129],
        [0.5145, 0.5126, 0.5264, 0.5201],
        [0.5146, 0.5156, 0.5200, 0.5268]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:24,812:INFO::its now!!!!!!!!5
2023-12-01 10:03:25,013:INFO::its now!!!!!!!!0
2023-12-01 10:03:25,014:INFO::its now!!!!!!!!3
2023-12-01 10:03:25,126:INFO::its now!!!!!!!!5
2023-12-01 10:03:25,340:INFO::its now!!!!!!!!
2023-12-01 10:03:25,340:INFO::its now!!!!!!!! on 
2023-12-01 10:03:25,466:INFO::its now!!!!!!!!5
2023-12-01 10:03:25,668:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:25,670:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.2867 | Train_Classification_Loss 1.3180 | Dmon_Loss -0.0627 | Val_Loss 1.3013 | Search Time(s) 0.6533 | Infer Time(s) 0.2045 | Time(s) 0.8577 
2023-12-01 10:03:25,710:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 2;	4: 2;	5: 2;	6: 1;	7: 2;	8: 2;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 3;	16: 2;	17: 3;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 3;	27: 2;	28: 2;	29: 0;	30: 2;	31: 1;	32: 2;	33: 3;	34: 0;	35: 3;	36: 2;	37: 2;	38: 3;	39: 0;	40: 0;	41: 0;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 2;	26101: 0;	26102: 0;	26103: 0;	26104: 2;	26105: 2;	26106: 1;	26107: 2;	26108: 2;	26109: 0;	26110: 2;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 0;	26123: 2;	26124: 2;	26125: 1;	26126: 2;	26127: 2;	
2023-12-01 10:03:25,711:INFO::Validation loss decreased (1.315074 --> 1.301345).  Saving model ...
2023-12-01 10:03:25,713:INFO::Epoch: 9
tensor([[0.5073, 0.5196, 0.5182, 0.5266],
        [0.5129, 0.5182, 0.5267, 0.5105],
        [0.5129, 0.5105, 0.5266, 0.5183],
        [0.5130, 0.5135, 0.5182, 0.5270]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:25,714:INFO::its now!!!!!!!!5
2023-12-01 10:03:25,912:INFO::its now!!!!!!!!0
2023-12-01 10:03:25,913:INFO::its now!!!!!!!!3
2023-12-01 10:03:26,030:INFO::its now!!!!!!!!5
2023-12-01 10:03:26,242:INFO::its now!!!!!!!!
2023-12-01 10:03:26,242:INFO::its now!!!!!!!! on 
2023-12-01 10:03:26,367:INFO::its now!!!!!!!!5
2023-12-01 10:03:26,583:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:26,584:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.2675 | Train_Classification_Loss 1.2989 | Dmon_Loss -0.0628 | Val_Loss 1.2859 | Search Time(s) 0.6533 | Infer Time(s) 0.2184 | Time(s) 0.8717 
2023-12-01 10:03:26,632:INFO::cluster info:
0: 1;	1: 0;	2: 0;	3: 0;	4: 2;	5: 3;	6: 2;	7: 0;	8: 2;	9: 3;	10: 0;	11: 0;	12: 2;	13: 0;	14: 0;	15: 0;	16: 0;	17: 3;	18: 0;	19: 0;	20: 0;	21: 3;	22: 2;	23: 0;	24: 1;	25: 2;	26: 0;	27: 3;	28: 0;	29: 0;	30: 0;	31: 2;	32: 2;	33: 1;	34: 2;	35: 2;	36: 2;	37: 0;	38: 0;	39: 0;	40: 0;	41: 0;	42: 0;	43: 2;	44
26098: 3;	26099: 2;	26100: 3;	26101: 0;	26102: 3;	26103: 2;	26104: 2;	26105: 1;	26106: 2;	26107: 2;	26108: 0;	26109: 0;	26110: 0;	26111: 2;	26112: 0;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 0;	26118: 0;	26119: 0;	26120: 2;	26121: 0;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 0;	
2023-12-01 10:03:26,634:INFO::Validation loss decreased (1.301345 --> 1.285877).  Saving model ...
2023-12-01 10:03:26,637:INFO::Epoch: 10
tensor([[0.5049, 0.5174, 0.5158, 0.5268],
        [0.5108, 0.5161, 0.5268, 0.5076],
        [0.5108, 0.5079, 0.5265, 0.5160],
        [0.5109, 0.5108, 0.5160, 0.5271]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:26,638:INFO::its now!!!!!!!!5
2023-12-01 10:03:26,836:INFO::its now!!!!!!!!0
2023-12-01 10:03:26,837:INFO::its now!!!!!!!!3
2023-12-01 10:03:26,954:INFO::its now!!!!!!!!5
2023-12-01 10:03:27,166:INFO::its now!!!!!!!!
2023-12-01 10:03:27,166:INFO::its now!!!!!!!! on 
2023-12-01 10:03:27,291:INFO::its now!!!!!!!!5
2023-12-01 10:03:27,495:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:27,496:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.2374 | Train_Classification_Loss 1.2688 | Dmon_Loss -0.0627 | Val_Loss 1.2616 | Search Time(s) 0.6533 | Infer Time(s) 0.2074 | Time(s) 0.8607 
2023-12-01 10:03:27,535:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 2;	5: 1;	6: 2;	7: 1;	8: 1;	9: 3;	10: 0;	11: 2;	12: 1;	13: 3;	14: 2;	15: 3;	16: 0;	17: 2;	18: 0;	19: 1;	20: 1;	21: 3;	22: 2;	23: 0;	24: 1;	25: 1;	26: 0;	27: 2;	28: 2;	29: 2;	30: 2;	31: 1;	32: 2;	33: 2;	34: 0;	35: 3;	36: 0;	37: 2;	38: 1;	39: 0;	40: 0;	41: 2;	42: 0;	43: 0;	44
26098: 1;	26099: 3;	26100: 2;	26101: 1;	26102: 3;	26103: 1;	26104: 0;	26105: 3;	26106: 3;	26107: 1;	26108: 2;	26109: 2;	26110: 0;	26111: 0;	26112: 1;	26113: 0;	26114: 2;	26115: 1;	26116: 0;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 0;	26126: 1;	26127: 3;	
2023-12-01 10:03:27,536:INFO::Validation loss decreased (1.285877 --> 1.261612).  Saving model ...
2023-12-01 10:03:27,539:INFO::Epoch: 11
tensor([[0.5024, 0.5152, 0.5133, 0.5271],
        [0.5086, 0.5138, 0.5269, 0.5047],
        [0.5085, 0.5052, 0.5264, 0.5136],
        [0.5087, 0.5081, 0.5136, 0.5272]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:27,540:INFO::its now!!!!!!!!5
2023-12-01 10:03:27,740:INFO::its now!!!!!!!!0
2023-12-01 10:03:27,741:INFO::its now!!!!!!!!3
2023-12-01 10:03:27,857:INFO::its now!!!!!!!!5
2023-12-01 10:03:28,062:INFO::its now!!!!!!!!
2023-12-01 10:03:28,062:INFO::its now!!!!!!!! on 
2023-12-01 10:03:28,187:INFO::its now!!!!!!!!5
2023-12-01 10:03:28,423:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:28,424:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.2422 | Train_Classification_Loss 1.2736 | Dmon_Loss -0.0627 | Val_Loss 1.2572 | Search Time(s) 0.6473 | Infer Time(s) 0.2394 | Time(s) 0.8866 
2023-12-01 10:03:28,470:INFO::cluster info:
0: 3;	1: 0;	2: 0;	3: 0;	4: 2;	5: 0;	6: 0;	7: 3;	8: 2;	9: 3;	10: 0;	11: 2;	12: 2;	13: 0;	14: 0;	15: 3;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 3;	22: 0;	23: 2;	24: 3;	25: 2;	26: 1;	27: 2;	28: 2;	29: 0;	30: 0;	31: 0;	32: 3;	33: 0;	34: 3;	35: 0;	36: 0;	37: 3;	38: 2;	39: 1;	40: 0;	41: 2;	42: 0;	43: 0;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 2;	26103: 2;	26104: 0;	26105: 3;	26106: 2;	26107: 0;	26108: 0;	26109: 0;	26110: 0;	26111: 1;	26112: 0;	26113: 0;	26114: 0;	26115: 0;	26116: 2;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 2;	
2023-12-01 10:03:28,471:INFO::Validation loss decreased (1.261612 --> 1.257166).  Saving model ...
2023-12-01 10:03:28,475:INFO::Epoch: 12
tensor([[0.5026, 0.5154, 0.5134, 0.5273],
        [0.5088, 0.5140, 0.5268, 0.5049],
        [0.5087, 0.5053, 0.5263, 0.5138],
        [0.5088, 0.5083, 0.5138, 0.5273]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:28,476:INFO::its now!!!!!!!!5
2023-12-01 10:03:28,719:INFO::its now!!!!!!!!0
2023-12-01 10:03:28,720:INFO::its now!!!!!!!!3
2023-12-01 10:03:28,835:INFO::its now!!!!!!!!5
2023-12-01 10:03:29,055:INFO::its now!!!!!!!!
2023-12-01 10:03:29,056:INFO::its now!!!!!!!! on 
2023-12-01 10:03:29,182:INFO::its now!!!!!!!!5
2023-12-01 10:03:29,375:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:29,377:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.2110 | Train_Classification_Loss 1.2424 | Dmon_Loss -0.0627 | Val_Loss 1.2241 | Search Time(s) 0.7061 | Infer Time(s) 0.1965 | Time(s) 0.9026 
2023-12-01 10:03:29,413:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 0;	4: 2;	5: 0;	6: 1;	7: 3;	8: 3;	9: 1;	10: 2;	11: 2;	12: 3;	13: 0;	14: 0;	15: 3;	16: 3;	17: 1;	18: 3;	19: 0;	20: 1;	21: 1;	22: 1;	23: 1;	24: 3;	25: 1;	26: 0;	27: 2;	28: 1;	29: 1;	30: 2;	31: 0;	32: 2;	33: 2;	34: 3;	35: 3;	36: 2;	37: 3;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 0;	26099: 0;	26100: 2;	26101: 1;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 0;	26111: 2;	26112: 1;	26113: 1;	26114: 2;	26115: 0;	26116: 0;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 3;	26122: 1;	26123: 1;	26124: 0;	26125: 0;	26126: 2;	26127: 3;	
2023-12-01 10:03:29,414:INFO::Validation loss decreased (1.257166 --> 1.224127).  Saving model ...
2023-12-01 10:03:29,418:INFO::Epoch: 13
tensor([[0.5028, 0.5156, 0.5137, 0.5276],
        [0.5090, 0.5142, 0.5269, 0.5052],
        [0.5089, 0.5056, 0.5262, 0.5140],
        [0.5091, 0.5085, 0.5140, 0.5273]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:29,418:INFO::its now!!!!!!!!5
2023-12-01 10:03:29,611:INFO::its now!!!!!!!!0
2023-12-01 10:03:29,612:INFO::its now!!!!!!!!3
2023-12-01 10:03:29,728:INFO::its now!!!!!!!!5
2023-12-01 10:03:29,966:INFO::its now!!!!!!!!
2023-12-01 10:03:29,967:INFO::its now!!!!!!!! on 
2023-12-01 10:03:30,091:INFO::its now!!!!!!!!5
2023-12-01 10:03:30,299:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:30,301:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.2012 | Train_Classification_Loss 1.2326 | Dmon_Loss -0.0627 | Val_Loss 1.2132 | Search Time(s) 0.6742 | Infer Time(s) 0.2105 | Time(s) 0.8847 
2023-12-01 10:03:30,360:INFO::cluster info:
0: 1;	1: 0;	2: 0;	3: 2;	4: 1;	5: 2;	6: 2;	7: 0;	8: 1;	9: 1;	10: 2;	11: 3;	12: 1;	13: 0;	14: 2;	15: 2;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 0;	22: 3;	23: 2;	24: 0;	25: 2;	26: 1;	27: 2;	28: 2;	29: 2;	30: 2;	31: 3;	32: 2;	33: 0;	34: 0;	35: 2;	36: 3;	37: 3;	38: 0;	39: 0;	40: 2;	41: 2;	42: 0;	43: 1;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 2;	26111: 0;	26112: 0;	26113: 0;	26114: 0;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 0;	
2023-12-01 10:03:30,361:INFO::Validation loss decreased (1.224127 --> 1.213178).  Saving model ...
2023-12-01 10:03:30,364:INFO::Epoch: 14
tensor([[0.5008, 0.5137, 0.5116, 0.5277],
        [0.5072, 0.5124, 0.5270, 0.5028],
        [0.5071, 0.5034, 0.5262, 0.5121],
        [0.5072, 0.5063, 0.5121, 0.5273]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:30,365:INFO::its now!!!!!!!!5
2023-12-01 10:03:30,558:INFO::its now!!!!!!!!0
2023-12-01 10:03:30,559:INFO::its now!!!!!!!!3
2023-12-01 10:03:30,673:INFO::its now!!!!!!!!5
2023-12-01 10:03:30,945:INFO::its now!!!!!!!!
2023-12-01 10:03:30,945:INFO::its now!!!!!!!! on 
2023-12-01 10:03:31,070:INFO::its now!!!!!!!!5
2023-12-01 10:03:31,288:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:31,290:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.1770 | Train_Classification_Loss 1.2083 | Dmon_Loss -0.0627 | Val_Loss 1.1790 | Search Time(s) 0.7042 | Infer Time(s) 0.2224 | Time(s) 0.9265 
2023-12-01 10:03:31,332:INFO::cluster info:
0: 3;	1: 0;	2: 3;	3: 0;	4: 1;	5: 2;	6: 2;	7: 2;	8: 3;	9: 2;	10: 2;	11: 0;	12: 2;	13: 2;	14: 2;	15: 3;	16: 1;	17: 3;	18: 3;	19: 1;	20: 1;	21: 3;	22: 2;	23: 2;	24: 3;	25: 3;	26: 3;	27: 0;	28: 0;	29: 0;	30: 2;	31: 1;	32: 0;	33: 2;	34: 3;	35: 2;	36: 2;	37: 2;	38: 1;	39: 0;	40: 0;	41: 3;	42: 1;	43: 2;	44
26098: 2;	26099: 2;	26100: 0;	26101: 2;	26102: 0;	26103: 2;	26104: 0;	26105: 0;	26106: 2;	26107: 1;	26108: 1;	26109: 0;	26110: 2;	26111: 1;	26112: 1;	26113: 1;	26114: 2;	26115: 2;	26116: 2;	26117: 1;	26118: 2;	26119: 2;	26120: 1;	26121: 3;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 10:03:31,333:INFO::Validation loss decreased (1.213178 --> 1.179047).  Saving model ...
2023-12-01 10:03:31,336:INFO::Epoch: 15
tensor([[0.4990, 0.5121, 0.5098, 0.5279],
        [0.5056, 0.5107, 0.5270, 0.5008],
        [0.5055, 0.5015, 0.5261, 0.5104],
        [0.5056, 0.5044, 0.5104, 0.5273]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:31,337:INFO::its now!!!!!!!!5
2023-12-01 10:03:31,533:INFO::its now!!!!!!!!0
2023-12-01 10:03:31,535:INFO::its now!!!!!!!!3
2023-12-01 10:03:31,668:INFO::its now!!!!!!!!5
2023-12-01 10:03:31,895:INFO::its now!!!!!!!!
2023-12-01 10:03:31,895:INFO::its now!!!!!!!! on 
2023-12-01 10:03:32,020:INFO::its now!!!!!!!!5
2023-12-01 10:03:32,232:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:32,234:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.1667 | Train_Classification_Loss 1.1981 | Dmon_Loss -0.0627 | Val_Loss 1.1722 | Search Time(s) 0.6842 | Infer Time(s) 0.2154 | Time(s) 0.8996 
2023-12-01 10:03:32,272:INFO::cluster info:
0: 2;	1: 2;	2: 3;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 2;	12: 0;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 2;	19: 0;	20: 0;	21: 3;	22: 0;	23: 2;	24: 3;	25: 3;	26: 2;	27: 0;	28: 0;	29: 0;	30: 2;	31: 0;	32: 0;	33: 0;	34: 3;	35: 0;	36: 0;	37: 2;	38: 0;	39: 0;	40: 0;	41: 0;	42: 0;	43: 2;	44
26098: 0;	26099: 0;	26100: 2;	26101: 3;	26102: 1;	26103: 0;	26104: 1;	26105: 0;	26106: 0;	26107: 0;	26108: 0;	26109: 0;	26110: 0;	26111: 2;	26112: 0;	26113: 2;	26114: 0;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 10:03:32,273:INFO::Validation loss decreased (1.179047 --> 1.172173).  Saving model ...
2023-12-01 10:03:32,275:INFO::Epoch: 16
tensor([[0.5010, 0.5139, 0.5118, 0.5280],
        [0.5044, 0.5126, 0.5302, 0.5030],
        [0.5073, 0.5002, 0.5293, 0.5123],
        [0.5046, 0.5065, 0.5123, 0.5305]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:32,276:INFO::its now!!!!!!!!5
2023-12-01 10:03:32,485:INFO::its now!!!!!!!!0
2023-12-01 10:03:32,486:INFO::its now!!!!!!!!3
2023-12-01 10:03:32,603:INFO::its now!!!!!!!!5
2023-12-01 10:03:32,810:INFO::its now!!!!!!!!
2023-12-01 10:03:32,810:INFO::its now!!!!!!!! on 
2023-12-01 10:03:32,935:INFO::its now!!!!!!!!5
2023-12-01 10:03:33,129:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:33,131:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 1.1287 | Train_Classification_Loss 1.1600 | Dmon_Loss -0.0627 | Val_Loss 1.1231 | Search Time(s) 0.6572 | Infer Time(s) 0.1985 | Time(s) 0.8557 
2023-12-01 10:03:33,182:INFO::cluster info:
0: 3;	1: 2;	2: 1;	3: 2;	4: 0;	5: 2;	6: 3;	7: 0;	8: 2;	9: 3;	10: 0;	11: 0;	12: 3;	13: 1;	14: 2;	15: 1;	16: 2;	17: 0;	18: 2;	19: 2;	20: 1;	21: 0;	22: 2;	23: 3;	24: 1;	25: 1;	26: 2;	27: 2;	28: 1;	29: 2;	30: 2;	31: 1;	32: 2;	33: 3;	34: 1;	35: 1;	36: 3;	37: 1;	38: 2;	39: 0;	40: 2;	41: 1;	42: 1;	43: 3;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 2;	26103: 2;	26104: 3;	26105: 3;	26106: 3;	26107: 2;	26108: 0;	26109: 1;	26110: 0;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 1;	26123: 3;	26124: 2;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 10:03:33,183:INFO::Validation loss decreased (1.172173 --> 1.123056).  Saving model ...
2023-12-01 10:03:33,185:INFO::Epoch: 17
tensor([[0.5030, 0.5158, 0.5139, 0.5285],
        [0.5047, 0.5144, 0.5318, 0.5053],
        [0.5091, 0.5007, 0.5308, 0.5142],
        [0.5051, 0.5087, 0.5142, 0.5321]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:33,186:INFO::its now!!!!!!!!5
2023-12-01 10:03:33,401:INFO::its now!!!!!!!!0
2023-12-01 10:03:33,402:INFO::its now!!!!!!!!3
2023-12-01 10:03:33,516:INFO::its now!!!!!!!!5
2023-12-01 10:03:33,716:INFO::its now!!!!!!!!
2023-12-01 10:03:33,716:INFO::its now!!!!!!!! on 
2023-12-01 10:03:33,840:INFO::its now!!!!!!!!5
2023-12-01 10:03:34,057:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:34,059:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 1.1021 | Train_Classification_Loss 1.1334 | Dmon_Loss -0.0627 | Val_Loss 1.1045 | Search Time(s) 0.6542 | Infer Time(s) 0.2194 | Time(s) 0.8737 
2023-12-01 10:03:34,130:INFO::cluster info:
0: 3;	1: 0;	2: 0;	3: 0;	4: 0;	5: 0;	6: 3;	7: 0;	8: 3;	9: 2;	10: 2;	11: 3;	12: 1;	13: 0;	14: 0;	15: 3;	16: 2;	17: 2;	18: 2;	19: 2;	20: 0;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 2;	33: 0;	34: 0;	35: 3;	36: 0;	37: 3;	38: 2;	39: 2;	40: 2;	41: 2;	42: 0;	43: 3;	44
26098: 2;	26099: 0;	26100: 3;	26101: 0;	26102: 2;	26103: 1;	26104: 2;	26105: 0;	26106: 2;	26107: 0;	26108: 0;	26109: 0;	26110: 0;	26111: 0;	26112: 0;	26113: 2;	26114: 0;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 2;	26124: 2;	26125: 0;	26126: 0;	26127: 2;	
2023-12-01 10:03:34,132:INFO::Validation loss decreased (1.123056 --> 1.104451).  Saving model ...
2023-12-01 10:03:34,136:INFO::Epoch: 18
tensor([[0.5039, 0.5171, 0.5154, 0.5292],
        [0.5048, 0.5158, 0.5332, 0.5070],
        [0.5105, 0.5014, 0.5316, 0.5156],
        [0.5053, 0.5103, 0.5156, 0.5334]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:34,137:INFO::its now!!!!!!!!5
2023-12-01 10:03:34,403:INFO::its now!!!!!!!!0
2023-12-01 10:03:34,404:INFO::its now!!!!!!!!3
2023-12-01 10:03:34,517:INFO::its now!!!!!!!!5
2023-12-01 10:03:34,725:INFO::its now!!!!!!!!
2023-12-01 10:03:34,725:INFO::its now!!!!!!!! on 
2023-12-01 10:03:34,850:INFO::its now!!!!!!!!5
2023-12-01 10:03:35,059:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:35,060:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 1.0510 | Train_Classification_Loss 1.0823 | Dmon_Loss -0.0627 | Val_Loss 1.0616 | Search Time(s) 0.7141 | Infer Time(s) 0.2124 | Time(s) 0.9265 
2023-12-01 10:03:35,098:INFO::cluster info:
0: 3;	1: 1;	2: 2;	3: 1;	4: 0;	5: 1;	6: 3;	7: 1;	8: 1;	9: 1;	10: 0;	11: 0;	12: 0;	13: 1;	14: 0;	15: 1;	16: 2;	17: 1;	18: 0;	19: 0;	20: 2;	21: 2;	22: 1;	23: 3;	24: 1;	25: 1;	26: 3;	27: 2;	28: 3;	29: 1;	30: 2;	31: 1;	32: 0;	33: 0;	34: 3;	35: 2;	36: 3;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 1;	26099: 1;	26100: 1;	26101: 0;	26102: 1;	26103: 2;	26104: 2;	26105: 0;	26106: 3;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 1;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 1;	26123: 2;	26124: 2;	26125: 0;	26126: 1;	26127: 2;	
2023-12-01 10:03:35,099:INFO::Validation loss decreased (1.104451 --> 1.061640).  Saving model ...
2023-12-01 10:03:35,101:INFO::Epoch: 19
tensor([[0.5095, 0.5227, 0.5213, 0.5298],
        [0.5098, 0.5213, 0.5338, 0.5134],
        [0.5159, 0.5074, 0.5319, 0.5213],
        [0.5104, 0.5165, 0.5213, 0.5341]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:35,102:INFO::its now!!!!!!!!5
2023-12-01 10:03:35,324:INFO::its now!!!!!!!!0
2023-12-01 10:03:35,325:INFO::its now!!!!!!!!3
2023-12-01 10:03:35,442:INFO::its now!!!!!!!!5
2023-12-01 10:03:35,659:INFO::its now!!!!!!!!
2023-12-01 10:03:35,659:INFO::its now!!!!!!!! on 
2023-12-01 10:03:35,784:INFO::its now!!!!!!!!5
2023-12-01 10:03:35,997:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:35,998:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 1.0318 | Train_Classification_Loss 1.0631 | Dmon_Loss -0.0627 | Val_Loss 1.0406 | Search Time(s) 0.6822 | Infer Time(s) 0.2164 | Time(s) 0.8986 
2023-12-01 10:03:36,048:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 2;	9: 3;	10: 0;	11: 0;	12: 0;	13: 0;	14: 0;	15: 1;	16: 0;	17: 0;	18: 2;	19: 0;	20: 0;	21: 0;	22: 2;	23: 0;	24: 1;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 3;	31: 1;	32: 0;	33: 3;	34: 2;	35: 0;	36: 3;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 2;	26099: 0;	26100: 3;	26101: 2;	26102: 2;	26103: 2;	26104: 0;	26105: 1;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 0;	26112: 2;	26113: 0;	26114: 0;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 0;	26121: 0;	26122: 0;	26123: 2;	26124: 2;	26125: 0;	26126: 0;	26127: 0;	
2023-12-01 10:03:36,049:INFO::Validation loss decreased (1.061640 --> 1.040583).  Saving model ...
2023-12-01 10:03:36,053:INFO::Epoch: 20
tensor([[0.5147, 0.5277, 0.5268, 0.5304],
        [0.5146, 0.5263, 0.5341, 0.5193],
        [0.5210, 0.5130, 0.5321, 0.5265],
        [0.5152, 0.5222, 0.5264, 0.5345]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:36,054:INFO::its now!!!!!!!!5
2023-12-01 10:03:36,254:INFO::its now!!!!!!!!0
2023-12-01 10:03:36,255:INFO::its now!!!!!!!!3
2023-12-01 10:03:36,369:INFO::its now!!!!!!!!5
2023-12-01 10:03:36,585:INFO::its now!!!!!!!!
2023-12-01 10:03:36,585:INFO::its now!!!!!!!! on 
2023-12-01 10:03:36,728:INFO::its now!!!!!!!!5
2023-12-01 10:03:36,946:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 1.2052 | Train_Classification_Loss 1.2367 | Dmon_Loss -0.0629 | Val_Loss 1.1995 | Search Time(s) 0.6762 | Infer Time(s) 0.2194 | Time(s) 0.8956 
2023-12-01 10:03:36,998:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 0;	4: 2;	5: 2;	6: 0;	7: 2;	8: 0;	9: 3;	10: 2;	11: 0;	12: 2;	13: 2;	14: 2;	15: 1;	16: 2;	17: 3;	18: 0;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 1;	27: 2;	28: 2;	29: 0;	30: 2;	31: 0;	32: 2;	33: 0;	34: 0;	35: 3;	36: 0;	37: 3;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 1;	26101: 1;	26102: 0;	26103: 2;	26104: 2;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 0;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 10:03:36,999:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:03:37,003:INFO::Epoch: 21
tensor([[0.5195, 0.5323, 0.5317, 0.5310],
        [0.5192, 0.5309, 0.5342, 0.5246],
        [0.5255, 0.5182, 0.5323, 0.5312],
        [0.5198, 0.5274, 0.5311, 0.5347]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:37,004:INFO::its now!!!!!!!!5
2023-12-01 10:03:37,218:INFO::its now!!!!!!!!0
2023-12-01 10:03:37,219:INFO::its now!!!!!!!!3
2023-12-01 10:03:37,352:INFO::its now!!!!!!!!5
2023-12-01 10:03:37,565:INFO::its now!!!!!!!!
2023-12-01 10:03:37,565:INFO::its now!!!!!!!! on 
2023-12-01 10:03:37,690:INFO::its now!!!!!!!!5
2023-12-01 10:03:37,910:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:37,919:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 0.9904 | Train_Classification_Loss 1.0218 | Dmon_Loss -0.0627 | Val_Loss 0.9818 | Search Time(s) 0.6872 | Infer Time(s) 0.2234 | Time(s) 0.9106 
2023-12-01 10:03:37,957:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 2;	4: 2;	5: 2;	6: 0;	7: 0;	8: 3;	9: 0;	10: 2;	11: 2;	12: 0;	13: 2;	14: 2;	15: 0;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 3;	22: 0;	23: 0;	24: 2;	25: 0;	26: 3;	27: 0;	28: 0;	29: 0;	30: 0;	31: 3;	32: 2;	33: 3;	34: 2;	35: 3;	36: 0;	37: 0;	38: 0;	39: 2;	40: 2;	41: 0;	42: 2;	43: 0;	44
26098: 1;	26099: 2;	26100: 3;	26101: 1;	26102: 2;	26103: 0;	26104: 0;	26105: 2;	26106: 2;	26107: 2;	26108: 0;	26109: 0;	26110: 0;	26111: 2;	26112: 2;	26113: 0;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 2;	26123: 0;	26124: 2;	26125: 2;	26126: 0;	26127: 2;	
2023-12-01 10:03:37,958:INFO::Validation loss decreased (1.040583 --> 0.981821).  Saving model ...
2023-12-01 10:03:37,960:INFO::Epoch: 22
tensor([[0.5305, 0.5344, 0.5428, 0.5416],
        [0.5215, 0.5417, 0.5446, 0.5359],
        [0.5363, 0.5164, 0.5427, 0.5421],
        [0.5221, 0.5386, 0.5421, 0.5451]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:37,960:INFO::its now!!!!!!!!5
2023-12-01 10:03:38,209:INFO::its now!!!!!!!!0
2023-12-01 10:03:38,210:INFO::its now!!!!!!!!3
2023-12-01 10:03:38,329:INFO::its now!!!!!!!!5
2023-12-01 10:03:38,550:INFO::its now!!!!!!!!
2023-12-01 10:03:38,550:INFO::its now!!!!!!!! on 
2023-12-01 10:03:38,674:INFO::its now!!!!!!!!5
2023-12-01 10:03:38,888:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:38,889:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 0.9311 | Train_Classification_Loss 0.9625 | Dmon_Loss -0.0627 | Val_Loss 0.9306 | Search Time(s) 0.7121 | Infer Time(s) 0.2174 | Time(s) 0.9295 
2023-12-01 10:03:38,928:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 1;	5: 1;	6: 0;	7: 2;	8: 2;	9: 3;	10: 0;	11: 2;	12: 1;	13: 2;	14: 1;	15: 0;	16: 2;	17: 2;	18: 1;	19: 1;	20: 2;	21: 1;	22: 3;	23: 1;	24: 1;	25: 1;	26: 1;	27: 2;	28: 1;	29: 1;	30: 1;	31: 1;	32: 2;	33: 2;	34: 0;	35: 0;	36: 1;	37: 0;	38: 2;	39: 0;	40: 0;	41: 0;	42: 1;	43: 2;	44
26098: 1;	26099: 2;	26100: 1;	26101: 0;	26102: 2;	26103: 1;	26104: 0;	26105: 1;	26106: 3;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 1;	26112: 2;	26113: 1;	26114: 2;	26115: 1;	26116: 2;	26117: 1;	26118: 2;	26119: 2;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 0;	26125: 2;	26126: 1;	26127: 3;	
2023-12-01 10:03:38,929:INFO::Validation loss decreased (0.981821 --> 0.930561).  Saving model ...
2023-12-01 10:03:38,932:INFO::Epoch: 23
tensor([[0.5388, 0.5399, 0.5485, 0.5500],
        [0.5271, 0.5499, 0.5499, 0.5444],
        [0.5445, 0.5204, 0.5480, 0.5503],
        [0.5278, 0.5470, 0.5503, 0.5504]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:38,933:INFO::its now!!!!!!!!5
2023-12-01 10:03:39,120:INFO::its now!!!!!!!!0
2023-12-01 10:03:39,121:INFO::its now!!!!!!!!3
2023-12-01 10:03:39,238:INFO::its now!!!!!!!!5
2023-12-01 10:03:39,460:INFO::its now!!!!!!!!
2023-12-01 10:03:39,460:INFO::its now!!!!!!!! on 
2023-12-01 10:03:39,585:INFO::its now!!!!!!!!5
2023-12-01 10:03:39,842:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:39,844:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 0.9409 | Train_Classification_Loss 0.9722 | Dmon_Loss -0.0627 | Val_Loss 0.9156 | Search Time(s) 0.6542 | Infer Time(s) 0.2583 | Time(s) 0.9126 
2023-12-01 10:03:39,884:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 2;	6: 0;	7: 0;	8: 3;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 1;	16: 2;	17: 2;	18: 2;	19: 0;	20: 1;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 2;	28: 0;	29: 0;	30: 3;	31: 0;	32: 2;	33: 3;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 3;	40: 2;	41: 0;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 2;	26105: 2;	26106: 2;	26107: 0;	26108: 2;	26109: 1;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 2;	
2023-12-01 10:03:39,885:INFO::Validation loss decreased (0.930561 --> 0.915631).  Saving model ...
2023-12-01 10:03:39,888:INFO::Epoch: 24
tensor([[0.5411, 0.5397, 0.5494, 0.5542],
        [0.5269, 0.5521, 0.5527, 0.5468],
        [0.5467, 0.5192, 0.5485, 0.5545],
        [0.5276, 0.5494, 0.5525, 0.5532]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:39,888:INFO::its now!!!!!!!!5
2023-12-01 10:03:40,130:INFO::its now!!!!!!!!0
2023-12-01 10:03:40,131:INFO::its now!!!!!!!!3
2023-12-01 10:03:40,245:INFO::its now!!!!!!!!5
2023-12-01 10:03:40,458:INFO::its now!!!!!!!!
2023-12-01 10:03:40,458:INFO::its now!!!!!!!! on 
2023-12-01 10:03:40,582:INFO::its now!!!!!!!!5
2023-12-01 10:03:40,818:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:40,819:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 0.8712 | Train_Classification_Loss 0.9026 | Dmon_Loss -0.0627 | Val_Loss 0.8560 | Search Time(s) 0.6941 | Infer Time(s) 0.2394 | Time(s) 0.9335 
2023-12-01 10:03:40,864:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 0;	16: 2;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 3;	25: 1;	26: 2;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 0;	34: 2;	35: 1;	36: 2;	37: 3;	38: 2;	39: 3;	40: 1;	41: 2;	42: 1;	43: 3;	44
26098: 2;	26099: 2;	26100: 2;	26101: 1;	26102: 3;	26103: 0;	26104: 1;	26105: 1;	26106: 0;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 1;	26114: 2;	26115: 1;	26116: 2;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 3;	26124: 1;	26125: 0;	26126: 1;	26127: 3;	
2023-12-01 10:03:40,865:INFO::Validation loss decreased (0.915631 --> 0.855960).  Saving model ...
2023-12-01 10:03:40,869:INFO::Epoch: 25
tensor([[0.5406, 0.5371, 0.5482, 0.5565],
        [0.5243, 0.5517, 0.5541, 0.5463],
        [0.5463, 0.5160, 0.5471, 0.5567],
        [0.5250, 0.5489, 0.5521, 0.5546]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:40,870:INFO::its now!!!!!!!!5
2023-12-01 10:03:41,084:INFO::its now!!!!!!!!0
2023-12-01 10:03:41,085:INFO::its now!!!!!!!!3
2023-12-01 10:03:41,198:INFO::its now!!!!!!!!5
2023-12-01 10:03:41,409:INFO::its now!!!!!!!!
2023-12-01 10:03:41,409:INFO::its now!!!!!!!! on 
2023-12-01 10:03:41,534:INFO::its now!!!!!!!!5
2023-12-01 10:03:41,732:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:41,734:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 0.8668 | Train_Classification_Loss 0.8981 | Dmon_Loss -0.0627 | Val_Loss 0.8285 | Search Time(s) 0.6632 | Infer Time(s) 0.2025 | Time(s) 0.8657 
2023-12-01 10:03:41,778:INFO::cluster info:
0: 2;	1: 2;	2: 3;	3: 0;	4: 0;	5: 0;	6: 3;	7: 2;	8: 0;	9: 2;	10: 2;	11: 0;	12: 2;	13: 3;	14: 2;	15: 2;	16: 2;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 3;	25: 2;	26: 0;	27: 2;	28: 2;	29: 0;	30: 2;	31: 0;	32: 3;	33: 2;	34: 0;	35: 0;	36: 2;	37: 3;	38: 2;	39: 0;	40: 2;	41: 3;	42: 2;	43: 0;	44
26098: 1;	26099: 3;	26100: 2;	26101: 1;	26102: 0;	26103: 2;	26104: 3;	26105: 0;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 3;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 0;	26123: 2;	26124: 2;	26125: 0;	26126: 2;	26127: 2;	
2023-12-01 10:03:41,779:INFO::Validation loss decreased (0.855960 --> 0.828485).  Saving model ...
2023-12-01 10:03:41,781:INFO::Epoch: 26
tensor([[0.5396, 0.5346, 0.5468, 0.5578],
        [0.5218, 0.5507, 0.5549, 0.5453],
        [0.5453, 0.5131, 0.5455, 0.5579],
        [0.5224, 0.5479, 0.5511, 0.5553]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:41,782:INFO::its now!!!!!!!!5
2023-12-01 10:03:41,987:INFO::its now!!!!!!!!0
2023-12-01 10:03:41,988:INFO::its now!!!!!!!!3
2023-12-01 10:03:42,105:INFO::its now!!!!!!!!5
2023-12-01 10:03:42,320:INFO::its now!!!!!!!!
2023-12-01 10:03:42,321:INFO::its now!!!!!!!! on 
2023-12-01 10:03:42,445:INFO::its now!!!!!!!!5
2023-12-01 10:03:42,665:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:42,667:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 0.7988 | Train_Classification_Loss 0.8302 | Dmon_Loss -0.0628 | Val_Loss 0.7769 | Search Time(s) 0.6627 | Infer Time(s) 0.2234 | Time(s) 0.8860 
2023-12-01 10:03:42,708:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 0;	4: 1;	5: 2;	6: 2;	7: 3;	8: 2;	9: 0;	10: 0;	11: 0;	12: 2;	13: 1;	14: 2;	15: 1;	16: 2;	17: 2;	18: 2;	19: 3;	20: 1;	21: 0;	22: 1;	23: 1;	24: 2;	25: 2;	26: 0;	27: 2;	28: 2;	29: 0;	30: 0;	31: 3;	32: 0;	33: 0;	34: 0;	35: 2;	36: 2;	37: 0;	38: 2;	39: 2;	40: 0;	41: 3;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 0;	26101: 1;	26102: 3;	26103: 2;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 3;	26109: 1;	26110: 2;	26111: 2;	26112: 3;	26113: 1;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 2;	26121: 1;	26122: 1;	26123: 1;	26124: 0;	26125: 0;	26126: 1;	26127: 1;	
2023-12-01 10:03:42,709:INFO::Validation loss decreased (0.828485 --> 0.776947).  Saving model ...
2023-12-01 10:03:42,712:INFO::Epoch: 27
tensor([[0.5357, 0.5283, 0.5426, 0.5587],
        [0.5155, 0.5468, 0.5553, 0.5413],
        [0.5414, 0.5065, 0.5409, 0.5587],
        [0.5161, 0.5439, 0.5472, 0.5557]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:42,713:INFO::its now!!!!!!!!5
2023-12-01 10:03:42,922:INFO::its now!!!!!!!!0
2023-12-01 10:03:42,923:INFO::its now!!!!!!!!3
2023-12-01 10:03:43,037:INFO::its now!!!!!!!!5
2023-12-01 10:03:43,243:INFO::its now!!!!!!!!
2023-12-01 10:03:43,243:INFO::its now!!!!!!!! on 
2023-12-01 10:03:43,367:INFO::its now!!!!!!!!5
2023-12-01 10:03:43,582:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:43,584:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 0.7669 | Train_Classification_Loss 0.7983 | Dmon_Loss -0.0628 | Val_Loss 0.7465 | Search Time(s) 0.6552 | Infer Time(s) 0.2174 | Time(s) 0.8727 
2023-12-01 10:03:43,623:INFO::cluster info:
0: 0;	1: 2;	2: 3;	3: 0;	4: 1;	5: 2;	6: 0;	7: 2;	8: 0;	9: 0;	10: 2;	11: 2;	12: 3;	13: 2;	14: 2;	15: 0;	16: 2;	17: 2;	18: 0;	19: 0;	20: 0;	21: 3;	22: 2;	23: 0;	24: 2;	25: 3;	26: 2;	27: 2;	28: 0;	29: 2;	30: 0;	31: 1;	32: 2;	33: 3;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 2;	40: 0;	41: 2;	42: 2;	43: 0;	44
26098: 2;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 3;	26104: 0;	26105: 3;	26106: 3;	26107: 3;	26108: 0;	26109: 2;	26110: 2;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 0;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 0;	26126: 2;	26127: 0;	
2023-12-01 10:03:43,624:INFO::Validation loss decreased (0.776947 --> 0.746493).  Saving model ...
2023-12-01 10:03:43,626:INFO::Epoch: 28
tensor([[0.5347, 0.5266, 0.5414, 0.5592],
        [0.5137, 0.5458, 0.5557, 0.5403],
        [0.5404, 0.5046, 0.5397, 0.5591],
        [0.5144, 0.5429, 0.5462, 0.5560]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:43,627:INFO::its now!!!!!!!!5
2023-12-01 10:03:43,825:INFO::its now!!!!!!!!0
2023-12-01 10:03:43,826:INFO::its now!!!!!!!!3
2023-12-01 10:03:43,940:INFO::its now!!!!!!!!5
2023-12-01 10:03:44,173:INFO::its now!!!!!!!!
2023-12-01 10:03:44,174:INFO::its now!!!!!!!! on 
2023-12-01 10:03:44,302:INFO::its now!!!!!!!!5
2023-12-01 10:03:44,513:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:44,514:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 0.7330 | Train_Classification_Loss 0.7644 | Dmon_Loss -0.0628 | Val_Loss 0.6997 | Search Time(s) 0.6772 | Infer Time(s) 0.2114 | Time(s) 0.8886 
2023-12-01 10:03:44,560:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 2;	7: 2;	8: 2;	9: 3;	10: 0;	11: 2;	12: 3;	13: 0;	14: 1;	15: 0;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 2;	24: 3;	25: 1;	26: 1;	27: 2;	28: 3;	29: 1;	30: 0;	31: 1;	32: 1;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 1;	40: 0;	41: 0;	42: 3;	43: 2;	44
26098: 3;	26099: 1;	26100: 0;	26101: 1;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 3;	26107: 0;	26108: 2;	26109: 0;	26110: 1;	26111: 2;	26112: 2;	26113: 1;	26114: 2;	26115: 3;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 1;	26122: 1;	26123: 2;	26124: 0;	26125: 0;	26126: 1;	26127: 2;	
2023-12-01 10:03:44,561:INFO::Validation loss decreased (0.746493 --> 0.699715).  Saving model ...
2023-12-01 10:03:44,563:INFO::Epoch: 29
tensor([[0.5361, 0.5286, 0.5429, 0.5596],
        [0.5158, 0.5473, 0.5559, 0.5417],
        [0.5419, 0.5067, 0.5412, 0.5593],
        [0.5164, 0.5444, 0.5477, 0.5561]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:44,564:INFO::its now!!!!!!!!5
2023-12-01 10:03:44,760:INFO::its now!!!!!!!!0
2023-12-01 10:03:44,761:INFO::its now!!!!!!!!3
2023-12-01 10:03:44,877:INFO::its now!!!!!!!!5
2023-12-01 10:03:45,124:INFO::its now!!!!!!!!
2023-12-01 10:03:45,124:INFO::its now!!!!!!!! on 
2023-12-01 10:03:45,251:INFO::its now!!!!!!!!5
2023-12-01 10:03:45,465:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:45,466:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 0.7210 | Train_Classification_Loss 0.7524 | Dmon_Loss -0.0628 | Val_Loss 0.6695 | Search Time(s) 0.6852 | Infer Time(s) 0.2184 | Time(s) 0.9036 
2023-12-01 10:03:45,503:INFO::cluster info:
0: 2;	1: 2;	2: 1;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 1;	9: 1;	10: 3;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 1;	20: 2;	21: 1;	22: 0;	23: 2;	24: 2;	25: 2;	26: 1;	27: 2;	28: 2;	29: 3;	30: 2;	31: 3;	32: 2;	33: 0;	34: 2;	35: 1;	36: 2;	37: 1;	38: 1;	39: 2;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 0;	26099: 2;	26100: 2;	26101: 3;	26102: 3;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 2;	26111: 3;	26112: 0;	26113: 2;	26114: 2;	26115: 1;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:45,504:INFO::Validation loss decreased (0.699715 --> 0.669505).  Saving model ...
2023-12-01 10:03:45,506:INFO::Epoch: 30
tensor([[0.5405, 0.5346, 0.5473, 0.5598],
        [0.5218, 0.5515, 0.5561, 0.5462],
        [0.5461, 0.5129, 0.5458, 0.5596],
        [0.5224, 0.5487, 0.5519, 0.5562]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:45,507:INFO::its now!!!!!!!!5
2023-12-01 10:03:45,709:INFO::its now!!!!!!!!0
2023-12-01 10:03:45,710:INFO::its now!!!!!!!!3
2023-12-01 10:03:45,824:INFO::its now!!!!!!!!5
2023-12-01 10:03:46,051:INFO::its now!!!!!!!!
2023-12-01 10:03:46,051:INFO::its now!!!!!!!! on 
2023-12-01 10:03:46,175:INFO::its now!!!!!!!!5
2023-12-01 10:03:46,388:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:46,390:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 0.6749 | Train_Classification_Loss 0.7063 | Dmon_Loss -0.0629 | Val_Loss 0.6293 | Search Time(s) 0.6672 | Infer Time(s) 0.2164 | Time(s) 0.8836 
2023-12-01 10:03:46,432:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 2;	6: 1;	7: 1;	8: 2;	9: 2;	10: 1;	11: 2;	12: 2;	13: 3;	14: 1;	15: 0;	16: 2;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 2;	33: 1;	34: 2;	35: 0;	36: 2;	37: 2;	38: 0;	39: 1;	40: 2;	41: 3;	42: 2;	43: 0;	44
26098: 1;	26099: 2;	26100: 1;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 1;	26106: 3;	26107: 3;	26108: 2;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 1;	26114: 2;	26115: 2;	26116: 2;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 1;	26127: 3;	
2023-12-01 10:03:46,433:INFO::Validation loss decreased (0.669505 --> 0.629258).  Saving model ...
2023-12-01 10:03:46,435:INFO::Epoch: 31
tensor([[0.5449, 0.5406, 0.5518, 0.5600],
        [0.5279, 0.5559, 0.5562, 0.5507],
        [0.5505, 0.5191, 0.5506, 0.5600],
        [0.5285, 0.5532, 0.5563, 0.5562]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:46,435:INFO::its now!!!!!!!!5
2023-12-01 10:03:46,628:INFO::its now!!!!!!!!0
2023-12-01 10:03:46,629:INFO::its now!!!!!!!!3
2023-12-01 10:03:46,743:INFO::its now!!!!!!!!5
2023-12-01 10:03:46,942:INFO::its now!!!!!!!!
2023-12-01 10:03:46,942:INFO::its now!!!!!!!! on 
2023-12-01 10:03:47,084:INFO::its now!!!!!!!!5
2023-12-01 10:03:47,301:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 0.7778 | Train_Classification_Loss 0.8093 | Dmon_Loss -0.0629 | Val_Loss 0.6932 | Search Time(s) 0.6473 | Infer Time(s) 0.2214 | Time(s) 0.8687 
2023-12-01 10:03:47,344:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 2;	4: 1;	5: 2;	6: 0;	7: 0;	8: 2;	9: 2;	10: 0;	11: 0;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 3;	22: 3;	23: 2;	24: 2;	25: 2;	26: 0;	27: 2;	28: 0;	29: 0;	30: 0;	31: 0;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 1;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 1;	26099: 0;	26100: 1;	26101: 1;	26102: 1;	26103: 3;	26104: 0;	26105: 2;	26106: 3;	26107: 2;	26108: 0;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:03:47,345:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:03:47,348:INFO::Epoch: 32
tensor([[0.5491, 0.5464, 0.5561, 0.5600],
        [0.5337, 0.5600, 0.5563, 0.5549],
        [0.5546, 0.5250, 0.5552, 0.5604],
        [0.5343, 0.5575, 0.5586, 0.5587]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:47,348:INFO::its now!!!!!!!!5
2023-12-01 10:03:47,547:INFO::its now!!!!!!!!0
2023-12-01 10:03:47,548:INFO::its now!!!!!!!!3
2023-12-01 10:03:47,679:INFO::its now!!!!!!!!5
2023-12-01 10:03:47,892:INFO::its now!!!!!!!!
2023-12-01 10:03:47,892:INFO::its now!!!!!!!! on 
2023-12-01 10:03:48,034:INFO::its now!!!!!!!!5
2023-12-01 10:03:48,230:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:48,231:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 0.6035 | Train_Classification_Loss 0.6349 | Dmon_Loss -0.0630 | Val_Loss 0.5601 | Search Time(s) 0.6842 | Infer Time(s) 0.1995 | Time(s) 0.8837 
2023-12-01 10:03:48,275:INFO::cluster info:
0: 1;	1: 1;	2: 0;	3: 1;	4: 2;	5: 0;	6: 3;	7: 2;	8: 1;	9: 0;	10: 2;	11: 1;	12: 3;	13: 3;	14: 1;	15: 3;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 0;	22: 1;	23: 2;	24: 2;	25: 2;	26: 3;	27: 2;	28: 2;	29: 3;	30: 1;	31: 1;	32: 2;	33: 0;	34: 0;	35: 3;	36: 2;	37: 1;	38: 2;	39: 0;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 2;	26099: 0;	26100: 1;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 3;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 1;	26114: 2;	26115: 2;	26116: 2;	26117: 1;	26118: 1;	26119: 2;	26120: 3;	26121: 2;	26122: 1;	26123: 3;	26124: 0;	26125: 2;	26126: 1;	26127: 2;	
2023-12-01 10:03:48,276:INFO::Validation loss decreased (0.629258 --> 0.560058).  Saving model ...
2023-12-01 10:03:48,279:INFO::Epoch: 33
tensor([[0.5504, 0.5482, 0.5575, 0.5602],
        [0.5355, 0.5621, 0.5553, 0.5563],
        [0.5559, 0.5269, 0.5566, 0.5608],
        [0.5362, 0.5588, 0.5589, 0.5600]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:48,280:INFO::its now!!!!!!!!5
2023-12-01 10:03:48,502:INFO::its now!!!!!!!!0
2023-12-01 10:03:48,503:INFO::its now!!!!!!!!3
2023-12-01 10:03:48,636:INFO::its now!!!!!!!!5
2023-12-01 10:03:48,837:INFO::its now!!!!!!!!
2023-12-01 10:03:48,838:INFO::its now!!!!!!!! on 
2023-12-01 10:03:48,982:INFO::its now!!!!!!!!5
2023-12-01 10:03:49,202:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:49,203:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 0.5789 | Train_Classification_Loss 0.6105 | Dmon_Loss -0.0632 | Val_Loss 0.5335 | Search Time(s) 0.7021 | Infer Time(s) 0.2224 | Time(s) 0.9245 
2023-12-01 10:03:49,240:INFO::cluster info:
0: 1;	1: 2;	2: 0;	3: 1;	4: 1;	5: 0;	6: 0;	7: 0;	8: 2;	9: 3;	10: 3;	11: 0;	12: 2;	13: 3;	14: 2;	15: 2;	16: 2;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 2;	23: 2;	24: 2;	25: 1;	26: 2;	27: 1;	28: 0;	29: 2;	30: 2;	31: 1;	32: 0;	33: 0;	34: 3;	35: 0;	36: 3;	37: 1;	38: 0;	39: 2;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 0;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 1;	26114: 2;	26115: 2;	26116: 2;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:49,241:INFO::Validation loss decreased (0.560058 --> 0.533544).  Saving model ...
2023-12-01 10:03:49,243:INFO::Epoch: 34
tensor([[0.5603, 0.5598, 0.5676, 0.5604],
        [0.5471, 0.5614, 0.5656, 0.5663],
        [0.5658, 0.5386, 0.5670, 0.5609],
        [0.5478, 0.5688, 0.5685, 0.5608]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:49,244:INFO::its now!!!!!!!!5
2023-12-01 10:03:49,456:INFO::its now!!!!!!!!0
2023-12-01 10:03:49,457:INFO::its now!!!!!!!!3
2023-12-01 10:03:49,588:INFO::its now!!!!!!!!5
2023-12-01 10:03:49,783:INFO::its now!!!!!!!!
2023-12-01 10:03:49,784:INFO::its now!!!!!!!! on 
2023-12-01 10:03:49,925:INFO::its now!!!!!!!!5
2023-12-01 10:03:50,129:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:50,131:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 0.5778 | Train_Classification_Loss 0.6094 | Dmon_Loss -0.0632 | Val_Loss 0.4975 | Search Time(s) 0.6802 | Infer Time(s) 0.2074 | Time(s) 0.8876 
2023-12-01 10:03:50,186:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 1;	4: 3;	5: 1;	6: 0;	7: 2;	8: 3;	9: 2;	10: 3;	11: 0;	12: 3;	13: 2;	14: 2;	15: 0;	16: 1;	17: 0;	18: 2;	19: 3;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 1;	27: 2;	28: 3;	29: 1;	30: 2;	31: 0;	32: 0;	33: 3;	34: 0;	35: 0;	36: 3;	37: 2;	38: 2;	39: 0;	40: 3;	41: 3;	42: 2;	43: 1;	44
26098: 1;	26099: 2;	26100: 2;	26101: 2;	26102: 0;	26103: 1;	26104: 2;	26105: 1;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:50,187:INFO::Validation loss decreased (0.533544 --> 0.497512).  Saving model ...
2023-12-01 10:03:50,190:INFO::Epoch: 35
tensor([[0.5620, 0.5617, 0.5727, 0.5553],
        [0.5491, 0.5570, 0.5671, 0.5715],
        [0.5674, 0.5406, 0.5722, 0.5563],
        [0.5497, 0.5739, 0.5699, 0.5560]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:50,190:INFO::its now!!!!!!!!5
2023-12-01 10:03:50,411:INFO::its now!!!!!!!!0
2023-12-01 10:03:50,412:INFO::its now!!!!!!!!3
2023-12-01 10:03:50,528:INFO::its now!!!!!!!!5
2023-12-01 10:03:50,787:INFO::its now!!!!!!!!
2023-12-01 10:03:50,787:INFO::its now!!!!!!!! on 
2023-12-01 10:03:50,933:INFO::its now!!!!!!!!5
2023-12-01 10:03:51,148:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:51,150:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 0.5265 | Train_Classification_Loss 0.5581 | Dmon_Loss -0.0632 | Val_Loss 0.4832 | Search Time(s) 0.7420 | Infer Time(s) 0.2194 | Time(s) 0.9614 
2023-12-01 10:03:51,189:INFO::cluster info:
0: 0;	1: 1;	2: 1;	3: 2;	4: 2;	5: 3;	6: 1;	7: 3;	8: 2;	9: 3;	10: 0;	11: 3;	12: 2;	13: 2;	14: 3;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 0;	21: 3;	22: 1;	23: 2;	24: 2;	25: 3;	26: 3;	27: 2;	28: 2;	29: 3;	30: 2;	31: 1;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 0;	42: 2;	43: 3;	44
26098: 2;	26099: 2;	26100: 1;	26101: 3;	26102: 0;	26103: 2;	26104: 2;	26105: 3;	26106: 3;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:51,190:INFO::Validation loss decreased (0.497512 --> 0.483163).  Saving model ...
2023-12-01 10:03:51,192:INFO::Epoch: 36
tensor([[0.5634, 0.5633, 0.5758, 0.5528],
        [0.5507, 0.5554, 0.5678, 0.5746],
        [0.5688, 0.5422, 0.5748, 0.5547],
        [0.5513, 0.5770, 0.5707, 0.5544]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:51,193:INFO::its now!!!!!!!!5
2023-12-01 10:03:51,397:INFO::its now!!!!!!!!0
2023-12-01 10:03:51,398:INFO::its now!!!!!!!!3
2023-12-01 10:03:51,531:INFO::its now!!!!!!!!5
2023-12-01 10:03:51,767:INFO::its now!!!!!!!!
2023-12-01 10:03:51,767:INFO::its now!!!!!!!! on 
2023-12-01 10:03:51,910:INFO::its now!!!!!!!!5
2023-12-01 10:03:52,106:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:52,108:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 0.5439 | Train_Classification_Loss 0.5755 | Dmon_Loss -0.0632 | Val_Loss 0.4605 | Search Time(s) 0.7161 | Infer Time(s) 0.1994 | Time(s) 0.9156 
2023-12-01 10:03:52,159:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 1;	5: 3;	6: 2;	7: 3;	8: 3;	9: 2;	10: 2;	11: 2;	12: 3;	13: 2;	14: 3;	15: 2;	16: 2;	17: 2;	18: 2;	19: 0;	20: 3;	21: 2;	22: 2;	23: 3;	24: 2;	25: 2;	26: 0;	27: 2;	28: 3;	29: 0;	30: 1;	31: 1;	32: 0;	33: 0;	34: 0;	35: 0;	36: 2;	37: 2;	38: 2;	39: 1;	40: 0;	41: 0;	42: 2;	43: 0;	44
26098: 3;	26099: 2;	26100: 3;	26101: 3;	26102: 0;	26103: 1;	26104: 2;	26105: 2;	26106: 3;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:52,160:INFO::Validation loss decreased (0.483163 --> 0.460525).  Saving model ...
2023-12-01 10:03:52,163:INFO::Epoch: 37
tensor([[0.5645, 0.5646, 0.5774, 0.5522],
        [0.5520, 0.5552, 0.5687, 0.5762],
        [0.5699, 0.5436, 0.5763, 0.5546],
        [0.5527, 0.5786, 0.5716, 0.5544]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:52,163:INFO::its now!!!!!!!!5
2023-12-01 10:03:52,381:INFO::its now!!!!!!!!0
2023-12-01 10:03:52,382:INFO::its now!!!!!!!!3
2023-12-01 10:03:52,515:INFO::its now!!!!!!!!5
2023-12-01 10:03:52,723:INFO::its now!!!!!!!!
2023-12-01 10:03:52,723:INFO::its now!!!!!!!! on 
2023-12-01 10:03:52,866:INFO::its now!!!!!!!!5
2023-12-01 10:03:53,094:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:53,096:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 0.5046 | Train_Classification_Loss 0.5362 | Dmon_Loss -0.0633 | Val_Loss 0.4309 | Search Time(s) 0.7012 | Infer Time(s) 0.2313 | Time(s) 0.9325 
2023-12-01 10:03:53,133:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 1;	7: 2;	8: 2;	9: 2;	10: 0;	11: 3;	12: 1;	13: 3;	14: 2;	15: 2;	16: 2;	17: 0;	18: 1;	19: 0;	20: 2;	21: 2;	22: 2;	23: 1;	24: 1;	25: 3;	26: 1;	27: 3;	28: 2;	29: 2;	30: 3;	31: 1;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 3;	41: 2;	42: 2;	43: 0;	44
26098: 1;	26099: 0;	26100: 2;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 10:03:53,134:INFO::Validation loss decreased (0.460525 --> 0.430885).  Saving model ...
2023-12-01 10:03:53,136:INFO::Epoch: 38
tensor([[0.5656, 0.5658, 0.5782, 0.5526],
        [0.5532, 0.5556, 0.5696, 0.5770],
        [0.5710, 0.5448, 0.5772, 0.5552],
        [0.5539, 0.5793, 0.5724, 0.5551]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:53,137:INFO::its now!!!!!!!!5
2023-12-01 10:03:53,360:INFO::its now!!!!!!!!0
2023-12-01 10:03:53,361:INFO::its now!!!!!!!!3
2023-12-01 10:03:53,497:INFO::its now!!!!!!!!5
2023-12-01 10:03:53,735:INFO::its now!!!!!!!!
2023-12-01 10:03:53,735:INFO::its now!!!!!!!! on 
2023-12-01 10:03:53,881:INFO::its now!!!!!!!!5
2023-12-01 10:03:54,102:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:54,104:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 0.5094 | Train_Classification_Loss 0.5411 | Dmon_Loss -0.0635 | Val_Loss 0.4104 | Search Time(s) 0.7440 | Infer Time(s) 0.2244 | Time(s) 0.9684 
2023-12-01 10:03:54,143:INFO::cluster info:
0: 3;	1: 0;	2: 0;	3: 2;	4: 3;	5: 0;	6: 0;	7: 2;	8: 1;	9: 3;	10: 1;	11: 0;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 1;	19: 2;	20: 3;	21: 0;	22: 2;	23: 2;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 2;	30: 2;	31: 1;	32: 3;	33: 0;	34: 0;	35: 2;	36: 2;	37: 3;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 1;	26104: 0;	26105: 3;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:54,144:INFO::Validation loss decreased (0.430885 --> 0.410405).  Saving model ...
2023-12-01 10:03:54,146:INFO::Epoch: 39
tensor([[0.5692, 0.5700, 0.5786, 0.5576],
        [0.5574, 0.5598, 0.5736, 0.5774],
        [0.5746, 0.5490, 0.5776, 0.5599],
        [0.5581, 0.5797, 0.5760, 0.5602]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:54,147:INFO::its now!!!!!!!!5
2023-12-01 10:03:54,344:INFO::its now!!!!!!!!0
2023-12-01 10:03:54,345:INFO::its now!!!!!!!!3
2023-12-01 10:03:54,478:INFO::its now!!!!!!!!5
2023-12-01 10:03:54,693:INFO::its now!!!!!!!!
2023-12-01 10:03:54,693:INFO::its now!!!!!!!! on 
2023-12-01 10:03:54,836:INFO::its now!!!!!!!!5
2023-12-01 10:03:55,039:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:55,040:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 0.4561 | Train_Classification_Loss 0.4880 | Dmon_Loss -0.0638 | Val_Loss 0.3932 | Search Time(s) 0.6892 | Infer Time(s) 0.2055 | Time(s) 0.8946 
2023-12-01 10:03:55,084:INFO::cluster info:
0: 3;	1: 1;	2: 2;	3: 2;	4: 2;	5: 1;	6: 0;	7: 2;	8: 1;	9: 3;	10: 2;	11: 3;	12: 2;	13: 1;	14: 2;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 3;	22: 2;	23: 1;	24: 3;	25: 2;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 2;	33: 0;	34: 2;	35: 2;	36: 2;	37: 3;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 0;	26101: 1;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 3;	26107: 3;	26108: 0;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:55,085:INFO::Validation loss decreased (0.410405 --> 0.393190).  Saving model ...
2023-12-01 10:03:55,087:INFO::Epoch: 40
tensor([[0.5719, 0.5731, 0.5788, 0.5614],
        [0.5605, 0.5629, 0.5766, 0.5776],
        [0.5772, 0.5521, 0.5779, 0.5635],
        [0.5612, 0.5799, 0.5787, 0.5640]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:55,088:INFO::its now!!!!!!!!5
2023-12-01 10:03:55,276:INFO::its now!!!!!!!!0
2023-12-01 10:03:55,277:INFO::its now!!!!!!!!3
2023-12-01 10:03:55,413:INFO::its now!!!!!!!!5
2023-12-01 10:03:55,616:INFO::its now!!!!!!!!
2023-12-01 10:03:55,616:INFO::its now!!!!!!!! on 
2023-12-01 10:03:55,740:INFO::its now!!!!!!!!5
2023-12-01 10:03:55,956:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 0.5989 | Train_Classification_Loss 0.6307 | Dmon_Loss -0.0636 | Val_Loss 0.4388 | Search Time(s) 0.6463 | Infer Time(s) 0.2244 | Time(s) 0.8707 
2023-12-01 10:03:56,021:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 3;	5: 1;	6: 0;	7: 1;	8: 1;	9: 3;	10: 0;	11: 2;	12: 1;	13: 3;	14: 1;	15: 3;	16: 3;	17: 2;	18: 1;	19: 1;	20: 1;	21: 0;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 1;	29: 2;	30: 1;	31: 2;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 3;	38: 1;	39: 3;	40: 3;	41: 1;	42: 1;	43: 1;	44
26098: 2;	26099: 0;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 2;	26105: 3;	26106: 3;	26107: 2;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 2;	26113: 2;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 2;	26122: 2;	26123: 0;	26124: 2;	26125: 1;	26126: 1;	26127: 0;	
2023-12-01 10:03:56,022:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:03:56,024:INFO::Epoch: 41
tensor([[0.5746, 0.5762, 0.5789, 0.5653],
        [0.5636, 0.5662, 0.5796, 0.5778],
        [0.5799, 0.5553, 0.5781, 0.5672],
        [0.5643, 0.5800, 0.5814, 0.5681]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:56,025:INFO::its now!!!!!!!!5
2023-12-01 10:03:56,276:INFO::its now!!!!!!!!0
2023-12-01 10:03:56,277:INFO::its now!!!!!!!!3
2023-12-01 10:03:56,399:INFO::its now!!!!!!!!5
2023-12-01 10:03:56,635:INFO::its now!!!!!!!!
2023-12-01 10:03:56,635:INFO::its now!!!!!!!! on 
2023-12-01 10:03:56,760:INFO::its now!!!!!!!!5
2023-12-01 10:03:56,974:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:56,976:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 0.4480 | Train_Classification_Loss 0.4802 | Dmon_Loss -0.0644 | Val_Loss 0.3601 | Search Time(s) 0.7301 | Infer Time(s) 0.2214 | Time(s) 0.9515 
2023-12-01 10:03:57,024:INFO::cluster info:
0: 1;	1: 3;	2: 2;	3: 2;	4: 1;	5: 1;	6: 2;	7: 3;	8: 0;	9: 3;	10: 0;	11: 0;	12: 2;	13: 3;	14: 2;	15: 2;	16: 2;	17: 0;	18: 2;	19: 1;	20: 2;	21: 0;	22: 3;	23: 1;	24: 1;	25: 3;	26: 1;	27: 2;	28: 2;	29: 2;	30: 2;	31: 1;	32: 3;	33: 0;	34: 2;	35: 0;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 3;	26099: 3;	26100: 1;	26101: 2;	26102: 1;	26103: 1;	26104: 2;	26105: 1;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:03:57,025:INFO::Validation loss decreased (0.393190 --> 0.360055).  Saving model ...
2023-12-01 10:03:57,027:INFO::Epoch: 42
tensor([[0.5741, 0.5756, 0.5790, 0.5645],
        [0.5631, 0.5655, 0.5812, 0.5759],
        [0.5811, 0.5547, 0.5762, 0.5664],
        [0.5637, 0.5781, 0.5827, 0.5672]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:57,028:INFO::its now!!!!!!!!5
2023-12-01 10:03:57,229:INFO::its now!!!!!!!!0
2023-12-01 10:03:57,231:INFO::its now!!!!!!!!3
2023-12-01 10:03:57,348:INFO::its now!!!!!!!!5
2023-12-01 10:03:57,579:INFO::its now!!!!!!!!
2023-12-01 10:03:57,580:INFO::its now!!!!!!!! on 
2023-12-01 10:03:57,704:INFO::its now!!!!!!!!5
2023-12-01 10:03:57,920:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 0.4856 | Train_Classification_Loss 0.5178 | Dmon_Loss -0.0644 | Val_Loss 0.3863 | Search Time(s) 0.6712 | Infer Time(s) 0.2234 | Time(s) 0.8946 
2023-12-01 10:03:57,963:INFO::cluster info:
0: 0;	1: 2;	2: 3;	3: 2;	4: 2;	5: 2;	6: 0;	7: 2;	8: 3;	9: 2;	10: 2;	11: 1;	12: 3;	13: 2;	14: 2;	15: 2;	16: 1;	17: 0;	18: 2;	19: 1;	20: 0;	21: 2;	22: 2;	23: 3;	24: 3;	25: 1;	26: 0;	27: 2;	28: 3;	29: 2;	30: 2;	31: 0;	32: 1;	33: 2;	34: 0;	35: 1;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 3;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 1;	26105: 2;	26106: 3;	26107: 1;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 3;	26123: 1;	26124: 2;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 10:03:57,964:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:03:57,967:INFO::Epoch: 43
tensor([[0.5743, 0.5759, 0.5791, 0.5648],
        [0.5633, 0.5658, 0.5822, 0.5754],
        [0.5806, 0.5549, 0.5757, 0.5667],
        [0.5639, 0.5776, 0.5834, 0.5675]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:57,967:INFO::its now!!!!!!!!5
2023-12-01 10:03:58,161:INFO::its now!!!!!!!!0
2023-12-01 10:03:58,162:INFO::its now!!!!!!!!3
2023-12-01 10:03:58,278:INFO::its now!!!!!!!!5
2023-12-01 10:03:58,503:INFO::its now!!!!!!!!
2023-12-01 10:03:58,503:INFO::its now!!!!!!!! on 
2023-12-01 10:03:58,627:INFO::its now!!!!!!!!5
2023-12-01 10:03:58,822:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:58,824:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 0.4211 | Train_Classification_Loss 0.4535 | Dmon_Loss -0.0648 | Val_Loss 0.3544 | Search Time(s) 0.6552 | Infer Time(s) 0.2025 | Time(s) 0.8577 
2023-12-01 10:03:58,874:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 3;	9: 3;	10: 1;	11: 0;	12: 2;	13: 2;	14: 2;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 2;	23: 3;	24: 2;	25: 2;	26: 1;	27: 2;	28: 2;	29: 2;	30: 2;	31: 1;	32: 3;	33: 1;	34: 2;	35: 2;	36: 2;	37: 3;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 2;	26099: 2;	26100: 3;	26101: 1;	26102: 2;	26103: 3;	26104: 2;	26105: 2;	26106: 3;	26107: 3;	26108: 1;	26109: 2;	26110: 2;	26111: 0;	26112: 2;	26113: 2;	26114: 2;	26115: 3;	26116: 2;	26117: 1;	26118: 3;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 3;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:03:58,875:INFO::Validation loss decreased (0.360055 --> 0.354409).  Saving model ...
2023-12-01 10:03:58,878:INFO::Epoch: 44
tensor([[0.5731, 0.5745, 0.5791, 0.5630],
        [0.5620, 0.5643, 0.5827, 0.5738],
        [0.5799, 0.5536, 0.5741, 0.5650],
        [0.5626, 0.5760, 0.5838, 0.5657]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:58,878:INFO::its now!!!!!!!!5
2023-12-01 10:03:59,107:INFO::its now!!!!!!!!0
2023-12-01 10:03:59,108:INFO::its now!!!!!!!!3
2023-12-01 10:03:59,223:INFO::its now!!!!!!!!5
2023-12-01 10:03:59,446:INFO::its now!!!!!!!!
2023-12-01 10:03:59,446:INFO::its now!!!!!!!! on 
2023-12-01 10:03:59,571:INFO::its now!!!!!!!!5
2023-12-01 10:03:59,786:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:03:59,788:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 0.4533 | Train_Classification_Loss 0.4859 | Dmon_Loss -0.0650 | Val_Loss 0.3445 | Search Time(s) 0.6872 | Infer Time(s) 0.2244 | Time(s) 0.9116 
2023-12-01 10:03:59,833:INFO::cluster info:
0: 1;	1: 2;	2: 0;	3: 2;	4: 2;	5: 2;	6: 0;	7: 2;	8: 1;	9: 2;	10: 2;	11: 2;	12: 3;	13: 3;	14: 2;	15: 0;	16: 2;	17: 2;	18: 1;	19: 2;	20: 2;	21: 0;	22: 1;	23: 3;	24: 1;	25: 3;	26: 2;	27: 3;	28: 3;	29: 1;	30: 2;	31: 2;	32: 2;	33: 1;	34: 2;	35: 0;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 3;	43: 1;	44
26098: 1;	26099: 2;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 3;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:03:59,834:INFO::Validation loss decreased (0.354409 --> 0.344544).  Saving model ...
2023-12-01 10:03:59,837:INFO::Epoch: 45
tensor([[0.5739, 0.5754, 0.5791, 0.5641],
        [0.5628, 0.5652, 0.5828, 0.5744],
        [0.5791, 0.5544, 0.5747, 0.5660],
        [0.5635, 0.5766, 0.5839, 0.5669]], device='cuda:0', requires_grad=True)
2023-12-01 10:03:59,838:INFO::its now!!!!!!!!5
2023-12-01 10:04:00,042:INFO::its now!!!!!!!!0
2023-12-01 10:04:00,043:INFO::its now!!!!!!!!3
2023-12-01 10:04:00,159:INFO::its now!!!!!!!!5
2023-12-01 10:04:00,368:INFO::its now!!!!!!!!
2023-12-01 10:04:00,368:INFO::its now!!!!!!!! on 
2023-12-01 10:04:00,493:INFO::its now!!!!!!!!5
2023-12-01 10:04:00,710:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:00,712:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 0.4639 | Train_Classification_Loss 0.4967 | Dmon_Loss -0.0655 | Val_Loss 0.3434 | Search Time(s) 0.6513 | Infer Time(s) 0.2244 | Time(s) 0.8757 
2023-12-01 10:04:00,750:INFO::cluster info:
0: 1;	1: 2;	2: 3;	3: 2;	4: 1;	5: 1;	6: 0;	7: 3;	8: 3;	9: 3;	10: 2;	11: 3;	12: 2;	13: 2;	14: 2;	15: 0;	16: 2;	17: 2;	18: 3;	19: 2;	20: 2;	21: 0;	22: 2;	23: 2;	24: 2;	25: 3;	26: 1;	27: 3;	28: 2;	29: 2;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 3;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 3;	26100: 3;	26101: 2;	26102: 2;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 3;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 3;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:00,751:INFO::Validation loss decreased (0.344544 --> 0.343358).  Saving model ...
2023-12-01 10:04:00,754:INFO::Epoch: 46
tensor([[0.5768, 0.5787, 0.5791, 0.5684],
        [0.5662, 0.5688, 0.5829, 0.5774],
        [0.5782, 0.5578, 0.5779, 0.5701],
        [0.5668, 0.5796, 0.5840, 0.5712]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:00,754:INFO::its now!!!!!!!!5
2023-12-01 10:04:00,964:INFO::its now!!!!!!!!0
2023-12-01 10:04:00,965:INFO::its now!!!!!!!!3
2023-12-01 10:04:01,082:INFO::its now!!!!!!!!5
2023-12-01 10:04:01,286:INFO::its now!!!!!!!!
2023-12-01 10:04:01,286:INFO::its now!!!!!!!! on 
2023-12-01 10:04:01,428:INFO::its now!!!!!!!!5
2023-12-01 10:04:01,701:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:01,703:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 0.3606 | Train_Classification_Loss 0.3942 | Dmon_Loss -0.0673 | Val_Loss 0.2982 | Search Time(s) 0.6603 | Infer Time(s) 0.2902 | Time(s) 0.9505 
2023-12-01 10:04:01,750:INFO::cluster info:
0: 1;	1: 0;	2: 2;	3: 1;	4: 3;	5: 0;	6: 0;	7: 1;	8: 1;	9: 3;	10: 2;	11: 0;	12: 2;	13: 2;	14: 1;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 3;	21: 0;	22: 1;	23: 1;	24: 1;	25: 2;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 3;	33: 2;	34: 2;	35: 0;	36: 1;	37: 1;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 0;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:01,751:INFO::Validation loss decreased (0.343358 --> 0.298243).  Saving model ...
2023-12-01 10:04:01,753:INFO::Epoch: 47
tensor([[0.5777, 0.5798, 0.5792, 0.5698],
        [0.5672, 0.5700, 0.5829, 0.5784],
        [0.5771, 0.5589, 0.5788, 0.5713],
        [0.5679, 0.5806, 0.5840, 0.5725]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:01,754:INFO::its now!!!!!!!!5
2023-12-01 10:04:01,956:INFO::its now!!!!!!!!0
2023-12-01 10:04:01,957:INFO::its now!!!!!!!!3
2023-12-01 10:04:02,088:INFO::its now!!!!!!!!5
2023-12-01 10:04:02,321:INFO::its now!!!!!!!!
2023-12-01 10:04:02,321:INFO::its now!!!!!!!! on 
2023-12-01 10:04:02,463:INFO::its now!!!!!!!!5
2023-12-01 10:04:02,673:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:02,675:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 0.3533 | Train_Classification_Loss 0.3875 | Dmon_Loss -0.0684 | Val_Loss 0.2892 | Search Time(s) 0.6912 | Infer Time(s) 0.2314 | Time(s) 0.9226 
2023-12-01 10:04:02,717:INFO::cluster info:
0: 3;	1: 0;	2: 3;	3: 1;	4: 3;	5: 3;	6: 1;	7: 1;	8: 1;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 3;	15: 2;	16: 2;	17: 0;	18: 1;	19: 1;	20: 2;	21: 3;	22: 3;	23: 1;	24: 1;	25: 3;	26: 1;	27: 3;	28: 2;	29: 3;	30: 1;	31: 1;	32: 1;	33: 2;	34: 0;	35: 0;	36: 2;	37: 1;	38: 2;	39: 3;	40: 2;	41: 0;	42: 3;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 2;	26103: 1;	26104: 0;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:02,718:INFO::Validation loss decreased (0.298243 --> 0.289154).  Saving model ...
2023-12-01 10:04:02,721:INFO::Epoch: 48
tensor([[0.5720, 0.5804, 0.5725, 0.5619],
        [0.5608, 0.5631, 0.5828, 0.5723],
        [0.5703, 0.5524, 0.5794, 0.5639],
        [0.5614, 0.5745, 0.5840, 0.5646]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:02,721:INFO::its now!!!!!!!!5
2023-12-01 10:04:02,915:INFO::its now!!!!!!!!0
2023-12-01 10:04:02,916:INFO::its now!!!!!!!!3
2023-12-01 10:04:03,046:INFO::its now!!!!!!!!5
2023-12-01 10:04:03,248:INFO::its now!!!!!!!!
2023-12-01 10:04:03,248:INFO::its now!!!!!!!! on 
2023-12-01 10:04:03,391:INFO::its now!!!!!!!!5
2023-12-01 10:04:03,601:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:03,602:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 0.3467 | Train_Classification_Loss 0.3815 | Dmon_Loss -0.0697 | Val_Loss 0.2792 | Search Time(s) 0.6533 | Infer Time(s) 0.2284 | Time(s) 0.8816 
2023-12-01 10:04:03,648:INFO::cluster info:
0: 3;	1: 1;	2: 0;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 0;	12: 2;	13: 2;	14: 1;	15: 2;	16: 2;	17: 2;	18: 1;	19: 1;	20: 2;	21: 0;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 0;	36: 2;	37: 1;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 2;	26102: 1;	26103: 1;	26104: 2;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:04:03,649:INFO::Validation loss decreased (0.289154 --> 0.279226).  Saving model ...
2023-12-01 10:04:03,651:INFO::Epoch: 49
tensor([[0.5630, 0.5806, 0.5627, 0.5503],
        [0.5509, 0.5527, 0.5828, 0.5629],
        [0.5608, 0.5425, 0.5797, 0.5527],
        [0.5515, 0.5652, 0.5839, 0.5530]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:03,651:INFO::its now!!!!!!!!5
2023-12-01 10:04:03,888:INFO::its now!!!!!!!!0
2023-12-01 10:04:03,891:INFO::its now!!!!!!!!3
2023-12-01 10:04:04,022:INFO::its now!!!!!!!!5
2023-12-01 10:04:04,228:INFO::its now!!!!!!!!
2023-12-01 10:04:04,228:INFO::its now!!!!!!!! on 
2023-12-01 10:04:04,371:INFO::its now!!!!!!!!5
2023-12-01 10:04:04,579:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:04,581:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 0.3516 | Train_Classification_Loss 0.3870 | Dmon_Loss -0.0708 | Val_Loss 0.2755 | Search Time(s) 0.7022 | Infer Time(s) 0.2283 | Time(s) 0.9305 
2023-12-01 10:04:04,642:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 3;	33: 0;	34: 0;	35: 2;	36: 1;	37: 3;	38: 0;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 3;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:04,643:INFO::Validation loss decreased (0.279226 --> 0.275506).  Saving model ...
2023-12-01 10:04:04,647:INFO::Epoch: 50
tensor([[0.5587, 0.5807, 0.5579, 0.5446],
        [0.5461, 0.5476, 0.5828, 0.5583],
        [0.5562, 0.5376, 0.5800, 0.5473],
        [0.5467, 0.5606, 0.5839, 0.5473]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:04,648:INFO::its now!!!!!!!!5
2023-12-01 10:04:04,857:INFO::its now!!!!!!!!0
2023-12-01 10:04:04,858:INFO::its now!!!!!!!!3
2023-12-01 10:04:04,989:INFO::its now!!!!!!!!5
2023-12-01 10:04:05,216:INFO::its now!!!!!!!!
2023-12-01 10:04:05,216:INFO::its now!!!!!!!! on 
2023-12-01 10:04:05,357:INFO::its now!!!!!!!!5
2023-12-01 10:04:05,587:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:05,588:INFO::Epoch 00050 | lr 0.00050 | Train_Loss 0.3127 | Train_Classification_Loss 0.3488 | Dmon_Loss -0.0721 | Val_Loss 0.2668 | Search Time(s) 0.6941 | Infer Time(s) 0.2483 | Time(s) 0.9425 
2023-12-01 10:04:05,625:INFO::cluster info:
0: 1;	1: 0;	2: 3;	3: 1;	4: 3;	5: 1;	6: 0;	7: 1;	8: 1;	9: 2;	10: 3;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 0;	35: 0;	36: 2;	37: 0;	38: 2;	39: 3;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 3;	26099: 3;	26100: 2;	26101: 1;	26102: 3;	26103: 2;	26104: 1;	26105: 3;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:05,626:INFO::Validation loss decreased (0.275506 --> 0.266850).  Saving model ...
2023-12-01 10:04:05,630:INFO::Epoch: 51
tensor([[0.5543, 0.5808, 0.5532, 0.5390],
        [0.5413, 0.5426, 0.5828, 0.5538],
        [0.5517, 0.5329, 0.5802, 0.5419],
        [0.5420, 0.5561, 0.5838, 0.5417]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:05,631:INFO::its now!!!!!!!!5
2023-12-01 10:04:05,828:INFO::its now!!!!!!!!0
2023-12-01 10:04:05,829:INFO::its now!!!!!!!!3
2023-12-01 10:04:05,960:INFO::its now!!!!!!!!5
2023-12-01 10:04:06,166:INFO::its now!!!!!!!!
2023-12-01 10:04:06,166:INFO::its now!!!!!!!! on 
2023-12-01 10:04:06,311:INFO::its now!!!!!!!!5
2023-12-01 10:04:06,520:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:06,522:INFO::Epoch 00051 | lr 0.00050 | Train_Loss 0.2866 | Train_Classification_Loss 0.3237 | Dmon_Loss -0.0742 | Val_Loss 0.2650 | Search Time(s) 0.6622 | Infer Time(s) 0.2324 | Time(s) 0.8946 
2023-12-01 10:04:06,563:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 3;	10: 1;	11: 3;	12: 2;	13: 2;	14: 1;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 3;	21: 0;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 2;	33: 2;	34: 2;	35: 0;	36: 2;	37: 3;	38: 2;	39: 1;	40: 0;	41: 2;	42: 3;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 3;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:06,565:INFO::Validation loss decreased (0.266850 --> 0.264972).  Saving model ...
2023-12-01 10:04:06,568:INFO::Epoch: 52
tensor([[0.5514, 0.5808, 0.5500, 0.5352],
        [0.5381, 0.5392, 0.5829, 0.5507],
        [0.5486, 0.5296, 0.5803, 0.5382],
        [0.5387, 0.5530, 0.5837, 0.5379]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:06,568:INFO::its now!!!!!!!!5
2023-12-01 10:04:06,767:INFO::its now!!!!!!!!0
2023-12-01 10:04:06,768:INFO::its now!!!!!!!!3
2023-12-01 10:04:06,901:INFO::its now!!!!!!!!5
2023-12-01 10:04:07,125:INFO::its now!!!!!!!!
2023-12-01 10:04:07,125:INFO::its now!!!!!!!! on 
2023-12-01 10:04:07,268:INFO::its now!!!!!!!!5
2023-12-01 10:04:07,478:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:07,480:INFO::Epoch 00052 | lr 0.00050 | Train_Loss 0.3010 | Train_Classification_Loss 0.3393 | Dmon_Loss -0.0766 | Val_Loss 0.2603 | Search Time(s) 0.6822 | Infer Time(s) 0.2304 | Time(s) 0.9125 
2023-12-01 10:04:07,516:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 3;	8: 1;	9: 3;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 2;	26099: 2;	26100: 2;	26101: 3;	26102: 3;	26103: 1;	26104: 0;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:07,517:INFO::Validation loss decreased (0.264972 --> 0.260347).  Saving model ...
2023-12-01 10:04:07,519:INFO::Epoch: 53
tensor([[0.5514, 0.5808, 0.5500, 0.5352],
        [0.5380, 0.5392, 0.5830, 0.5507],
        [0.5486, 0.5296, 0.5802, 0.5382],
        [0.5387, 0.5530, 0.5837, 0.5378]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:07,520:INFO::its now!!!!!!!!5
2023-12-01 10:04:07,711:INFO::its now!!!!!!!!0
2023-12-01 10:04:07,712:INFO::its now!!!!!!!!3
2023-12-01 10:04:07,844:INFO::its now!!!!!!!!5
2023-12-01 10:04:08,048:INFO::its now!!!!!!!!
2023-12-01 10:04:08,048:INFO::its now!!!!!!!! on 
2023-12-01 10:04:08,189:INFO::its now!!!!!!!!5
2023-12-01 10:04:08,451:INFO::Epoch 00053 | lr 0.00050 | Train_Loss 0.2885 | Train_Classification_Loss 0.3278 | Dmon_Loss -0.0787 | Val_Loss 0.2610 | Search Time(s) 0.6503 | Infer Time(s) 0.2832 | Time(s) 0.9335 
2023-12-01 10:04:08,495:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 3;	12: 2;	13: 2;	14: 1;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 0;	36: 2;	37: 2;	38: 2;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 2;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:04:08,497:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:04:08,499:INFO::Epoch: 54
tensor([[0.5524, 0.5807, 0.5512, 0.5366],
        [0.5392, 0.5404, 0.5831, 0.5518],
        [0.5497, 0.5308, 0.5801, 0.5395],
        [0.5399, 0.5541, 0.5837, 0.5392]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:08,500:INFO::its now!!!!!!!!5
2023-12-01 10:04:08,715:INFO::its now!!!!!!!!0
2023-12-01 10:04:08,716:INFO::its now!!!!!!!!3
2023-12-01 10:04:08,852:INFO::its now!!!!!!!!5
2023-12-01 10:04:09,048:INFO::its now!!!!!!!!
2023-12-01 10:04:09,048:INFO::its now!!!!!!!! on 
2023-12-01 10:04:09,190:INFO::its now!!!!!!!!5
2023-12-01 10:04:09,394:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:09,396:INFO::Epoch 00054 | lr 0.00050 | Train_Loss 0.2802 | Train_Classification_Loss 0.3211 | Dmon_Loss -0.0818 | Val_Loss 0.2598 | Search Time(s) 0.6718 | Infer Time(s) 0.2254 | Time(s) 0.8972 
2023-12-01 10:04:09,433:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 3;	12: 2;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 3;	33: 0;	34: 0;	35: 2;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 2;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:09,435:INFO::Validation loss decreased (0.260347 --> 0.259829).  Saving model ...
2023-12-01 10:04:09,437:INFO::Epoch: 55
tensor([[0.5579, 0.5807, 0.5569, 0.5434],
        [0.5451, 0.5466, 0.5832, 0.5575],
        [0.5551, 0.5367, 0.5800, 0.5461],
        [0.5458, 0.5597, 0.5837, 0.5461]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:09,438:INFO::its now!!!!!!!!5
2023-12-01 10:04:09,625:INFO::its now!!!!!!!!0
2023-12-01 10:04:09,626:INFO::its now!!!!!!!!3
2023-12-01 10:04:09,759:INFO::its now!!!!!!!!5
2023-12-01 10:04:09,965:INFO::its now!!!!!!!!
2023-12-01 10:04:09,965:INFO::its now!!!!!!!! on 
2023-12-01 10:04:10,106:INFO::its now!!!!!!!!5
2023-12-01 10:04:10,319:INFO::Epoch 00055 | lr 0.00050 | Train_Loss 0.2625 | Train_Classification_Loss 0.3046 | Dmon_Loss -0.0842 | Val_Loss 0.2601 | Search Time(s) 0.6512 | Infer Time(s) 0.2324 | Time(s) 0.8836 
2023-12-01 10:04:10,367:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 3;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 0;	42: 3;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 3;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:04:10,368:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:04:10,370:INFO::Epoch: 56
tensor([[0.5610, 0.5807, 0.5603, 0.5474],
        [0.5486, 0.5502, 0.5833, 0.5607],
        [0.5583, 0.5401, 0.5799, 0.5499],
        [0.5492, 0.5630, 0.5836, 0.5500]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:10,371:INFO::its now!!!!!!!!5
2023-12-01 10:04:10,566:INFO::its now!!!!!!!!0
2023-12-01 10:04:10,567:INFO::its now!!!!!!!!3
2023-12-01 10:04:10,700:INFO::its now!!!!!!!!5
2023-12-01 10:04:10,896:INFO::its now!!!!!!!!
2023-12-01 10:04:10,896:INFO::its now!!!!!!!! on 
2023-12-01 10:04:11,038:INFO::its now!!!!!!!!5
2023-12-01 10:04:11,252:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:11,254:INFO::Epoch 00056 | lr 0.00050 | Train_Loss 0.2789 | Train_Classification_Loss 0.3227 | Dmon_Loss -0.0877 | Val_Loss 0.2561 | Search Time(s) 0.6493 | Infer Time(s) 0.2344 | Time(s) 0.8836 
2023-12-01 10:04:11,300:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 3;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:11,301:INFO::Validation loss decreased (0.259829 --> 0.256087).  Saving model ...
2023-12-01 10:04:11,303:INFO::Epoch: 57
tensor([[0.5576, 0.5806, 0.5566, 0.5431],
        [0.5449, 0.5463, 0.5835, 0.5572],
        [0.5549, 0.5408, 0.5735, 0.5458],
        [0.5509, 0.5595, 0.5776, 0.5458]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:11,304:INFO::its now!!!!!!!!5
2023-12-01 10:04:11,499:INFO::its now!!!!!!!!0
2023-12-01 10:04:11,501:INFO::its now!!!!!!!!3
2023-12-01 10:04:11,632:INFO::its now!!!!!!!!5
2023-12-01 10:04:11,830:INFO::its now!!!!!!!!
2023-12-01 10:04:11,831:INFO::its now!!!!!!!! on 
2023-12-01 10:04:11,969:INFO::its now!!!!!!!!5
2023-12-01 10:04:12,176:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:12,177:INFO::Epoch 00057 | lr 0.00050 | Train_Loss 0.2979 | Train_Classification_Loss 0.3435 | Dmon_Loss -0.0912 | Val_Loss 0.2525 | Search Time(s) 0.6482 | Infer Time(s) 0.2254 | Time(s) 0.8736 
2023-12-01 10:04:12,216:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 0;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:04:12,218:INFO::Validation loss decreased (0.256087 --> 0.252457).  Saving model ...
2023-12-01 10:04:12,221:INFO::Epoch: 58
tensor([[0.5556, 0.5806, 0.5545, 0.5407],
        [0.5427, 0.5441, 0.5835, 0.5551],
        [0.5528, 0.5408, 0.5702, 0.5435],
        [0.5514, 0.5574, 0.5745, 0.5433]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:12,222:INFO::its now!!!!!!!!5
2023-12-01 10:04:12,480:INFO::its now!!!!!!!!0
2023-12-01 10:04:12,481:INFO::its now!!!!!!!!3
2023-12-01 10:04:12,613:INFO::its now!!!!!!!!5
2023-12-01 10:04:12,824:INFO::its now!!!!!!!!
2023-12-01 10:04:12,824:INFO::its now!!!!!!!! on 
2023-12-01 10:04:12,966:INFO::its now!!!!!!!!5
2023-12-01 10:04:13,193:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:13,194:INFO::Epoch 00058 | lr 0.00050 | Train_Loss 0.2740 | Train_Classification_Loss 0.3216 | Dmon_Loss -0.0952 | Val_Loss 0.2491 | Search Time(s) 0.7280 | Infer Time(s) 0.2473 | Time(s) 0.9754 
2023-12-01 10:04:13,233:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 2;	25: 2;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 0;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:13,234:INFO::Validation loss decreased (0.252457 --> 0.249074).  Saving model ...
2023-12-01 10:04:13,237:INFO::Epoch: 59
tensor([[0.5584, 0.5806, 0.5575, 0.5441],
        [0.5458, 0.5473, 0.5837, 0.5581],
        [0.5557, 0.5452, 0.5683, 0.5468],
        [0.5560, 0.5603, 0.5730, 0.5468]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:13,238:INFO::its now!!!!!!!!5
2023-12-01 10:04:13,461:INFO::its now!!!!!!!!0
2023-12-01 10:04:13,462:INFO::its now!!!!!!!!3
2023-12-01 10:04:13,593:INFO::its now!!!!!!!!5
2023-12-01 10:04:13,816:INFO::its now!!!!!!!!
2023-12-01 10:04:13,816:INFO::its now!!!!!!!! on 
2023-12-01 10:04:13,957:INFO::its now!!!!!!!!5
2023-12-01 10:04:14,178:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:14,180:INFO::Epoch 00059 | lr 0.00050 | Train_Loss 0.2586 | Train_Classification_Loss 0.3087 | Dmon_Loss -0.1001 | Val_Loss 0.2484 | Search Time(s) 0.7021 | Infer Time(s) 0.2424 | Time(s) 0.9445 
2023-12-01 10:04:14,221:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 1;	11: 3;	12: 2;	13: 2;	14: 1;	15: 3;	16: 3;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:14,222:INFO::Validation loss decreased (0.249074 --> 0.248421).  Saving model ...
2023-12-01 10:04:14,224:INFO::Epoch: 60
tensor([[0.5600, 0.5806, 0.5591, 0.5460],
        [0.5474, 0.5490, 0.5836, 0.5596],
        [0.5572, 0.5474, 0.5672, 0.5486],
        [0.5584, 0.5619, 0.5722, 0.5487]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:14,225:INFO::its now!!!!!!!!5
2023-12-01 10:04:14,429:INFO::its now!!!!!!!!0
2023-12-01 10:04:14,431:INFO::its now!!!!!!!!3
2023-12-01 10:04:14,561:INFO::its now!!!!!!!!5
2023-12-01 10:04:14,770:INFO::its now!!!!!!!!
2023-12-01 10:04:14,770:INFO::its now!!!!!!!! on 
2023-12-01 10:04:14,910:INFO::its now!!!!!!!!5
2023-12-01 10:04:15,132:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:15,133:INFO::Epoch 00060 | lr 0.00050 | Train_Loss 0.2609 | Train_Classification_Loss 0.3123 | Dmon_Loss -0.1027 | Val_Loss 0.2479 | Search Time(s) 0.6672 | Infer Time(s) 0.2424 | Time(s) 0.9096 
2023-12-01 10:04:15,171:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 0;	35: 0;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 0;	42: 3;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:15,172:INFO::Validation loss decreased (0.248421 --> 0.247950).  Saving model ...
2023-12-01 10:04:15,175:INFO::Epoch: 61
tensor([[0.5622, 0.5805, 0.5615, 0.5487],
        [0.5498, 0.5515, 0.5836, 0.5620],
        [0.5595, 0.5502, 0.5661, 0.5513],
        [0.5612, 0.5642, 0.5718, 0.5514]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:15,176:INFO::its now!!!!!!!!5
2023-12-01 10:04:15,401:INFO::its now!!!!!!!!0
2023-12-01 10:04:15,402:INFO::its now!!!!!!!!3
2023-12-01 10:04:15,534:INFO::its now!!!!!!!!5
2023-12-01 10:04:15,738:INFO::its now!!!!!!!!
2023-12-01 10:04:15,738:INFO::its now!!!!!!!! on 
2023-12-01 10:04:15,880:INFO::its now!!!!!!!!5
2023-12-01 10:04:16,091:INFO::Epoch 00061 | lr 0.00050 | Train_Loss 0.2329 | Train_Classification_Loss 0.2870 | Dmon_Loss -0.1082 | Val_Loss 0.2486 | Search Time(s) 0.6862 | Infer Time(s) 0.2314 | Time(s) 0.9175 
2023-12-01 10:04:16,141:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 2;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 0;	34: 2;	35: 0;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:16,142:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:04:16,144:INFO::Epoch: 62
tensor([[0.5578, 0.5805, 0.5569, 0.5435],
        [0.5452, 0.5466, 0.5835, 0.5575],
        [0.5551, 0.5455, 0.5586, 0.5525],
        [0.5566, 0.5597, 0.5717, 0.5462]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:16,144:INFO::its now!!!!!!!!5
2023-12-01 10:04:16,357:INFO::its now!!!!!!!!0
2023-12-01 10:04:16,358:INFO::its now!!!!!!!!3
2023-12-01 10:04:16,489:INFO::its now!!!!!!!!5
2023-12-01 10:04:16,700:INFO::its now!!!!!!!!
2023-12-01 10:04:16,700:INFO::its now!!!!!!!! on 
2023-12-01 10:04:16,841:INFO::its now!!!!!!!!5
2023-12-01 10:04:17,034:INFO::Epoch 00062 | lr 0.00050 | Train_Loss 0.2431 | Train_Classification_Loss 0.3003 | Dmon_Loss -0.1144 | Val_Loss 0.2521 | Search Time(s) 0.6786 | Infer Time(s) 0.2134 | Time(s) 0.8920 
2023-12-01 10:04:17,075:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 3;	12: 2;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 0;	41: 0;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:04:17,076:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:04:17,078:INFO::Epoch: 63
tensor([[0.5546, 0.5805, 0.5535, 0.5397],
        [0.5417, 0.5431, 0.5835, 0.5541],
        [0.5519, 0.5420, 0.5548, 0.5519],
        [0.5531, 0.5564, 0.5716, 0.5423]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:17,079:INFO::its now!!!!!!!!5
2023-12-01 10:04:17,284:INFO::its now!!!!!!!!0
2023-12-01 10:04:17,286:INFO::its now!!!!!!!!3
2023-12-01 10:04:17,417:INFO::its now!!!!!!!!5
2023-12-01 10:04:17,627:INFO::its now!!!!!!!!
2023-12-01 10:04:17,627:INFO::its now!!!!!!!! on 
2023-12-01 10:04:17,770:INFO::its now!!!!!!!!5
2023-12-01 10:04:18,025:INFO::Epoch 00063 | lr 0.00050 | Train_Loss 0.2234 | Train_Classification_Loss 0.2826 | Dmon_Loss -0.1184 | Val_Loss 0.2502 | Search Time(s) 0.6722 | Infer Time(s) 0.2773 | Time(s) 0.9495 
2023-12-01 10:04:18,075:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 0;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 0;	35: 3;	36: 2;	37: 2;	38: 0;	39: 1;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 10:04:18,076:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 10:04:18,079:INFO::Epoch: 64
tensor([[0.5536, 0.5805, 0.5525, 0.5385],
        [0.5407, 0.5420, 0.5834, 0.5531],
        [0.5509, 0.5409, 0.5527, 0.5524],
        [0.5520, 0.5554, 0.5715, 0.5412]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:18,080:INFO::its now!!!!!!!!5
2023-12-01 10:04:18,307:INFO::its now!!!!!!!!0
2023-12-01 10:04:18,308:INFO::its now!!!!!!!!3
2023-12-01 10:04:18,439:INFO::its now!!!!!!!!5
2023-12-01 10:04:18,667:INFO::its now!!!!!!!!
2023-12-01 10:04:18,667:INFO::its now!!!!!!!! on 
2023-12-01 10:04:18,810:INFO::its now!!!!!!!!5
2023-12-01 10:04:19,023:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:19,024:INFO::Epoch 00064 | lr 0.00050 | Train_Loss 0.2514 | Train_Classification_Loss 0.3085 | Dmon_Loss -0.1142 | Val_Loss 0.2473 | Search Time(s) 0.7311 | Infer Time(s) 0.2154 | Time(s) 0.9465 
2023-12-01 10:04:19,064:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 2;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 3;	41: 0;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 1;	26110: 1;	26111: 3;	26112: 1;	26113: 1;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 0;	26126: 1;	26127: 3;	
2023-12-01 10:04:19,064:INFO::Validation loss decreased (0.247950 --> 0.247296).  Saving model ...
2023-12-01 10:04:19,067:INFO::Epoch: 65
tensor([[0.5531, 0.5806, 0.5519, 0.5378],
        [0.5401, 0.5413, 0.5831, 0.5525],
        [0.5503, 0.5403, 0.5518, 0.5525],
        [0.5514, 0.5548, 0.5715, 0.5405]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:19,067:INFO::its now!!!!!!!!5
2023-12-01 10:04:19,257:INFO::its now!!!!!!!!0
2023-12-01 10:04:19,259:INFO::its now!!!!!!!!3
2023-12-01 10:04:19,391:INFO::its now!!!!!!!!5
2023-12-01 10:04:19,592:INFO::its now!!!!!!!!
2023-12-01 10:04:19,592:INFO::its now!!!!!!!! on 
2023-12-01 10:04:19,735:INFO::its now!!!!!!!!5
2023-12-01 10:04:19,926:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:19,928:INFO::Epoch 00065 | lr 0.00050 | Train_Loss 0.2370 | Train_Classification_Loss 0.2989 | Dmon_Loss -0.1238 | Val_Loss 0.2284 | Search Time(s) 0.6672 | Infer Time(s) 0.1945 | Time(s) 0.8617 
2023-12-01 10:04:19,966:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 0;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 0;	42: 3;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 2;	26102: 1;	26103: 0;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 10:04:19,967:INFO::Validation loss decreased (0.247296 --> 0.228351).  Saving model ...
2023-12-01 10:04:19,970:INFO::Epoch: 66
tensor([[0.5658, 0.5805, 0.5650, 0.5518],
        [0.5533, 0.5382, 0.5988, 0.5655],
        [0.5497, 0.5538, 0.5662, 0.5670],
        [0.5649, 0.5544, 0.5864, 0.5545]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:19,971:INFO::its now!!!!!!!!5
2023-12-01 10:04:20,165:INFO::its now!!!!!!!!0
2023-12-01 10:04:20,167:INFO::its now!!!!!!!!3
2023-12-01 10:04:20,301:INFO::its now!!!!!!!!5
2023-12-01 10:04:20,543:INFO::its now!!!!!!!!
2023-12-01 10:04:20,543:INFO::its now!!!!!!!! on 
2023-12-01 10:04:20,686:INFO::its now!!!!!!!!5
2023-12-01 10:04:20,895:INFO::Epoch 00066 | lr 0.00050 | Train_Loss 0.2375 | Train_Classification_Loss 0.2987 | Dmon_Loss -0.1223 | Val_Loss 0.2398 | Search Time(s) 0.7151 | Infer Time(s) 0.2104 | Time(s) 0.9255 
2023-12-01 10:04:20,937:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 0;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 1;	41: 0;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 0;	26103: 3;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 1;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 0;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 1;	26122: 2;	26123: 3;	26124: 0;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 10:04:20,938:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:04:20,941:INFO::Epoch: 67
tensor([[0.5804, 0.5947, 0.5800, 0.5588],
        [0.5684, 0.5358, 0.6161, 0.5804],
        [0.5490, 0.5692, 0.5824, 0.5831],
        [0.5803, 0.5655, 0.6028, 0.5615]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:20,941:INFO::its now!!!!!!!!5
2023-12-01 10:04:21,143:INFO::its now!!!!!!!!0
2023-12-01 10:04:21,144:INFO::its now!!!!!!!!3
2023-12-01 10:04:21,277:INFO::its now!!!!!!!!5
2023-12-01 10:04:21,517:INFO::its now!!!!!!!!
2023-12-01 10:04:21,517:INFO::its now!!!!!!!! on 
2023-12-01 10:04:21,658:INFO::its now!!!!!!!!5
2023-12-01 10:04:21,888:INFO::Epoch 00067 | lr 0.00050 | Train_Loss 0.2241 | Train_Classification_Loss 0.2937 | Dmon_Loss -0.1391 | Val_Loss 0.2607 | Search Time(s) 0.7001 | Infer Time(s) 0.2503 | Time(s) 0.9505 
2023-12-01 10:04:21,936:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 0;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 0;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 2;	26102: 2;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 2;	
2023-12-01 10:04:21,937:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:04:21,939:INFO::Epoch: 68
tensor([[0.5900, 0.6017, 0.5898, 0.5651],
        [0.5783, 0.5382, 0.6248, 0.5901],
        [0.5520, 0.5793, 0.5930, 0.5912],
        [0.5903, 0.5738, 0.6111, 0.5678]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:21,940:INFO::its now!!!!!!!!5
2023-12-01 10:04:22,155:INFO::its now!!!!!!!!0
2023-12-01 10:04:22,156:INFO::its now!!!!!!!!3
2023-12-01 10:04:22,288:INFO::its now!!!!!!!!5
2023-12-01 10:04:22,533:INFO::its now!!!!!!!!
2023-12-01 10:04:22,533:INFO::its now!!!!!!!! on 
2023-12-01 10:04:22,674:INFO::its now!!!!!!!!5
2023-12-01 10:04:22,904:INFO::Epoch 00068 | lr 0.00050 | Train_Loss 0.2018 | Train_Classification_Loss 0.2745 | Dmon_Loss -0.1454 | Val_Loss 0.2639 | Search Time(s) 0.7161 | Infer Time(s) 0.2513 | Time(s) 0.9674 
2023-12-01 10:04:22,941:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 0;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:04:22,942:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 10:04:22,944:INFO::Epoch: 69
tensor([[0.5970, 0.6052, 0.5969, 0.5708],
        [0.5854, 0.5427, 0.6291, 0.5971],
        [0.5565, 0.5865, 0.5981, 0.5976],
        [0.5976, 0.5806, 0.6153, 0.5735]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:22,945:INFO::its now!!!!!!!!5
2023-12-01 10:04:23,161:INFO::its now!!!!!!!!0
2023-12-01 10:04:23,162:INFO::its now!!!!!!!!3
2023-12-01 10:04:23,294:INFO::its now!!!!!!!!5
2023-12-01 10:04:23,537:INFO::its now!!!!!!!!
2023-12-01 10:04:23,538:INFO::its now!!!!!!!! on 
2023-12-01 10:04:23,681:INFO::its now!!!!!!!!5
2023-12-01 10:04:23,880:INFO::Epoch 00069 | lr 0.00050 | Train_Loss 0.2130 | Train_Classification_Loss 0.2803 | Dmon_Loss -0.1345 | Val_Loss 0.2431 | Search Time(s) 0.7361 | Infer Time(s) 0.2014 | Time(s) 0.9375 
2023-12-01 10:04:23,928:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 2;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 1;	26110: 1;	26111: 3;	26112: 1;	26113: 1;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 3;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 10:04:23,929:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 10:04:23,931:INFO::Epoch: 70
tensor([[0.6029, 0.6070, 0.6030, 0.5767],
        [0.5916, 0.5489, 0.6313, 0.6032],
        [0.5624, 0.5928, 0.6007, 0.6035],
        [0.6038, 0.5871, 0.6175, 0.5794]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:23,932:INFO::its now!!!!!!!!5
2023-12-01 10:04:24,131:INFO::its now!!!!!!!!0
2023-12-01 10:04:24,133:INFO::its now!!!!!!!!3
2023-12-01 10:04:24,268:INFO::its now!!!!!!!!5
2023-12-01 10:04:24,505:INFO::its now!!!!!!!!
2023-12-01 10:04:24,505:INFO::its now!!!!!!!! on 
2023-12-01 10:04:24,650:INFO::its now!!!!!!!!5
2023-12-01 10:04:24,890:INFO::Epoch 00070 | lr 0.00050 | Train_Loss 0.2010 | Train_Classification_Loss 0.2743 | Dmon_Loss -0.1465 | Val_Loss 0.2323 | Search Time(s) 0.7181 | Infer Time(s) 0.2434 | Time(s) 0.9614 
2023-12-01 10:04:24,931:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 3;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 0;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 0;	41: 2;	42: 2;	43: 1;	44
26098: 3;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 10:04:24,932:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 10:04:24,935:INFO::Epoch: 71
tensor([[0.6046, 0.6079, 0.6047, 0.5780],
        [0.5933, 0.5499, 0.6324, 0.6049],
        [0.5634, 0.5945, 0.6004, 0.6065],
        [0.6056, 0.5887, 0.6187, 0.5807]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:24,935:INFO::its now!!!!!!!!5
2023-12-01 10:04:25,135:INFO::its now!!!!!!!!0
2023-12-01 10:04:25,136:INFO::its now!!!!!!!!3
2023-12-01 10:04:25,271:INFO::its now!!!!!!!!5
2023-12-01 10:04:25,477:INFO::its now!!!!!!!!
2023-12-01 10:04:25,477:INFO::its now!!!!!!!! on 
2023-12-01 10:04:25,619:INFO::its now!!!!!!!!5
2023-12-01 10:04:25,822:INFO::Epoch 00071 | lr 0.00050 | Train_Loss 0.2518 | Train_Classification_Loss 0.3220 | Dmon_Loss -0.1404 | Val_Loss 0.2462 | Search Time(s) 0.6832 | Infer Time(s) 0.2055 | Time(s) 0.8886 
2023-12-01 10:04:25,858:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 2;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 1;	34: 0;	35: 2;	36: 1;	37: 2;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 1;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 10:04:25,859:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 10:04:25,863:INFO::Epoch: 72
tensor([[0.6046, 0.6084, 0.6047, 0.5778],
        [0.5934, 0.5491, 0.6328, 0.6049],
        [0.5628, 0.5946, 0.5995, 0.6080],
        [0.6056, 0.5885, 0.6193, 0.5804]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:25,863:INFO::its now!!!!!!!!5
2023-12-01 10:04:26,069:INFO::its now!!!!!!!!0
2023-12-01 10:04:26,070:INFO::its now!!!!!!!!3
2023-12-01 10:04:26,205:INFO::its now!!!!!!!!5
2023-12-01 10:04:26,414:INFO::its now!!!!!!!!
2023-12-01 10:04:26,415:INFO::its now!!!!!!!! on 
2023-12-01 10:04:26,540:INFO::its now!!!!!!!!5
2023-12-01 10:04:26,753:INFO::Epoch 00072 | lr 0.00050 | Train_Loss 0.1964 | Train_Classification_Loss 0.2755 | Dmon_Loss -0.1582 | Val_Loss 0.2547 | Search Time(s) 0.6792 | Infer Time(s) 0.2134 | Time(s) 0.8926 
2023-12-01 10:04:26,790:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 2;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 3;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 3;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 10:04:26,791:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 10:04:26,796:INFO::Epoch: 73
tensor([[0.6108, 0.6083, 0.6110, 0.5849],
        [0.5997, 0.5578, 0.6330, 0.6111],
        [0.5709, 0.6010, 0.6058, 0.6087],
        [0.6120, 0.5958, 0.6196, 0.5876]], device='cuda:0', requires_grad=True)
2023-12-01 10:04:26,797:INFO::its now!!!!!!!!5
2023-12-01 10:04:26,990:INFO::its now!!!!!!!!0
2023-12-01 10:04:26,991:INFO::its now!!!!!!!!3
2023-12-01 10:04:27,105:INFO::its now!!!!!!!!5
2023-12-01 10:04:27,330:INFO::its now!!!!!!!!
2023-12-01 10:04:27,330:INFO::its now!!!!!!!! on 
2023-12-01 10:04:27,455:INFO::its now!!!!!!!!5
2023-12-01 10:04:27,649:INFO::Epoch 00073 | lr 0.00050 | Train_Loss 0.1928 | Train_Classification_Loss 0.2778 | Dmon_Loss -0.1699 | Val_Loss 0.2749 | Search Time(s) 0.6562 | Infer Time(s) 0.2015 | Time(s) 0.8577 
2023-12-01 10:04:27,700:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 1;	11: 1;	12: 3;	13: 2;	14: 1;	15: 2;	16: 3;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 2;	25: 1;	26: 1;	27: 2;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 1;	44
26098: 1;	26099: 1;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 1;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 10:04:27,700:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 10:04:27,700:INFO::Eearly stopping!
2023-12-01 10:04:27,874:INFO::############### Search Stage Ends! ###############
2023-12-01 10:04:27,913:INFO::=============== Retrain Stage Starts:
2023-12-01 10:04:27,914:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:27,922:INFO::node_assign_Counter:
Counter({-1: 14328, 1: 5364, 2: 3089, 3: 2093, 0: 1254})
2023-12-01 10:04:27,922:INFO::save_dir_name: gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:04:28,305:INFO::============= repeat round: 4; seed: 2022
2023-12-01 10:04:28,334:INFO::arch_weights:
[[0.56577986 0.58054686 0.56497616 0.5517963 ]
 [0.55327475 0.5381936  0.5988425  0.5654832 ]
 [0.5496775  0.5538224  0.56616884 0.5669842 ]
 [0.5649007  0.55443144 0.5863578  0.55447876]]
2023-12-01 10:04:28,334:INFO::arch_weights_softmax:
[[0.24998832 0.2537073  0.2497875  0.2465169 ]
 [0.24728376 0.24358243 0.2588126  0.25032124]
 [0.2476327  0.24866126 0.25175035 0.2519557 ]
 [0.24994336 0.24734029 0.25536436 0.24735199]]
2023-12-01 10:04:28,334:INFO::genotype choice:
['ppnp', 'mean', 'one-hot', 'mean']
2023-12-01 10:04:29,138:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.4012 | Val_Loss 1.3544 | Time(s) 0.7660
2023-12-01 10:04:29,712:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3607 | Val_Loss 1.3242 | Time(s) 0.5326
2023-12-01 10:04:29,724:INFO::Validation loss decreased (inf --> 1.324213).  Saving model ...
2023-12-01 10:04:30,287:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3347 | Val_Loss 1.2944 | Time(s) 0.5615
2023-12-01 10:04:30,302:INFO::Validation loss decreased (1.324213 --> 1.294401).  Saving model ...
2023-12-01 10:04:30,886:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.3068 | Val_Loss 1.2642 | Time(s) 0.5844
2023-12-01 10:04:30,900:INFO::Validation loss decreased (1.294401 --> 1.264212).  Saving model ...
2023-12-01 10:04:31,438:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.2831 | Val_Loss 1.2336 | Time(s) 0.5356
2023-12-01 10:04:31,452:INFO::Validation loss decreased (1.264212 --> 1.233612).  Saving model ...
2023-12-01 10:04:32,023:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.2451 | Val_Loss 1.2023 | Time(s) 0.5705
2023-12-01 10:04:32,039:INFO::Validation loss decreased (1.233612 --> 1.202331).  Saving model ...
2023-12-01 10:04:32,570:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.2291 | Val_Loss 1.1712 | Time(s) 0.5306
2023-12-01 10:04:32,580:INFO::Validation loss decreased (1.202331 --> 1.171198).  Saving model ...
2023-12-01 10:04:33,115:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.1870 | Val_Loss 1.1395 | Time(s) 0.5336
2023-12-01 10:04:33,125:INFO::Validation loss decreased (1.171198 --> 1.139531).  Saving model ...
2023-12-01 10:04:33,637:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.1625 | Val_Loss 1.1073 | Time(s) 0.5116
2023-12-01 10:04:33,649:INFO::Validation loss decreased (1.139531 --> 1.107313).  Saving model ...
2023-12-01 10:04:34,190:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.1229 | Val_Loss 1.0744 | Time(s) 0.5416
2023-12-01 10:04:34,202:INFO::Validation loss decreased (1.107313 --> 1.074401).  Saving model ...
2023-12-01 10:04:34,782:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.0923 | Val_Loss 1.0407 | Time(s) 0.5794
2023-12-01 10:04:34,794:INFO::Validation loss decreased (1.074401 --> 1.040666).  Saving model ...
2023-12-01 10:04:35,350:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.0800 | Val_Loss 1.0059 | Time(s) 0.5565
2023-12-01 10:04:35,361:INFO::Validation loss decreased (1.040666 --> 1.005895).  Saving model ...
2023-12-01 10:04:35,920:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 1.0470 | Val_Loss 0.9709 | Time(s) 0.5575
2023-12-01 10:04:35,931:INFO::Validation loss decreased (1.005895 --> 0.970923).  Saving model ...
2023-12-01 10:04:36,505:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 0.9977 | Val_Loss 0.9357 | Time(s) 0.5735
2023-12-01 10:04:36,518:INFO::Validation loss decreased (0.970923 --> 0.935717).  Saving model ...
2023-12-01 10:04:37,057:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 1.0046 | Val_Loss 0.9009 | Time(s) 0.5379
2023-12-01 10:04:37,070:INFO::Validation loss decreased (0.935717 --> 0.900921).  Saving model ...
2023-12-01 10:04:37,606:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 0.9551 | Val_Loss 0.8671 | Time(s) 0.5356
2023-12-01 10:04:37,617:INFO::Validation loss decreased (0.900921 --> 0.867142).  Saving model ...
2023-12-01 10:04:38,154:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 0.9218 | Val_Loss 0.8339 | Time(s) 0.5356
2023-12-01 10:04:38,165:INFO::Validation loss decreased (0.867142 --> 0.833944).  Saving model ...
2023-12-01 10:04:38,718:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 0.9119 | Val_Loss 0.8018 | Time(s) 0.5535
2023-12-01 10:04:38,730:INFO::Validation loss decreased (0.833944 --> 0.801799).  Saving model ...
2023-12-01 10:04:39,282:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 0.8911 | Val_Loss 0.7707 | Time(s) 0.5505
2023-12-01 10:04:39,297:INFO::Validation loss decreased (0.801799 --> 0.770654).  Saving model ...
2023-12-01 10:04:39,837:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 0.8340 | Val_Loss 0.7401 | Time(s) 0.5406
2023-12-01 10:04:39,848:INFO::Validation loss decreased (0.770654 --> 0.740148).  Saving model ...
2023-12-01 10:04:40,403:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 0.8205 | Val_Loss 0.7094 | Time(s) 0.5545
2023-12-01 10:04:40,416:INFO::Validation loss decreased (0.740148 --> 0.709359).  Saving model ...
2023-12-01 10:04:40,966:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 0.8007 | Val_Loss 0.6788 | Time(s) 0.5505
2023-12-01 10:04:40,979:INFO::Validation loss decreased (0.709359 --> 0.678801).  Saving model ...
2023-12-01 10:04:41,512:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 0.7713 | Val_Loss 0.6471 | Time(s) 0.5326
2023-12-01 10:04:41,522:INFO::Validation loss decreased (0.678801 --> 0.647058).  Saving model ...
2023-12-01 10:04:42,061:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 0.7471 | Val_Loss 0.6157 | Time(s) 0.5396
2023-12-01 10:04:42,072:INFO::Validation loss decreased (0.647058 --> 0.615716).  Saving model ...
2023-12-01 10:04:42,661:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 0.7353 | Val_Loss 0.5855 | Time(s) 0.5884
2023-12-01 10:04:42,675:INFO::Validation loss decreased (0.615716 --> 0.585522).  Saving model ...
2023-12-01 10:04:43,210:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 0.6772 | Val_Loss 0.5554 | Time(s) 0.5346
2023-12-01 10:04:43,224:INFO::Validation loss decreased (0.585522 --> 0.555422).  Saving model ...
2023-12-01 10:04:43,797:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 0.6532 | Val_Loss 0.5266 | Time(s) 0.5725
2023-12-01 10:04:43,808:INFO::Validation loss decreased (0.555422 --> 0.526567).  Saving model ...
2023-12-01 10:04:44,363:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 0.6337 | Val_Loss 0.4988 | Time(s) 0.5555
2023-12-01 10:04:44,374:INFO::Validation loss decreased (0.526567 --> 0.498776).  Saving model ...
2023-12-01 10:04:44,895:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 0.6073 | Val_Loss 0.4731 | Time(s) 0.5206
2023-12-01 10:04:44,907:INFO::Validation loss decreased (0.498776 --> 0.473149).  Saving model ...
2023-12-01 10:04:45,495:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 0.5867 | Val_Loss 0.4497 | Time(s) 0.5884
2023-12-01 10:04:45,508:INFO::Validation loss decreased (0.473149 --> 0.449748).  Saving model ...
2023-12-01 10:04:46,058:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 0.5980 | Val_Loss 0.4289 | Time(s) 0.5495
2023-12-01 10:04:46,072:INFO::Validation loss decreased (0.449748 --> 0.428891).  Saving model ...
2023-12-01 10:04:46,622:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 0.5667 | Val_Loss 0.4086 | Time(s) 0.5505
2023-12-01 10:04:46,634:INFO::Validation loss decreased (0.428891 --> 0.408606).  Saving model ...
2023-12-01 10:04:47,182:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 0.5291 | Val_Loss 0.3871 | Time(s) 0.5475
2023-12-01 10:04:47,195:INFO::Validation loss decreased (0.408606 --> 0.387092).  Saving model ...
2023-12-01 10:04:47,767:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 0.4958 | Val_Loss 0.3669 | Time(s) 0.5725
2023-12-01 10:04:47,782:INFO::Validation loss decreased (0.387092 --> 0.366921).  Saving model ...
2023-12-01 10:04:48,341:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 0.5038 | Val_Loss 0.3484 | Time(s) 0.5575
2023-12-01 10:04:48,353:INFO::Validation loss decreased (0.366921 --> 0.348416).  Saving model ...
2023-12-01 10:04:48,915:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 0.4971 | Val_Loss 0.3327 | Time(s) 0.5615
2023-12-01 10:04:48,926:INFO::Validation loss decreased (0.348416 --> 0.332734).  Saving model ...
2023-12-01 10:04:49,509:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 0.4424 | Val_Loss 0.3178 | Time(s) 0.5824
2023-12-01 10:04:49,520:INFO::Validation loss decreased (0.332734 --> 0.317832).  Saving model ...
2023-12-01 10:04:50,075:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 0.4483 | Val_Loss 0.3043 | Time(s) 0.5525
2023-12-01 10:04:50,086:INFO::Validation loss decreased (0.317832 --> 0.304310).  Saving model ...
2023-12-01 10:04:50,660:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 0.4441 | Val_Loss 0.2935 | Time(s) 0.5735
2023-12-01 10:04:50,674:INFO::Validation loss decreased (0.304310 --> 0.293510).  Saving model ...
2023-12-01 10:04:51,289:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 0.4409 | Val_Loss 0.2831 | Time(s) 0.6144
2023-12-01 10:04:51,304:INFO::Validation loss decreased (0.293510 --> 0.283106).  Saving model ...
2023-12-01 10:04:51,864:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 0.4195 | Val_Loss 0.2731 | Time(s) 0.5605
2023-12-01 10:04:51,877:INFO::Validation loss decreased (0.283106 --> 0.273106).  Saving model ...
2023-12-01 10:04:52,434:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 0.4406 | Val_Loss 0.2642 | Time(s) 0.5565
2023-12-01 10:04:52,446:INFO::Validation loss decreased (0.273106 --> 0.264190).  Saving model ...
2023-12-01 10:04:53,012:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 0.4304 | Val_Loss 0.2568 | Time(s) 0.5655
2023-12-01 10:04:53,025:INFO::Validation loss decreased (0.264190 --> 0.256786).  Saving model ...
2023-12-01 10:04:53,559:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 0.3908 | Val_Loss 0.2493 | Time(s) 0.5326
2023-12-01 10:04:53,570:INFO::Validation loss decreased (0.256786 --> 0.249338).  Saving model ...
2023-12-01 10:04:54,129:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 0.3963 | Val_Loss 0.2433 | Time(s) 0.5585
2023-12-01 10:04:54,142:INFO::Validation loss decreased (0.249338 --> 0.243260).  Saving model ...
2023-12-01 10:04:54,682:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 0.3586 | Val_Loss 0.2370 | Time(s) 0.5396
2023-12-01 10:04:54,694:INFO::Validation loss decreased (0.243260 --> 0.237027).  Saving model ...
2023-12-01 10:04:55,229:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 0.3752 | Val_Loss 0.2309 | Time(s) 0.5356
2023-12-01 10:04:55,240:INFO::Validation loss decreased (0.237027 --> 0.230861).  Saving model ...
2023-12-01 10:04:55,798:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 0.3478 | Val_Loss 0.2247 | Time(s) 0.5575
2023-12-01 10:04:55,812:INFO::Validation loss decreased (0.230861 --> 0.224707).  Saving model ...
2023-12-01 10:04:56,382:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 0.3264 | Val_Loss 0.2189 | Time(s) 0.5705
2023-12-01 10:04:56,392:INFO::Validation loss decreased (0.224707 --> 0.218947).  Saving model ...
2023-12-01 10:04:56,943:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 0.3353 | Val_Loss 0.2128 | Time(s) 0.5495
2023-12-01 10:04:56,955:INFO::Validation loss decreased (0.218947 --> 0.212833).  Saving model ...
2023-12-01 10:04:57,503:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 0.3470 | Val_Loss 0.2068 | Time(s) 0.5487
2023-12-01 10:04:57,515:INFO::Validation loss decreased (0.212833 --> 0.206792).  Saving model ...
2023-12-01 10:04:58,072:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.3170 | Val_Loss 0.2023 | Time(s) 0.5555
2023-12-01 10:04:58,086:INFO::Validation loss decreased (0.206792 --> 0.202334).  Saving model ...
2023-12-01 10:04:58,640:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.3460 | Val_Loss 0.1981 | Time(s) 0.5535
2023-12-01 10:04:58,653:INFO::Validation loss decreased (0.202334 --> 0.198058).  Saving model ...
2023-12-01 10:04:59,191:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 0.3580 | Val_Loss 0.1942 | Time(s) 0.5376
2023-12-01 10:04:59,205:INFO::Validation loss decreased (0.198058 --> 0.194221).  Saving model ...
2023-12-01 10:04:59,726:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.3254 | Val_Loss 0.1909 | Time(s) 0.5216
2023-12-01 10:04:59,736:INFO::Validation loss decreased (0.194221 --> 0.190934).  Saving model ...
2023-12-01 10:05:00,276:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.3257 | Val_Loss 0.1883 | Time(s) 0.5386
2023-12-01 10:05:00,288:INFO::Validation loss decreased (0.190934 --> 0.188309).  Saving model ...
2023-12-01 10:05:00,836:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.2916 | Val_Loss 0.1864 | Time(s) 0.5485
2023-12-01 10:05:00,849:INFO::Validation loss decreased (0.188309 --> 0.186385).  Saving model ...
2023-12-01 10:05:01,401:INFO::Epoch 00057 | lr 0.00050 |Train_Loss 0.3226 | Val_Loss 0.1848 | Time(s) 0.5515
2023-12-01 10:05:01,413:INFO::Validation loss decreased (0.186385 --> 0.184804).  Saving model ...
2023-12-01 10:05:02,024:INFO::Epoch 00058 | lr 0.00050 |Train_Loss 0.2908 | Val_Loss 0.1834 | Time(s) 0.6114
2023-12-01 10:05:02,036:INFO::Validation loss decreased (0.184804 --> 0.183448).  Saving model ...
2023-12-01 10:05:02,575:INFO::Epoch 00059 | lr 0.00050 |Train_Loss 0.2965 | Val_Loss 0.1835 | Time(s) 0.5386
2023-12-01 10:05:02,576:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:05:03,141:INFO::Epoch 00060 | lr 0.00050 |Train_Loss 0.2679 | Val_Loss 0.1839 | Time(s) 0.5655
2023-12-01 10:05:03,142:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:05:03,685:INFO::Epoch 00061 | lr 0.00050 |Train_Loss 0.3023 | Val_Loss 0.1832 | Time(s) 0.5425
2023-12-01 10:05:03,701:INFO::Validation loss decreased (0.183448 --> 0.183240).  Saving model ...
2023-12-01 10:05:04,262:INFO::Epoch 00062 | lr 0.00050 |Train_Loss 0.3006 | Val_Loss 0.1827 | Time(s) 0.5615
2023-12-01 10:05:04,273:INFO::Validation loss decreased (0.183240 --> 0.182731).  Saving model ...
2023-12-01 10:05:04,814:INFO::Epoch 00063 | lr 0.00050 |Train_Loss 0.3031 | Val_Loss 0.1815 | Time(s) 0.5406
2023-12-01 10:05:04,828:INFO::Validation loss decreased (0.182731 --> 0.181520).  Saving model ...
2023-12-01 10:05:05,381:INFO::Epoch 00064 | lr 0.00050 |Train_Loss 0.2654 | Val_Loss 0.1802 | Time(s) 0.5535
2023-12-01 10:05:05,392:INFO::Validation loss decreased (0.181520 --> 0.180240).  Saving model ...
2023-12-01 10:05:05,940:INFO::Epoch 00065 | lr 0.00050 |Train_Loss 0.2902 | Val_Loss 0.1791 | Time(s) 0.5475
2023-12-01 10:05:05,951:INFO::Validation loss decreased (0.180240 --> 0.179109).  Saving model ...
2023-12-01 10:05:06,523:INFO::Epoch 00066 | lr 0.00050 |Train_Loss 0.2610 | Val_Loss 0.1777 | Time(s) 0.5715
2023-12-01 10:05:06,535:INFO::Validation loss decreased (0.179109 --> 0.177700).  Saving model ...
2023-12-01 10:05:07,082:INFO::Epoch 00067 | lr 0.00050 |Train_Loss 0.2578 | Val_Loss 0.1760 | Time(s) 0.5455
2023-12-01 10:05:07,097:INFO::Validation loss decreased (0.177700 --> 0.175987).  Saving model ...
2023-12-01 10:05:07,652:INFO::Epoch 00068 | lr 0.00050 |Train_Loss 0.2667 | Val_Loss 0.1753 | Time(s) 0.5555
2023-12-01 10:05:07,663:INFO::Validation loss decreased (0.175987 --> 0.175261).  Saving model ...
2023-12-01 10:05:08,233:INFO::Epoch 00069 | lr 0.00050 |Train_Loss 0.2800 | Val_Loss 0.1750 | Time(s) 0.5695
2023-12-01 10:05:08,243:INFO::Validation loss decreased (0.175261 --> 0.175033).  Saving model ...
2023-12-01 10:05:08,831:INFO::Epoch 00070 | lr 0.00050 |Train_Loss 0.2779 | Val_Loss 0.1752 | Time(s) 0.5884
2023-12-01 10:05:08,832:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 10:05:09,375:INFO::Epoch 00071 | lr 0.00050 |Train_Loss 0.2693 | Val_Loss 0.1757 | Time(s) 0.5435
2023-12-01 10:05:09,376:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 10:05:09,918:INFO::Epoch 00072 | lr 0.00050 |Train_Loss 0.2331 | Val_Loss 0.1769 | Time(s) 0.5415
2023-12-01 10:05:09,919:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 10:05:10,462:INFO::Epoch 00073 | lr 0.00050 |Train_Loss 0.2787 | Val_Loss 0.1787 | Time(s) 0.5425
2023-12-01 10:05:10,463:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 10:05:11,025:INFO::Epoch 00074 | lr 0.00050 |Train_Loss 0.2645 | Val_Loss 0.1809 | Time(s) 0.5625
2023-12-01 10:05:11,026:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 10:05:11,575:INFO::Epoch 00075 | lr 0.00050 |Train_Loss 0.2506 | Val_Loss 0.1832 | Time(s) 0.5485
2023-12-01 10:05:11,576:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 10:05:12,121:INFO::Epoch 00076 | lr 0.00050 |Train_Loss 0.2605 | Val_Loss 0.1855 | Time(s) 0.5441
2023-12-01 10:05:12,121:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 10:05:12,696:INFO::Epoch 00077 | lr 0.00050 |Train_Loss 0.2771 | Val_Loss 0.1872 | Time(s) 0.5745
2023-12-01 10:05:12,697:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 10:05:12,697:INFO::Eearly stopping!
2023-12-01 10:05:12,698:INFO::
testing...
2023-12-01 10:05:12,716:INFO::submit dir: submit/submit_gat_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 10:05:12,938:INFO::{'micro-f1': 0.898943661971831, 'macro-f1': 0.8911373593471541}
2023-12-01 10:05:13,058:INFO::############### Retrain Stage Ends! #################
