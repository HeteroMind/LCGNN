2023-12-01 16:46:32,482:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gcn', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-16-46-32', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=123, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=0, last_hidden_dim=64, logger=<Logger log_output (INFO)>)
2023-12-01 16:46:52,245:INFO::node_type_num: 4
2023-12-01 16:46:57,605:INFO::=============== Prepare basic data stage finish, use 25.122782707214355 time.
2023-12-01 16:47:15,082:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:47:45,829:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 16:47:45,902:INFO::its now!!!!!!!!5
2023-12-01 16:47:59,860:INFO::its now!!!!!!!!0
2023-12-01 16:47:59,936:INFO::its now!!!!!!!!3
2023-12-01 16:48:00,317:INFO::its now!!!!!!!!5
2023-12-01 16:48:00,789:INFO::its now!!!!!!!!
2023-12-01 16:48:00,789:INFO::its now!!!!!!!! on 
2023-12-01 16:48:01,002:INFO::its now!!!!!!!!5
2023-12-01 16:48:01,171:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:01,174:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.3517 | Train_Classification_Loss 1.3827 | Dmon_Loss -0.0620 | Val_Loss 1.3811 | Search Time(s) 15.6871 | Infer Time(s) 0.1855 | Time(s) 15.8725 
2023-12-01 16:48:01,245:INFO::cluster info:
0: 2;	1: 3;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 3;	21: 3;	22: 2;	23: 2;	24: 3;	25: 3;	26: 3;	27: 2;	28: 3;	29: 2;	30: 2;	31: 3;	32: 2;	33: 3;	34: 2;	35: 2;	36: 2;	37: 3;	38: 3;	39: 2;	40: 2;	41: 3;	42: 2;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:01,249:INFO::Epoch: 1
tensor([[0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.5050, 0.5050, 0.5050, 0.5050]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:01,250:INFO::its now!!!!!!!!5
2023-12-01 16:48:01,399:INFO::its now!!!!!!!!0
2023-12-01 16:48:01,399:INFO::its now!!!!!!!!3
2023-12-01 16:48:01,450:INFO::its now!!!!!!!!5
2023-12-01 16:48:01,615:INFO::its now!!!!!!!!
2023-12-01 16:48:01,615:INFO::its now!!!!!!!! on 
2023-12-01 16:48:01,649:INFO::its now!!!!!!!!5
2023-12-01 16:48:01,781:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:01,782:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3519 | Train_Classification_Loss 1.3831 | Dmon_Loss -0.0625 | Val_Loss 1.3787 | Search Time(s) 0.3969 | Infer Time(s) 0.1376 | Time(s) 0.5346 
2023-12-01 16:48:01,819:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 1;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 1;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 0;	26099: 2;	26100: 3;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 2;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:48:01,820:INFO::Validation loss decreased (inf --> 1.378690).  Saving model ...
2023-12-01 16:48:01,824:INFO::Epoch: 2
tensor([[0.4997, 0.5074, 0.5102, 0.5102],
        [0.4997, 0.5074, 0.5102, 0.5102],
        [0.4997, 0.5074, 0.5102, 0.5102],
        [0.5097, 0.5074, 0.5102, 0.5102]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:01,825:INFO::its now!!!!!!!!5
2023-12-01 16:48:02,003:INFO::its now!!!!!!!!0
2023-12-01 16:48:02,003:INFO::its now!!!!!!!!3
2023-12-01 16:48:02,030:INFO::its now!!!!!!!!5
2023-12-01 16:48:02,193:INFO::its now!!!!!!!!
2023-12-01 16:48:02,193:INFO::its now!!!!!!!! on 
2023-12-01 16:48:02,247:INFO::its now!!!!!!!!5
2023-12-01 16:48:02,423:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:02,424:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3479 | Train_Classification_Loss 1.3792 | Dmon_Loss -0.0626 | Val_Loss 1.3746 | Search Time(s) 0.4259 | Infer Time(s) 0.1765 | Time(s) 0.6024 
2023-12-01 16:48:02,474:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 1;	4: 3;	5: 3;	6: 2;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 2;	16: 1;	17: 3;	18: 0;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 2;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 2;	40: 3;	41: 3;	42: 3;	43: 2;	44
26098: 2;	26099: 3;	26100: 3;	26101: 3;	26102: 0;	26103: 2;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 2;	26110: 1;	26111: 0;	26112: 2;	26113: 2;	26114: 2;	26115: 3;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 3;	26122: 0;	26123: 2;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 16:48:02,476:INFO::Validation loss decreased (1.378690 --> 1.374646).  Saving model ...
2023-12-01 16:48:02,481:INFO::Epoch: 3
tensor([[0.5047, 0.5117, 0.5129, 0.5151],
        [0.5047, 0.5117, 0.5129, 0.5151],
        [0.5047, 0.5118, 0.5129, 0.5151],
        [0.5147, 0.5118, 0.5128, 0.5151]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:02,482:INFO::its now!!!!!!!!5
2023-12-01 16:48:02,631:INFO::its now!!!!!!!!0
2023-12-01 16:48:02,632:INFO::its now!!!!!!!!3
2023-12-01 16:48:02,657:INFO::its now!!!!!!!!5
2023-12-01 16:48:02,825:INFO::its now!!!!!!!!
2023-12-01 16:48:02,825:INFO::its now!!!!!!!! on 
2023-12-01 16:48:02,864:INFO::its now!!!!!!!!5
2023-12-01 16:48:03,003:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:03,005:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3423 | Train_Classification_Loss 1.3736 | Dmon_Loss -0.0627 | Val_Loss 1.3719 | Search Time(s) 0.3850 | Infer Time(s) 0.1426 | Time(s) 0.5276 
2023-12-01 16:48:03,042:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 1;	4: 3;	5: 2;	6: 2;	7: 2;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 2;	15: 3;	16: 1;	17: 3;	18: 2;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 3;	28: 3;	29: 1;	30: 3;	31: 2;	32: 3;	33: 2;	34: 3;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:03,043:INFO::Validation loss decreased (1.374646 --> 1.371922).  Saving model ...
2023-12-01 16:48:03,047:INFO::Epoch: 4
tensor([[0.5101, 0.5170, 0.5172, 0.5177],
        [0.5101, 0.5170, 0.5172, 0.5177],
        [0.5101, 0.5170, 0.5172, 0.5177],
        [0.5201, 0.5170, 0.5172, 0.5177]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:03,048:INFO::its now!!!!!!!!5
2023-12-01 16:48:03,200:INFO::its now!!!!!!!!0
2023-12-01 16:48:03,201:INFO::its now!!!!!!!!3
2023-12-01 16:48:03,231:INFO::its now!!!!!!!!5
2023-12-01 16:48:03,393:INFO::its now!!!!!!!!
2023-12-01 16:48:03,394:INFO::its now!!!!!!!! on 
2023-12-01 16:48:03,446:INFO::its now!!!!!!!!5
2023-12-01 16:48:03,579:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:03,581:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3413 | Train_Classification_Loss 1.3726 | Dmon_Loss -0.0626 | Val_Loss 1.3686 | Search Time(s) 0.3820 | Infer Time(s) 0.1536 | Time(s) 0.5356 
2023-12-01 16:48:03,623:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 0;	7: 2;	8: 2;	9: 2;	10: 2;	11: 3;	12: 3;	13: 2;	14: 2;	15: 3;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 3;	31: 0;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 3;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 2;	26106: 3;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:03,624:INFO::Validation loss decreased (1.371922 --> 1.368602).  Saving model ...
2023-12-01 16:48:03,627:INFO::Epoch: 5
tensor([[0.5158, 0.5228, 0.5225, 0.5192],
        [0.5158, 0.5228, 0.5225, 0.5192],
        [0.5158, 0.5228, 0.5225, 0.5192],
        [0.5230, 0.5228, 0.5225, 0.5224]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:03,628:INFO::its now!!!!!!!!5
2023-12-01 16:48:03,764:INFO::its now!!!!!!!!0
2023-12-01 16:48:03,764:INFO::its now!!!!!!!!3
2023-12-01 16:48:03,809:INFO::its now!!!!!!!!5
2023-12-01 16:48:03,948:INFO::its now!!!!!!!!
2023-12-01 16:48:03,949:INFO::its now!!!!!!!! on 
2023-12-01 16:48:04,002:INFO::its now!!!!!!!!5
2023-12-01 16:48:04,128:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:04,129:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3368 | Train_Classification_Loss 1.3682 | Dmon_Loss -0.0628 | Val_Loss 1.3661 | Search Time(s) 0.3580 | Infer Time(s) 0.1466 | Time(s) 0.5046 
2023-12-01 16:48:04,169:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 2;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 2;	16: 2;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 1;	27: 3;	28: 3;	29: 2;	30: 3;	31: 0;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 2;	26118: 2;	26119: 2;	26120: 3;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:04,170:INFO::Validation loss decreased (1.368602 --> 1.366052).  Saving model ...
2023-12-01 16:48:04,173:INFO::Epoch: 6
tensor([[0.5204, 0.5259, 0.5269, 0.5220],
        [0.5204, 0.5259, 0.5269, 0.5220],
        [0.5204, 0.5259, 0.5269, 0.5219],
        [0.5245, 0.5275, 0.5269, 0.5265]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:04,174:INFO::its now!!!!!!!!5
2023-12-01 16:48:04,324:INFO::its now!!!!!!!!0
2023-12-01 16:48:04,324:INFO::its now!!!!!!!!3
2023-12-01 16:48:04,369:INFO::its now!!!!!!!!5
2023-12-01 16:48:04,527:INFO::its now!!!!!!!!
2023-12-01 16:48:04,528:INFO::its now!!!!!!!! on 
2023-12-01 16:48:04,581:INFO::its now!!!!!!!!5
2023-12-01 16:48:04,732:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:04,734:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.3306 | Train_Classification_Loss 1.3620 | Dmon_Loss -0.0629 | Val_Loss 1.3623 | Search Time(s) 0.3910 | Infer Time(s) 0.1705 | Time(s) 0.5615 
2023-12-01 16:48:04,781:INFO::cluster info:
0: 2;	1: 3;	2: 2;	3: 3;	4: 2;	5: 3;	6: 3;	7: 2;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 2;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 2;	24: 3;	25: 3;	26: 1;	27: 3;	28: 2;	29: 2;	30: 3;	31: 2;	32: 3;	33: 2;	34: 2;	35: 3;	36: 3;	37: 3;	38: 2;	39: 2;	40: 3;	41: 3;	42: 2;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 2;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:04,782:INFO::Validation loss decreased (1.366052 --> 1.362312).  Saving model ...
2023-12-01 16:48:04,785:INFO::Epoch: 7
tensor([[0.5248, 0.5297, 0.5292, 0.5259],
        [0.5248, 0.5297, 0.5292, 0.5259],
        [0.5248, 0.5297, 0.5292, 0.5259],
        [0.5279, 0.5300, 0.5312, 0.5307]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:04,785:INFO::its now!!!!!!!!5
2023-12-01 16:48:04,937:INFO::its now!!!!!!!!0
2023-12-01 16:48:04,938:INFO::its now!!!!!!!!3
2023-12-01 16:48:04,982:INFO::its now!!!!!!!!5
2023-12-01 16:48:05,130:INFO::its now!!!!!!!!
2023-12-01 16:48:05,130:INFO::its now!!!!!!!! on 
2023-12-01 16:48:05,166:INFO::its now!!!!!!!!5
2023-12-01 16:48:05,302:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:05,303:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.3299 | Train_Classification_Loss 1.3613 | Dmon_Loss -0.0629 | Val_Loss 1.3594 | Search Time(s) 0.3800 | Infer Time(s) 0.1386 | Time(s) 0.5186 
2023-12-01 16:48:05,358:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 2;	4: 2;	5: 3;	6: 3;	7: 2;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 2;	24: 0;	25: 3;	26: 3;	27: 3;	28: 3;	29: 2;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 2;	36: 3;	37: 3;	38: 2;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 0;	26105: 2;	26106: 3;	26107: 2;	26108: 2;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 3;	26120: 2;	26121: 2;	26122: 3;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:05,359:INFO::Validation loss decreased (1.362312 --> 1.359380).  Saving model ...
2023-12-01 16:48:05,362:INFO::Epoch: 8
tensor([[0.5294, 0.5318, 0.5329, 0.5307],
        [0.5294, 0.5318, 0.5329, 0.5307],
        [0.5294, 0.5318, 0.5328, 0.5307],
        [0.5324, 0.5338, 0.5335, 0.5352]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:05,362:INFO::its now!!!!!!!!5
2023-12-01 16:48:05,508:INFO::its now!!!!!!!!0
2023-12-01 16:48:05,509:INFO::its now!!!!!!!!3
2023-12-01 16:48:05,536:INFO::its now!!!!!!!!5
2023-12-01 16:48:05,681:INFO::its now!!!!!!!!
2023-12-01 16:48:05,681:INFO::its now!!!!!!!! on 
2023-12-01 16:48:05,732:INFO::its now!!!!!!!!5
2023-12-01 16:48:05,873:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:05,874:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.3258 | Train_Classification_Loss 1.3575 | Dmon_Loss -0.0634 | Val_Loss 1.3568 | Search Time(s) 0.3700 | Infer Time(s) 0.1426 | Time(s) 0.5126 
2023-12-01 16:48:05,917:INFO::cluster info:
0: 2;	1: 2;	2: 3;	3: 2;	4: 3;	5: 2;	6: 3;	7: 3;	8: 2;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 2;	15: 3;	16: 2;	17: 3;	18: 2;	19: 2;	20: 3;	21: 2;	22: 2;	23: 3;	24: 3;	25: 2;	26: 3;	27: 2;	28: 2;	29: 2;	30: 3;	31: 2;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 3;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 3;	44
26098: 2;	26099: 2;	26100: 2;	26101: 3;	26102: 3;	26103: 2;	26104: 0;	26105: 3;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:05,918:INFO::Validation loss decreased (1.359380 --> 1.356811).  Saving model ...
2023-12-01 16:48:05,921:INFO::Epoch: 9
tensor([[0.5341, 0.5355, 0.5348, 0.5359],
        [0.5341, 0.5355, 0.5348, 0.5359],
        [0.5341, 0.5355, 0.5347, 0.5358],
        [0.5374, 0.5383, 0.5371, 0.5376]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:05,922:INFO::its now!!!!!!!!5
2023-12-01 16:48:06,055:INFO::its now!!!!!!!!0
2023-12-01 16:48:06,055:INFO::its now!!!!!!!!3
2023-12-01 16:48:06,100:INFO::its now!!!!!!!!5
2023-12-01 16:48:06,278:INFO::its now!!!!!!!!
2023-12-01 16:48:06,278:INFO::its now!!!!!!!! on 
2023-12-01 16:48:06,331:INFO::its now!!!!!!!!5
2023-12-01 16:48:06,508:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:06,510:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.3221 | Train_Classification_Loss 1.3539 | Dmon_Loss -0.0636 | Val_Loss 1.3533 | Search Time(s) 0.3940 | Infer Time(s) 0.1954 | Time(s) 0.5894 
2023-12-01 16:48:06,564:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 3;	9: 3;	10: 3;	11: 2;	12: 3;	13: 2;	14: 2;	15: 2;	16: 2;	17: 3;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 3;	32: 3;	33: 2;	34: 3;	35: 2;	36: 3;	37: 3;	38: 3;	39: 2;	40: 2;	41: 3;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 2;	26105: 3;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:06,619:INFO::Validation loss decreased (1.356811 --> 1.353332).  Saving model ...
2023-12-01 16:48:06,622:INFO::Epoch: 10
tensor([[0.5391, 0.5403, 0.5386, 0.5386],
        [0.5391, 0.5403, 0.5387, 0.5386],
        [0.5391, 0.5403, 0.5386, 0.5386],
        [0.5429, 0.5407, 0.5418, 0.5417]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:06,623:INFO::its now!!!!!!!!5
2023-12-01 16:48:06,912:INFO::its now!!!!!!!!0
2023-12-01 16:48:06,913:INFO::its now!!!!!!!!3
2023-12-01 16:48:06,960:INFO::its now!!!!!!!!5
2023-12-01 16:48:07,122:INFO::its now!!!!!!!!
2023-12-01 16:48:07,122:INFO::its now!!!!!!!! on 
2023-12-01 16:48:07,159:INFO::its now!!!!!!!!5
2023-12-01 16:48:07,315:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:07,317:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.3170 | Train_Classification_Loss 1.3489 | Dmon_Loss -0.0637 | Val_Loss 1.3499 | Search Time(s) 0.5306 | Infer Time(s) 0.1646 | Time(s) 0.6951 
2023-12-01 16:48:07,358:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 3;	9: 3;	10: 3;	11: 2;	12: 3;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 3;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 3;	33: 2;	34: 3;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 3;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 3;	26104: 3;	26105: 3;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:07,360:INFO::Validation loss decreased (1.353332 --> 1.349889).  Saving model ...
2023-12-01 16:48:07,362:INFO::Epoch: 11
tensor([[0.5438, 0.5428, 0.5430, 0.5426],
        [0.5438, 0.5428, 0.5430, 0.5426],
        [0.5438, 0.5429, 0.5429, 0.5426],
        [0.5458, 0.5443, 0.5464, 0.5461]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:07,363:INFO::its now!!!!!!!!5
2023-12-01 16:48:07,514:INFO::its now!!!!!!!!0
2023-12-01 16:48:07,515:INFO::its now!!!!!!!!3
2023-12-01 16:48:07,544:INFO::its now!!!!!!!!5
2023-12-01 16:48:07,686:INFO::its now!!!!!!!!
2023-12-01 16:48:07,686:INFO::its now!!!!!!!! on 
2023-12-01 16:48:07,724:INFO::its now!!!!!!!!5
2023-12-01 16:48:07,877:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:07,879:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.3149 | Train_Classification_Loss 1.3466 | Dmon_Loss -0.0634 | Val_Loss 1.3476 | Search Time(s) 0.3600 | Infer Time(s) 0.1576 | Time(s) 0.5176 
2023-12-01 16:48:07,916:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 2;	4: 3;	5: 3;	6: 3;	7: 2;	8: 2;	9: 2;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 2;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 2;	32: 3;	33: 3;	34: 3;	35: 2;	36: 3;	37: 2;	38: 3;	39: 2;	40: 3;	41: 3;	42: 3;	43: 2;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 0;	26105: 3;	26106: 3;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 3;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:07,917:INFO::Validation loss decreased (1.349889 --> 1.347572).  Saving model ...
2023-12-01 16:48:07,919:INFO::Epoch: 12
tensor([[0.5463, 0.5471, 0.5480, 0.5479],
        [0.5463, 0.5471, 0.5481, 0.5479],
        [0.5463, 0.5472, 0.5480, 0.5478],
        [0.5504, 0.5492, 0.5488, 0.5512]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:07,919:INFO::its now!!!!!!!!5
2023-12-01 16:48:08,082:INFO::its now!!!!!!!!0
2023-12-01 16:48:08,083:INFO::its now!!!!!!!!3
2023-12-01 16:48:08,114:INFO::its now!!!!!!!!5
2023-12-01 16:48:08,262:INFO::its now!!!!!!!!
2023-12-01 16:48:08,262:INFO::its now!!!!!!!! on 
2023-12-01 16:48:08,301:INFO::its now!!!!!!!!5
2023-12-01 16:48:08,472:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:08,474:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.3107 | Train_Classification_Loss 1.3426 | Dmon_Loss -0.0637 | Val_Loss 1.3443 | Search Time(s) 0.3820 | Infer Time(s) 0.1725 | Time(s) 0.5545 
2023-12-01 16:48:08,516:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 3;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 3;	13: 2;	14: 2;	15: 3;	16: 2;	17: 3;	18: 3;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 3;	37: 2;	38: 3;	39: 2;	40: 2;	41: 3;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 3;	26101: 3;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 3;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:08,517:INFO::Validation loss decreased (1.347572 --> 1.344331).  Saving model ...
2023-12-01 16:48:08,520:INFO::Epoch: 13
tensor([[0.5502, 0.5521, 0.5507, 0.5534],
        [0.5502, 0.5521, 0.5507, 0.5534],
        [0.5502, 0.5522, 0.5506, 0.5534],
        [0.5557, 0.5544, 0.5527, 0.5538]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:08,520:INFO::its now!!!!!!!!5
2023-12-01 16:48:08,657:INFO::its now!!!!!!!!0
2023-12-01 16:48:08,658:INFO::its now!!!!!!!!3
2023-12-01 16:48:08,684:INFO::its now!!!!!!!!5
2023-12-01 16:48:08,841:INFO::its now!!!!!!!!
2023-12-01 16:48:08,842:INFO::its now!!!!!!!! on 
2023-12-01 16:48:08,891:INFO::its now!!!!!!!!5
2023-12-01 16:48:09,038:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:09,040:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.3084 | Train_Classification_Loss 1.3407 | Dmon_Loss -0.0646 | Val_Loss 1.3417 | Search Time(s) 0.3550 | Infer Time(s) 0.1656 | Time(s) 0.5206 
2023-12-01 16:48:09,081:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 0;	10: 3;	11: 3;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 3;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 3;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 3;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:09,082:INFO::Validation loss decreased (1.344331 --> 1.341724).  Saving model ...
2023-12-01 16:48:09,086:INFO::Epoch: 14
tensor([[0.5554, 0.5580, 0.5555, 0.5563],
        [0.5554, 0.5580, 0.5555, 0.5563],
        [0.5554, 0.5581, 0.5554, 0.5563],
        [0.5584, 0.5604, 0.5581, 0.5585]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:09,086:INFO::its now!!!!!!!!5
2023-12-01 16:48:09,231:INFO::its now!!!!!!!!0
2023-12-01 16:48:09,231:INFO::its now!!!!!!!!3
2023-12-01 16:48:09,273:INFO::its now!!!!!!!!5
2023-12-01 16:48:09,439:INFO::its now!!!!!!!!
2023-12-01 16:48:09,439:INFO::its now!!!!!!!! on 
2023-12-01 16:48:09,490:INFO::its now!!!!!!!!5
2023-12-01 16:48:09,628:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:09,630:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.3049 | Train_Classification_Loss 1.3374 | Dmon_Loss -0.0651 | Val_Loss 1.3387 | Search Time(s) 0.3900 | Infer Time(s) 0.1556 | Time(s) 0.5456 
2023-12-01 16:48:09,683:INFO::cluster info:
0: 2;	1: 2;	2: 3;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 3;	26105: 0;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:09,684:INFO::Validation loss decreased (1.341724 --> 1.338658).  Saving model ...
2023-12-01 16:48:09,688:INFO::Epoch: 15
tensor([[0.5602, 0.5611, 0.5601, 0.5604],
        [0.5602, 0.5611, 0.5602, 0.5603],
        [0.5602, 0.5611, 0.5601, 0.5603],
        [0.5622, 0.5635, 0.5630, 0.5632]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:09,689:INFO::its now!!!!!!!!5
2023-12-01 16:48:09,868:INFO::its now!!!!!!!!0
2023-12-01 16:48:09,869:INFO::its now!!!!!!!!3
2023-12-01 16:48:09,912:INFO::its now!!!!!!!!5
2023-12-01 16:48:10,077:INFO::its now!!!!!!!!
2023-12-01 16:48:10,077:INFO::its now!!!!!!!! on 
2023-12-01 16:48:10,112:INFO::its now!!!!!!!!5
2023-12-01 16:48:10,273:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:10,275:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.3020 | Train_Classification_Loss 1.3340 | Dmon_Loss -0.0639 | Val_Loss 1.3356 | Search Time(s) 0.4239 | Infer Time(s) 0.1636 | Time(s) 0.5874 
2023-12-01 16:48:10,315:INFO::cluster info:
0: 2;	1: 3;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 3;	16: 2;	17: 2;	18: 3;	19: 2;	20: 3;	21: 3;	22: 2;	23: 2;	24: 3;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 3;	31: 2;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 0;	38: 3;	39: 3;	40: 2;	41: 3;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:10,316:INFO::Validation loss decreased (1.338658 --> 1.335585).  Saving model ...
2023-12-01 16:48:10,319:INFO::Epoch: 16
tensor([[0.5648, 0.5626, 0.5648, 0.5649],
        [0.5648, 0.5626, 0.5648, 0.5649],
        [0.5648, 0.5627, 0.5648, 0.5649],
        [0.5667, 0.5651, 0.5677, 0.5678]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:10,319:INFO::its now!!!!!!!!5
2023-12-01 16:48:10,452:INFO::its now!!!!!!!!0
2023-12-01 16:48:10,453:INFO::its now!!!!!!!!3
2023-12-01 16:48:10,478:INFO::its now!!!!!!!!5
2023-12-01 16:48:10,652:INFO::its now!!!!!!!!
2023-12-01 16:48:10,652:INFO::its now!!!!!!!! on 
2023-12-01 16:48:10,687:INFO::its now!!!!!!!!5
2023-12-01 16:48:10,853:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:10,854:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 1.2973 | Train_Classification_Loss 1.3296 | Dmon_Loss -0.0648 | Val_Loss 1.3311 | Search Time(s) 0.3660 | Infer Time(s) 0.1705 | Time(s) 0.5366 
2023-12-01 16:48:10,898:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 3;	4: 3;	5: 2;	6: 2;	7: 2;	8: 3;	9: 3;	10: 3;	11: 2;	12: 3;	13: 2;	14: 2;	15: 2;	16: 2;	17: 3;	18: 2;	19: 3;	20: 2;	21: 3;	22: 2;	23: 2;	24: 3;	25: 3;	26: 2;	27: 3;	28: 3;	29: 2;	30: 3;	31: 2;	32: 2;	33: 2;	34: 3;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 3;	41: 3;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:10,899:INFO::Validation loss decreased (1.335585 --> 1.331110).  Saving model ...
2023-12-01 16:48:10,902:INFO::Epoch: 17
tensor([[0.5697, 0.5663, 0.5699, 0.5673],
        [0.5697, 0.5663, 0.5699, 0.5673],
        [0.5697, 0.5665, 0.5698, 0.5673],
        [0.5719, 0.5688, 0.5728, 0.5702]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:10,902:INFO::its now!!!!!!!!5
2023-12-01 16:48:11,063:INFO::its now!!!!!!!!0
2023-12-01 16:48:11,063:INFO::its now!!!!!!!!3
2023-12-01 16:48:11,088:INFO::its now!!!!!!!!5
2023-12-01 16:48:11,354:INFO::its now!!!!!!!!
2023-12-01 16:48:11,354:INFO::its now!!!!!!!! on 
2023-12-01 16:48:11,388:INFO::its now!!!!!!!!5
2023-12-01 16:48:11,537:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:11,538:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 1.2931 | Train_Classification_Loss 1.3259 | Dmon_Loss -0.0658 | Val_Loss 1.3271 | Search Time(s) 0.4837 | Infer Time(s) 0.1546 | Time(s) 0.6383 
2023-12-01 16:48:11,577:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 3;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 3;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:11,578:INFO::Validation loss decreased (1.331110 --> 1.327059).  Saving model ...
2023-12-01 16:48:11,580:INFO::Epoch: 18
tensor([[0.5747, 0.5709, 0.5725, 0.5715],
        [0.5747, 0.5709, 0.5725, 0.5715],
        [0.5747, 0.5711, 0.5725, 0.5715],
        [0.5774, 0.5734, 0.5754, 0.5741]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:11,582:INFO::its now!!!!!!!!5
2023-12-01 16:48:11,761:INFO::its now!!!!!!!!0
2023-12-01 16:48:11,761:INFO::its now!!!!!!!!3
2023-12-01 16:48:11,788:INFO::its now!!!!!!!!5
2023-12-01 16:48:11,974:INFO::its now!!!!!!!!
2023-12-01 16:48:11,974:INFO::its now!!!!!!!! on 
2023-12-01 16:48:12,009:INFO::its now!!!!!!!!5
2023-12-01 16:48:12,157:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:12,158:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 1.2906 | Train_Classification_Loss 1.3236 | Dmon_Loss -0.0659 | Val_Loss 1.3234 | Search Time(s) 0.4259 | Infer Time(s) 0.1526 | Time(s) 0.5785 
2023-12-01 16:48:12,201:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 3;	9: 2;	10: 3;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 2;	25: 2;	26: 3;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:12,202:INFO::Validation loss decreased (1.327059 --> 1.323385).  Saving model ...
2023-12-01 16:48:12,205:INFO::Epoch: 19
tensor([[0.5773, 0.5763, 0.5768, 0.5769],
        [0.5773, 0.5763, 0.5769, 0.5769],
        [0.5773, 0.5764, 0.5768, 0.5769],
        [0.5802, 0.5787, 0.5797, 0.5790]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:12,206:INFO::its now!!!!!!!!5
2023-12-01 16:48:12,378:INFO::its now!!!!!!!!0
2023-12-01 16:48:12,379:INFO::its now!!!!!!!!3
2023-12-01 16:48:12,405:INFO::its now!!!!!!!!5
2023-12-01 16:48:12,546:INFO::its now!!!!!!!!
2023-12-01 16:48:12,546:INFO::its now!!!!!!!! on 
2023-12-01 16:48:12,584:INFO::its now!!!!!!!!5
2023-12-01 16:48:12,729:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:12,730:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 1.2832 | Train_Classification_Loss 1.3158 | Dmon_Loss -0.0653 | Val_Loss 1.3223 | Search Time(s) 0.3790 | Infer Time(s) 0.1486 | Time(s) 0.5276 
2023-12-01 16:48:12,770:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 3;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 3;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 3;	26100: 3;	26101: 2;	26102: 2;	26103: 3;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:12,771:INFO::Validation loss decreased (1.323385 --> 1.322252).  Saving model ...
2023-12-01 16:48:12,774:INFO::Epoch: 20
tensor([[0.5786, 0.5815, 0.5815, 0.5823],
        [0.5786, 0.5815, 0.5815, 0.5823],
        [0.5787, 0.5816, 0.5815, 0.5823],
        [0.5816, 0.5838, 0.5843, 0.5840]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:12,775:INFO::its now!!!!!!!!5
2023-12-01 16:48:12,931:INFO::its now!!!!!!!!0
2023-12-01 16:48:12,932:INFO::its now!!!!!!!!3
2023-12-01 16:48:12,959:INFO::its now!!!!!!!!5
2023-12-01 16:48:13,120:INFO::its now!!!!!!!!
2023-12-01 16:48:13,120:INFO::its now!!!!!!!! on 
2023-12-01 16:48:13,170:INFO::its now!!!!!!!!5
2023-12-01 16:48:13,301:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:13,302:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 1.2835 | Train_Classification_Loss 1.3171 | Dmon_Loss -0.0672 | Val_Loss 1.3192 | Search Time(s) 0.3820 | Infer Time(s) 0.1466 | Time(s) 0.5286 
2023-12-01 16:48:13,338:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 3;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 3;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:13,339:INFO::Validation loss decreased (1.322252 --> 1.319216).  Saving model ...
2023-12-01 16:48:13,343:INFO::Epoch: 21
tensor([[0.5814, 0.5863, 0.5860, 0.5851],
        [0.5814, 0.5863, 0.5861, 0.5850],
        [0.5815, 0.5864, 0.5860, 0.5851],
        [0.5848, 0.5887, 0.5867, 0.5886]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:13,344:INFO::its now!!!!!!!!5
2023-12-01 16:48:13,542:INFO::its now!!!!!!!!0
2023-12-01 16:48:13,543:INFO::its now!!!!!!!!3
2023-12-01 16:48:13,586:INFO::its now!!!!!!!!5
2023-12-01 16:48:13,828:INFO::its now!!!!!!!!
2023-12-01 16:48:13,828:INFO::its now!!!!!!!! on 
2023-12-01 16:48:13,868:INFO::its now!!!!!!!!5
2023-12-01 16:48:14,096:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:14,096:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 1.2769 | Train_Classification_Loss 1.3100 | Dmon_Loss -0.0664 | Val_Loss 1.3138 | Search Time(s) 0.5286 | Infer Time(s) 0.2284 | Time(s) 0.7570 
2023-12-01 16:48:14,139:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 3;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 3;	17: 2;	18: 2;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 3;	25: 2;	26: 3;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 3;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:14,140:INFO::Validation loss decreased (1.319216 --> 1.313768).  Saving model ...
2023-12-01 16:48:14,143:INFO::Epoch: 22
tensor([[0.5839, 0.5888, 0.5894, 0.5876],
        [0.5839, 0.5888, 0.5894, 0.5876],
        [0.5840, 0.5889, 0.5894, 0.5876],
        [0.5875, 0.5911, 0.5889, 0.5920]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:14,144:INFO::its now!!!!!!!!5
2023-12-01 16:48:14,279:INFO::its now!!!!!!!!0
2023-12-01 16:48:14,280:INFO::its now!!!!!!!!3
2023-12-01 16:48:14,308:INFO::its now!!!!!!!!5
2023-12-01 16:48:14,469:INFO::its now!!!!!!!!
2023-12-01 16:48:14,469:INFO::its now!!!!!!!! on 
2023-12-01 16:48:14,518:INFO::its now!!!!!!!!5
2023-12-01 16:48:14,678:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:14,680:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 1.2772 | Train_Classification_Loss 1.3115 | Dmon_Loss -0.0686 | Val_Loss 1.3120 | Search Time(s) 0.3600 | Infer Time(s) 0.1765 | Time(s) 0.5366 
2023-12-01 16:48:14,732:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:14,733:INFO::Validation loss decreased (1.313768 --> 1.312035).  Saving model ...
2023-12-01 16:48:14,737:INFO::Epoch: 23
tensor([[0.5889, 0.5939, 0.5911, 0.5931],
        [0.5889, 0.5939, 0.5911, 0.5931],
        [0.5890, 0.5940, 0.5911, 0.5931],
        [0.5931, 0.5962, 0.5938, 0.5938]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:14,738:INFO::its now!!!!!!!!5
2023-12-01 16:48:14,901:INFO::its now!!!!!!!!0
2023-12-01 16:48:14,902:INFO::its now!!!!!!!!3
2023-12-01 16:48:14,948:INFO::its now!!!!!!!!5
2023-12-01 16:48:15,130:INFO::its now!!!!!!!!
2023-12-01 16:48:15,130:INFO::its now!!!!!!!! on 
2023-12-01 16:48:15,170:INFO::its now!!!!!!!!5
2023-12-01 16:48:15,326:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:15,327:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 1.2679 | Train_Classification_Loss 1.3013 | Dmon_Loss -0.0668 | Val_Loss 1.3081 | Search Time(s) 0.4328 | Infer Time(s) 0.1596 | Time(s) 0.5924 
2023-12-01 16:48:15,369:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:15,370:INFO::Validation loss decreased (1.312035 --> 1.308098).  Saving model ...
2023-12-01 16:48:15,372:INFO::Epoch: 24
tensor([[0.5941, 0.5965, 0.5948, 0.5987],
        [0.5941, 0.5965, 0.5948, 0.5987],
        [0.5942, 0.5967, 0.5948, 0.5988],
        [0.5988, 0.5988, 0.5990, 0.5975]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:15,373:INFO::its now!!!!!!!!5
2023-12-01 16:48:15,506:INFO::its now!!!!!!!!0
2023-12-01 16:48:15,506:INFO::its now!!!!!!!!3
2023-12-01 16:48:15,533:INFO::its now!!!!!!!!5
2023-12-01 16:48:15,680:INFO::its now!!!!!!!!
2023-12-01 16:48:15,680:INFO::its now!!!!!!!! on 
2023-12-01 16:48:15,714:INFO::its now!!!!!!!!5
2023-12-01 16:48:15,892:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:15,893:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 1.2665 | Train_Classification_Loss 1.3001 | Dmon_Loss -0.0672 | Val_Loss 1.3043 | Search Time(s) 0.3401 | Infer Time(s) 0.1815 | Time(s) 0.5216 
2023-12-01 16:48:15,941:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 3;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 3;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 3;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:15,943:INFO::Validation loss decreased (1.308098 --> 1.304256).  Saving model ...
2023-12-01 16:48:15,946:INFO::Epoch: 25
tensor([[0.5991, 0.6004, 0.5992, 0.6016],
        [0.5991, 0.6004, 0.5992, 0.6016],
        [0.5993, 0.6006, 0.5992, 0.6017],
        [0.6043, 0.6026, 0.6017, 0.6019]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:16,011:INFO::its now!!!!!!!!5
2023-12-01 16:48:16,187:INFO::its now!!!!!!!!0
2023-12-01 16:48:16,188:INFO::its now!!!!!!!!3
2023-12-01 16:48:16,236:INFO::its now!!!!!!!!5
2023-12-01 16:48:16,403:INFO::its now!!!!!!!!
2023-12-01 16:48:16,403:INFO::its now!!!!!!!! on 
2023-12-01 16:48:16,443:INFO::its now!!!!!!!!5
2023-12-01 16:48:16,637:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:16,639:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 1.2617 | Train_Classification_Loss 1.2955 | Dmon_Loss -0.0677 | Val_Loss 1.3004 | Search Time(s) 0.4946 | Infer Time(s) 0.1995 | Time(s) 0.6940 
2023-12-01 16:48:16,709:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 3;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:16,711:INFO::Validation loss decreased (1.304256 --> 1.300409).  Saving model ...
2023-12-01 16:48:16,714:INFO::Epoch: 26
tensor([[0.6016, 0.6059, 0.6050, 0.6070],
        [0.6050, 0.6023, 0.6051, 0.6069],
        [0.6052, 0.6061, 0.6015, 0.6070],
        [0.6108, 0.6046, 0.6066, 0.6077]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:16,715:INFO::its now!!!!!!!!5
2023-12-01 16:48:17,020:INFO::its now!!!!!!!!0
2023-12-01 16:48:17,020:INFO::its now!!!!!!!!3
2023-12-01 16:48:17,055:INFO::its now!!!!!!!!5
2023-12-01 16:48:17,332:INFO::its now!!!!!!!!
2023-12-01 16:48:17,332:INFO::its now!!!!!!!! on 
2023-12-01 16:48:17,391:INFO::its now!!!!!!!!5
2023-12-01 16:48:17,575:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:17,577:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 1.2571 | Train_Classification_Loss 1.2922 | Dmon_Loss -0.0701 | Val_Loss 1.2962 | Search Time(s) 0.6654 | Infer Time(s) 0.1985 | Time(s) 0.8639 
2023-12-01 16:48:17,616:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:17,617:INFO::Validation loss decreased (1.300409 --> 1.296225).  Saving model ...
2023-12-01 16:48:17,619:INFO::Epoch: 27
tensor([[0.6051, 0.6109, 0.6102, 0.6097],
        [0.6102, 0.6056, 0.6102, 0.6097],
        [0.6103, 0.6111, 0.6050, 0.6097],
        [0.6142, 0.6079, 0.6112, 0.6129]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:17,620:INFO::its now!!!!!!!!5
2023-12-01 16:48:17,758:INFO::its now!!!!!!!!0
2023-12-01 16:48:17,758:INFO::its now!!!!!!!!3
2023-12-01 16:48:17,802:INFO::its now!!!!!!!!5
2023-12-01 16:48:17,949:INFO::its now!!!!!!!!
2023-12-01 16:48:17,949:INFO::its now!!!!!!!! on 
2023-12-01 16:48:17,984:INFO::its now!!!!!!!!5
2023-12-01 16:48:18,131:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:18,133:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 1.2496 | Train_Classification_Loss 1.2850 | Dmon_Loss -0.0708 | Val_Loss 1.2863 | Search Time(s) 0.3630 | Infer Time(s) 0.1512 | Time(s) 0.5142 
2023-12-01 16:48:18,171:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:18,172:INFO::Validation loss decreased (1.296225 --> 1.286261).  Saving model ...
2023-12-01 16:48:18,174:INFO::Epoch: 28
tensor([[0.6085, 0.6134, 0.6145, 0.6128],
        [0.6143, 0.6090, 0.6129, 0.6128],
        [0.6145, 0.6137, 0.6085, 0.6129],
        [0.6159, 0.6112, 0.6152, 0.6171]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:18,175:INFO::its now!!!!!!!!5
2023-12-01 16:48:18,299:INFO::its now!!!!!!!!0
2023-12-01 16:48:18,300:INFO::its now!!!!!!!!3
2023-12-01 16:48:18,328:INFO::its now!!!!!!!!5
2023-12-01 16:48:18,491:INFO::its now!!!!!!!!
2023-12-01 16:48:18,492:INFO::its now!!!!!!!! on 
2023-12-01 16:48:18,532:INFO::its now!!!!!!!!5
2023-12-01 16:48:18,672:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:18,673:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 1.2436 | Train_Classification_Loss 1.2792 | Dmon_Loss -0.0713 | Val_Loss 1.2812 | Search Time(s) 0.3576 | Infer Time(s) 0.1416 | Time(s) 0.4992 
2023-12-01 16:48:18,709:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 3;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:18,710:INFO::Validation loss decreased (1.286261 --> 1.281230).  Saving model ...
2023-12-01 16:48:18,713:INFO::Epoch: 29
tensor([[0.6111, 0.6156, 0.6167, 0.6153],
        [0.6165, 0.6116, 0.6151, 0.6153],
        [0.6167, 0.6158, 0.6112, 0.6154],
        [0.6176, 0.6138, 0.6180, 0.6193]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:18,714:INFO::its now!!!!!!!!5
2023-12-01 16:48:18,871:INFO::its now!!!!!!!!0
2023-12-01 16:48:18,872:INFO::its now!!!!!!!!3
2023-12-01 16:48:18,904:INFO::its now!!!!!!!!5
2023-12-01 16:48:19,046:INFO::its now!!!!!!!!
2023-12-01 16:48:19,046:INFO::its now!!!!!!!! on 
2023-12-01 16:48:19,103:INFO::its now!!!!!!!!5
2023-12-01 16:48:19,247:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 1.2419 | Train_Classification_Loss 1.2782 | Dmon_Loss -0.0725 | Val_Loss 1.2830 | Search Time(s) 0.3905 | Infer Time(s) 0.1446 | Time(s) 0.5351 
2023-12-01 16:48:19,280:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:19,282:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:19,284:INFO::Epoch: 30
tensor([[0.6153, 0.6196, 0.6178, 0.6197],
        [0.6175, 0.6159, 0.6192, 0.6197],
        [0.6180, 0.6198, 0.6156, 0.6198],
        [0.6216, 0.6181, 0.6223, 0.6204]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:19,285:INFO::its now!!!!!!!!5
2023-12-01 16:48:19,432:INFO::its now!!!!!!!!0
2023-12-01 16:48:19,433:INFO::its now!!!!!!!!3
2023-12-01 16:48:19,465:INFO::its now!!!!!!!!5
2023-12-01 16:48:19,620:INFO::its now!!!!!!!!
2023-12-01 16:48:19,620:INFO::its now!!!!!!!! on 
2023-12-01 16:48:19,675:INFO::its now!!!!!!!!5
2023-12-01 16:48:19,833:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:19,834:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 1.2378 | Train_Classification_Loss 1.2744 | Dmon_Loss -0.0732 | Val_Loss 1.2784 | Search Time(s) 0.3885 | Infer Time(s) 0.1616 | Time(s) 0.5501 
2023-12-01 16:48:19,881:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:19,883:INFO::Validation loss decreased (1.281230 --> 1.278399).  Saving model ...
2023-12-01 16:48:19,886:INFO::Epoch: 31
tensor([[0.6191, 0.6233, 0.6201, 0.6220],
        [0.6197, 0.6199, 0.6212, 0.6237],
        [0.6203, 0.6235, 0.6196, 0.6221],
        [0.6237, 0.6220, 0.6262, 0.6227]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:19,886:INFO::its now!!!!!!!!5
2023-12-01 16:48:20,022:INFO::its now!!!!!!!!0
2023-12-01 16:48:20,023:INFO::its now!!!!!!!!3
2023-12-01 16:48:20,065:INFO::its now!!!!!!!!5
2023-12-01 16:48:20,220:INFO::its now!!!!!!!!
2023-12-01 16:48:20,220:INFO::its now!!!!!!!! on 
2023-12-01 16:48:20,254:INFO::its now!!!!!!!!5
2023-12-01 16:48:20,376:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:20,378:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 1.2273 | Train_Classification_Loss 1.2628 | Dmon_Loss -0.0710 | Val_Loss 1.2743 | Search Time(s) 0.3676 | Infer Time(s) 0.1253 | Time(s) 0.4928 
2023-12-01 16:48:20,424:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:20,424:INFO::Validation loss decreased (1.278399 --> 1.274310).  Saving model ...
2023-12-01 16:48:20,426:INFO::Epoch: 32
tensor([[0.6242, 0.6252, 0.6246, 0.6266],
        [0.6240, 0.6252, 0.6256, 0.6258],
        [0.6246, 0.6254, 0.6249, 0.6267],
        [0.6281, 0.6273, 0.6281, 0.6272]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:20,427:INFO::its now!!!!!!!!5
2023-12-01 16:48:20,565:INFO::its now!!!!!!!!0
2023-12-01 16:48:20,565:INFO::its now!!!!!!!!3
2023-12-01 16:48:20,592:INFO::its now!!!!!!!!5
2023-12-01 16:48:20,739:INFO::its now!!!!!!!!
2023-12-01 16:48:20,740:INFO::its now!!!!!!!! on 
2023-12-01 16:48:20,789:INFO::its now!!!!!!!!5
2023-12-01 16:48:20,921:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:20,923:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 1.2193 | Train_Classification_Loss 1.2557 | Dmon_Loss -0.0728 | Val_Loss 1.2630 | Search Time(s) 0.3421 | Infer Time(s) 0.1526 | Time(s) 0.4947 
2023-12-01 16:48:20,964:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:20,965:INFO::Validation loss decreased (1.274310 --> 1.262994).  Saving model ...
2023-12-01 16:48:20,967:INFO::Epoch: 33
tensor([[0.6296, 0.6290, 0.6297, 0.6289],
        [0.6289, 0.6307, 0.6306, 0.6268],
        [0.6295, 0.6292, 0.6305, 0.6291],
        [0.6304, 0.6328, 0.6319, 0.6322]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:20,968:INFO::its now!!!!!!!!5
2023-12-01 16:48:21,154:INFO::its now!!!!!!!!0
2023-12-01 16:48:21,155:INFO::its now!!!!!!!!3
2023-12-01 16:48:21,199:INFO::its now!!!!!!!!5
2023-12-01 16:48:21,366:INFO::its now!!!!!!!!
2023-12-01 16:48:21,367:INFO::its now!!!!!!!! on 
2023-12-01 16:48:21,410:INFO::its now!!!!!!!!5
2023-12-01 16:48:21,564:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:21,566:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 1.2097 | Train_Classification_Loss 1.2474 | Dmon_Loss -0.0754 | Val_Loss 1.2541 | Search Time(s) 0.4389 | Infer Time(s) 0.1596 | Time(s) 0.5985 
2023-12-01 16:48:21,607:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:21,609:INFO::Validation loss decreased (1.262994 --> 1.254084).  Saving model ...
2023-12-01 16:48:21,611:INFO::Epoch: 34
tensor([[0.6356, 0.6344, 0.6323, 0.6338],
        [0.6347, 0.6335, 0.6365, 0.6311],
        [0.6353, 0.6346, 0.6335, 0.6339],
        [0.6352, 0.6356, 0.6372, 0.6382]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:21,611:INFO::its now!!!!!!!!5
2023-12-01 16:48:21,770:INFO::its now!!!!!!!!0
2023-12-01 16:48:21,771:INFO::its now!!!!!!!!3
2023-12-01 16:48:21,800:INFO::its now!!!!!!!!5
2023-12-01 16:48:21,951:INFO::its now!!!!!!!!
2023-12-01 16:48:21,951:INFO::its now!!!!!!!! on 
2023-12-01 16:48:22,006:INFO::its now!!!!!!!!5
2023-12-01 16:48:22,148:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 1.2163 | Train_Classification_Loss 1.2542 | Dmon_Loss -0.0758 | Val_Loss 1.2581 | Search Time(s) 0.3740 | Infer Time(s) 0.1641 | Time(s) 0.5381 
2023-12-01 16:48:22,195:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:22,196:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:22,198:INFO::Epoch: 35
tensor([[0.6386, 0.6401, 0.6366, 0.6393],
        [0.6404, 0.6380, 0.6395, 0.6365],
        [0.6384, 0.6402, 0.6380, 0.6395],
        [0.6407, 0.6400, 0.6428, 0.6413]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:22,199:INFO::its now!!!!!!!!5
2023-12-01 16:48:22,364:INFO::its now!!!!!!!!0
2023-12-01 16:48:22,365:INFO::its now!!!!!!!!3
2023-12-01 16:48:22,414:INFO::its now!!!!!!!!5
2023-12-01 16:48:22,585:INFO::its now!!!!!!!!
2023-12-01 16:48:22,585:INFO::its now!!!!!!!! on 
2023-12-01 16:48:22,626:INFO::its now!!!!!!!!5
2023-12-01 16:48:22,825:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:22,826:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 1.2030 | Train_Classification_Loss 1.2401 | Dmon_Loss -0.0742 | Val_Loss 1.2540 | Search Time(s) 0.4275 | Infer Time(s) 0.2014 | Time(s) 0.6289 
2023-12-01 16:48:22,877:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:22,877:INFO::Validation loss decreased (1.254084 --> 1.254038).  Saving model ...
2023-12-01 16:48:22,880:INFO::Epoch: 36
tensor([[0.6427, 0.6429, 0.6414, 0.6448],
        [0.6433, 0.6428, 0.6436, 0.6419],
        [0.6425, 0.6431, 0.6429, 0.6450],
        [0.6461, 0.6449, 0.6456, 0.6454]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:22,881:INFO::its now!!!!!!!!5
2023-12-01 16:48:23,038:INFO::its now!!!!!!!!0
2023-12-01 16:48:23,039:INFO::its now!!!!!!!!3
2023-12-01 16:48:23,068:INFO::its now!!!!!!!!5
2023-12-01 16:48:23,252:INFO::its now!!!!!!!!
2023-12-01 16:48:23,252:INFO::its now!!!!!!!! on 
2023-12-01 16:48:23,309:INFO::its now!!!!!!!!5
2023-12-01 16:48:23,468:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:23,469:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 1.1902 | Train_Classification_Loss 1.2277 | Dmon_Loss -0.0751 | Val_Loss 1.2394 | Search Time(s) 0.4280 | Infer Time(s) 0.1626 | Time(s) 0.5905 
2023-12-01 16:48:23,507:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:23,507:INFO::Validation loss decreased (1.254038 --> 1.239354).  Saving model ...
2023-12-01 16:48:23,509:INFO::Epoch: 37
tensor([[0.6478, 0.6475, 0.6471, 0.6476],
        [0.6478, 0.6485, 0.6457, 0.6480],
        [0.6476, 0.6478, 0.6487, 0.6478],
        [0.6489, 0.6506, 0.6501, 0.6507]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:23,510:INFO::its now!!!!!!!!5
2023-12-01 16:48:23,654:INFO::its now!!!!!!!!0
2023-12-01 16:48:23,654:INFO::its now!!!!!!!!3
2023-12-01 16:48:23,704:INFO::its now!!!!!!!!5
2023-12-01 16:48:23,859:INFO::its now!!!!!!!!
2023-12-01 16:48:23,859:INFO::its now!!!!!!!! on 
2023-12-01 16:48:23,915:INFO::its now!!!!!!!!5
2023-12-01 16:48:24,066:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 1.1925 | Train_Classification_Loss 1.2316 | Dmon_Loss -0.0782 | Val_Loss 1.2414 | Search Time(s) 0.4039 | Infer Time(s) 0.1536 | Time(s) 0.5575 
2023-12-01 16:48:24,100:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:24,101:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:24,103:INFO::Epoch: 38
tensor([[0.6505, 0.6525, 0.6525, 0.6517],
        [0.6525, 0.6514, 0.6494, 0.6538],
        [0.6527, 0.6527, 0.6517, 0.6520],
        [0.6530, 0.6560, 0.6549, 0.6534]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:24,103:INFO::its now!!!!!!!!5
2023-12-01 16:48:24,257:INFO::its now!!!!!!!!0
2023-12-01 16:48:24,257:INFO::its now!!!!!!!!3
2023-12-01 16:48:24,300:INFO::its now!!!!!!!!5
2023-12-01 16:48:24,464:INFO::its now!!!!!!!!
2023-12-01 16:48:24,464:INFO::its now!!!!!!!! on 
2023-12-01 16:48:24,516:INFO::its now!!!!!!!!5
2023-12-01 16:48:24,649:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:24,650:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 1.1758 | Train_Classification_Loss 1.2153 | Dmon_Loss -0.0790 | Val_Loss 1.2219 | Search Time(s) 0.3965 | Infer Time(s) 0.1516 | Time(s) 0.5481 
2023-12-01 16:48:24,698:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:24,699:INFO::Validation loss decreased (1.239354 --> 1.221874).  Saving model ...
2023-12-01 16:48:24,704:INFO::Epoch: 39
tensor([[0.6553, 0.6585, 0.6552, 0.6576],
        [0.6584, 0.6565, 0.6549, 0.6567],
        [0.6586, 0.6552, 0.6569, 0.6578],
        [0.6588, 0.6588, 0.6609, 0.6583]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:24,705:INFO::its now!!!!!!!!5
2023-12-01 16:48:24,894:INFO::its now!!!!!!!!0
2023-12-01 16:48:24,895:INFO::its now!!!!!!!!3
2023-12-01 16:48:24,940:INFO::its now!!!!!!!!5
2023-12-01 16:48:25,124:INFO::its now!!!!!!!!
2023-12-01 16:48:25,124:INFO::its now!!!!!!!! on 
2023-12-01 16:48:25,178:INFO::its now!!!!!!!!5
2023-12-01 16:48:25,332:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 1.1768 | Train_Classification_Loss 1.2149 | Dmon_Loss -0.0762 | Val_Loss 1.2316 | Search Time(s) 0.4763 | Infer Time(s) 0.1551 | Time(s) 0.6314 
2023-12-01 16:48:25,379:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:25,380:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:25,384:INFO::Epoch: 40
tensor([[0.6612, 0.6615, 0.6602, 0.6641],
        [0.6613, 0.6626, 0.6611, 0.6619],
        [0.6620, 0.6600, 0.6631, 0.6644],
        [0.6653, 0.6637, 0.6639, 0.6643]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:25,385:INFO::its now!!!!!!!!5
2023-12-01 16:48:25,533:INFO::its now!!!!!!!!0
2023-12-01 16:48:25,533:INFO::its now!!!!!!!!3
2023-12-01 16:48:25,577:INFO::its now!!!!!!!!5
2023-12-01 16:48:25,723:INFO::its now!!!!!!!!
2023-12-01 16:48:25,723:INFO::its now!!!!!!!! on 
2023-12-01 16:48:25,754:INFO::its now!!!!!!!!5
2023-12-01 16:48:25,881:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:25,882:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 1.1645 | Train_Classification_Loss 1.2038 | Dmon_Loss -0.0785 | Val_Loss 1.2127 | Search Time(s) 0.3710 | Infer Time(s) 0.1297 | Time(s) 0.5007 
2023-12-01 16:48:25,918:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:25,919:INFO::Validation loss decreased (1.221874 --> 1.212657).  Saving model ...
2023-12-01 16:48:25,921:INFO::Epoch: 41
tensor([[0.6674, 0.6665, 0.6662, 0.6675],
        [0.6661, 0.6657, 0.6676, 0.6681],
        [0.6669, 0.6659, 0.6696, 0.6677],
        [0.6686, 0.6697, 0.6688, 0.6707]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:25,922:INFO::its now!!!!!!!!5
2023-12-01 16:48:26,085:INFO::its now!!!!!!!!0
2023-12-01 16:48:26,086:INFO::its now!!!!!!!!3
2023-12-01 16:48:26,116:INFO::its now!!!!!!!!5
2023-12-01 16:48:26,280:INFO::its now!!!!!!!!
2023-12-01 16:48:26,280:INFO::its now!!!!!!!! on 
2023-12-01 16:48:26,339:INFO::its now!!!!!!!!5
2023-12-01 16:48:26,487:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 1.1646 | Train_Classification_Loss 1.2034 | Dmon_Loss -0.0776 | Val_Loss 1.2197 | Search Time(s) 0.4161 | Infer Time(s) 0.1516 | Time(s) 0.5677 
2023-12-01 16:48:26,531:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 3;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:26,533:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:26,535:INFO::Epoch: 42
tensor([[0.6748, 0.6735, 0.6737, 0.6691],
        [0.6729, 0.6718, 0.6753, 0.6713],
        [0.6738, 0.6733, 0.6731, 0.6741],
        [0.6749, 0.6772, 0.6756, 0.6739]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:26,536:INFO::its now!!!!!!!!5
2023-12-01 16:48:26,700:INFO::its now!!!!!!!!0
2023-12-01 16:48:26,701:INFO::its now!!!!!!!!3
2023-12-01 16:48:26,746:INFO::its now!!!!!!!!5
2023-12-01 16:48:26,903:INFO::its now!!!!!!!!
2023-12-01 16:48:26,903:INFO::its now!!!!!!!! on 
2023-12-01 16:48:26,936:INFO::its now!!!!!!!!5
2023-12-01 16:48:27,089:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:27,091:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 1.1377 | Train_Classification_Loss 1.1789 | Dmon_Loss -0.0824 | Val_Loss 1.1927 | Search Time(s) 0.3975 | Infer Time(s) 0.1586 | Time(s) 0.5561 
2023-12-01 16:48:27,126:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:27,127:INFO::Validation loss decreased (1.212657 --> 1.192698).  Saving model ...
2023-12-01 16:48:27,130:INFO::Epoch: 43
tensor([[0.6786, 0.6810, 0.6815, 0.6745],
        [0.6802, 0.6791, 0.6792, 0.6773],
        [0.6812, 0.6811, 0.6792, 0.6774],
        [0.6823, 0.6810, 0.6831, 0.6798]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:27,130:INFO::its now!!!!!!!!5
2023-12-01 16:48:27,284:INFO::its now!!!!!!!!0
2023-12-01 16:48:27,285:INFO::its now!!!!!!!!3
2023-12-01 16:48:27,309:INFO::its now!!!!!!!!5
2023-12-01 16:48:27,456:INFO::its now!!!!!!!!
2023-12-01 16:48:27,456:INFO::its now!!!!!!!! on 
2023-12-01 16:48:27,505:INFO::its now!!!!!!!!5
2023-12-01 16:48:27,642:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 1.1491 | Train_Classification_Loss 1.1905 | Dmon_Loss -0.0829 | Val_Loss 1.2037 | Search Time(s) 0.3556 | Infer Time(s) 0.1596 | Time(s) 0.5152 
2023-12-01 16:48:27,694:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:27,695:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:27,697:INFO::Epoch: 44
tensor([[0.6826, 0.6869, 0.6855, 0.6795],
        [0.6839, 0.6849, 0.6834, 0.6827],
        [0.6853, 0.6871, 0.6844, 0.6814],
        [0.6883, 0.6851, 0.6869, 0.6849]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:27,698:INFO::its now!!!!!!!!5
2023-12-01 16:48:27,866:INFO::its now!!!!!!!!0
2023-12-01 16:48:27,867:INFO::its now!!!!!!!!3
2023-12-01 16:48:27,909:INFO::its now!!!!!!!!5
2023-12-01 16:48:28,049:INFO::its now!!!!!!!!
2023-12-01 16:48:28,049:INFO::its now!!!!!!!! on 
2023-12-01 16:48:28,099:INFO::its now!!!!!!!!5
2023-12-01 16:48:28,279:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 1.1407 | Train_Classification_Loss 1.1829 | Dmon_Loss -0.0844 | Val_Loss 1.1970 | Search Time(s) 0.3810 | Infer Time(s) 0.2020 | Time(s) 0.5830 
2023-12-01 16:48:28,335:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:28,337:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:48:28,340:INFO::Epoch: 45
tensor([[0.6873, 0.6899, 0.6902, 0.6849],
        [0.6884, 0.6878, 0.6881, 0.6882],
        [0.6899, 0.6902, 0.6898, 0.6862],
        [0.6913, 0.6899, 0.6914, 0.6902]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:28,340:INFO::its now!!!!!!!!5
2023-12-01 16:48:28,518:INFO::its now!!!!!!!!0
2023-12-01 16:48:28,519:INFO::its now!!!!!!!!3
2023-12-01 16:48:28,562:INFO::its now!!!!!!!!5
2023-12-01 16:48:28,720:INFO::its now!!!!!!!!
2023-12-01 16:48:28,720:INFO::its now!!!!!!!! on 
2023-12-01 16:48:28,776:INFO::its now!!!!!!!!5
2023-12-01 16:48:28,906:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:28,908:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 1.1193 | Train_Classification_Loss 1.1602 | Dmon_Loss -0.0819 | Val_Loss 1.1748 | Search Time(s) 0.4349 | Infer Time(s) 0.1347 | Time(s) 0.5695 
2023-12-01 16:48:28,962:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:28,963:INFO::Validation loss decreased (1.192698 --> 1.174769).  Saving model ...
2023-12-01 16:48:28,965:INFO::Epoch: 46
tensor([[0.6939, 0.6957, 0.6926, 0.6921],
        [0.6906, 0.6937, 0.6949, 0.6955],
        [0.6964, 0.6919, 0.6969, 0.6931],
        [0.6972, 0.6967, 0.6937, 0.6971]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:28,966:INFO::its now!!!!!!!!5
2023-12-01 16:48:29,100:INFO::its now!!!!!!!!0
2023-12-01 16:48:29,101:INFO::its now!!!!!!!!3
2023-12-01 16:48:29,147:INFO::its now!!!!!!!!5
2023-12-01 16:48:29,313:INFO::its now!!!!!!!!
2023-12-01 16:48:29,313:INFO::its now!!!!!!!! on 
2023-12-01 16:48:29,351:INFO::its now!!!!!!!!5
2023-12-01 16:48:29,498:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:29,499:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 1.0990 | Train_Classification_Loss 1.1417 | Dmon_Loss -0.0852 | Val_Loss 1.1606 | Search Time(s) 0.3871 | Infer Time(s) 0.1476 | Time(s) 0.5347 
2023-12-01 16:48:29,551:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:29,552:INFO::Validation loss decreased (1.174769 --> 1.160552).  Saving model ...
2023-12-01 16:48:29,555:INFO::Epoch: 47
tensor([[0.7008, 0.6987, 0.6976, 0.6997],
        [0.6955, 0.7004, 0.7019, 0.6992],
        [0.7032, 0.6966, 0.7008, 0.7005],
        [0.7002, 0.7039, 0.6986, 0.7044]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:29,556:INFO::its now!!!!!!!!5
2023-12-01 16:48:29,716:INFO::its now!!!!!!!!0
2023-12-01 16:48:29,716:INFO::its now!!!!!!!!3
2023-12-01 16:48:29,744:INFO::its now!!!!!!!!5
2023-12-01 16:48:29,911:INFO::its now!!!!!!!!
2023-12-01 16:48:29,911:INFO::its now!!!!!!!! on 
2023-12-01 16:48:29,961:INFO::its now!!!!!!!!5
2023-12-01 16:48:30,099:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 1.1178 | Train_Classification_Loss 1.1594 | Dmon_Loss -0.0830 | Val_Loss 1.1802 | Search Time(s) 0.4049 | Infer Time(s) 0.1426 | Time(s) 0.5476 
2023-12-01 16:48:30,142:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:30,143:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:30,146:INFO::Epoch: 48
tensor([[0.7043, 0.7034, 0.7034, 0.7068],
        [0.7011, 0.7069, 0.7055, 0.7046],
        [0.7071, 0.7022, 0.7061, 0.7076],
        [0.7051, 0.7107, 0.7043, 0.7080]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:30,146:INFO::its now!!!!!!!!5
2023-12-01 16:48:30,300:INFO::its now!!!!!!!!0
2023-12-01 16:48:30,301:INFO::its now!!!!!!!!3
2023-12-01 16:48:30,343:INFO::its now!!!!!!!!5
2023-12-01 16:48:30,493:INFO::its now!!!!!!!!
2023-12-01 16:48:30,493:INFO::its now!!!!!!!! on 
2023-12-01 16:48:30,527:INFO::its now!!!!!!!!5
2023-12-01 16:48:30,663:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:30,665:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 1.0861 | Train_Classification_Loss 1.1287 | Dmon_Loss -0.0852 | Val_Loss 1.1495 | Search Time(s) 0.3815 | Infer Time(s) 0.1376 | Time(s) 0.5192 
2023-12-01 16:48:30,700:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:30,701:INFO::Validation loss decreased (1.160552 --> 1.149495).  Saving model ...
2023-12-01 16:48:30,703:INFO::Epoch: 49
tensor([[0.7110, 0.7107, 0.7114, 0.7104],
        [0.7087, 0.7103, 0.7123, 0.7125],
        [0.7138, 0.7100, 0.7139, 0.7112],
        [0.7127, 0.7142, 0.7121, 0.7149]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:30,704:INFO::its now!!!!!!!!5
2023-12-01 16:48:30,870:INFO::its now!!!!!!!!0
2023-12-01 16:48:30,871:INFO::its now!!!!!!!!3
2023-12-01 16:48:30,898:INFO::its now!!!!!!!!5
2023-12-01 16:48:31,072:INFO::its now!!!!!!!!
2023-12-01 16:48:31,072:INFO::its now!!!!!!!! on 
2023-12-01 16:48:31,126:INFO::its now!!!!!!!!5
2023-12-01 16:48:31,286:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:31,288:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 1.0715 | Train_Classification_Loss 1.1157 | Dmon_Loss -0.0883 | Val_Loss 1.1336 | Search Time(s) 0.4049 | Infer Time(s) 0.1805 | Time(s) 0.5854 
2023-12-01 16:48:31,324:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:31,325:INFO::Validation loss decreased (1.149495 --> 1.133564).  Saving model ...
2023-12-01 16:48:31,328:INFO::Epoch: 50
tensor([[0.7194, 0.7195, 0.7154, 0.7178],
        [0.7176, 0.7173, 0.7209, 0.7165],
        [0.7222, 0.7191, 0.7181, 0.7186],
        [0.7218, 0.7213, 0.7211, 0.7183]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:31,328:INFO::its now!!!!!!!!5
2023-12-01 16:48:31,480:INFO::its now!!!!!!!!0
2023-12-01 16:48:31,481:INFO::its now!!!!!!!!3
2023-12-01 16:48:31,526:INFO::its now!!!!!!!!5
2023-12-01 16:48:31,664:INFO::its now!!!!!!!!
2023-12-01 16:48:31,664:INFO::its now!!!!!!!! on 
2023-12-01 16:48:31,717:INFO::its now!!!!!!!!5
2023-12-01 16:48:31,858:INFO::Epoch 00050 | lr 0.00050 | Train_Loss 1.0944 | Train_Classification_Loss 1.1392 | Dmon_Loss -0.0895 | Val_Loss 1.1527 | Search Time(s) 0.3670 | Infer Time(s) 0.1666 | Time(s) 0.5336 
2023-12-01 16:48:31,905:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:31,906:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:31,908:INFO::Epoch: 51
tensor([[0.7272, 0.7240, 0.7211, 0.7253],
        [0.7255, 0.7245, 0.7252, 0.7224],
        [0.7269, 0.7272, 0.7241, 0.7260],
        [0.7263, 0.7286, 0.7291, 0.7238]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:31,909:INFO::its now!!!!!!!!5
2023-12-01 16:48:32,049:INFO::its now!!!!!!!!0
2023-12-01 16:48:32,050:INFO::its now!!!!!!!!3
2023-12-01 16:48:32,093:INFO::its now!!!!!!!!5
2023-12-01 16:48:32,246:INFO::its now!!!!!!!!
2023-12-01 16:48:32,246:INFO::its now!!!!!!!! on 
2023-12-01 16:48:32,296:INFO::its now!!!!!!!!5
2023-12-01 16:48:32,461:INFO::Epoch 00051 | lr 0.00050 | Train_Loss 1.0774 | Train_Classification_Loss 1.1207 | Dmon_Loss -0.0866 | Val_Loss 1.1513 | Search Time(s) 0.3872 | Infer Time(s) 0.1676 | Time(s) 0.5547 
2023-12-01 16:48:32,522:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:32,526:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:48:32,530:INFO::Epoch: 52
tensor([[0.7310, 0.7317, 0.7296, 0.7348],
        [0.7295, 0.7336, 0.7329, 0.7312],
        [0.7346, 0.7314, 0.7328, 0.7354],
        [0.7343, 0.7377, 0.7331, 0.7322]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:32,531:INFO::its now!!!!!!!!5
2023-12-01 16:48:32,665:INFO::its now!!!!!!!!0
2023-12-01 16:48:32,666:INFO::its now!!!!!!!!3
2023-12-01 16:48:32,710:INFO::its now!!!!!!!!5
2023-12-01 16:48:32,886:INFO::its now!!!!!!!!
2023-12-01 16:48:32,886:INFO::its now!!!!!!!! on 
2023-12-01 16:48:32,940:INFO::its now!!!!!!!!5
2023-12-01 16:48:33,082:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:33,084:INFO::Epoch 00052 | lr 0.00050 | Train_Loss 1.0393 | Train_Classification_Loss 1.0854 | Dmon_Loss -0.0922 | Val_Loss 1.1049 | Search Time(s) 0.3910 | Infer Time(s) 0.1656 | Time(s) 0.5565 
2023-12-01 16:48:33,127:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:33,128:INFO::Validation loss decreased (1.133564 --> 1.104897).  Saving model ...
2023-12-01 16:48:33,130:INFO::Epoch: 53
tensor([[0.7371, 0.7396, 0.7380, 0.7395],
        [0.7356, 0.7382, 0.7408, 0.7399],
        [0.7424, 0.7376, 0.7412, 0.7402],
        [0.7423, 0.7423, 0.7393, 0.7405]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:33,131:INFO::its now!!!!!!!!5
2023-12-01 16:48:33,284:INFO::its now!!!!!!!!0
2023-12-01 16:48:33,285:INFO::its now!!!!!!!!3
2023-12-01 16:48:33,332:INFO::its now!!!!!!!!5
2023-12-01 16:48:33,508:INFO::its now!!!!!!!!
2023-12-01 16:48:33,508:INFO::its now!!!!!!!! on 
2023-12-01 16:48:33,546:INFO::its now!!!!!!!!5
2023-12-01 16:48:33,711:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:33,713:INFO::Epoch 00053 | lr 0.00050 | Train_Loss 1.0370 | Train_Classification_Loss 1.0819 | Dmon_Loss -0.0896 | Val_Loss 1.1038 | Search Time(s) 0.4145 | Infer Time(s) 0.1676 | Time(s) 0.5820 
2023-12-01 16:48:33,752:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:33,753:INFO::Validation loss decreased (1.104897 --> 1.103805).  Saving model ...
2023-12-01 16:48:33,757:INFO::Epoch: 54
tensor([[0.7436, 0.7435, 0.7457, 0.7456],
        [0.7421, 0.7441, 0.7447, 0.7479],
        [0.7468, 0.7443, 0.7491, 0.7463],
        [0.7499, 0.7447, 0.7459, 0.7481]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:33,758:INFO::its now!!!!!!!!5
2023-12-01 16:48:33,912:INFO::its now!!!!!!!!0
2023-12-01 16:48:33,912:INFO::its now!!!!!!!!3
2023-12-01 16:48:33,944:INFO::its now!!!!!!!!5
2023-12-01 16:48:34,109:INFO::its now!!!!!!!!
2023-12-01 16:48:34,109:INFO::its now!!!!!!!! on 
2023-12-01 16:48:34,162:INFO::its now!!!!!!!!5
2023-12-01 16:48:34,320:INFO::Epoch 00054 | lr 0.00050 | Train_Loss 1.0551 | Train_Classification_Loss 1.0990 | Dmon_Loss -0.0879 | Val_Loss 1.1280 | Search Time(s) 0.4055 | Infer Time(s) 0.1611 | Time(s) 0.5666 
2023-12-01 16:48:34,377:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:34,378:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:34,386:INFO::Epoch: 55
tensor([[0.7520, 0.7507, 0.7496, 0.7540],
        [0.7504, 0.7522, 0.7519, 0.7519],
        [0.7541, 0.7528, 0.7534, 0.7546],
        [0.7537, 0.7512, 0.7543, 0.7571]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:34,388:INFO::its now!!!!!!!!5
2023-12-01 16:48:34,536:INFO::its now!!!!!!!!0
2023-12-01 16:48:34,537:INFO::its now!!!!!!!!3
2023-12-01 16:48:34,578:INFO::its now!!!!!!!!5
2023-12-01 16:48:34,739:INFO::its now!!!!!!!!
2023-12-01 16:48:34,739:INFO::its now!!!!!!!! on 
2023-12-01 16:48:34,772:INFO::its now!!!!!!!!5
2023-12-01 16:48:34,904:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:34,907:INFO::Epoch 00055 | lr 0.00050 | Train_Loss 1.0035 | Train_Classification_Loss 1.0504 | Dmon_Loss -0.0939 | Val_Loss 1.0742 | Search Time(s) 0.3830 | Infer Time(s) 0.1416 | Time(s) 0.5246 
2023-12-01 16:48:34,945:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:34,946:INFO::Validation loss decreased (1.103805 --> 1.074218).  Saving model ...
2023-12-01 16:48:34,949:INFO::Epoch: 56
tensor([[0.7600, 0.7581, 0.7556, 0.7582],
        [0.7584, 0.7563, 0.7593, 0.7581],
        [0.7614, 0.7610, 0.7597, 0.7589],
        [0.7596, 0.7585, 0.7623, 0.7616]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:34,949:INFO::its now!!!!!!!!5
2023-12-01 16:48:35,102:INFO::its now!!!!!!!!0
2023-12-01 16:48:35,103:INFO::its now!!!!!!!!3
2023-12-01 16:48:35,133:INFO::its now!!!!!!!!5
2023-12-01 16:48:35,300:INFO::its now!!!!!!!!
2023-12-01 16:48:35,300:INFO::its now!!!!!!!! on 
2023-12-01 16:48:35,357:INFO::its now!!!!!!!!5
2023-12-01 16:48:35,512:INFO::Epoch 00056 | lr 0.00050 | Train_Loss 1.0338 | Train_Classification_Loss 1.0812 | Dmon_Loss -0.0949 | Val_Loss 1.1038 | Search Time(s) 0.4090 | Infer Time(s) 0.1566 | Time(s) 0.5656 
2023-12-01 16:48:35,559:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:35,559:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:35,562:INFO::Epoch: 57
tensor([[0.7640, 0.7667, 0.7638, 0.7657],
        [0.7673, 0.7635, 0.7630, 0.7666],
        [0.7657, 0.7701, 0.7681, 0.7663],
        [0.7678, 0.7672, 0.7664, 0.7690]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:35,562:INFO::its now!!!!!!!!5
2023-12-01 16:48:35,707:INFO::its now!!!!!!!!0
2023-12-01 16:48:35,708:INFO::its now!!!!!!!!3
2023-12-01 16:48:35,752:INFO::its now!!!!!!!!5
2023-12-01 16:48:35,901:INFO::its now!!!!!!!!
2023-12-01 16:48:35,901:INFO::its now!!!!!!!! on 
2023-12-01 16:48:35,938:INFO::its now!!!!!!!!5
2023-12-01 16:48:36,083:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:36,085:INFO::Epoch 00057 | lr 0.00050 | Train_Loss 0.9917 | Train_Classification_Loss 1.0382 | Dmon_Loss -0.0931 | Val_Loss 1.0636 | Search Time(s) 0.3750 | Infer Time(s) 0.1476 | Time(s) 0.5226 
2023-12-01 16:48:36,120:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:36,122:INFO::Validation loss decreased (1.074218 --> 1.063639).  Saving model ...
2023-12-01 16:48:36,124:INFO::Epoch: 58
tensor([[0.7713, 0.7711, 0.7731, 0.7746],
        [0.7718, 0.7723, 0.7702, 0.7761],
        [0.7730, 0.7748, 0.7775, 0.7753],
        [0.7770, 0.7767, 0.7737, 0.7727]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:36,125:INFO::its now!!!!!!!!5
2023-12-01 16:48:36,264:INFO::its now!!!!!!!!0
2023-12-01 16:48:36,265:INFO::its now!!!!!!!!3
2023-12-01 16:48:36,292:INFO::its now!!!!!!!!5
2023-12-01 16:48:36,463:INFO::its now!!!!!!!!
2023-12-01 16:48:36,463:INFO::its now!!!!!!!! on 
2023-12-01 16:48:36,515:INFO::its now!!!!!!!!5
2023-12-01 16:48:36,669:INFO::Epoch 00058 | lr 0.00050 | Train_Loss 1.0157 | Train_Classification_Loss 1.0617 | Dmon_Loss -0.0920 | Val_Loss 1.0954 | Search Time(s) 0.3895 | Infer Time(s) 0.1576 | Time(s) 0.5471 
2023-12-01 16:48:36,709:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:36,710:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:36,713:INFO::Epoch: 59
tensor([[0.7786, 0.7771, 0.7815, 0.7792],
        [0.7778, 0.7805, 0.7775, 0.7809],
        [0.7803, 0.7810, 0.7828, 0.7836],
        [0.7817, 0.7852, 0.7811, 0.7785]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:36,714:INFO::its now!!!!!!!!5
2023-12-01 16:48:36,849:INFO::its now!!!!!!!!0
2023-12-01 16:48:36,850:INFO::its now!!!!!!!!3
2023-12-01 16:48:36,894:INFO::its now!!!!!!!!5
2023-12-01 16:48:37,036:INFO::its now!!!!!!!!
2023-12-01 16:48:37,037:INFO::its now!!!!!!!! on 
2023-12-01 16:48:37,089:INFO::its now!!!!!!!!5
2023-12-01 16:48:37,228:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:37,230:INFO::Epoch 00059 | lr 0.00050 | Train_Loss 0.9587 | Train_Classification_Loss 1.0066 | Dmon_Loss -0.0958 | Val_Loss 1.0422 | Search Time(s) 0.3590 | Infer Time(s) 0.1591 | Time(s) 0.5182 
2023-12-01 16:48:37,267:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:37,268:INFO::Validation loss decreased (1.063639 --> 1.042222).  Saving model ...
2023-12-01 16:48:37,271:INFO::Epoch: 60
tensor([[0.7867, 0.7845, 0.7858, 0.7860],
        [0.7852, 0.7889, 0.7855, 0.7834],
        [0.7883, 0.7885, 0.7900, 0.7879],
        [0.7885, 0.7895, 0.7892, 0.7859]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:37,271:INFO::its now!!!!!!!!5
2023-12-01 16:48:37,432:INFO::its now!!!!!!!!0
2023-12-01 16:48:37,433:INFO::its now!!!!!!!!3
2023-12-01 16:48:37,484:INFO::its now!!!!!!!!5
2023-12-01 16:48:37,640:INFO::its now!!!!!!!!
2023-12-01 16:48:37,640:INFO::its now!!!!!!!! on 
2023-12-01 16:48:37,703:INFO::its now!!!!!!!!5
2023-12-01 16:48:37,860:INFO::Epoch 00060 | lr 0.00050 | Train_Loss 0.9922 | Train_Classification_Loss 1.0413 | Dmon_Loss -0.0981 | Val_Loss 1.0678 | Search Time(s) 0.4324 | Infer Time(s) 0.1576 | Time(s) 0.5900 
2023-12-01 16:48:37,901:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:37,902:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:37,906:INFO::Epoch: 61
tensor([[0.7907, 0.7927, 0.7926, 0.7941],
        [0.7933, 0.7931, 0.7940, 0.7895],
        [0.7966, 0.7968, 0.7942, 0.7947],
        [0.7965, 0.7917, 0.7977, 0.7941]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:37,907:INFO::its now!!!!!!!!5
2023-12-01 16:48:38,061:INFO::its now!!!!!!!!0
2023-12-01 16:48:38,061:INFO::its now!!!!!!!!3
2023-12-01 16:48:38,104:INFO::its now!!!!!!!!5
2023-12-01 16:48:38,277:INFO::its now!!!!!!!!
2023-12-01 16:48:38,277:INFO::its now!!!!!!!! on 
2023-12-01 16:48:38,326:INFO::its now!!!!!!!!5
2023-12-01 16:48:38,474:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:38,476:INFO::Epoch 00061 | lr 0.00050 | Train_Loss 0.9323 | Train_Classification_Loss 0.9820 | Dmon_Loss -0.0993 | Val_Loss 1.0101 | Search Time(s) 0.4020 | Infer Time(s) 0.1685 | Time(s) 0.5706 
2023-12-01 16:48:38,513:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:38,514:INFO::Validation loss decreased (1.042222 --> 1.010055).  Saving model ...
2023-12-01 16:48:38,516:INFO::Epoch: 62
tensor([[0.7976, 0.8014, 0.8007, 0.7982],
        [0.8020, 0.8000, 0.7983, 0.7975],
        [0.8054, 0.8012, 0.8012, 0.8029],
        [0.8052, 0.7977, 0.8020, 0.8030]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:38,516:INFO::its now!!!!!!!!5
2023-12-01 16:48:38,659:INFO::its now!!!!!!!!0
2023-12-01 16:48:38,659:INFO::its now!!!!!!!!3
2023-12-01 16:48:38,704:INFO::its now!!!!!!!!5
2023-12-01 16:48:38,847:INFO::its now!!!!!!!!
2023-12-01 16:48:38,848:INFO::its now!!!!!!!! on 
2023-12-01 16:48:38,902:INFO::its now!!!!!!!!5
2023-12-01 16:48:39,081:INFO::Epoch 00062 | lr 0.00050 | Train_Loss 0.9804 | Train_Classification_Loss 1.0278 | Dmon_Loss -0.0946 | Val_Loss 1.0614 | Search Time(s) 0.3850 | Infer Time(s) 0.1815 | Time(s) 0.5665 
2023-12-01 16:48:39,129:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:39,130:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:39,132:INFO::Epoch: 63
tensor([[0.8052, 0.8058, 0.8090, 0.8046],
        [0.8064, 0.8077, 0.8047, 0.8059],
        [0.8105, 0.8076, 0.8090, 0.8113],
        [0.8096, 0.8050, 0.8083, 0.8116]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:39,132:INFO::its now!!!!!!!!5
2023-12-01 16:48:39,295:INFO::its now!!!!!!!!0
2023-12-01 16:48:39,296:INFO::its now!!!!!!!!3
2023-12-01 16:48:39,338:INFO::its now!!!!!!!!5
2023-12-01 16:48:39,503:INFO::its now!!!!!!!!
2023-12-01 16:48:39,503:INFO::its now!!!!!!!! on 
2023-12-01 16:48:39,536:INFO::its now!!!!!!!!5
2023-12-01 16:48:39,685:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:39,686:INFO::Epoch 00063 | lr 0.00050 | Train_Loss 0.9087 | Train_Classification_Loss 0.9582 | Dmon_Loss -0.0988 | Val_Loss 0.9980 | Search Time(s) 0.4025 | Infer Time(s) 0.1526 | Time(s) 0.5551 
2023-12-01 16:48:39,737:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:39,738:INFO::Validation loss decreased (1.010055 --> 0.998015).  Saving model ...
2023-12-01 16:48:39,742:INFO::Epoch: 64
tensor([[0.8127, 0.8118, 0.8132, 0.8117],
        [0.8123, 0.8115, 0.8116, 0.8140],
        [0.8167, 0.8147, 0.8168, 0.8155],
        [0.8157, 0.8124, 0.8153, 0.8159]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:39,742:INFO::its now!!!!!!!!5
2023-12-01 16:48:39,871:INFO::its now!!!!!!!!0
2023-12-01 16:48:39,871:INFO::its now!!!!!!!!3
2023-12-01 16:48:39,901:INFO::its now!!!!!!!!5
2023-12-01 16:48:40,049:INFO::its now!!!!!!!!
2023-12-01 16:48:40,049:INFO::its now!!!!!!!! on 
2023-12-01 16:48:40,088:INFO::its now!!!!!!!!5
2023-12-01 16:48:40,244:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:40,246:INFO::Epoch 00064 | lr 0.00050 | Train_Loss 0.8924 | Train_Classification_Loss 0.9435 | Dmon_Loss -0.1022 | Val_Loss 0.9759 | Search Time(s) 0.3391 | Infer Time(s) 0.1651 | Time(s) 0.5042 
2023-12-01 16:48:40,293:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:40,294:INFO::Validation loss decreased (0.998015 --> 0.975897).  Saving model ...
2023-12-01 16:48:40,298:INFO::Epoch: 65
tensor([[0.8198, 0.8181, 0.8153, 0.8187],
        [0.8186, 0.8169, 0.8185, 0.8181],
        [0.8231, 0.8216, 0.8213, 0.8211],
        [0.8221, 0.8196, 0.8222, 0.8181]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:40,299:INFO::its now!!!!!!!!5
2023-12-01 16:48:40,446:INFO::its now!!!!!!!!0
2023-12-01 16:48:40,446:INFO::its now!!!!!!!!3
2023-12-01 16:48:40,476:INFO::its now!!!!!!!!5
2023-12-01 16:48:40,663:INFO::its now!!!!!!!!
2023-12-01 16:48:40,663:INFO::its now!!!!!!!! on 
2023-12-01 16:48:40,722:INFO::its now!!!!!!!!5
2023-12-01 16:48:40,859:INFO::Epoch 00065 | lr 0.00050 | Train_Loss 0.9371 | Train_Classification_Loss 0.9874 | Dmon_Loss -0.1005 | Val_Loss 1.0208 | Search Time(s) 0.4239 | Infer Time(s) 0.1397 | Time(s) 0.5635 
2023-12-01 16:48:40,907:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:40,908:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:40,910:INFO::Epoch: 66
tensor([[0.8234, 0.8254, 0.8206, 0.8265],
        [0.8218, 0.8237, 0.8261, 0.8245],
        [0.8271, 0.8292, 0.8279, 0.8282],
        [0.8295, 0.8274, 0.8256, 0.8235]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:40,911:INFO::its now!!!!!!!!5
2023-12-01 16:48:41,076:INFO::its now!!!!!!!!0
2023-12-01 16:48:41,076:INFO::its now!!!!!!!!3
2023-12-01 16:48:41,123:INFO::its now!!!!!!!!5
2023-12-01 16:48:41,267:INFO::its now!!!!!!!!
2023-12-01 16:48:41,267:INFO::its now!!!!!!!! on 
2023-12-01 16:48:41,316:INFO::its now!!!!!!!!5
2023-12-01 16:48:41,486:INFO::Epoch 00066 | lr 0.00050 | Train_Loss 0.9256 | Train_Classification_Loss 0.9745 | Dmon_Loss -0.0977 | Val_Loss 1.0262 | Search Time(s) 0.4050 | Infer Time(s) 0.1725 | Time(s) 0.5776 
2023-12-01 16:48:41,522:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:41,523:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:48:41,525:INFO::Epoch: 67
tensor([[0.8298, 0.8335, 0.8279, 0.8304],
        [0.8280, 0.8317, 0.8299, 0.8324],
        [0.8336, 0.8332, 0.8359, 0.8363],
        [0.8332, 0.8358, 0.8320, 0.8308]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:41,526:INFO::its now!!!!!!!!5
2023-12-01 16:48:41,656:INFO::its now!!!!!!!!0
2023-12-01 16:48:41,657:INFO::its now!!!!!!!!3
2023-12-01 16:48:41,698:INFO::its now!!!!!!!!5
2023-12-01 16:48:41,867:INFO::its now!!!!!!!!
2023-12-01 16:48:41,867:INFO::its now!!!!!!!! on 
2023-12-01 16:48:41,917:INFO::its now!!!!!!!!5
2023-12-01 16:48:42,050:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:42,052:INFO::Epoch 00067 | lr 0.00050 | Train_Loss 0.8585 | Train_Classification_Loss 0.9093 | Dmon_Loss -0.1015 | Val_Loss 0.9527 | Search Time(s) 0.3730 | Infer Time(s) 0.1546 | Time(s) 0.5276 
2023-12-01 16:48:42,092:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:42,093:INFO::Validation loss decreased (0.975897 --> 0.952727).  Saving model ...
2023-12-01 16:48:42,095:INFO::Epoch: 68
tensor([[0.8375, 0.8376, 0.8361, 0.8370],
        [0.8355, 0.8401, 0.8363, 0.8364],
        [0.8413, 0.8398, 0.8444, 0.8404],
        [0.8397, 0.8400, 0.8397, 0.8389]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:42,095:INFO::its now!!!!!!!!5
2023-12-01 16:48:42,235:INFO::its now!!!!!!!!0
2023-12-01 16:48:42,236:INFO::its now!!!!!!!!3
2023-12-01 16:48:42,280:INFO::its now!!!!!!!!5
2023-12-01 16:48:42,454:INFO::its now!!!!!!!!
2023-12-01 16:48:42,454:INFO::its now!!!!!!!! on 
2023-12-01 16:48:42,507:INFO::its now!!!!!!!!5
2023-12-01 16:48:42,666:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:42,667:INFO::Epoch 00068 | lr 0.00050 | Train_Loss 0.8293 | Train_Classification_Loss 0.8825 | Dmon_Loss -0.1063 | Val_Loss 0.9297 | Search Time(s) 0.3911 | Infer Time(s) 0.1815 | Time(s) 0.5726 
2023-12-01 16:48:42,714:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:42,716:INFO::Validation loss decreased (0.952727 --> 0.929657).  Saving model ...
2023-12-01 16:48:42,719:INFO::Epoch: 69
tensor([[0.8457, 0.8397, 0.8447, 0.8449],
        [0.8437, 0.8444, 0.8440, 0.8431],
        [0.8494, 0.8476, 0.8493, 0.8471],
        [0.8474, 0.8422, 0.8480, 0.8474]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:42,720:INFO::its now!!!!!!!!5
2023-12-01 16:48:42,864:INFO::its now!!!!!!!!0
2023-12-01 16:48:42,865:INFO::its now!!!!!!!!3
2023-12-01 16:48:42,912:INFO::its now!!!!!!!!5
2023-12-01 16:48:43,079:INFO::its now!!!!!!!!
2023-12-01 16:48:43,080:INFO::its now!!!!!!!! on 
2023-12-01 16:48:43,117:INFO::its now!!!!!!!!5
2023-12-01 16:48:43,264:INFO::Epoch 00069 | lr 0.00050 | Train_Loss 0.8300 | Train_Classification_Loss 0.8816 | Dmon_Loss -0.1033 | Val_Loss 0.9301 | Search Time(s) 0.3975 | Infer Time(s) 0.1506 | Time(s) 0.5481 
2023-12-01 16:48:43,307:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:43,308:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:43,310:INFO::Epoch: 70
tensor([[0.8499, 0.8453, 0.8535, 0.8535],
        [0.8523, 0.8465, 0.8524, 0.8511],
        [0.8544, 0.8561, 0.8565, 0.8551],
        [0.8558, 0.8480, 0.8522, 0.8562]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:43,311:INFO::its now!!!!!!!!5
2023-12-01 16:48:43,478:INFO::its now!!!!!!!!0
2023-12-01 16:48:43,479:INFO::its now!!!!!!!!3
2023-12-01 16:48:43,508:INFO::its now!!!!!!!!5
2023-12-01 16:48:43,664:INFO::its now!!!!!!!!
2023-12-01 16:48:43,664:INFO::its now!!!!!!!! on 
2023-12-01 16:48:43,720:INFO::its now!!!!!!!!5
2023-12-01 16:48:43,885:INFO::Epoch 00070 | lr 0.00050 | Train_Loss 0.8834 | Train_Classification_Loss 0.9354 | Dmon_Loss -0.1040 | Val_Loss 0.9732 | Search Time(s) 0.3850 | Infer Time(s) 0.1915 | Time(s) 0.5765 
2023-12-01 16:48:43,932:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:43,933:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:48:43,936:INFO::Epoch: 71
tensor([[0.8553, 0.8515, 0.8611, 0.8578],
        [0.8598, 0.8510, 0.8566, 0.8586],
        [0.8601, 0.8636, 0.8609, 0.8624],
        [0.8634, 0.8543, 0.8576, 0.8606]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:43,936:INFO::its now!!!!!!!!5
2023-12-01 16:48:44,077:INFO::its now!!!!!!!!0
2023-12-01 16:48:44,078:INFO::its now!!!!!!!!3
2023-12-01 16:48:44,122:INFO::its now!!!!!!!!5
2023-12-01 16:48:44,283:INFO::its now!!!!!!!!
2023-12-01 16:48:44,283:INFO::its now!!!!!!!! on 
2023-12-01 16:48:44,318:INFO::its now!!!!!!!!5
2023-12-01 16:48:44,512:INFO::Epoch 00071 | lr 0.00050 | Train_Loss 0.8753 | Train_Classification_Loss 0.9256 | Dmon_Loss -0.1006 | Val_Loss 0.9810 | Search Time(s) 0.3821 | Infer Time(s) 0.1975 | Time(s) 0.5796 
2023-12-01 16:48:44,571:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:44,572:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:48:44,574:INFO::Epoch: 72
tensor([[0.8628, 0.8594, 0.8650, 0.8649],
        [0.8635, 0.8581, 0.8635, 0.8672],
        [0.8677, 0.8676, 0.8680, 0.8708],
        [0.8671, 0.8623, 0.8651, 0.8676]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:44,575:INFO::its now!!!!!!!!5
2023-12-01 16:48:44,729:INFO::its now!!!!!!!!0
2023-12-01 16:48:44,730:INFO::its now!!!!!!!!3
2023-12-01 16:48:44,755:INFO::its now!!!!!!!!5
2023-12-01 16:48:44,908:INFO::its now!!!!!!!!
2023-12-01 16:48:44,909:INFO::its now!!!!!!!! on 
2023-12-01 16:48:44,944:INFO::its now!!!!!!!!5
2023-12-01 16:48:45,107:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:45,108:INFO::Epoch 00072 | lr 0.00050 | Train_Loss 0.7911 | Train_Classification_Loss 0.8436 | Dmon_Loss -0.1049 | Val_Loss 0.8934 | Search Time(s) 0.3690 | Infer Time(s) 0.1661 | Time(s) 0.5351 
2023-12-01 16:48:45,147:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:45,148:INFO::Validation loss decreased (0.929657 --> 0.893388).  Saving model ...
2023-12-01 16:48:45,151:INFO::Epoch: 73
tensor([[0.8711, 0.8679, 0.8670, 0.8731],
        [0.8700, 0.8663, 0.8715, 0.8715],
        [0.8760, 0.8742, 0.8762, 0.8751],
        [0.8737, 0.8709, 0.8735, 0.8711]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:45,151:INFO::its now!!!!!!!!5
2023-12-01 16:48:45,282:INFO::its now!!!!!!!!0
2023-12-01 16:48:45,283:INFO::its now!!!!!!!!3
2023-12-01 16:48:45,312:INFO::its now!!!!!!!!5
2023-12-01 16:48:45,483:INFO::its now!!!!!!!!
2023-12-01 16:48:45,483:INFO::its now!!!!!!!! on 
2023-12-01 16:48:45,520:INFO::its now!!!!!!!!5
2023-12-01 16:48:45,673:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:45,674:INFO::Epoch 00073 | lr 0.00050 | Train_Loss 0.7660 | Train_Classification_Loss 0.8206 | Dmon_Loss -0.1092 | Val_Loss 0.8710 | Search Time(s) 0.3616 | Infer Time(s) 0.1626 | Time(s) 0.5242 
2023-12-01 16:48:45,717:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 1;	24: 2;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:45,718:INFO::Validation loss decreased (0.893388 --> 0.870980).  Saving model ...
2023-12-01 16:48:45,721:INFO::Epoch: 74
tensor([[0.8792, 0.8762, 0.8721, 0.8772],
        [0.8773, 0.8744, 0.8795, 0.8737],
        [0.8841, 0.8816, 0.8811, 0.8814],
        [0.8770, 0.8793, 0.8816, 0.8769]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:45,722:INFO::its now!!!!!!!!5
2023-12-01 16:48:45,865:INFO::its now!!!!!!!!0
2023-12-01 16:48:45,865:INFO::its now!!!!!!!!3
2023-12-01 16:48:45,893:INFO::its now!!!!!!!!5
2023-12-01 16:48:46,059:INFO::its now!!!!!!!!
2023-12-01 16:48:46,059:INFO::its now!!!!!!!! on 
2023-12-01 16:48:46,113:INFO::its now!!!!!!!!5
2023-12-01 16:48:46,261:INFO::Epoch 00074 | lr 0.00050 | Train_Loss 0.8380 | Train_Classification_Loss 0.8914 | Dmon_Loss -0.1069 | Val_Loss 0.9324 | Search Time(s) 0.3730 | Infer Time(s) 0.1702 | Time(s) 0.5431 
2023-12-01 16:48:46,318:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:46,319:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:46,321:INFO::Epoch: 75
tensor([[0.8833, 0.8845, 0.8790, 0.8836],
        [0.8850, 0.8827, 0.8835, 0.8793],
        [0.8890, 0.8896, 0.8879, 0.8888],
        [0.8831, 0.8877, 0.8858, 0.8841]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:46,322:INFO::its now!!!!!!!!5
2023-12-01 16:48:46,471:INFO::its now!!!!!!!!0
2023-12-01 16:48:46,472:INFO::its now!!!!!!!!3
2023-12-01 16:48:46,516:INFO::its now!!!!!!!!5
2023-12-01 16:48:46,669:INFO::its now!!!!!!!!
2023-12-01 16:48:46,669:INFO::its now!!!!!!!! on 
2023-12-01 16:48:46,722:INFO::its now!!!!!!!!5
2023-12-01 16:48:46,860:INFO::Epoch 00075 | lr 0.00050 | Train_Loss 0.8231 | Train_Classification_Loss 0.8747 | Dmon_Loss -0.1033 | Val_Loss 0.9448 | Search Time(s) 0.3999 | Infer Time(s) 0.1416 | Time(s) 0.5416 
2023-12-01 16:48:46,903:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:46,904:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:48:46,906:INFO::Epoch: 76
tensor([[0.8889, 0.8886, 0.8860, 0.8903],
        [0.8890, 0.8903, 0.8890, 0.8857],
        [0.8948, 0.8938, 0.8948, 0.8960],
        [0.8896, 0.8920, 0.8914, 0.8912]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:46,907:INFO::its now!!!!!!!!5
2023-12-01 16:48:47,067:INFO::its now!!!!!!!!0
2023-12-01 16:48:47,068:INFO::its now!!!!!!!!3
2023-12-01 16:48:47,108:INFO::its now!!!!!!!!5
2023-12-01 16:48:47,274:INFO::its now!!!!!!!!
2023-12-01 16:48:47,275:INFO::its now!!!!!!!! on 
2023-12-01 16:48:47,311:INFO::its now!!!!!!!!5
2023-12-01 16:48:47,486:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:47,487:INFO::Epoch 00076 | lr 0.00050 | Train_Loss 0.7255 | Train_Classification_Loss 0.7796 | Dmon_Loss -0.1082 | Val_Loss 0.8464 | Search Time(s) 0.4031 | Infer Time(s) 0.1785 | Time(s) 0.5816 
2023-12-01 16:48:47,527:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:47,528:INFO::Validation loss decreased (0.870980 --> 0.846432).  Saving model ...
2023-12-01 16:48:47,530:INFO::Epoch: 77
tensor([[0.8967, 0.8958, 0.8946, 0.8937],
        [0.8960, 0.8941, 0.8967, 0.8941],
        [0.9028, 0.9011, 0.9034, 0.8997],
        [0.8980, 0.8941, 0.8992, 0.8997]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:47,531:INFO::its now!!!!!!!!5
2023-12-01 16:48:47,688:INFO::its now!!!!!!!!0
2023-12-01 16:48:47,689:INFO::its now!!!!!!!!3
2023-12-01 16:48:47,719:INFO::its now!!!!!!!!5
2023-12-01 16:48:47,876:INFO::its now!!!!!!!!
2023-12-01 16:48:47,876:INFO::its now!!!!!!!! on 
2023-12-01 16:48:47,931:INFO::its now!!!!!!!!5
2023-12-01 16:48:48,091:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:48,093:INFO::Epoch 00077 | lr 0.00050 | Train_Loss 0.7121 | Train_Classification_Loss 0.7676 | Dmon_Loss -0.1111 | Val_Loss 0.8246 | Search Time(s) 0.3810 | Infer Time(s) 0.1825 | Time(s) 0.5635 
2023-12-01 16:48:48,142:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 1;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 1;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 1;	24: 2;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:48,143:INFO::Validation loss decreased (0.846432 --> 0.824567).  Saving model ...
2023-12-01 16:48:48,147:INFO::Epoch: 78
tensor([[0.9006, 0.9047, 0.9043, 0.9010],
        [0.9048, 0.9016, 0.9007, 0.9039],
        [0.9120, 0.9101, 0.9086, 0.9070],
        [0.9076, 0.9008, 0.9085, 0.9040]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:48,148:INFO::its now!!!!!!!!5
2023-12-01 16:48:48,290:INFO::its now!!!!!!!!0
2023-12-01 16:48:48,291:INFO::its now!!!!!!!!3
2023-12-01 16:48:48,338:INFO::its now!!!!!!!!5
2023-12-01 16:48:48,490:INFO::its now!!!!!!!!
2023-12-01 16:48:48,490:INFO::its now!!!!!!!! on 
2023-12-01 16:48:48,549:INFO::its now!!!!!!!!5
2023-12-01 16:48:48,700:INFO::Epoch 00078 | lr 0.00050 | Train_Loss 0.7898 | Train_Classification_Loss 0.8444 | Dmon_Loss -0.1092 | Val_Loss 0.8920 | Search Time(s) 0.4015 | Infer Time(s) 0.1546 | Time(s) 0.5561 
2023-12-01 16:48:48,744:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:48,745:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:48,748:INFO::Epoch: 79
tensor([[0.9058, 0.9092, 0.9123, 0.9079],
        [0.9092, 0.9084, 0.9058, 0.9120],
        [0.9174, 0.9177, 0.9144, 0.9139],
        [0.9155, 0.9073, 0.9132, 0.9094]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:48,749:INFO::its now!!!!!!!!5
2023-12-01 16:48:48,899:INFO::its now!!!!!!!!0
2023-12-01 16:48:48,900:INFO::its now!!!!!!!!3
2023-12-01 16:48:48,949:INFO::its now!!!!!!!!5
2023-12-01 16:48:49,090:INFO::its now!!!!!!!!
2023-12-01 16:48:49,090:INFO::its now!!!!!!!! on 
2023-12-01 16:48:49,146:INFO::its now!!!!!!!!5
2023-12-01 16:48:49,300:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:49,302:INFO::Epoch 00079 | lr 0.00050 | Train_Loss 0.6850 | Train_Classification_Loss 0.7417 | Dmon_Loss -0.1135 | Val_Loss 0.8019 | Search Time(s) 0.3795 | Infer Time(s) 0.1751 | Time(s) 0.5546 
2023-12-01 16:48:49,344:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 1;	4: 2;	5: 2;	6: 2;	7: 1;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 1;	24: 3;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 1;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:49,345:INFO::Validation loss decreased (0.824567 --> 0.801869).  Saving model ...
2023-12-01 16:48:49,348:INFO::Epoch: 80
tensor([[0.9130, 0.9159, 0.9163, 0.9160],
        [0.9160, 0.9164, 0.9130, 0.9160],
        [0.9246, 0.9218, 0.9221, 0.9220],
        [0.9195, 0.9152, 0.9201, 0.9167]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:49,348:INFO::its now!!!!!!!!5
2023-12-01 16:48:49,528:INFO::its now!!!!!!!!0
2023-12-01 16:48:49,529:INFO::its now!!!!!!!!3
2023-12-01 16:48:49,575:INFO::its now!!!!!!!!5
2023-12-01 16:48:49,735:INFO::its now!!!!!!!!
2023-12-01 16:48:49,735:INFO::its now!!!!!!!! on 
2023-12-01 16:48:49,773:INFO::its now!!!!!!!!5
2023-12-01 16:48:49,952:INFO::Epoch 00080 | lr 0.00050 | Train_Loss 0.7651 | Train_Classification_Loss 0.8180 | Dmon_Loss -0.1057 | Val_Loss 0.8888 | Search Time(s) 0.4259 | Infer Time(s) 0.1815 | Time(s) 0.6074 
2023-12-01 16:48:50,004:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 1;	26113: 2;	26114: 2;	26115: 2;	26116: 1;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:50,005:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:50,008:INFO::Epoch: 81
tensor([[0.9203, 0.9229, 0.9183, 0.9238],
        [0.9230, 0.9205, 0.9203, 0.9219],
        [0.9290, 0.9275, 0.9296, 0.9297],
        [0.9252, 0.9229, 0.9237, 0.9240]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:50,009:INFO::its now!!!!!!!!5
2023-12-01 16:48:50,168:INFO::its now!!!!!!!!0
2023-12-01 16:48:50,169:INFO::its now!!!!!!!!3
2023-12-01 16:48:50,199:INFO::its now!!!!!!!!5
2023-12-01 16:48:50,356:INFO::its now!!!!!!!!
2023-12-01 16:48:50,356:INFO::its now!!!!!!!! on 
2023-12-01 16:48:50,412:INFO::its now!!!!!!!!5
2023-12-01 16:48:50,565:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:50,567:INFO::Epoch 00081 | lr 0.00050 | Train_Loss 0.6616 | Train_Classification_Loss 0.7169 | Dmon_Loss -0.1106 | Val_Loss 0.7933 | Search Time(s) 0.4041 | Infer Time(s) 0.1556 | Time(s) 0.5597 
2023-12-01 16:48:50,613:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:50,615:INFO::Validation loss decreased (0.801869 --> 0.793304).  Saving model ...
2023-12-01 16:48:50,617:INFO::Epoch: 82
tensor([[0.9280, 0.9303, 0.9234, 0.9277],
        [0.9265, 0.9266, 0.9280, 0.9290],
        [0.9352, 0.9344, 0.9375, 0.9337],
        [0.9281, 0.9308, 0.9295, 0.9317]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:50,618:INFO::its now!!!!!!!!5
2023-12-01 16:48:50,761:INFO::its now!!!!!!!!0
2023-12-01 16:48:50,762:INFO::its now!!!!!!!!3
2023-12-01 16:48:50,806:INFO::its now!!!!!!!!5
2023-12-01 16:48:50,978:INFO::its now!!!!!!!!
2023-12-01 16:48:50,978:INFO::its now!!!!!!!! on 
2023-12-01 16:48:51,035:INFO::its now!!!!!!!!5
2023-12-01 16:48:51,181:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:51,182:INFO::Epoch 00082 | lr 0.00050 | Train_Loss 0.6412 | Train_Classification_Loss 0.6982 | Dmon_Loss -0.1140 | Val_Loss 0.7678 | Search Time(s) 0.4187 | Infer Time(s) 0.1472 | Time(s) 0.5659 
2023-12-01 16:48:51,219:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 1;	4: 3;	5: 2;	6: 2;	7: 1;	8: 1;	9: 0;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 2;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 2;	23: 1;	24: 2;	25: 3;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 1;	32: 3;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 2;	26118: 1;	26119: 2;	26120: 1;	26121: 2;	26122: 1;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:51,221:INFO::Validation loss decreased (0.793304 --> 0.767771).  Saving model ...
2023-12-01 16:48:51,224:INFO::Epoch: 83
tensor([[0.9361, 0.9383, 0.9260, 0.9342],
        [0.9326, 0.9296, 0.9362, 0.9370],
        [0.9426, 0.9422, 0.9424, 0.9401],
        [0.9341, 0.9391, 0.9324, 0.9399]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:51,225:INFO::its now!!!!!!!!5
2023-12-01 16:48:51,367:INFO::its now!!!!!!!!0
2023-12-01 16:48:51,368:INFO::its now!!!!!!!!3
2023-12-01 16:48:51,416:INFO::its now!!!!!!!!5
2023-12-01 16:48:51,572:INFO::its now!!!!!!!!
2023-12-01 16:48:51,572:INFO::its now!!!!!!!! on 
2023-12-01 16:48:51,628:INFO::its now!!!!!!!!5
2023-12-01 16:48:51,757:INFO::Epoch 00083 | lr 0.00050 | Train_Loss 0.7281 | Train_Classification_Loss 0.7834 | Dmon_Loss -0.1105 | Val_Loss 0.8429 | Search Time(s) 0.3886 | Infer Time(s) 0.1476 | Time(s) 0.5362 
2023-12-01 16:48:51,807:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 2;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:51,808:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:51,813:INFO::Epoch: 84
tensor([[0.9442, 0.9424, 0.9314, 0.9415],
        [0.9396, 0.9352, 0.9442, 0.9410],
        [0.9472, 0.9501, 0.9489, 0.9473],
        [0.9411, 0.9472, 0.9379, 0.9440]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:51,814:INFO::its now!!!!!!!!5
2023-12-01 16:48:51,971:INFO::its now!!!!!!!!0
2023-12-01 16:48:51,972:INFO::its now!!!!!!!!3
2023-12-01 16:48:52,020:INFO::its now!!!!!!!!5
2023-12-01 16:48:52,173:INFO::its now!!!!!!!!
2023-12-01 16:48:52,173:INFO::its now!!!!!!!! on 
2023-12-01 16:48:52,210:INFO::its now!!!!!!!!5
2023-12-01 16:48:52,375:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:52,377:INFO::Epoch 00084 | lr 0.00050 | Train_Loss 0.6213 | Train_Classification_Loss 0.6770 | Dmon_Loss -0.1112 | Val_Loss 0.7561 | Search Time(s) 0.3995 | Infer Time(s) 0.1671 | Time(s) 0.5666 
2023-12-01 16:48:52,415:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 3;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:52,416:INFO::Validation loss decreased (0.767771 --> 0.756082).  Saving model ...
2023-12-01 16:48:52,419:INFO::Epoch: 85
tensor([[0.9482, 0.9496, 0.9396, 0.9505],
        [0.9483, 0.9434, 0.9482, 0.9485],
        [0.9548, 0.9543, 0.9576, 0.9563],
        [0.9500, 0.9512, 0.9460, 0.9515]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:52,420:INFO::its now!!!!!!!!5
2023-12-01 16:48:52,560:INFO::its now!!!!!!!!0
2023-12-01 16:48:52,561:INFO::its now!!!!!!!!3
2023-12-01 16:48:52,589:INFO::its now!!!!!!!!5
2023-12-01 16:48:52,773:INFO::its now!!!!!!!!
2023-12-01 16:48:52,773:INFO::its now!!!!!!!! on 
2023-12-01 16:48:52,829:INFO::its now!!!!!!!!5
2023-12-01 16:48:52,973:INFO::Epoch 00085 | lr 0.00050 | Train_Loss 0.7160 | Train_Classification_Loss 0.7696 | Dmon_Loss -0.1071 | Val_Loss 0.8486 | Search Time(s) 0.4089 | Infer Time(s) 0.1476 | Time(s) 0.5565 
2023-12-01 16:48:53,030:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:53,031:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:53,034:INFO::Epoch: 86
tensor([[0.9550, 0.9579, 0.9485, 0.9550],
        [0.9573, 0.9523, 0.9550, 0.9523],
        [0.9632, 0.9612, 0.9628, 0.9655],
        [0.9591, 0.9581, 0.9548, 0.9552]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:53,035:INFO::its now!!!!!!!!5
2023-12-01 16:48:53,187:INFO::its now!!!!!!!!0
2023-12-01 16:48:53,188:INFO::its now!!!!!!!!3
2023-12-01 16:48:53,237:INFO::its now!!!!!!!!5
2023-12-01 16:48:53,393:INFO::its now!!!!!!!!
2023-12-01 16:48:53,393:INFO::its now!!!!!!!! on 
2023-12-01 16:48:53,452:INFO::its now!!!!!!!!5
2023-12-01 16:48:53,589:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:53,590:INFO::Epoch 00086 | lr 0.00050 | Train_Loss 0.5998 | Train_Classification_Loss 0.6575 | Dmon_Loss -0.1153 | Val_Loss 0.7243 | Search Time(s) 0.4012 | Infer Time(s) 0.1576 | Time(s) 0.5587 
2023-12-01 16:48:53,629:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 1;	4: 3;	5: 2;	6: 2;	7: 1;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 1;	24: 2;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 3;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:53,630:INFO::Validation loss decreased (0.756082 --> 0.724313).  Saving model ...
2023-12-01 16:48:53,633:INFO::Epoch: 87
tensor([[0.9634, 0.9621, 0.9579, 0.9624],
        [0.9618, 0.9616, 0.9634, 0.9594],
        [0.9723, 0.9696, 0.9705, 0.9701],
        [0.9638, 0.9665, 0.9641, 0.9622]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:53,633:INFO::its now!!!!!!!!5
2023-12-01 16:48:53,791:INFO::its now!!!!!!!!0
2023-12-01 16:48:53,792:INFO::its now!!!!!!!!3
2023-12-01 16:48:53,838:INFO::its now!!!!!!!!5
2023-12-01 16:48:53,999:INFO::its now!!!!!!!!
2023-12-01 16:48:53,999:INFO::its now!!!!!!!! on 
2023-12-01 16:48:54,056:INFO::its now!!!!!!!!5
2023-12-01 16:48:54,194:INFO::Epoch 00087 | lr 0.00050 | Train_Loss 0.5855 | Train_Classification_Loss 0.6416 | Dmon_Loss -0.1121 | Val_Loss 0.7281 | Search Time(s) 0.4219 | Infer Time(s) 0.1422 | Time(s) 0.5640 
2023-12-01 16:48:54,250:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 3;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:54,251:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:54,257:INFO::Epoch: 88
tensor([[0.9677, 0.9680, 0.9665, 0.9700],
        [0.9679, 0.9701, 0.9677, 0.9669],
        [0.9775, 0.9777, 0.9783, 0.9764],
        [0.9700, 0.9708, 0.9725, 0.9695]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:54,258:INFO::its now!!!!!!!!5
2023-12-01 16:48:54,409:INFO::its now!!!!!!!!0
2023-12-01 16:48:54,410:INFO::its now!!!!!!!!3
2023-12-01 16:48:54,456:INFO::its now!!!!!!!!5
2023-12-01 16:48:54,621:INFO::its now!!!!!!!!
2023-12-01 16:48:54,621:INFO::its now!!!!!!!! on 
2023-12-01 16:48:54,677:INFO::its now!!!!!!!!5
2023-12-01 16:48:54,826:INFO::Epoch 00088 | lr 0.00050 | Train_Loss 0.6777 | Train_Classification_Loss 0.7336 | Dmon_Loss -0.1117 | Val_Loss 0.7933 | Search Time(s) 0.4045 | Infer Time(s) 0.1695 | Time(s) 0.5740 
2023-12-01 16:48:54,875:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 2;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:54,875:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:48:54,878:INFO::Epoch: 89
tensor([[0.9748, 0.9759, 0.9758, 0.9738],
        [0.9758, 0.9744, 0.9749, 0.9757],
        [0.9850, 0.9867, 0.9831, 0.9845],
        [0.9782, 0.9780, 0.9769, 0.9782]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:54,879:INFO::its now!!!!!!!!5
2023-12-01 16:48:55,035:INFO::its now!!!!!!!!0
2023-12-01 16:48:55,036:INFO::its now!!!!!!!!3
2023-12-01 16:48:55,080:INFO::its now!!!!!!!!5
2023-12-01 16:48:55,227:INFO::its now!!!!!!!!
2023-12-01 16:48:55,227:INFO::its now!!!!!!!! on 
2023-12-01 16:48:55,268:INFO::its now!!!!!!!!5
2023-12-01 16:48:55,430:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:55,432:INFO::Epoch 00089 | lr 0.00050 | Train_Loss 0.5498 | Train_Classification_Loss 0.6087 | Dmon_Loss -0.1178 | Val_Loss 0.6926 | Search Time(s) 0.3876 | Infer Time(s) 0.1661 | Time(s) 0.5537 
2023-12-01 16:48:55,479:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 1;	4: 2;	5: 2;	6: 2;	7: 1;	8: 2;	9: 3;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 2;	23: 1;	24: 1;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 1;	26101: 3;	26102: 2;	26103: 1;	26104: 2;	26105: 2;	26106: 3;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:55,480:INFO::Validation loss decreased (0.724313 --> 0.692638).  Saving model ...
2023-12-01 16:48:55,482:INFO::Epoch: 90
tensor([[0.9819, 0.9799, 0.9839, 0.9794],
        [0.9798, 0.9802, 0.9820, 0.9838],
        [0.9922, 0.9915, 0.9892, 0.9922],
        [0.9823, 0.9851, 0.9826, 0.9860]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:55,483:INFO::its now!!!!!!!!5
2023-12-01 16:48:55,668:INFO::its now!!!!!!!!0
2023-12-01 16:48:55,668:INFO::its now!!!!!!!!3
2023-12-01 16:48:55,699:INFO::its now!!!!!!!!5
2023-12-01 16:48:55,861:INFO::its now!!!!!!!!
2023-12-01 16:48:55,861:INFO::its now!!!!!!!! on 
2023-12-01 16:48:55,917:INFO::its now!!!!!!!!5
2023-12-01 16:48:56,088:INFO::Epoch 00090 | lr 0.00050 | Train_Loss 0.6475 | Train_Classification_Loss 0.7014 | Dmon_Loss -0.1078 | Val_Loss 0.7953 | Search Time(s) 0.4325 | Infer Time(s) 0.1735 | Time(s) 0.6061 
2023-12-01 16:48:56,129:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 1;	24: 2;	25: 3;	26: 2;	27: 2;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:56,131:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:56,133:INFO::Epoch: 91
tensor([[0.9890, 0.9854, 0.9881, 0.9858],
        [0.9853, 0.9866, 0.9891, 0.9878],
        [0.9966, 0.9975, 0.9959, 0.9995],
        [0.9879, 0.9923, 0.9890, 0.9900]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:56,135:INFO::its now!!!!!!!!5
2023-12-01 16:48:56,286:INFO::its now!!!!!!!!0
2023-12-01 16:48:56,287:INFO::its now!!!!!!!!3
2023-12-01 16:48:56,336:INFO::its now!!!!!!!!5
2023-12-01 16:48:56,495:INFO::its now!!!!!!!!
2023-12-01 16:48:56,495:INFO::its now!!!!!!!! on 
2023-12-01 16:48:56,551:INFO::its now!!!!!!!!5
2023-12-01 16:48:56,694:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:56,696:INFO::Epoch 00091 | lr 0.00050 | Train_Loss 0.5347 | Train_Classification_Loss 0.5939 | Dmon_Loss -0.1184 | Val_Loss 0.6718 | Search Time(s) 0.4184 | Infer Time(s) 0.1446 | Time(s) 0.5630 
2023-12-01 16:48:56,747:INFO::cluster info:
0: 3;	1: 2;	2: 2;	3: 1;	4: 3;	5: 2;	6: 2;	7: 1;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 0;	25: 2;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:56,749:INFO::Validation loss decreased (0.692638 --> 0.671800).  Saving model ...
2023-12-01 16:48:56,752:INFO::Epoch: 92
tensor([[0.9926, 0.9917, 0.9938, 0.9927],
        [0.9917, 0.9934, 0.9927, 0.9936],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9944, 0.9958, 0.9958, 0.9956]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:56,753:INFO::its now!!!!!!!!5
2023-12-01 16:48:56,903:INFO::its now!!!!!!!!0
2023-12-01 16:48:56,904:INFO::its now!!!!!!!!3
2023-12-01 16:48:56,954:INFO::its now!!!!!!!!5
2023-12-01 16:48:57,124:INFO::its now!!!!!!!!
2023-12-01 16:48:57,124:INFO::its now!!!!!!!! on 
2023-12-01 16:48:57,181:INFO::its now!!!!!!!!5
2023-12-01 16:48:57,319:INFO::Epoch 00092 | lr 0.00050 | Train_Loss 0.5358 | Train_Classification_Loss 0.5953 | Dmon_Loss -0.1190 | Val_Loss 0.6793 | Search Time(s) 0.4294 | Infer Time(s) 0.1392 | Time(s) 0.5686 
2023-12-01 16:48:57,360:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 2;	8: 2;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 2;	22: 2;	23: 2;	24: 2;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 3;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:57,361:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:48:57,365:INFO::Epoch: 93
tensor([[0.9984, 0.9988, 0.9966, 1.0000],
        [0.9988, 1.0000, 0.9985, 0.9965],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 0.9977, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:57,366:INFO::its now!!!!!!!!5
2023-12-01 16:48:57,523:INFO::its now!!!!!!!!0
2023-12-01 16:48:57,524:INFO::its now!!!!!!!!3
2023-12-01 16:48:57,571:INFO::its now!!!!!!!!5
2023-12-01 16:48:57,745:INFO::its now!!!!!!!!
2023-12-01 16:48:57,745:INFO::its now!!!!!!!! on 
2023-12-01 16:48:57,779:INFO::its now!!!!!!!!5
2023-12-01 16:48:57,933:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:57,935:INFO::Epoch 00093 | lr 0.00050 | Train_Loss 0.4970 | Train_Classification_Loss 0.5577 | Dmon_Loss -0.1213 | Val_Loss 0.6469 | Search Time(s) 0.4119 | Infer Time(s) 0.1596 | Time(s) 0.5715 
2023-12-01 16:48:57,995:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 2;	6: 2;	7: 1;	8: 1;	9: 3;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 0;	25: 3;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 1;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:48:57,996:INFO::Validation loss decreased (0.671800 --> 0.646937).  Saving model ...
2023-12-01 16:48:58,030:INFO::Epoch: 94
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:58,031:INFO::its now!!!!!!!!5
2023-12-01 16:48:58,181:INFO::its now!!!!!!!!0
2023-12-01 16:48:58,182:INFO::its now!!!!!!!!3
2023-12-01 16:48:58,208:INFO::its now!!!!!!!!5
2023-12-01 16:48:58,342:INFO::its now!!!!!!!!
2023-12-01 16:48:58,342:INFO::its now!!!!!!!! on 
2023-12-01 16:48:58,377:INFO::its now!!!!!!!!5
2023-12-01 16:48:58,540:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:58,542:INFO::Epoch 00094 | lr 0.00050 | Train_Loss 0.4882 | Train_Classification_Loss 0.5490 | Dmon_Loss -0.1217 | Val_Loss 0.6358 | Search Time(s) 0.3751 | Infer Time(s) 0.1695 | Time(s) 0.5447 
2023-12-01 16:48:58,585:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 1;	4: 1;	5: 2;	6: 2;	7: 1;	8: 2;	9: 1;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 2;	23: 1;	24: 1;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 3;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:58,587:INFO::Validation loss decreased (0.646937 --> 0.635820).  Saving model ...
2023-12-01 16:48:58,591:INFO::Epoch: 95
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:58,591:INFO::its now!!!!!!!!5
2023-12-01 16:48:58,736:INFO::its now!!!!!!!!0
2023-12-01 16:48:58,737:INFO::its now!!!!!!!!3
2023-12-01 16:48:58,764:INFO::its now!!!!!!!!5
2023-12-01 16:48:58,941:INFO::its now!!!!!!!!
2023-12-01 16:48:58,941:INFO::its now!!!!!!!! on 
2023-12-01 16:48:58,976:INFO::its now!!!!!!!!5
2023-12-01 16:48:59,141:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:59,143:INFO::Epoch 00095 | lr 0.00050 | Train_Loss 0.4719 | Train_Classification_Loss 0.5334 | Dmon_Loss -0.1230 | Val_Loss 0.6248 | Search Time(s) 0.3820 | Infer Time(s) 0.1721 | Time(s) 0.5541 
2023-12-01 16:48:59,194:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 1;	4: 1;	5: 2;	6: 2;	7: 1;	8: 1;	9: 0;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 2;	23: 1;	24: 2;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 3;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 1;	26104: 2;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:59,195:INFO::Validation loss decreased (0.635820 --> 0.624834).  Saving model ...
2023-12-01 16:48:59,198:INFO::Epoch: 96
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:59,199:INFO::its now!!!!!!!!5
2023-12-01 16:48:59,332:INFO::its now!!!!!!!!0
2023-12-01 16:48:59,333:INFO::its now!!!!!!!!3
2023-12-01 16:48:59,359:INFO::its now!!!!!!!!5
2023-12-01 16:48:59,534:INFO::its now!!!!!!!!
2023-12-01 16:48:59,534:INFO::its now!!!!!!!! on 
2023-12-01 16:48:59,570:INFO::its now!!!!!!!!5
2023-12-01 16:48:59,709:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:48:59,710:INFO::Epoch 00096 | lr 0.00050 | Train_Loss 0.4605 | Train_Classification_Loss 0.5219 | Dmon_Loss -0.1229 | Val_Loss 0.6140 | Search Time(s) 0.3686 | Infer Time(s) 0.1456 | Time(s) 0.5142 
2023-12-01 16:48:59,755:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 1;	4: 1;	5: 2;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 2;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:48:59,756:INFO::Validation loss decreased (0.624834 --> 0.614046).  Saving model ...
2023-12-01 16:48:59,760:INFO::Epoch: 97
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:48:59,761:INFO::its now!!!!!!!!5
2023-12-01 16:48:59,910:INFO::its now!!!!!!!!0
2023-12-01 16:48:59,910:INFO::its now!!!!!!!!3
2023-12-01 16:48:59,937:INFO::its now!!!!!!!!5
2023-12-01 16:49:00,123:INFO::its now!!!!!!!!
2023-12-01 16:49:00,123:INFO::its now!!!!!!!! on 
2023-12-01 16:49:00,159:INFO::its now!!!!!!!!5
2023-12-01 16:49:00,298:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:00,300:INFO::Epoch 00097 | lr 0.00050 | Train_Loss 0.4452 | Train_Classification_Loss 0.5080 | Dmon_Loss -0.1255 | Val_Loss 0.6035 | Search Time(s) 0.3965 | Infer Time(s) 0.1452 | Time(s) 0.5417 
2023-12-01 16:49:00,337:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 2;	6: 2;	7: 1;	8: 1;	9: 2;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 0;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 2;	26101: 2;	26102: 1;	26103: 3;	26104: 3;	26105: 2;	26106: 2;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:00,338:INFO::Validation loss decreased (0.614046 --> 0.603540).  Saving model ...
2023-12-01 16:49:00,342:INFO::Epoch: 98
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:00,343:INFO::its now!!!!!!!!5
2023-12-01 16:49:00,509:INFO::its now!!!!!!!!0
2023-12-01 16:49:00,510:INFO::its now!!!!!!!!3
2023-12-01 16:49:00,535:INFO::its now!!!!!!!!5
2023-12-01 16:49:00,695:INFO::its now!!!!!!!!
2023-12-01 16:49:00,695:INFO::its now!!!!!!!! on 
2023-12-01 16:49:00,731:INFO::its now!!!!!!!!5
2023-12-01 16:49:00,895:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:00,897:INFO::Epoch 00098 | lr 0.00050 | Train_Loss 0.4280 | Train_Classification_Loss 0.4915 | Dmon_Loss -0.1270 | Val_Loss 0.5932 | Search Time(s) 0.3870 | Infer Time(s) 0.1701 | Time(s) 0.5571 
2023-12-01 16:49:00,957:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 3;	26101: 1;	26102: 2;	26103: 2;	26104: 1;	26105: 2;	26106: 3;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:49:00,958:INFO::Validation loss decreased (0.603540 --> 0.593231).  Saving model ...
2023-12-01 16:49:00,964:INFO::Epoch: 99
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:00,965:INFO::its now!!!!!!!!5
2023-12-01 16:49:01,169:INFO::its now!!!!!!!!0
2023-12-01 16:49:01,170:INFO::its now!!!!!!!!3
2023-12-01 16:49:01,196:INFO::its now!!!!!!!!5
2023-12-01 16:49:01,370:INFO::its now!!!!!!!!
2023-12-01 16:49:01,370:INFO::its now!!!!!!!! on 
2023-12-01 16:49:01,407:INFO::its now!!!!!!!!5
2023-12-01 16:49:01,567:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:01,569:INFO::Epoch 00099 | lr 0.00050 | Train_Loss 0.4170 | Train_Classification_Loss 0.4807 | Dmon_Loss -0.1273 | Val_Loss 0.5831 | Search Time(s) 0.4400 | Infer Time(s) 0.1695 | Time(s) 0.6096 
2023-12-01 16:49:01,612:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 2;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 0;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 2;	26099: 2;	26100: 2;	26101: 2;	26102: 1;	26103: 2;	26104: 2;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:01,613:INFO::Validation loss decreased (0.593231 --> 0.583146).  Saving model ...
2023-12-01 16:49:01,616:INFO::Epoch: 100
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:01,616:INFO::its now!!!!!!!!5
2023-12-01 16:49:01,777:INFO::its now!!!!!!!!0
2023-12-01 16:49:01,778:INFO::its now!!!!!!!!3
2023-12-01 16:49:01,804:INFO::its now!!!!!!!!5
2023-12-01 16:49:01,967:INFO::its now!!!!!!!!
2023-12-01 16:49:01,967:INFO::its now!!!!!!!! on 
2023-12-01 16:49:02,004:INFO::its now!!!!!!!!5
2023-12-01 16:49:02,154:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:02,156:INFO::Epoch 00100 | lr 0.00050 | Train_Loss 0.4165 | Train_Classification_Loss 0.4809 | Dmon_Loss -0.1287 | Val_Loss 0.5733 | Search Time(s) 0.3840 | Infer Time(s) 0.1562 | Time(s) 0.5402 
2023-12-01 16:49:02,191:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 2;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 2;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 3;	26101: 2;	26102: 2;	26103: 2;	26104: 2;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:02,192:INFO::Validation loss decreased (0.583146 --> 0.573322).  Saving model ...
2023-12-01 16:49:02,195:INFO::Epoch: 101
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:02,196:INFO::its now!!!!!!!!5
2023-12-01 16:49:02,374:INFO::its now!!!!!!!!0
2023-12-01 16:49:02,375:INFO::its now!!!!!!!!3
2023-12-01 16:49:02,401:INFO::its now!!!!!!!!5
2023-12-01 16:49:02,551:INFO::its now!!!!!!!!
2023-12-01 16:49:02,551:INFO::its now!!!!!!!! on 
2023-12-01 16:49:02,585:INFO::its now!!!!!!!!5
2023-12-01 16:49:02,725:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:02,727:INFO::Epoch 00101 | lr 0.00050 | Train_Loss 0.4035 | Train_Classification_Loss 0.4690 | Dmon_Loss -0.1310 | Val_Loss 0.5638 | Search Time(s) 0.3855 | Infer Time(s) 0.1466 | Time(s) 0.5321 
2023-12-01 16:49:02,773:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 2;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 2;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 3;	26100: 1;	26101: 2;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:02,774:INFO::Validation loss decreased (0.573322 --> 0.563779).  Saving model ...
2023-12-01 16:49:02,776:INFO::Epoch: 102
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:02,777:INFO::its now!!!!!!!!5
2023-12-01 16:49:02,911:INFO::its now!!!!!!!!0
2023-12-01 16:49:02,912:INFO::its now!!!!!!!!3
2023-12-01 16:49:02,938:INFO::its now!!!!!!!!5
2023-12-01 16:49:03,102:INFO::its now!!!!!!!!
2023-12-01 16:49:03,102:INFO::its now!!!!!!!! on 
2023-12-01 16:49:03,136:INFO::its now!!!!!!!!5
2023-12-01 16:49:03,281:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:03,282:INFO::Epoch 00102 | lr 0.00050 | Train_Loss 0.3729 | Train_Classification_Loss 0.4394 | Dmon_Loss -0.1330 | Val_Loss 0.5545 | Search Time(s) 0.3556 | Infer Time(s) 0.1506 | Time(s) 0.5062 
2023-12-01 16:49:03,330:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 1;	26100: 3;	26101: 2;	26102: 2;	26103: 3;	26104: 2;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:03,332:INFO::Validation loss decreased (0.563779 --> 0.554483).  Saving model ...
2023-12-01 16:49:03,336:INFO::Epoch: 103
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:03,337:INFO::its now!!!!!!!!5
2023-12-01 16:49:03,487:INFO::its now!!!!!!!!0
2023-12-01 16:49:03,488:INFO::its now!!!!!!!!3
2023-12-01 16:49:03,532:INFO::its now!!!!!!!!5
2023-12-01 16:49:03,696:INFO::its now!!!!!!!!
2023-12-01 16:49:03,696:INFO::its now!!!!!!!! on 
2023-12-01 16:49:03,731:INFO::its now!!!!!!!!5
2023-12-01 16:49:03,893:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:03,895:INFO::Epoch 00103 | lr 0.00050 | Train_Loss 0.3692 | Train_Classification_Loss 0.4363 | Dmon_Loss -0.1343 | Val_Loss 0.5455 | Search Time(s) 0.3927 | Infer Time(s) 0.1685 | Time(s) 0.5612 
2023-12-01 16:49:03,946:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 2;	25: 3;	26: 1;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:03,947:INFO::Validation loss decreased (0.554483 --> 0.545490).  Saving model ...
2023-12-01 16:49:03,951:INFO::Epoch: 104
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:03,952:INFO::its now!!!!!!!!5
2023-12-01 16:49:04,095:INFO::its now!!!!!!!!0
2023-12-01 16:49:04,096:INFO::its now!!!!!!!!3
2023-12-01 16:49:04,122:INFO::its now!!!!!!!!5
2023-12-01 16:49:04,296:INFO::its now!!!!!!!!
2023-12-01 16:49:04,296:INFO::its now!!!!!!!! on 
2023-12-01 16:49:04,329:INFO::its now!!!!!!!!5
2023-12-01 16:49:04,502:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:04,503:INFO::Epoch 00104 | lr 0.00050 | Train_Loss 0.3618 | Train_Classification_Loss 0.4301 | Dmon_Loss -0.1366 | Val_Loss 0.5366 | Search Time(s) 0.3744 | Infer Time(s) 0.1795 | Time(s) 0.5540 
2023-12-01 16:49:04,546:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 2;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 2;	26103: 1;	26104: 3;	26105: 2;	26106: 3;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:04,547:INFO::Validation loss decreased (0.545490 --> 0.536637).  Saving model ...
2023-12-01 16:49:04,558:INFO::Epoch: 105
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:04,559:INFO::its now!!!!!!!!5
2023-12-01 16:49:04,721:INFO::its now!!!!!!!!0
2023-12-01 16:49:04,721:INFO::its now!!!!!!!!3
2023-12-01 16:49:04,748:INFO::its now!!!!!!!!5
2023-12-01 16:49:04,906:INFO::its now!!!!!!!!
2023-12-01 16:49:04,906:INFO::its now!!!!!!!! on 
2023-12-01 16:49:04,941:INFO::its now!!!!!!!!5
2023-12-01 16:49:05,116:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:05,117:INFO::Epoch 00105 | lr 0.00050 | Train_Loss 0.3491 | Train_Classification_Loss 0.4186 | Dmon_Loss -0.1390 | Val_Loss 0.5281 | Search Time(s) 0.3890 | Infer Time(s) 0.1781 | Time(s) 0.5671 
2023-12-01 16:49:05,178:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 3;	5: 1;	6: 2;	7: 1;	8: 1;	9: 3;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 2;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 3;	26099: 2;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 2;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:05,179:INFO::Validation loss decreased (0.536637 --> 0.528114).  Saving model ...
2023-12-01 16:49:05,182:INFO::Epoch: 106
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:05,183:INFO::its now!!!!!!!!5
2023-12-01 16:49:05,325:INFO::its now!!!!!!!!0
2023-12-01 16:49:05,325:INFO::its now!!!!!!!!3
2023-12-01 16:49:05,351:INFO::its now!!!!!!!!5
2023-12-01 16:49:05,533:INFO::its now!!!!!!!!
2023-12-01 16:49:05,533:INFO::its now!!!!!!!! on 
2023-12-01 16:49:05,567:INFO::its now!!!!!!!!5
2023-12-01 16:49:05,713:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:05,715:INFO::Epoch 00106 | lr 0.00050 | Train_Loss 0.3355 | Train_Classification_Loss 0.4058 | Dmon_Loss -0.1406 | Val_Loss 0.5197 | Search Time(s) 0.3816 | Infer Time(s) 0.1526 | Time(s) 0.5342 
2023-12-01 16:49:05,775:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 3;	26102: 1;	26103: 2;	26104: 1;	26105: 2;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:05,776:INFO::Validation loss decreased (0.528114 --> 0.519691).  Saving model ...
2023-12-01 16:49:05,780:INFO::Epoch: 107
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:05,780:INFO::its now!!!!!!!!5
2023-12-01 16:49:05,941:INFO::its now!!!!!!!!0
2023-12-01 16:49:05,942:INFO::its now!!!!!!!!3
2023-12-01 16:49:05,968:INFO::its now!!!!!!!!5
2023-12-01 16:49:06,139:INFO::its now!!!!!!!!
2023-12-01 16:49:06,139:INFO::its now!!!!!!!! on 
2023-12-01 16:49:06,173:INFO::its now!!!!!!!!5
2023-12-01 16:49:06,332:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:06,333:INFO::Epoch 00107 | lr 0.00050 | Train_Loss 0.3148 | Train_Classification_Loss 0.3865 | Dmon_Loss -0.1435 | Val_Loss 0.5114 | Search Time(s) 0.3915 | Infer Time(s) 0.1632 | Time(s) 0.5547 
2023-12-01 16:49:06,385:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 2;	26100: 2;	26101: 3;	26102: 2;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:06,387:INFO::Validation loss decreased (0.519691 --> 0.511442).  Saving model ...
2023-12-01 16:49:06,391:INFO::Epoch: 108
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:06,392:INFO::its now!!!!!!!!5
2023-12-01 16:49:06,568:INFO::its now!!!!!!!!0
2023-12-01 16:49:06,569:INFO::its now!!!!!!!!3
2023-12-01 16:49:06,595:INFO::its now!!!!!!!!5
2023-12-01 16:49:06,754:INFO::its now!!!!!!!!
2023-12-01 16:49:06,754:INFO::its now!!!!!!!! on 
2023-12-01 16:49:06,789:INFO::its now!!!!!!!!5
2023-12-01 16:49:06,935:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:06,936:INFO::Epoch 00108 | lr 0.00050 | Train_Loss 0.3120 | Train_Classification_Loss 0.3846 | Dmon_Loss -0.1452 | Val_Loss 0.5035 | Search Time(s) 0.3949 | Infer Time(s) 0.1526 | Time(s) 0.5475 
2023-12-01 16:49:06,979:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 1;	26099: 1;	26100: 1;	26101: 0;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:06,980:INFO::Validation loss decreased (0.511442 --> 0.503457).  Saving model ...
2023-12-01 16:49:06,985:INFO::Epoch: 109
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:06,987:INFO::its now!!!!!!!!5
2023-12-01 16:49:07,136:INFO::its now!!!!!!!!0
2023-12-01 16:49:07,136:INFO::its now!!!!!!!!3
2023-12-01 16:49:07,162:INFO::its now!!!!!!!!5
2023-12-01 16:49:07,334:INFO::its now!!!!!!!!
2023-12-01 16:49:07,335:INFO::its now!!!!!!!! on 
2023-12-01 16:49:07,369:INFO::its now!!!!!!!!5
2023-12-01 16:49:07,528:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:07,530:INFO::Epoch 00109 | lr 0.00050 | Train_Loss 0.2939 | Train_Classification_Loss 0.3677 | Dmon_Loss -0.1477 | Val_Loss 0.4956 | Search Time(s) 0.3833 | Infer Time(s) 0.1646 | Time(s) 0.5478 
2023-12-01 16:49:07,582:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 3;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 0;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:07,583:INFO::Validation loss decreased (0.503457 --> 0.495633).  Saving model ...
2023-12-01 16:49:07,587:INFO::Epoch: 110
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:07,588:INFO::its now!!!!!!!!5
2023-12-01 16:49:07,732:INFO::its now!!!!!!!!0
2023-12-01 16:49:07,733:INFO::its now!!!!!!!!3
2023-12-01 16:49:07,758:INFO::its now!!!!!!!!5
2023-12-01 16:49:07,903:INFO::its now!!!!!!!!
2023-12-01 16:49:07,903:INFO::its now!!!!!!!! on 
2023-12-01 16:49:07,936:INFO::its now!!!!!!!!5
2023-12-01 16:49:08,076:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:08,077:INFO::Epoch 00110 | lr 0.00050 | Train_Loss 0.2927 | Train_Classification_Loss 0.3676 | Dmon_Loss -0.1497 | Val_Loss 0.4881 | Search Time(s) 0.3471 | Infer Time(s) 0.1466 | Time(s) 0.4937 
2023-12-01 16:49:08,122:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 0;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 0;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 2;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 16:49:08,123:INFO::Validation loss decreased (0.495633 --> 0.488096).  Saving model ...
2023-12-01 16:49:08,127:INFO::Epoch: 111
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:08,128:INFO::its now!!!!!!!!5
2023-12-01 16:49:08,265:INFO::its now!!!!!!!!0
2023-12-01 16:49:08,266:INFO::its now!!!!!!!!3
2023-12-01 16:49:08,294:INFO::its now!!!!!!!!5
2023-12-01 16:49:08,463:INFO::its now!!!!!!!!
2023-12-01 16:49:08,463:INFO::its now!!!!!!!! on 
2023-12-01 16:49:08,497:INFO::its now!!!!!!!!5
2023-12-01 16:49:08,639:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:08,641:INFO::Epoch 00111 | lr 0.00050 | Train_Loss 0.2768 | Train_Classification_Loss 0.3521 | Dmon_Loss -0.1506 | Val_Loss 0.4808 | Search Time(s) 0.3676 | Infer Time(s) 0.1482 | Time(s) 0.5159 
2023-12-01 16:49:08,692:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 2;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:08,693:INFO::Validation loss decreased (0.488096 --> 0.480761).  Saving model ...
2023-12-01 16:49:08,697:INFO::Epoch: 112
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:08,697:INFO::its now!!!!!!!!5
2023-12-01 16:49:08,839:INFO::its now!!!!!!!!0
2023-12-01 16:49:08,839:INFO::its now!!!!!!!!3
2023-12-01 16:49:08,865:INFO::its now!!!!!!!!5
2023-12-01 16:49:09,009:INFO::its now!!!!!!!!
2023-12-01 16:49:09,010:INFO::its now!!!!!!!! on 
2023-12-01 16:49:09,044:INFO::its now!!!!!!!!5
2023-12-01 16:49:09,186:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:09,188:INFO::Epoch 00112 | lr 0.00050 | Train_Loss 0.2700 | Train_Classification_Loss 0.3465 | Dmon_Loss -0.1531 | Val_Loss 0.4737 | Search Time(s) 0.3441 | Infer Time(s) 0.1492 | Time(s) 0.4933 
2023-12-01 16:49:09,231:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 2;	44
26098: 0;	26099: 1;	26100: 3;	26101: 3;	26102: 2;	26103: 2;	26104: 2;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:09,232:INFO::Validation loss decreased (0.480761 --> 0.473743).  Saving model ...
2023-12-01 16:49:09,237:INFO::Epoch: 113
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:09,237:INFO::its now!!!!!!!!5
2023-12-01 16:49:09,394:INFO::its now!!!!!!!!0
2023-12-01 16:49:09,394:INFO::its now!!!!!!!!3
2023-12-01 16:49:09,422:INFO::its now!!!!!!!!5
2023-12-01 16:49:09,596:INFO::its now!!!!!!!!
2023-12-01 16:49:09,596:INFO::its now!!!!!!!! on 
2023-12-01 16:49:09,631:INFO::its now!!!!!!!!5
2023-12-01 16:49:09,793:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:09,794:INFO::Epoch 00113 | lr 0.00050 | Train_Loss 0.2599 | Train_Classification_Loss 0.3386 | Dmon_Loss -0.1575 | Val_Loss 0.4670 | Search Time(s) 0.3936 | Infer Time(s) 0.1675 | Time(s) 0.5611 
2023-12-01 16:49:09,840:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 2;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 0;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 1;	26105: 1;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:09,841:INFO::Validation loss decreased (0.473743 --> 0.466991).  Saving model ...
2023-12-01 16:49:09,846:INFO::Epoch: 114
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:09,847:INFO::its now!!!!!!!!5
2023-12-01 16:49:09,987:INFO::its now!!!!!!!!0
2023-12-01 16:49:09,988:INFO::its now!!!!!!!!3
2023-12-01 16:49:10,014:INFO::its now!!!!!!!!5
2023-12-01 16:49:10,173:INFO::its now!!!!!!!!
2023-12-01 16:49:10,173:INFO::its now!!!!!!!! on 
2023-12-01 16:49:10,209:INFO::its now!!!!!!!!5
2023-12-01 16:49:10,351:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:10,354:INFO::Epoch 00114 | lr 0.00050 | Train_Loss 0.2519 | Train_Classification_Loss 0.3315 | Dmon_Loss -0.1592 | Val_Loss 0.4604 | Search Time(s) 0.3610 | Infer Time(s) 0.1482 | Time(s) 0.5092 
2023-12-01 16:49:10,399:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 2;	26103: 2;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:10,400:INFO::Validation loss decreased (0.466991 --> 0.460427).  Saving model ...
2023-12-01 16:49:10,407:INFO::Epoch: 115
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:10,407:INFO::its now!!!!!!!!5
2023-12-01 16:49:10,577:INFO::its now!!!!!!!!0
2023-12-01 16:49:10,578:INFO::its now!!!!!!!!3
2023-12-01 16:49:10,603:INFO::its now!!!!!!!!5
2023-12-01 16:49:10,755:INFO::its now!!!!!!!!
2023-12-01 16:49:10,755:INFO::its now!!!!!!!! on 
2023-12-01 16:49:10,790:INFO::its now!!!!!!!!5
2023-12-01 16:49:10,936:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:10,938:INFO::Epoch 00115 | lr 0.00050 | Train_Loss 0.2318 | Train_Classification_Loss 0.3133 | Dmon_Loss -0.1631 | Val_Loss 0.4541 | Search Time(s) 0.3840 | Infer Time(s) 0.1526 | Time(s) 0.5366 
2023-12-01 16:49:10,974:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 2;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:10,975:INFO::Validation loss decreased (0.460427 --> 0.454144).  Saving model ...
2023-12-01 16:49:10,979:INFO::Epoch: 116
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:10,980:INFO::its now!!!!!!!!5
2023-12-01 16:49:11,154:INFO::its now!!!!!!!!0
2023-12-01 16:49:11,155:INFO::its now!!!!!!!!3
2023-12-01 16:49:11,180:INFO::its now!!!!!!!!5
2023-12-01 16:49:11,339:INFO::its now!!!!!!!!
2023-12-01 16:49:11,339:INFO::its now!!!!!!!! on 
2023-12-01 16:49:11,372:INFO::its now!!!!!!!!5
2023-12-01 16:49:11,536:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:11,538:INFO::Epoch 00116 | lr 0.00050 | Train_Loss 0.2281 | Train_Classification_Loss 0.3109 | Dmon_Loss -0.1657 | Val_Loss 0.4482 | Search Time(s) 0.3912 | Infer Time(s) 0.1686 | Time(s) 0.5598 
2023-12-01 16:49:11,590:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:11,591:INFO::Validation loss decreased (0.454144 --> 0.448188).  Saving model ...
2023-12-01 16:49:11,596:INFO::Epoch: 117
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:11,597:INFO::its now!!!!!!!!5
2023-12-01 16:49:11,781:INFO::its now!!!!!!!!0
2023-12-01 16:49:11,782:INFO::its now!!!!!!!!3
2023-12-01 16:49:11,809:INFO::its now!!!!!!!!5
2023-12-01 16:49:12,016:INFO::its now!!!!!!!!
2023-12-01 16:49:12,017:INFO::its now!!!!!!!! on 
2023-12-01 16:49:12,053:INFO::its now!!!!!!!!5
2023-12-01 16:49:12,201:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:12,203:INFO::Epoch 00117 | lr 0.00050 | Train_Loss 0.2055 | Train_Classification_Loss 0.2896 | Dmon_Loss -0.1682 | Val_Loss 0.4423 | Search Time(s) 0.4548 | Infer Time(s) 0.1559 | Time(s) 0.6107 
2023-12-01 16:49:12,261:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 0;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:12,262:INFO::Validation loss decreased (0.448188 --> 0.442349).  Saving model ...
2023-12-01 16:49:12,265:INFO::Epoch: 118
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:12,266:INFO::its now!!!!!!!!5
2023-12-01 16:49:12,424:INFO::its now!!!!!!!!0
2023-12-01 16:49:12,425:INFO::its now!!!!!!!!3
2023-12-01 16:49:12,451:INFO::its now!!!!!!!!5
2023-12-01 16:49:12,599:INFO::its now!!!!!!!!
2023-12-01 16:49:12,599:INFO::its now!!!!!!!! on 
2023-12-01 16:49:12,635:INFO::its now!!!!!!!!5
2023-12-01 16:49:12,770:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:12,772:INFO::Epoch 00118 | lr 0.00050 | Train_Loss 0.2017 | Train_Classification_Loss 0.2867 | Dmon_Loss -0.1700 | Val_Loss 0.4367 | Search Time(s) 0.3666 | Infer Time(s) 0.1406 | Time(s) 0.5072 
2023-12-01 16:49:12,808:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 0;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:12,809:INFO::Validation loss decreased (0.442349 --> 0.436664).  Saving model ...
2023-12-01 16:49:12,812:INFO::Epoch: 119
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:12,813:INFO::its now!!!!!!!!5
2023-12-01 16:49:12,979:INFO::its now!!!!!!!!0
2023-12-01 16:49:12,979:INFO::its now!!!!!!!!3
2023-12-01 16:49:13,006:INFO::its now!!!!!!!!5
2023-12-01 16:49:13,173:INFO::its now!!!!!!!!
2023-12-01 16:49:13,174:INFO::its now!!!!!!!! on 
2023-12-01 16:49:13,208:INFO::its now!!!!!!!!5
2023-12-01 16:49:13,351:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:13,352:INFO::Epoch 00119 | lr 0.00050 | Train_Loss 0.1958 | Train_Classification_Loss 0.2818 | Dmon_Loss -0.1719 | Val_Loss 0.4313 | Search Time(s) 0.3935 | Infer Time(s) 0.1482 | Time(s) 0.5417 
2023-12-01 16:49:13,395:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:13,396:INFO::Validation loss decreased (0.436664 --> 0.431284).  Saving model ...
2023-12-01 16:49:13,399:INFO::Epoch: 120
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:13,400:INFO::its now!!!!!!!!5
2023-12-01 16:49:13,541:INFO::its now!!!!!!!!0
2023-12-01 16:49:13,542:INFO::its now!!!!!!!!3
2023-12-01 16:49:13,569:INFO::its now!!!!!!!!5
2023-12-01 16:49:13,725:INFO::its now!!!!!!!!
2023-12-01 16:49:13,725:INFO::its now!!!!!!!! on 
2023-12-01 16:49:13,761:INFO::its now!!!!!!!!5
2023-12-01 16:49:13,915:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:13,917:INFO::Epoch 00120 | lr 0.00050 | Train_Loss 0.1956 | Train_Classification_Loss 0.2819 | Dmon_Loss -0.1725 | Val_Loss 0.4261 | Search Time(s) 0.3587 | Infer Time(s) 0.1606 | Time(s) 0.5193 
2023-12-01 16:49:13,981:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 2;	26102: 2;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:13,982:INFO::Validation loss decreased (0.431284 --> 0.426105).  Saving model ...
2023-12-01 16:49:13,987:INFO::Epoch: 121
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:13,988:INFO::its now!!!!!!!!5
2023-12-01 16:49:14,149:INFO::its now!!!!!!!!0
2023-12-01 16:49:14,150:INFO::its now!!!!!!!!3
2023-12-01 16:49:14,176:INFO::its now!!!!!!!!5
2023-12-01 16:49:14,371:INFO::its now!!!!!!!!
2023-12-01 16:49:14,371:INFO::its now!!!!!!!! on 
2023-12-01 16:49:14,407:INFO::its now!!!!!!!!5
2023-12-01 16:49:14,580:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:14,581:INFO::Epoch 00121 | lr 0.00050 | Train_Loss 0.1867 | Train_Classification_Loss 0.2753 | Dmon_Loss -0.1772 | Val_Loss 0.4211 | Search Time(s) 0.4190 | Infer Time(s) 0.1785 | Time(s) 0.5976 
2023-12-01 16:49:14,630:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:14,631:INFO::Validation loss decreased (0.426105 --> 0.421070).  Saving model ...
2023-12-01 16:49:14,635:INFO::Epoch: 122
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:14,636:INFO::its now!!!!!!!!5
2023-12-01 16:49:14,783:INFO::its now!!!!!!!!0
2023-12-01 16:49:14,784:INFO::its now!!!!!!!!3
2023-12-01 16:49:14,829:INFO::its now!!!!!!!!5
2023-12-01 16:49:15,003:INFO::its now!!!!!!!!
2023-12-01 16:49:15,003:INFO::its now!!!!!!!! on 
2023-12-01 16:49:15,038:INFO::its now!!!!!!!!5
2023-12-01 16:49:15,193:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:15,194:INFO::Epoch 00122 | lr 0.00050 | Train_Loss 0.1760 | Train_Classification_Loss 0.2666 | Dmon_Loss -0.1813 | Val_Loss 0.4162 | Search Time(s) 0.4009 | Infer Time(s) 0.1612 | Time(s) 0.5621 
2023-12-01 16:49:15,230:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:15,230:INFO::Validation loss decreased (0.421070 --> 0.416208).  Saving model ...
2023-12-01 16:49:15,233:INFO::Epoch: 123
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:15,234:INFO::its now!!!!!!!!5
2023-12-01 16:49:15,375:INFO::its now!!!!!!!!0
2023-12-01 16:49:15,376:INFO::its now!!!!!!!!3
2023-12-01 16:49:15,406:INFO::its now!!!!!!!!5
2023-12-01 16:49:15,560:INFO::its now!!!!!!!!
2023-12-01 16:49:15,561:INFO::its now!!!!!!!! on 
2023-12-01 16:49:15,595:INFO::its now!!!!!!!!5
2023-12-01 16:49:15,748:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:15,749:INFO::Epoch 00123 | lr 0.00050 | Train_Loss 0.1692 | Train_Classification_Loss 0.2601 | Dmon_Loss -0.1819 | Val_Loss 0.4116 | Search Time(s) 0.3586 | Infer Time(s) 0.1586 | Time(s) 0.5172 
2023-12-01 16:49:15,801:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 2;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:15,802:INFO::Validation loss decreased (0.416208 --> 0.411587).  Saving model ...
2023-12-01 16:49:15,805:INFO::Epoch: 124
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:15,806:INFO::its now!!!!!!!!5
2023-12-01 16:49:15,957:INFO::its now!!!!!!!!0
2023-12-01 16:49:15,958:INFO::its now!!!!!!!!3
2023-12-01 16:49:15,985:INFO::its now!!!!!!!!5
2023-12-01 16:49:16,164:INFO::its now!!!!!!!!
2023-12-01 16:49:16,164:INFO::its now!!!!!!!! on 
2023-12-01 16:49:16,197:INFO::its now!!!!!!!!5
2023-12-01 16:49:16,337:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:16,338:INFO::Epoch 00124 | lr 0.00050 | Train_Loss 0.1633 | Train_Classification_Loss 0.2543 | Dmon_Loss -0.1820 | Val_Loss 0.4072 | Search Time(s) 0.3886 | Infer Time(s) 0.1462 | Time(s) 0.5348 
2023-12-01 16:49:16,384:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 2;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:16,385:INFO::Validation loss decreased (0.411587 --> 0.407193).  Saving model ...
2023-12-01 16:49:16,392:INFO::Epoch: 125
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:16,392:INFO::its now!!!!!!!!5
2023-12-01 16:49:16,543:INFO::its now!!!!!!!!0
2023-12-01 16:49:16,544:INFO::its now!!!!!!!!3
2023-12-01 16:49:16,591:INFO::its now!!!!!!!!5
2023-12-01 16:49:16,739:INFO::its now!!!!!!!!
2023-12-01 16:49:16,739:INFO::its now!!!!!!!! on 
2023-12-01 16:49:16,773:INFO::its now!!!!!!!!5
2023-12-01 16:49:16,913:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:16,914:INFO::Epoch 00125 | lr 0.00050 | Train_Loss 0.1472 | Train_Classification_Loss 0.2409 | Dmon_Loss -0.1874 | Val_Loss 0.4030 | Search Time(s) 0.3810 | Infer Time(s) 0.1466 | Time(s) 0.5276 
2023-12-01 16:49:16,958:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 0;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:16,959:INFO::Validation loss decreased (0.407193 --> 0.403043).  Saving model ...
2023-12-01 16:49:16,962:INFO::Epoch: 126
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:16,962:INFO::its now!!!!!!!!5
2023-12-01 16:49:17,126:INFO::its now!!!!!!!!0
2023-12-01 16:49:17,127:INFO::its now!!!!!!!!3
2023-12-01 16:49:17,175:INFO::its now!!!!!!!!5
2023-12-01 16:49:17,343:INFO::its now!!!!!!!!
2023-12-01 16:49:17,343:INFO::its now!!!!!!!! on 
2023-12-01 16:49:17,378:INFO::its now!!!!!!!!5
2023-12-01 16:49:17,547:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:17,549:INFO::Epoch 00126 | lr 0.00050 | Train_Loss 0.1538 | Train_Classification_Loss 0.2478 | Dmon_Loss -0.1881 | Val_Loss 0.3991 | Search Time(s) 0.4150 | Infer Time(s) 0.1735 | Time(s) 0.5886 
2023-12-01 16:49:17,605:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:17,606:INFO::Validation loss decreased (0.403043 --> 0.399070).  Saving model ...
2023-12-01 16:49:17,609:INFO::Epoch: 127
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:17,610:INFO::its now!!!!!!!!5
2023-12-01 16:49:17,745:INFO::its now!!!!!!!!0
2023-12-01 16:49:17,746:INFO::its now!!!!!!!!3
2023-12-01 16:49:17,773:INFO::its now!!!!!!!!5
2023-12-01 16:49:17,937:INFO::its now!!!!!!!!
2023-12-01 16:49:17,937:INFO::its now!!!!!!!! on 
2023-12-01 16:49:17,971:INFO::its now!!!!!!!!5
2023-12-01 16:49:18,127:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:18,129:INFO::Epoch 00127 | lr 0.00050 | Train_Loss 0.1403 | Train_Classification_Loss 0.2358 | Dmon_Loss -0.1909 | Val_Loss 0.3954 | Search Time(s) 0.3580 | Infer Time(s) 0.1632 | Time(s) 0.5212 
2023-12-01 16:49:18,181:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 2;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:18,182:INFO::Validation loss decreased (0.399070 --> 0.395415).  Saving model ...
2023-12-01 16:49:18,187:INFO::Epoch: 128
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:18,189:INFO::its now!!!!!!!!5
2023-12-01 16:49:18,358:INFO::its now!!!!!!!!0
2023-12-01 16:49:18,359:INFO::its now!!!!!!!!3
2023-12-01 16:49:18,386:INFO::its now!!!!!!!!5
2023-12-01 16:49:18,546:INFO::its now!!!!!!!!
2023-12-01 16:49:18,546:INFO::its now!!!!!!!! on 
2023-12-01 16:49:18,581:INFO::its now!!!!!!!!5
2023-12-01 16:49:18,749:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:18,751:INFO::Epoch 00128 | lr 0.00050 | Train_Loss 0.1343 | Train_Classification_Loss 0.2306 | Dmon_Loss -0.1926 | Val_Loss 0.3920 | Search Time(s) 0.3931 | Infer Time(s) 0.1738 | Time(s) 0.5669 
2023-12-01 16:49:18,804:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:18,806:INFO::Validation loss decreased (0.395415 --> 0.392045).  Saving model ...
2023-12-01 16:49:18,810:INFO::Epoch: 129
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:18,811:INFO::its now!!!!!!!!5
2023-12-01 16:49:18,968:INFO::its now!!!!!!!!0
2023-12-01 16:49:18,969:INFO::its now!!!!!!!!3
2023-12-01 16:49:18,996:INFO::its now!!!!!!!!5
2023-12-01 16:49:19,145:INFO::its now!!!!!!!!
2023-12-01 16:49:19,145:INFO::its now!!!!!!!! on 
2023-12-01 16:49:19,180:INFO::its now!!!!!!!!5
2023-12-01 16:49:19,336:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:19,338:INFO::Epoch 00129 | lr 0.00050 | Train_Loss 0.1268 | Train_Classification_Loss 0.2248 | Dmon_Loss -0.1959 | Val_Loss 0.3888 | Search Time(s) 0.3666 | Infer Time(s) 0.1631 | Time(s) 0.5298 
2023-12-01 16:49:19,388:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:19,389:INFO::Validation loss decreased (0.392045 --> 0.388801).  Saving model ...
2023-12-01 16:49:19,395:INFO::Epoch: 130
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:19,396:INFO::its now!!!!!!!!5
2023-12-01 16:49:19,557:INFO::its now!!!!!!!!0
2023-12-01 16:49:19,557:INFO::its now!!!!!!!!3
2023-12-01 16:49:19,583:INFO::its now!!!!!!!!5
2023-12-01 16:49:19,763:INFO::its now!!!!!!!!
2023-12-01 16:49:19,763:INFO::its now!!!!!!!! on 
2023-12-01 16:49:19,796:INFO::its now!!!!!!!!5
2023-12-01 16:49:19,943:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:19,945:INFO::Epoch 00130 | lr 0.00050 | Train_Loss 0.1206 | Train_Classification_Loss 0.2182 | Dmon_Loss -0.1951 | Val_Loss 0.3859 | Search Time(s) 0.4009 | Infer Time(s) 0.1526 | Time(s) 0.5535 
2023-12-01 16:49:19,989:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:19,991:INFO::Validation loss decreased (0.388801 --> 0.385866).  Saving model ...
2023-12-01 16:49:19,995:INFO::Epoch: 131
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:19,996:INFO::its now!!!!!!!!5
2023-12-01 16:49:20,149:INFO::its now!!!!!!!!0
2023-12-01 16:49:20,150:INFO::its now!!!!!!!!3
2023-12-01 16:49:20,194:INFO::its now!!!!!!!!5
2023-12-01 16:49:20,369:INFO::its now!!!!!!!!
2023-12-01 16:49:20,369:INFO::its now!!!!!!!! on 
2023-12-01 16:49:20,403:INFO::its now!!!!!!!!5
2023-12-01 16:49:20,560:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:20,561:INFO::Epoch 00131 | lr 0.00050 | Train_Loss 0.1167 | Train_Classification_Loss 0.2154 | Dmon_Loss -0.1973 | Val_Loss 0.3828 | Search Time(s) 0.4061 | Infer Time(s) 0.1626 | Time(s) 0.5687 
2023-12-01 16:49:20,597:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:20,599:INFO::Validation loss decreased (0.385866 --> 0.382802).  Saving model ...
2023-12-01 16:49:20,605:INFO::Epoch: 132
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:20,606:INFO::its now!!!!!!!!5
2023-12-01 16:49:20,757:INFO::its now!!!!!!!!0
2023-12-01 16:49:20,758:INFO::its now!!!!!!!!3
2023-12-01 16:49:20,805:INFO::its now!!!!!!!!5
2023-12-01 16:49:20,960:INFO::its now!!!!!!!!
2023-12-01 16:49:20,960:INFO::its now!!!!!!!! on 
2023-12-01 16:49:20,995:INFO::its now!!!!!!!!5
2023-12-01 16:49:21,154:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:21,155:INFO::Epoch 00132 | lr 0.00050 | Train_Loss 0.1066 | Train_Classification_Loss 0.2064 | Dmon_Loss -0.1996 | Val_Loss 0.3798 | Search Time(s) 0.3879 | Infer Time(s) 0.1652 | Time(s) 0.5531 
2023-12-01 16:49:21,210:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:21,212:INFO::Validation loss decreased (0.382802 --> 0.379799).  Saving model ...
2023-12-01 16:49:21,216:INFO::Epoch: 133
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:21,216:INFO::its now!!!!!!!!5
2023-12-01 16:49:21,359:INFO::its now!!!!!!!!0
2023-12-01 16:49:21,360:INFO::its now!!!!!!!!3
2023-12-01 16:49:21,390:INFO::its now!!!!!!!!5
2023-12-01 16:49:21,543:INFO::its now!!!!!!!!
2023-12-01 16:49:21,543:INFO::its now!!!!!!!! on 
2023-12-01 16:49:21,580:INFO::its now!!!!!!!!5
2023-12-01 16:49:21,729:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:21,730:INFO::Epoch 00133 | lr 0.00050 | Train_Loss 0.1002 | Train_Classification_Loss 0.2016 | Dmon_Loss -0.2028 | Val_Loss 0.3771 | Search Time(s) 0.3587 | Infer Time(s) 0.1575 | Time(s) 0.5162 
2023-12-01 16:49:21,776:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:21,777:INFO::Validation loss decreased (0.379799 --> 0.377052).  Saving model ...
2023-12-01 16:49:21,781:INFO::Epoch: 134
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:21,782:INFO::its now!!!!!!!!5
2023-12-01 16:49:21,915:INFO::its now!!!!!!!!0
2023-12-01 16:49:21,916:INFO::its now!!!!!!!!3
2023-12-01 16:49:21,942:INFO::its now!!!!!!!!5
2023-12-01 16:49:22,098:INFO::its now!!!!!!!!
2023-12-01 16:49:22,098:INFO::its now!!!!!!!! on 
2023-12-01 16:49:22,133:INFO::its now!!!!!!!!5
2023-12-01 16:49:22,283:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:22,285:INFO::Epoch 00134 | lr 0.00050 | Train_Loss 0.1021 | Train_Classification_Loss 0.2033 | Dmon_Loss -0.2025 | Val_Loss 0.3743 | Search Time(s) 0.3506 | Infer Time(s) 0.1556 | Time(s) 0.5062 
2023-12-01 16:49:22,327:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:22,328:INFO::Validation loss decreased (0.377052 --> 0.374257).  Saving model ...
2023-12-01 16:49:22,332:INFO::Epoch: 135
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:22,333:INFO::its now!!!!!!!!5
2023-12-01 16:49:22,490:INFO::its now!!!!!!!!0
2023-12-01 16:49:22,491:INFO::its now!!!!!!!!3
2023-12-01 16:49:22,516:INFO::its now!!!!!!!!5
2023-12-01 16:49:22,709:INFO::its now!!!!!!!!
2023-12-01 16:49:22,709:INFO::its now!!!!!!!! on 
2023-12-01 16:49:22,743:INFO::its now!!!!!!!!5
2023-12-01 16:49:22,898:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:22,931:INFO::Epoch 00135 | lr 0.00050 | Train_Loss 0.0980 | Train_Classification_Loss 0.2002 | Dmon_Loss -0.2044 | Val_Loss 0.3713 | Search Time(s) 0.4079 | Infer Time(s) 0.1616 | Time(s) 0.5695 
2023-12-01 16:49:22,992:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:22,993:INFO::Validation loss decreased (0.374257 --> 0.371348).  Saving model ...
2023-12-01 16:49:22,996:INFO::Epoch: 136
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:22,996:INFO::its now!!!!!!!!5
2023-12-01 16:49:23,155:INFO::its now!!!!!!!!0
2023-12-01 16:49:23,156:INFO::its now!!!!!!!!3
2023-12-01 16:49:23,181:INFO::its now!!!!!!!!5
2023-12-01 16:49:23,333:INFO::its now!!!!!!!!
2023-12-01 16:49:23,333:INFO::its now!!!!!!!! on 
2023-12-01 16:49:23,385:INFO::its now!!!!!!!!5
2023-12-01 16:49:23,554:INFO::Epoch 00136 | lr 0.00050 | Train_Loss 0.1773 | Train_Classification_Loss 0.2648 | Dmon_Loss -0.1750 | Val_Loss 0.4082 | Search Time(s) 0.3721 | Infer Time(s) 0.1875 | Time(s) 0.5596 
2023-12-01 16:49:23,593:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:23,594:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:23,597:INFO::Epoch: 137
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:23,598:INFO::its now!!!!!!!!5
2023-12-01 16:49:23,729:INFO::its now!!!!!!!!0
2023-12-01 16:49:23,730:INFO::its now!!!!!!!!3
2023-12-01 16:49:23,772:INFO::its now!!!!!!!!5
2023-12-01 16:49:23,917:INFO::its now!!!!!!!!
2023-12-01 16:49:23,918:INFO::its now!!!!!!!! on 
2023-12-01 16:49:23,952:INFO::its now!!!!!!!!5
2023-12-01 16:49:24,104:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:24,105:INFO::Epoch 00137 | lr 0.00050 | Train_Loss 0.0887 | Train_Classification_Loss 0.1919 | Dmon_Loss -0.2064 | Val_Loss 0.3697 | Search Time(s) 0.3537 | Infer Time(s) 0.1562 | Time(s) 0.5099 
2023-12-01 16:49:24,145:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:24,146:INFO::Validation loss decreased (0.371348 --> 0.369685).  Saving model ...
2023-12-01 16:49:24,150:INFO::Epoch: 138
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:24,151:INFO::its now!!!!!!!!5
2023-12-01 16:49:24,303:INFO::its now!!!!!!!!0
2023-12-01 16:49:24,305:INFO::its now!!!!!!!!3
2023-12-01 16:49:24,332:INFO::its now!!!!!!!!5
2023-12-01 16:49:24,497:INFO::its now!!!!!!!!
2023-12-01 16:49:24,497:INFO::its now!!!!!!!! on 
2023-12-01 16:49:24,532:INFO::its now!!!!!!!!5
2023-12-01 16:49:24,682:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:24,685:INFO::Epoch 00138 | lr 0.00050 | Train_Loss 0.0797 | Train_Classification_Loss 0.1839 | Dmon_Loss -0.2085 | Val_Loss 0.3686 | Search Time(s) 0.3806 | Infer Time(s) 0.1556 | Time(s) 0.5362 
2023-12-01 16:49:24,731:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:24,732:INFO::Validation loss decreased (0.369685 --> 0.368585).  Saving model ...
2023-12-01 16:49:24,736:INFO::Epoch: 139
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:24,737:INFO::its now!!!!!!!!5
2023-12-01 16:49:24,874:INFO::its now!!!!!!!!0
2023-12-01 16:49:24,874:INFO::its now!!!!!!!!3
2023-12-01 16:49:24,901:INFO::its now!!!!!!!!5
2023-12-01 16:49:25,064:INFO::its now!!!!!!!!
2023-12-01 16:49:25,065:INFO::its now!!!!!!!! on 
2023-12-01 16:49:25,099:INFO::its now!!!!!!!!5
2023-12-01 16:49:25,248:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:25,249:INFO::Epoch 00139 | lr 0.00050 | Train_Loss 0.0712 | Train_Classification_Loss 0.1763 | Dmon_Loss -0.2101 | Val_Loss 0.3672 | Search Time(s) 0.3630 | Infer Time(s) 0.1532 | Time(s) 0.5162 
2023-12-01 16:49:25,292:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 2;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:25,293:INFO::Validation loss decreased (0.368585 --> 0.367224).  Saving model ...
2023-12-01 16:49:25,297:INFO::Epoch: 140
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:25,298:INFO::its now!!!!!!!!5
2023-12-01 16:49:25,450:INFO::its now!!!!!!!!0
2023-12-01 16:49:25,451:INFO::its now!!!!!!!!3
2023-12-01 16:49:25,480:INFO::its now!!!!!!!!5
2023-12-01 16:49:25,642:INFO::its now!!!!!!!!
2023-12-01 16:49:25,642:INFO::its now!!!!!!!! on 
2023-12-01 16:49:25,697:INFO::its now!!!!!!!!5
2023-12-01 16:49:25,838:INFO::Epoch 00140 | lr 0.00050 | Train_Loss 0.1529 | Train_Classification_Loss 0.2439 | Dmon_Loss -0.1820 | Val_Loss 0.3905 | Search Time(s) 0.3790 | Infer Time(s) 0.1646 | Time(s) 0.5435 
2023-12-01 16:49:25,878:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:25,879:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:25,881:INFO::Epoch: 141
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9998, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:25,882:INFO::its now!!!!!!!!5
2023-12-01 16:49:26,034:INFO::its now!!!!!!!!0
2023-12-01 16:49:26,035:INFO::its now!!!!!!!!3
2023-12-01 16:49:26,078:INFO::its now!!!!!!!!5
2023-12-01 16:49:26,220:INFO::its now!!!!!!!!
2023-12-01 16:49:26,221:INFO::its now!!!!!!!! on 
2023-12-01 16:49:26,253:INFO::its now!!!!!!!!5
2023-12-01 16:49:26,400:INFO::Epoch 00141 | lr 0.00050 | Train_Loss 0.0722 | Train_Classification_Loss 0.1774 | Dmon_Loss -0.2106 | Val_Loss 0.3677 | Search Time(s) 0.3686 | Infer Time(s) 0.1522 | Time(s) 0.5208 
2023-12-01 16:49:26,444:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:26,446:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:49:26,456:INFO::Epoch: 142
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:26,457:INFO::its now!!!!!!!!5
2023-12-01 16:49:26,599:INFO::its now!!!!!!!!0
2023-12-01 16:49:26,600:INFO::its now!!!!!!!!3
2023-12-01 16:49:26,625:INFO::its now!!!!!!!!5
2023-12-01 16:49:26,784:INFO::its now!!!!!!!!
2023-12-01 16:49:26,784:INFO::its now!!!!!!!! on 
2023-12-01 16:49:26,817:INFO::its now!!!!!!!!5
2023-12-01 16:49:26,983:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:26,985:INFO::Epoch 00142 | lr 0.00050 | Train_Loss 0.0649 | Train_Classification_Loss 0.1706 | Dmon_Loss -0.2113 | Val_Loss 0.3667 | Search Time(s) 0.3650 | Infer Time(s) 0.1725 | Time(s) 0.5376 
2023-12-01 16:49:27,031:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:27,033:INFO::Validation loss decreased (0.367224 --> 0.366681).  Saving model ...
2023-12-01 16:49:27,037:INFO::Epoch: 143
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:27,038:INFO::its now!!!!!!!!5
2023-12-01 16:49:27,203:INFO::its now!!!!!!!!0
2023-12-01 16:49:27,203:INFO::its now!!!!!!!!3
2023-12-01 16:49:27,229:INFO::its now!!!!!!!!5
2023-12-01 16:49:27,379:INFO::its now!!!!!!!!
2023-12-01 16:49:27,379:INFO::its now!!!!!!!! on 
2023-12-01 16:49:27,412:INFO::its now!!!!!!!!5
2023-12-01 16:49:27,567:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:27,568:INFO::Epoch 00143 | lr 0.00050 | Train_Loss 0.0624 | Train_Classification_Loss 0.1685 | Dmon_Loss -0.2122 | Val_Loss 0.3649 | Search Time(s) 0.3742 | Infer Time(s) 0.1596 | Time(s) 0.5338 
2023-12-01 16:49:27,613:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 2;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:27,614:INFO::Validation loss decreased (0.366681 --> 0.364869).  Saving model ...
2023-12-01 16:49:27,619:INFO::Epoch: 144
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:27,620:INFO::its now!!!!!!!!5
2023-12-01 16:49:27,805:INFO::its now!!!!!!!!0
2023-12-01 16:49:27,806:INFO::its now!!!!!!!!3
2023-12-01 16:49:27,832:INFO::its now!!!!!!!!5
2023-12-01 16:49:27,974:INFO::its now!!!!!!!!
2023-12-01 16:49:27,975:INFO::its now!!!!!!!! on 
2023-12-01 16:49:28,028:INFO::its now!!!!!!!!5
2023-12-01 16:49:28,203:INFO::Epoch 00144 | lr 0.00050 | Train_Loss 0.1238 | Train_Classification_Loss 0.2189 | Dmon_Loss -0.1902 | Val_Loss 0.3788 | Search Time(s) 0.3939 | Infer Time(s) 0.1940 | Time(s) 0.5880 
2023-12-01 16:49:28,254:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:28,256:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:28,259:INFO::Epoch: 145
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9998, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:28,260:INFO::its now!!!!!!!!5
2023-12-01 16:49:28,418:INFO::its now!!!!!!!!0
2023-12-01 16:49:28,419:INFO::its now!!!!!!!!3
2023-12-01 16:49:28,468:INFO::its now!!!!!!!!5
2023-12-01 16:49:28,631:INFO::its now!!!!!!!!
2023-12-01 16:49:28,631:INFO::its now!!!!!!!! on 
2023-12-01 16:49:28,664:INFO::its now!!!!!!!!5
2023-12-01 16:49:28,808:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:28,810:INFO::Epoch 00145 | lr 0.00050 | Train_Loss 0.0528 | Train_Classification_Loss 0.1603 | Dmon_Loss -0.2149 | Val_Loss 0.3637 | Search Time(s) 0.4015 | Infer Time(s) 0.1506 | Time(s) 0.5521 
2023-12-01 16:49:28,860:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:28,861:INFO::Validation loss decreased (0.364869 --> 0.363663).  Saving model ...
2023-12-01 16:49:28,865:INFO::Epoch: 146
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:28,866:INFO::its now!!!!!!!!5
2023-12-01 16:49:29,026:INFO::its now!!!!!!!!0
2023-12-01 16:49:29,027:INFO::its now!!!!!!!!3
2023-12-01 16:49:29,052:INFO::its now!!!!!!!!5
2023-12-01 16:49:29,216:INFO::its now!!!!!!!!
2023-12-01 16:49:29,216:INFO::its now!!!!!!!! on 
2023-12-01 16:49:29,250:INFO::its now!!!!!!!!5
2023-12-01 16:49:29,427:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:29,428:INFO::Epoch 00146 | lr 0.00050 | Train_Loss 0.0438 | Train_Classification_Loss 0.1518 | Dmon_Loss -0.2160 | Val_Loss 0.3618 | Search Time(s) 0.3826 | Infer Time(s) 0.1831 | Time(s) 0.5657 
2023-12-01 16:49:29,471:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:29,472:INFO::Validation loss decreased (0.363663 --> 0.361753).  Saving model ...
2023-12-01 16:49:29,474:INFO::Epoch: 147
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:29,475:INFO::its now!!!!!!!!5
2023-12-01 16:49:29,628:INFO::its now!!!!!!!!0
2023-12-01 16:49:29,629:INFO::its now!!!!!!!!3
2023-12-01 16:49:29,653:INFO::its now!!!!!!!!5
2023-12-01 16:49:29,822:INFO::its now!!!!!!!!
2023-12-01 16:49:29,823:INFO::its now!!!!!!!! on 
2023-12-01 16:49:29,873:INFO::its now!!!!!!!!5
2023-12-01 16:49:30,028:INFO::Epoch 00147 | lr 0.00050 | Train_Loss 0.1034 | Train_Classification_Loss 0.2007 | Dmon_Loss -0.1945 | Val_Loss 0.3701 | Search Time(s) 0.3790 | Infer Time(s) 0.1755 | Time(s) 0.5545 
2023-12-01 16:49:30,071:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:30,072:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:30,075:INFO::Epoch: 148
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9998, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:30,076:INFO::its now!!!!!!!!5
2023-12-01 16:49:30,219:INFO::its now!!!!!!!!0
2023-12-01 16:49:30,220:INFO::its now!!!!!!!!3
2023-12-01 16:49:30,268:INFO::its now!!!!!!!!5
2023-12-01 16:49:30,420:INFO::its now!!!!!!!!
2023-12-01 16:49:30,420:INFO::its now!!!!!!!! on 
2023-12-01 16:49:30,482:INFO::its now!!!!!!!!5
2023-12-01 16:49:30,633:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:30,634:INFO::Epoch 00148 | lr 0.00050 | Train_Loss 0.0442 | Train_Classification_Loss 0.1533 | Dmon_Loss -0.2182 | Val_Loss 0.3600 | Search Time(s) 0.3881 | Infer Time(s) 0.1725 | Time(s) 0.5606 
2023-12-01 16:49:30,673:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:30,673:INFO::Validation loss decreased (0.361753 --> 0.359996).  Saving model ...
2023-12-01 16:49:30,676:INFO::Epoch: 149
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:30,677:INFO::its now!!!!!!!!5
2023-12-01 16:49:30,841:INFO::its now!!!!!!!!0
2023-12-01 16:49:30,841:INFO::its now!!!!!!!!3
2023-12-01 16:49:30,884:INFO::its now!!!!!!!!5
2023-12-01 16:49:31,049:INFO::its now!!!!!!!!
2023-12-01 16:49:31,050:INFO::its now!!!!!!!! on 
2023-12-01 16:49:31,101:INFO::its now!!!!!!!!5
2023-12-01 16:49:31,255:INFO::Epoch 00149 | lr 0.00050 | Train_Loss 0.0896 | Train_Classification_Loss 0.1882 | Dmon_Loss -0.1972 | Val_Loss 0.3629 | Search Time(s) 0.4054 | Infer Time(s) 0.1751 | Time(s) 0.5805 
2023-12-01 16:49:31,327:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:31,329:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:31,333:INFO::Epoch: 150
tensor([[0.9999, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:31,334:INFO::its now!!!!!!!!5
2023-12-01 16:49:31,488:INFO::its now!!!!!!!!0
2023-12-01 16:49:31,488:INFO::its now!!!!!!!!3
2023-12-01 16:49:31,531:INFO::its now!!!!!!!!5
2023-12-01 16:49:31,695:INFO::its now!!!!!!!!
2023-12-01 16:49:31,696:INFO::its now!!!!!!!! on 
2023-12-01 16:49:31,729:INFO::its now!!!!!!!!5
2023-12-01 16:49:31,875:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:31,876:INFO::Epoch 00150 | lr 0.00050 | Train_Loss 0.0313 | Train_Classification_Loss 0.1412 | Dmon_Loss -0.2197 | Val_Loss 0.3588 | Search Time(s) 0.3939 | Infer Time(s) 0.1526 | Time(s) 0.5465 
2023-12-01 16:49:31,937:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:31,938:INFO::Validation loss decreased (0.359996 --> 0.358786).  Saving model ...
2023-12-01 16:49:31,942:INFO::Epoch: 151
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:31,943:INFO::its now!!!!!!!!5
2023-12-01 16:49:32,095:INFO::its now!!!!!!!!0
2023-12-01 16:49:32,095:INFO::its now!!!!!!!!3
2023-12-01 16:49:32,120:INFO::its now!!!!!!!!5
2023-12-01 16:49:32,280:INFO::its now!!!!!!!!
2023-12-01 16:49:32,280:INFO::its now!!!!!!!! on 
2023-12-01 16:49:32,312:INFO::its now!!!!!!!!5
2023-12-01 16:49:32,472:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:32,473:INFO::Epoch 00151 | lr 0.00050 | Train_Loss 0.0310 | Train_Classification_Loss 0.1415 | Dmon_Loss -0.2211 | Val_Loss 0.3566 | Search Time(s) 0.3662 | Infer Time(s) 0.1666 | Time(s) 0.5327 
2023-12-01 16:49:32,519:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:32,520:INFO::Validation loss decreased (0.358786 --> 0.356560).  Saving model ...
2023-12-01 16:49:32,531:INFO::Epoch: 152
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:32,532:INFO::its now!!!!!!!!5
2023-12-01 16:49:32,689:INFO::its now!!!!!!!!0
2023-12-01 16:49:32,689:INFO::its now!!!!!!!!3
2023-12-01 16:49:32,714:INFO::its now!!!!!!!!5
2023-12-01 16:49:32,863:INFO::its now!!!!!!!!
2023-12-01 16:49:32,863:INFO::its now!!!!!!!! on 
2023-12-01 16:49:32,914:INFO::its now!!!!!!!!5
2023-12-01 16:49:33,086:INFO::Epoch 00152 | lr 0.00050 | Train_Loss 0.0733 | Train_Classification_Loss 0.1751 | Dmon_Loss -0.2037 | Val_Loss 0.3588 | Search Time(s) 0.3750 | Infer Time(s) 0.1915 | Time(s) 0.5665 
2023-12-01 16:49:33,130:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:33,131:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:33,134:INFO::Epoch: 153
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9999, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:33,135:INFO::its now!!!!!!!!5
2023-12-01 16:49:33,276:INFO::its now!!!!!!!!0
2023-12-01 16:49:33,277:INFO::its now!!!!!!!!3
2023-12-01 16:49:33,320:INFO::its now!!!!!!!!5
2023-12-01 16:49:33,491:INFO::its now!!!!!!!!
2023-12-01 16:49:33,491:INFO::its now!!!!!!!! on 
2023-12-01 16:49:33,542:INFO::its now!!!!!!!!5
2023-12-01 16:49:33,706:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:33,708:INFO::Epoch 00153 | lr 0.00050 | Train_Loss 0.0687 | Train_Classification_Loss 0.1723 | Dmon_Loss -0.2073 | Val_Loss 0.3539 | Search Time(s) 0.3936 | Infer Time(s) 0.1812 | Time(s) 0.5748 
2023-12-01 16:49:33,750:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:33,752:INFO::Validation loss decreased (0.356560 --> 0.353920).  Saving model ...
2023-12-01 16:49:33,757:INFO::Epoch: 154
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9997, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:33,758:INFO::its now!!!!!!!!5
2023-12-01 16:49:33,915:INFO::its now!!!!!!!!0
2023-12-01 16:49:33,915:INFO::its now!!!!!!!!3
2023-12-01 16:49:33,960:INFO::its now!!!!!!!!5
2023-12-01 16:49:34,125:INFO::its now!!!!!!!!
2023-12-01 16:49:34,125:INFO::its now!!!!!!!! on 
2023-12-01 16:49:34,158:INFO::its now!!!!!!!!5
2023-12-01 16:49:34,313:INFO::Epoch 00154 | lr 0.00050 | Train_Loss 0.0163 | Train_Classification_Loss 0.1285 | Dmon_Loss -0.2244 | Val_Loss 0.3561 | Search Time(s) 0.3995 | Infer Time(s) 0.1602 | Time(s) 0.5597 
2023-12-01 16:49:34,370:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 2;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:34,371:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:34,377:INFO::Epoch: 155
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:34,378:INFO::its now!!!!!!!!5
2023-12-01 16:49:34,528:INFO::its now!!!!!!!!0
2023-12-01 16:49:34,528:INFO::its now!!!!!!!!3
2023-12-01 16:49:34,553:INFO::its now!!!!!!!!5
2023-12-01 16:49:34,707:INFO::its now!!!!!!!!
2023-12-01 16:49:34,707:INFO::its now!!!!!!!! on 
2023-12-01 16:49:34,741:INFO::its now!!!!!!!!5
2023-12-01 16:49:34,885:INFO::Epoch 00155 | lr 0.00050 | Train_Loss 0.0154 | Train_Classification_Loss 0.1277 | Dmon_Loss -0.2246 | Val_Loss 0.3548 | Search Time(s) 0.3630 | Infer Time(s) 0.1496 | Time(s) 0.5126 
2023-12-01 16:49:34,934:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:34,935:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:49:34,939:INFO::Epoch: 156
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:34,939:INFO::its now!!!!!!!!5
2023-12-01 16:49:35,103:INFO::its now!!!!!!!!0
2023-12-01 16:49:35,104:INFO::its now!!!!!!!!3
2023-12-01 16:49:35,128:INFO::its now!!!!!!!!5
2023-12-01 16:49:35,269:INFO::its now!!!!!!!!
2023-12-01 16:49:35,269:INFO::its now!!!!!!!! on 
2023-12-01 16:49:35,321:INFO::its now!!!!!!!!5
2023-12-01 16:49:35,487:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:35,489:INFO::Epoch 00156 | lr 0.00050 | Train_Loss 0.0540 | Train_Classification_Loss 0.1598 | Dmon_Loss -0.2116 | Val_Loss 0.3505 | Search Time(s) 0.3651 | Infer Time(s) 0.1865 | Time(s) 0.5516 
2023-12-01 16:49:35,534:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:35,534:INFO::Validation loss decreased (0.353920 --> 0.350514).  Saving model ...
2023-12-01 16:49:35,537:INFO::Epoch: 157
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9997, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:35,538:INFO::its now!!!!!!!!5
2023-12-01 16:49:35,686:INFO::its now!!!!!!!!0
2023-12-01 16:49:35,687:INFO::its now!!!!!!!!3
2023-12-01 16:49:35,729:INFO::its now!!!!!!!!5
2023-12-01 16:49:35,890:INFO::its now!!!!!!!!
2023-12-01 16:49:35,890:INFO::its now!!!!!!!! on 
2023-12-01 16:49:35,923:INFO::its now!!!!!!!!5
2023-12-01 16:49:36,068:INFO::Epoch 00157 | lr 0.00050 | Train_Loss 0.0182 | Train_Classification_Loss 0.1303 | Dmon_Loss -0.2242 | Val_Loss 0.3524 | Search Time(s) 0.3836 | Infer Time(s) 0.1496 | Time(s) 0.5332 
2023-12-01 16:49:36,111:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:36,112:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:36,115:INFO::Epoch: 158
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:36,116:INFO::its now!!!!!!!!5
2023-12-01 16:49:36,250:INFO::its now!!!!!!!!0
2023-12-01 16:49:36,251:INFO::its now!!!!!!!!3
2023-12-01 16:49:36,275:INFO::its now!!!!!!!!5
2023-12-01 16:49:36,434:INFO::its now!!!!!!!!
2023-12-01 16:49:36,434:INFO::its now!!!!!!!! on 
2023-12-01 16:49:36,485:INFO::its now!!!!!!!!5
2023-12-01 16:49:36,627:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:36,628:INFO::Epoch 00158 | lr 0.00050 | Train_Loss 0.0448 | Train_Classification_Loss 0.1515 | Dmon_Loss -0.2133 | Val_Loss 0.3463 | Search Time(s) 0.3547 | Infer Time(s) 0.1596 | Time(s) 0.5142 
2023-12-01 16:49:36,667:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:36,668:INFO::Validation loss decreased (0.350514 --> 0.346342).  Saving model ...
2023-12-01 16:49:36,672:INFO::Epoch: 159
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:36,672:INFO::its now!!!!!!!!5
2023-12-01 16:49:36,823:INFO::its now!!!!!!!!0
2023-12-01 16:49:36,824:INFO::its now!!!!!!!!3
2023-12-01 16:49:36,871:INFO::its now!!!!!!!!5
2023-12-01 16:49:37,032:INFO::its now!!!!!!!!
2023-12-01 16:49:37,032:INFO::its now!!!!!!!! on 
2023-12-01 16:49:37,069:INFO::its now!!!!!!!!5
2023-12-01 16:49:37,222:INFO::Epoch 00159 | lr 0.00050 | Train_Loss 0.0150 | Train_Classification_Loss 0.1279 | Dmon_Loss -0.2259 | Val_Loss 0.3494 | Search Time(s) 0.3910 | Infer Time(s) 0.1631 | Time(s) 0.5541 
2023-12-01 16:49:37,263:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 2;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:37,264:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:37,268:INFO::Epoch: 160
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:37,268:INFO::its now!!!!!!!!5
2023-12-01 16:49:37,413:INFO::its now!!!!!!!!0
2023-12-01 16:49:37,414:INFO::its now!!!!!!!!3
2023-12-01 16:49:37,438:INFO::its now!!!!!!!!5
2023-12-01 16:49:37,569:INFO::its now!!!!!!!!
2023-12-01 16:49:37,569:INFO::its now!!!!!!!! on 
2023-12-01 16:49:37,602:INFO::its now!!!!!!!!5
2023-12-01 16:49:37,753:INFO::Epoch 00160 | lr 0.00050 | Train_Loss 0.0036 | Train_Classification_Loss 0.1169 | Dmon_Loss -0.2267 | Val_Loss 0.3468 | Search Time(s) 0.3317 | Infer Time(s) 0.1576 | Time(s) 0.4892 
2023-12-01 16:49:37,799:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:37,801:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:49:37,807:INFO::Epoch: 161
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:37,808:INFO::its now!!!!!!!!5
2023-12-01 16:49:37,957:INFO::its now!!!!!!!!0
2023-12-01 16:49:37,958:INFO::its now!!!!!!!!3
2023-12-01 16:49:38,002:INFO::its now!!!!!!!!5
2023-12-01 16:49:38,209:INFO::its now!!!!!!!!
2023-12-01 16:49:38,209:INFO::its now!!!!!!!! on 
2023-12-01 16:49:38,243:INFO::its now!!!!!!!!5
2023-12-01 16:49:38,386:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:38,387:INFO::Epoch 00161 | lr 0.00050 | Train_Loss 0.0027 | Train_Classification_Loss 0.1169 | Dmon_Loss -0.2284 | Val_Loss 0.3438 | Search Time(s) 0.4354 | Infer Time(s) 0.1502 | Time(s) 0.5856 
2023-12-01 16:49:38,424:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 2;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:38,425:INFO::Validation loss decreased (0.346342 --> 0.343849).  Saving model ...
2023-12-01 16:49:38,442:INFO::Epoch: 162
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:38,445:INFO::its now!!!!!!!!5
2023-12-01 16:49:38,627:INFO::its now!!!!!!!!0
2023-12-01 16:49:38,628:INFO::its now!!!!!!!!3
2023-12-01 16:49:38,652:INFO::its now!!!!!!!!5
2023-12-01 16:49:38,829:INFO::its now!!!!!!!!
2023-12-01 16:49:38,829:INFO::its now!!!!!!!! on 
2023-12-01 16:49:38,863:INFO::its now!!!!!!!!5
2023-12-01 16:49:39,059:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:39,060:INFO::Epoch 00162 | lr 0.00050 | Train_Loss 0.0013 | Train_Classification_Loss 0.1160 | Dmon_Loss -0.2294 | Val_Loss 0.3406 | Search Time(s) 0.4318 | Infer Time(s) 0.2005 | Time(s) 0.6323 
2023-12-01 16:49:39,119:INFO::cluster info:
0: 1;	1: 1;	2: 2;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:39,120:INFO::Validation loss decreased (0.343849 --> 0.340569).  Saving model ...
2023-12-01 16:49:39,123:INFO::Epoch: 163
tensor([[1.0000, 1.0000, 1.0000, 0.9997],
        [1.0000, 0.9997, 1.0000, 1.0000],
        [1.0000, 0.9994, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9998, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:39,124:INFO::its now!!!!!!!!5
2023-12-01 16:49:39,285:INFO::its now!!!!!!!!0
2023-12-01 16:49:39,286:INFO::its now!!!!!!!!3
2023-12-01 16:49:39,310:INFO::its now!!!!!!!!5
2023-12-01 16:49:39,471:INFO::its now!!!!!!!!
2023-12-01 16:49:39,471:INFO::its now!!!!!!!! on 
2023-12-01 16:49:39,505:INFO::its now!!!!!!!!5
2023-12-01 16:49:39,651:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:39,652:INFO::Epoch 00163 | lr 0.00050 | Train_Loss -0.0001 | Train_Classification_Loss 0.1145 | Dmon_Loss -0.2292 | Val_Loss 0.3371 | Search Time(s) 0.3805 | Infer Time(s) 0.1506 | Time(s) 0.5311 
2023-12-01 16:49:39,688:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:39,689:INFO::Validation loss decreased (0.340569 --> 0.337088).  Saving model ...
2023-12-01 16:49:39,691:INFO::Epoch: 164
tensor([[1.0000, 1.0000, 1.0000, 0.9999],
        [1.0000, 0.9999, 1.0000, 1.0000],
        [1.0000, 0.9994, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:39,692:INFO::its now!!!!!!!!5
2023-12-01 16:49:39,860:INFO::its now!!!!!!!!0
2023-12-01 16:49:39,861:INFO::its now!!!!!!!!3
2023-12-01 16:49:39,884:INFO::its now!!!!!!!!5
2023-12-01 16:49:40,070:INFO::its now!!!!!!!!
2023-12-01 16:49:40,070:INFO::its now!!!!!!!! on 
2023-12-01 16:49:40,103:INFO::its now!!!!!!!!5
2023-12-01 16:49:40,255:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:40,257:INFO::Epoch 00164 | lr 0.00050 | Train_Loss -0.0022 | Train_Classification_Loss 0.1134 | Dmon_Loss -0.2311 | Val_Loss 0.3337 | Search Time(s) 0.4069 | Infer Time(s) 0.1591 | Time(s) 0.5661 
2023-12-01 16:49:40,301:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:40,302:INFO::Validation loss decreased (0.337088 --> 0.333672).  Saving model ...
2023-12-01 16:49:40,307:INFO::Epoch: 165
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 0.9999, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:40,308:INFO::its now!!!!!!!!5
2023-12-01 16:49:40,460:INFO::its now!!!!!!!!0
2023-12-01 16:49:40,461:INFO::its now!!!!!!!!3
2023-12-01 16:49:40,486:INFO::its now!!!!!!!!5
2023-12-01 16:49:40,621:INFO::its now!!!!!!!!
2023-12-01 16:49:40,622:INFO::its now!!!!!!!! on 
2023-12-01 16:49:40,673:INFO::its now!!!!!!!!5
2023-12-01 16:49:40,855:INFO::Epoch 00165 | lr 0.00050 | Train_Loss 0.0192 | Train_Classification_Loss 0.1292 | Dmon_Loss -0.2202 | Val_Loss 0.3366 | Search Time(s) 0.3501 | Infer Time(s) 0.2034 | Time(s) 0.5535 
2023-12-01 16:49:40,892:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:40,893:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:40,897:INFO::Epoch: 166
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9998, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:40,897:INFO::its now!!!!!!!!5
2023-12-01 16:49:41,083:INFO::its now!!!!!!!!0
2023-12-01 16:49:41,084:INFO::its now!!!!!!!!3
2023-12-01 16:49:41,127:INFO::its now!!!!!!!!5
2023-12-01 16:49:41,272:INFO::its now!!!!!!!!
2023-12-01 16:49:41,272:INFO::its now!!!!!!!! on 
2023-12-01 16:49:41,305:INFO::its now!!!!!!!!5
2023-12-01 16:49:41,466:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:41,467:INFO::Epoch 00166 | lr 0.00050 | Train_Loss -0.0040 | Train_Classification_Loss 0.1109 | Dmon_Loss -0.2300 | Val_Loss 0.3291 | Search Time(s) 0.4052 | Infer Time(s) 0.1666 | Time(s) 0.5718 
2023-12-01 16:49:41,504:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:41,505:INFO::Validation loss decreased (0.333672 --> 0.329055).  Saving model ...
2023-12-01 16:49:41,508:INFO::Epoch: 167
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:41,509:INFO::its now!!!!!!!!5
2023-12-01 16:49:41,662:INFO::its now!!!!!!!!0
2023-12-01 16:49:41,663:INFO::its now!!!!!!!!3
2023-12-01 16:49:41,687:INFO::its now!!!!!!!!5
2023-12-01 16:49:41,845:INFO::its now!!!!!!!!
2023-12-01 16:49:41,845:INFO::its now!!!!!!!! on 
2023-12-01 16:49:41,880:INFO::its now!!!!!!!!5
2023-12-01 16:49:42,019:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:42,021:INFO::Epoch 00167 | lr 0.00050 | Train_Loss -0.0139 | Train_Classification_Loss 0.1022 | Dmon_Loss -0.2323 | Val_Loss 0.3270 | Search Time(s) 0.3670 | Infer Time(s) 0.1476 | Time(s) 0.5146 
2023-12-01 16:49:42,076:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 2;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 3;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:42,077:INFO::Validation loss decreased (0.329055 --> 0.326968).  Saving model ...
2023-12-01 16:49:42,080:INFO::Epoch: 168
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:42,081:INFO::its now!!!!!!!!5
2023-12-01 16:49:42,230:INFO::its now!!!!!!!!0
2023-12-01 16:49:42,231:INFO::its now!!!!!!!!3
2023-12-01 16:49:42,256:INFO::its now!!!!!!!!5
2023-12-01 16:49:42,430:INFO::its now!!!!!!!!
2023-12-01 16:49:42,430:INFO::its now!!!!!!!! on 
2023-12-01 16:49:42,463:INFO::its now!!!!!!!!5
2023-12-01 16:49:42,604:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:42,605:INFO::Epoch 00168 | lr 0.00050 | Train_Loss -0.0106 | Train_Classification_Loss 0.1056 | Dmon_Loss -0.2324 | Val_Loss 0.3250 | Search Time(s) 0.3801 | Infer Time(s) 0.1466 | Time(s) 0.5267 
2023-12-01 16:49:42,649:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:42,650:INFO::Validation loss decreased (0.326968 --> 0.325020).  Saving model ...
2023-12-01 16:49:42,654:INFO::Epoch: 169
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:42,654:INFO::its now!!!!!!!!5
2023-12-01 16:49:42,811:INFO::its now!!!!!!!!0
2023-12-01 16:49:42,811:INFO::its now!!!!!!!!3
2023-12-01 16:49:42,836:INFO::its now!!!!!!!!5
2023-12-01 16:49:42,983:INFO::its now!!!!!!!!
2023-12-01 16:49:42,983:INFO::its now!!!!!!!! on 
2023-12-01 16:49:43,033:INFO::its now!!!!!!!!5
2023-12-01 16:49:43,193:INFO::Epoch 00169 | lr 0.00050 | Train_Loss 0.0161 | Train_Classification_Loss 0.1273 | Dmon_Loss -0.2224 | Val_Loss 0.3309 | Search Time(s) 0.3620 | Infer Time(s) 0.1811 | Time(s) 0.5431 
2023-12-01 16:49:43,244:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:43,245:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:43,250:INFO::Epoch: 170
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9998, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:43,251:INFO::its now!!!!!!!!5
2023-12-01 16:49:43,410:INFO::its now!!!!!!!!0
2023-12-01 16:49:43,411:INFO::its now!!!!!!!!3
2023-12-01 16:49:43,457:INFO::its now!!!!!!!!5
2023-12-01 16:49:43,596:INFO::its now!!!!!!!!
2023-12-01 16:49:43,596:INFO::its now!!!!!!!! on 
2023-12-01 16:49:43,630:INFO::its now!!!!!!!!5
2023-12-01 16:49:43,775:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:43,777:INFO::Epoch 00170 | lr 0.00050 | Train_Loss -0.0170 | Train_Classification_Loss 0.1002 | Dmon_Loss -0.2345 | Val_Loss 0.3239 | Search Time(s) 0.3786 | Infer Time(s) 0.1516 | Time(s) 0.5302 
2023-12-01 16:49:43,834:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:43,835:INFO::Validation loss decreased (0.325020 --> 0.323890).  Saving model ...
2023-12-01 16:49:43,839:INFO::Epoch: 171
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:43,840:INFO::its now!!!!!!!!5
2023-12-01 16:49:43,988:INFO::its now!!!!!!!!0
2023-12-01 16:49:43,988:INFO::its now!!!!!!!!3
2023-12-01 16:49:44,014:INFO::its now!!!!!!!!5
2023-12-01 16:49:44,175:INFO::its now!!!!!!!!
2023-12-01 16:49:44,175:INFO::its now!!!!!!!! on 
2023-12-01 16:49:44,208:INFO::its now!!!!!!!!5
2023-12-01 16:49:44,364:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:44,366:INFO::Epoch 00171 | lr 0.00050 | Train_Loss -0.0195 | Train_Classification_Loss 0.0975 | Dmon_Loss -0.2339 | Val_Loss 0.3234 | Search Time(s) 0.3676 | Infer Time(s) 0.1611 | Time(s) 0.5287 
2023-12-01 16:49:44,404:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:44,405:INFO::Validation loss decreased (0.323890 --> 0.323414).  Saving model ...
2023-12-01 16:49:44,409:INFO::Epoch: 172
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:44,410:INFO::its now!!!!!!!!5
2023-12-01 16:49:44,579:INFO::its now!!!!!!!!0
2023-12-01 16:49:44,580:INFO::its now!!!!!!!!3
2023-12-01 16:49:44,605:INFO::its now!!!!!!!!5
2023-12-01 16:49:44,773:INFO::its now!!!!!!!!
2023-12-01 16:49:44,773:INFO::its now!!!!!!!! on 
2023-12-01 16:49:44,825:INFO::its now!!!!!!!!5
2023-12-01 16:49:44,992:INFO::Epoch 00172 | lr 0.00050 | Train_Loss 0.0042 | Train_Classification_Loss 0.1166 | Dmon_Loss -0.2247 | Val_Loss 0.3285 | Search Time(s) 0.4019 | Infer Time(s) 0.1845 | Time(s) 0.5864 
2023-12-01 16:49:45,051:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:45,053:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:49:45,057:INFO::Epoch: 173
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9999, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:45,058:INFO::its now!!!!!!!!5
2023-12-01 16:49:45,189:INFO::its now!!!!!!!!0
2023-12-01 16:49:45,190:INFO::its now!!!!!!!!3
2023-12-01 16:49:45,234:INFO::its now!!!!!!!!5
2023-12-01 16:49:45,410:INFO::its now!!!!!!!!
2023-12-01 16:49:45,411:INFO::its now!!!!!!!! on 
2023-12-01 16:49:45,444:INFO::its now!!!!!!!!5
2023-12-01 16:49:45,602:INFO::Epoch 00173 | lr 0.00050 | Train_Loss -0.0245 | Train_Classification_Loss 0.0931 | Dmon_Loss -0.2351 | Val_Loss 0.3241 | Search Time(s) 0.3832 | Infer Time(s) 0.1656 | Time(s) 0.5487 
2023-12-01 16:49:45,638:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:45,639:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:49:45,642:INFO::Epoch: 174
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:45,643:INFO::its now!!!!!!!!5
2023-12-01 16:49:45,798:INFO::its now!!!!!!!!0
2023-12-01 16:49:45,799:INFO::its now!!!!!!!!3
2023-12-01 16:49:45,825:INFO::its now!!!!!!!!5
2023-12-01 16:49:45,993:INFO::its now!!!!!!!!
2023-12-01 16:49:45,993:INFO::its now!!!!!!!! on 
2023-12-01 16:49:46,027:INFO::its now!!!!!!!!5
2023-12-01 16:49:46,185:INFO::Epoch 00174 | lr 0.00050 | Train_Loss -0.0283 | Train_Classification_Loss 0.0899 | Dmon_Loss -0.2364 | Val_Loss 0.3245 | Search Time(s) 0.3840 | Infer Time(s) 0.1622 | Time(s) 0.5462 
2023-12-01 16:49:46,243:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:46,244:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:49:46,248:INFO::Epoch: 175
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:46,249:INFO::its now!!!!!!!!5
2023-12-01 16:49:46,419:INFO::its now!!!!!!!!0
2023-12-01 16:49:46,421:INFO::its now!!!!!!!!3
2023-12-01 16:49:46,446:INFO::its now!!!!!!!!5
2023-12-01 16:49:46,602:INFO::its now!!!!!!!!
2023-12-01 16:49:46,602:INFO::its now!!!!!!!! on 
2023-12-01 16:49:46,653:INFO::its now!!!!!!!!5
2023-12-01 16:49:46,794:INFO::Epoch 00175 | lr 0.00050 | Train_Loss 0.0011 | Train_Classification_Loss 0.1154 | Dmon_Loss -0.2286 | Val_Loss 0.3283 | Search Time(s) 0.3905 | Infer Time(s) 0.1586 | Time(s) 0.5491 
2023-12-01 16:49:46,841:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:46,842:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 16:49:46,845:INFO::Epoch: 176
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9999, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:46,846:INFO::its now!!!!!!!!5
2023-12-01 16:49:46,986:INFO::its now!!!!!!!!0
2023-12-01 16:49:46,987:INFO::its now!!!!!!!!3
2023-12-01 16:49:47,030:INFO::its now!!!!!!!!5
2023-12-01 16:49:47,191:INFO::its now!!!!!!!!
2023-12-01 16:49:47,191:INFO::its now!!!!!!!! on 
2023-12-01 16:49:47,224:INFO::its now!!!!!!!!5
2023-12-01 16:49:47,390:INFO::Epoch 00176 | lr 0.00050 | Train_Loss -0.0318 | Train_Classification_Loss 0.0865 | Dmon_Loss -0.2366 | Val_Loss 0.3262 | Search Time(s) 0.3746 | Infer Time(s) 0.1721 | Time(s) 0.5467 
2023-12-01 16:49:47,452:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 2;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:47,453:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 16:49:47,456:INFO::Epoch: 177
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:47,457:INFO::its now!!!!!!!!5
2023-12-01 16:49:47,610:INFO::its now!!!!!!!!0
2023-12-01 16:49:47,610:INFO::its now!!!!!!!!3
2023-12-01 16:49:47,635:INFO::its now!!!!!!!!5
2023-12-01 16:49:47,812:INFO::its now!!!!!!!!
2023-12-01 16:49:47,812:INFO::its now!!!!!!!! on 
2023-12-01 16:49:47,863:INFO::its now!!!!!!!!5
2023-12-01 16:49:48,012:INFO::Epoch 00177 | lr 0.00050 | Train_Loss -0.0307 | Train_Classification_Loss 0.0882 | Dmon_Loss -0.2379 | Val_Loss 0.3268 | Search Time(s) 0.3900 | Infer Time(s) 0.1695 | Time(s) 0.5595 
2023-12-01 16:49:48,057:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:48,059:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 16:49:48,062:INFO::Epoch: 178
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:48,062:INFO::its now!!!!!!!!5
2023-12-01 16:49:48,226:INFO::its now!!!!!!!!0
2023-12-01 16:49:48,227:INFO::its now!!!!!!!!3
2023-12-01 16:49:48,269:INFO::its now!!!!!!!!5
2023-12-01 16:49:48,444:INFO::its now!!!!!!!!
2023-12-01 16:49:48,444:INFO::its now!!!!!!!! on 
2023-12-01 16:49:48,495:INFO::its now!!!!!!!!5
2023-12-01 16:49:48,637:INFO::Epoch 00178 | lr 0.00050 | Train_Loss -0.0041 | Train_Classification_Loss 0.1108 | Dmon_Loss -0.2297 | Val_Loss 0.3285 | Search Time(s) 0.4171 | Infer Time(s) 0.1606 | Time(s) 0.5776 
2023-12-01 16:49:48,690:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 1;	29: 1;	30: 1;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 1;	26099: 1;	26100: 1;	26101: 3;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:48,691:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 16:49:48,694:INFO::Epoch: 179
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9999, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:49:48,695:INFO::its now!!!!!!!!5
2023-12-01 16:49:48,849:INFO::its now!!!!!!!!0
2023-12-01 16:49:48,850:INFO::its now!!!!!!!!3
2023-12-01 16:49:48,895:INFO::its now!!!!!!!!5
2023-12-01 16:49:49,051:INFO::its now!!!!!!!!
2023-12-01 16:49:49,051:INFO::its now!!!!!!!! on 
2023-12-01 16:49:49,084:INFO::its now!!!!!!!!5
2023-12-01 16:49:49,237:INFO::Epoch 00179 | lr 0.00050 | Train_Loss -0.0367 | Train_Classification_Loss 0.0825 | Dmon_Loss -0.2384 | Val_Loss 0.3287 | Search Time(s) 0.3870 | Infer Time(s) 0.1593 | Time(s) 0.5463 
2023-12-01 16:49:49,281:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 1;	7: 1;	8: 1;	9: 1;	10: 1;	11: 1;	12: 3;	13: 1;	14: 1;	15: 2;	16: 1;	17: 2;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 3;	28: 2;	29: 1;	30: 2;	31: 1;	32: 1;	33: 2;	34: 2;	35: 3;	36: 1;	37: 1;	38: 2;	39: 1;	40: 2;	41: 2;	42: 1;	43: 1;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 1;	26106: 1;	26107: 1;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 2;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 2;	26122: 1;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:49:49,283:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 16:49:49,283:INFO::Eearly stopping!
2023-12-01 16:49:49,434:INFO::############### Search Stage Ends! ###############
2023-12-01 16:49:49,435:INFO::=============== Retrain Stage Starts:
2023-12-01 16:49:49,435:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:49,511:INFO::node_assign_Counter:
Counter({-1: 14328, 1: 5335, 2: 4251, 3: 2214})
2023-12-01 16:49:49,511:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:49:49,933:INFO::============= repeat round: 0; seed: 123
2023-12-01 16:49:50,034:INFO::arch_weights:
[[1. 1. 1. 1.]
 [1. 1. 1. 1.]
 [1. 1. 1. 1.]
 [1. 1. 1. 1.]]
2023-12-01 16:49:50,034:INFO::arch_weights_softmax:
[[0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25]]
2023-12-01 16:49:50,034:INFO::genotype choice:
['gcn', 'gcn', 'gcn', 'gcn']
2023-12-01 16:49:50,454:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.3852 | Val_Loss 1.3816 | Time(s) 0.3806
2023-12-01 16:49:50,808:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3812 | Val_Loss 1.3773 | Time(s) 0.2513
2023-12-01 16:49:50,816:INFO::Validation loss decreased (inf --> 1.377342).  Saving model ...
2023-12-01 16:49:50,968:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3765 | Val_Loss 1.3732 | Time(s) 0.1522
2023-12-01 16:49:50,976:INFO::Validation loss decreased (1.377342 --> 1.373173).  Saving model ...
2023-12-01 16:49:51,163:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.3735 | Val_Loss 1.3691 | Time(s) 0.1862
2023-12-01 16:49:51,171:INFO::Validation loss decreased (1.373173 --> 1.369094).  Saving model ...
2023-12-01 16:49:51,321:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.3653 | Val_Loss 1.3651 | Time(s) 0.1502
2023-12-01 16:49:51,328:INFO::Validation loss decreased (1.369094 --> 1.365080).  Saving model ...
2023-12-01 16:49:51,485:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.3656 | Val_Loss 1.3611 | Time(s) 0.1566
2023-12-01 16:49:51,493:INFO::Validation loss decreased (1.365080 --> 1.361125).  Saving model ...
2023-12-01 16:49:51,645:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.3607 | Val_Loss 1.3572 | Time(s) 0.1507
2023-12-01 16:49:51,653:INFO::Validation loss decreased (1.361125 --> 1.357215).  Saving model ...
2023-12-01 16:49:51,804:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.3550 | Val_Loss 1.3533 | Time(s) 0.1516
2023-12-01 16:49:51,814:INFO::Validation loss decreased (1.357215 --> 1.353330).  Saving model ...
2023-12-01 16:49:51,966:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.3504 | Val_Loss 1.3495 | Time(s) 0.1506
2023-12-01 16:49:51,973:INFO::Validation loss decreased (1.353330 --> 1.349461).  Saving model ...
2023-12-01 16:49:52,123:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.3476 | Val_Loss 1.3456 | Time(s) 0.1502
2023-12-01 16:49:52,131:INFO::Validation loss decreased (1.349461 --> 1.345583).  Saving model ...
2023-12-01 16:49:52,281:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.3418 | Val_Loss 1.3417 | Time(s) 0.1506
2023-12-01 16:49:52,289:INFO::Validation loss decreased (1.345583 --> 1.341687).  Saving model ...
2023-12-01 16:49:52,444:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.3383 | Val_Loss 1.3378 | Time(s) 0.1536
2023-12-01 16:49:52,466:INFO::Validation loss decreased (1.341687 --> 1.337763).  Saving model ...
2023-12-01 16:49:52,618:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 1.3352 | Val_Loss 1.3338 | Time(s) 0.1516
2023-12-01 16:49:52,625:INFO::Validation loss decreased (1.337763 --> 1.333815).  Saving model ...
2023-12-01 16:49:52,776:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 1.3293 | Val_Loss 1.3298 | Time(s) 0.1516
2023-12-01 16:49:52,784:INFO::Validation loss decreased (1.333815 --> 1.329809).  Saving model ...
2023-12-01 16:49:52,937:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 1.3253 | Val_Loss 1.3257 | Time(s) 0.1526
2023-12-01 16:49:52,946:INFO::Validation loss decreased (1.329809 --> 1.325734).  Saving model ...
2023-12-01 16:49:53,118:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 1.3224 | Val_Loss 1.3216 | Time(s) 0.1724
2023-12-01 16:49:53,125:INFO::Validation loss decreased (1.325734 --> 1.321586).  Saving model ...
2023-12-01 16:49:53,277:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 1.3160 | Val_Loss 1.3173 | Time(s) 0.1510
2023-12-01 16:49:53,285:INFO::Validation loss decreased (1.321586 --> 1.317335).  Saving model ...
2023-12-01 16:49:53,441:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 1.3126 | Val_Loss 1.3130 | Time(s) 0.1552
2023-12-01 16:49:53,449:INFO::Validation loss decreased (1.317335 --> 1.312971).  Saving model ...
2023-12-01 16:49:53,600:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 1.3062 | Val_Loss 1.3085 | Time(s) 0.1506
2023-12-01 16:49:53,607:INFO::Validation loss decreased (1.312971 --> 1.308486).  Saving model ...
2023-12-01 16:49:53,758:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 1.3022 | Val_Loss 1.3039 | Time(s) 0.1505
2023-12-01 16:49:53,765:INFO::Validation loss decreased (1.308486 --> 1.303855).  Saving model ...
2023-12-01 16:49:53,919:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 1.3007 | Val_Loss 1.2991 | Time(s) 0.1536
2023-12-01 16:49:53,928:INFO::Validation loss decreased (1.303855 --> 1.299073).  Saving model ...
2023-12-01 16:49:54,082:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 1.2916 | Val_Loss 1.2941 | Time(s) 0.1541
2023-12-01 16:49:54,090:INFO::Validation loss decreased (1.299073 --> 1.294120).  Saving model ...
2023-12-01 16:49:54,241:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 1.2899 | Val_Loss 1.2890 | Time(s) 0.1512
2023-12-01 16:49:54,249:INFO::Validation loss decreased (1.294120 --> 1.288995).  Saving model ...
2023-12-01 16:49:54,404:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 1.2801 | Val_Loss 1.2837 | Time(s) 0.1551
2023-12-01 16:49:54,413:INFO::Validation loss decreased (1.288995 --> 1.283679).  Saving model ...
2023-12-01 16:49:54,571:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 1.2754 | Val_Loss 1.2781 | Time(s) 0.1576
2023-12-01 16:49:54,586:INFO::Validation loss decreased (1.283679 --> 1.278145).  Saving model ...
2023-12-01 16:49:54,759:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 1.2661 | Val_Loss 1.2724 | Time(s) 0.1721
2023-12-01 16:49:54,768:INFO::Validation loss decreased (1.278145 --> 1.272390).  Saving model ...
2023-12-01 16:49:54,916:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 1.2607 | Val_Loss 1.2664 | Time(s) 0.1476
2023-12-01 16:49:54,924:INFO::Validation loss decreased (1.272390 --> 1.266404).  Saving model ...
2023-12-01 16:49:55,084:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 1.2548 | Val_Loss 1.2602 | Time(s) 0.1594
2023-12-01 16:49:55,092:INFO::Validation loss decreased (1.266404 --> 1.260170).  Saving model ...
2023-12-01 16:49:55,253:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 1.2442 | Val_Loss 1.2537 | Time(s) 0.1600
2023-12-01 16:49:55,262:INFO::Validation loss decreased (1.260170 --> 1.253689).  Saving model ...
2023-12-01 16:49:55,428:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 1.2410 | Val_Loss 1.2470 | Time(s) 0.1648
2023-12-01 16:49:55,437:INFO::Validation loss decreased (1.253689 --> 1.246968).  Saving model ...
2023-12-01 16:49:55,605:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 1.2337 | Val_Loss 1.2400 | Time(s) 0.1676
2023-12-01 16:49:55,614:INFO::Validation loss decreased (1.246968 --> 1.239999).  Saving model ...
2023-12-01 16:49:55,773:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 1.2263 | Val_Loss 1.2328 | Time(s) 0.1576
2023-12-01 16:49:55,782:INFO::Validation loss decreased (1.239999 --> 1.232781).  Saving model ...
2023-12-01 16:49:55,941:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 1.2165 | Val_Loss 1.2253 | Time(s) 0.1588
2023-12-01 16:49:55,950:INFO::Validation loss decreased (1.232781 --> 1.225305).  Saving model ...
2023-12-01 16:49:56,114:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 1.2096 | Val_Loss 1.2176 | Time(s) 0.1642
2023-12-01 16:49:56,123:INFO::Validation loss decreased (1.225305 --> 1.217580).  Saving model ...
2023-12-01 16:49:56,280:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 1.1997 | Val_Loss 1.2096 | Time(s) 0.1568
2023-12-01 16:49:56,289:INFO::Validation loss decreased (1.217580 --> 1.209603).  Saving model ...
2023-12-01 16:49:56,453:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 1.1893 | Val_Loss 1.2014 | Time(s) 0.1616
2023-12-01 16:49:56,462:INFO::Validation loss decreased (1.209603 --> 1.201378).  Saving model ...
2023-12-01 16:49:56,619:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 1.1806 | Val_Loss 1.1929 | Time(s) 0.1566
2023-12-01 16:49:56,627:INFO::Validation loss decreased (1.201378 --> 1.192880).  Saving model ...
2023-12-01 16:49:56,788:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 1.1713 | Val_Loss 1.1841 | Time(s) 0.1606
2023-12-01 16:49:56,796:INFO::Validation loss decreased (1.192880 --> 1.184114).  Saving model ...
2023-12-01 16:49:56,956:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 1.1624 | Val_Loss 1.1751 | Time(s) 0.1603
2023-12-01 16:49:56,964:INFO::Validation loss decreased (1.184114 --> 1.175084).  Saving model ...
2023-12-01 16:49:57,132:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 1.1468 | Val_Loss 1.1658 | Time(s) 0.1682
2023-12-01 16:49:57,141:INFO::Validation loss decreased (1.175084 --> 1.165761).  Saving model ...
2023-12-01 16:49:57,296:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 1.1463 | Val_Loss 1.1562 | Time(s) 0.1552
2023-12-01 16:49:57,306:INFO::Validation loss decreased (1.165761 --> 1.156177).  Saving model ...
2023-12-01 16:49:57,466:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 1.1277 | Val_Loss 1.1463 | Time(s) 0.1606
2023-12-01 16:49:57,476:INFO::Validation loss decreased (1.156177 --> 1.146330).  Saving model ...
2023-12-01 16:49:57,635:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 1.1177 | Val_Loss 1.1362 | Time(s) 0.1590
2023-12-01 16:49:57,644:INFO::Validation loss decreased (1.146330 --> 1.136218).  Saving model ...
2023-12-01 16:49:57,800:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 1.1031 | Val_Loss 1.1258 | Time(s) 0.1552
2023-12-01 16:49:57,809:INFO::Validation loss decreased (1.136218 --> 1.125841).  Saving model ...
2023-12-01 16:49:57,968:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 1.0888 | Val_Loss 1.1152 | Time(s) 0.1593
2023-12-01 16:49:57,977:INFO::Validation loss decreased (1.125841 --> 1.115188).  Saving model ...
2023-12-01 16:49:58,143:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 1.0839 | Val_Loss 1.1043 | Time(s) 0.1662
2023-12-01 16:49:58,152:INFO::Validation loss decreased (1.115188 --> 1.104283).  Saving model ...
2023-12-01 16:49:58,306:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 1.0736 | Val_Loss 1.0931 | Time(s) 0.1532
2023-12-01 16:49:58,313:INFO::Validation loss decreased (1.104283 --> 1.093122).  Saving model ...
2023-12-01 16:49:58,474:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 1.0552 | Val_Loss 1.0817 | Time(s) 0.1596
2023-12-01 16:49:58,483:INFO::Validation loss decreased (1.093122 --> 1.081708).  Saving model ...
2023-12-01 16:49:58,636:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 1.0339 | Val_Loss 1.0700 | Time(s) 0.1528
2023-12-01 16:49:58,644:INFO::Validation loss decreased (1.081708 --> 1.070035).  Saving model ...
2023-12-01 16:49:58,801:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 1.0253 | Val_Loss 1.0581 | Time(s) 0.1576
2023-12-01 16:49:58,811:INFO::Validation loss decreased (1.070035 --> 1.058138).  Saving model ...
2023-12-01 16:49:58,967:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 1.0165 | Val_Loss 1.0460 | Time(s) 0.1556
2023-12-01 16:49:58,976:INFO::Validation loss decreased (1.058138 --> 1.046007).  Saving model ...
2023-12-01 16:49:59,149:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.9984 | Val_Loss 1.0337 | Time(s) 0.1721
2023-12-01 16:49:59,159:INFO::Validation loss decreased (1.046007 --> 1.033665).  Saving model ...
2023-12-01 16:49:59,325:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.9921 | Val_Loss 1.0211 | Time(s) 0.1652
2023-12-01 16:49:59,333:INFO::Validation loss decreased (1.033665 --> 1.021140).  Saving model ...
2023-12-01 16:49:59,511:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 0.9754 | Val_Loss 1.0085 | Time(s) 0.1775
2023-12-01 16:49:59,520:INFO::Validation loss decreased (1.021140 --> 1.008453).  Saving model ...
2023-12-01 16:49:59,676:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.9597 | Val_Loss 0.9956 | Time(s) 0.1566
2023-12-01 16:49:59,684:INFO::Validation loss decreased (1.008453 --> 0.995588).  Saving model ...
2023-12-01 16:49:59,844:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.9500 | Val_Loss 0.9826 | Time(s) 0.1601
2023-12-01 16:49:59,853:INFO::Validation loss decreased (0.995588 --> 0.982597).  Saving model ...
2023-12-01 16:50:00,007:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.9225 | Val_Loss 0.9695 | Time(s) 0.1536
2023-12-01 16:50:00,019:INFO::Validation loss decreased (0.982597 --> 0.969458).  Saving model ...
2023-12-01 16:50:00,182:INFO::Epoch 00057 | lr 0.00050 |Train_Loss 0.9167 | Val_Loss 0.9562 | Time(s) 0.1632
2023-12-01 16:50:00,191:INFO::Validation loss decreased (0.969458 --> 0.956205).  Saving model ...
2023-12-01 16:50:00,361:INFO::Epoch 00058 | lr 0.00050 |Train_Loss 0.8938 | Val_Loss 0.9429 | Time(s) 0.1692
2023-12-01 16:50:00,369:INFO::Validation loss decreased (0.956205 --> 0.942877).  Saving model ...
2023-12-01 16:50:00,537:INFO::Epoch 00059 | lr 0.00050 |Train_Loss 0.8850 | Val_Loss 0.9295 | Time(s) 0.1666
2023-12-01 16:50:00,544:INFO::Validation loss decreased (0.942877 --> 0.929512).  Saving model ...
2023-12-01 16:50:00,713:INFO::Epoch 00060 | lr 0.00050 |Train_Loss 0.8716 | Val_Loss 0.9161 | Time(s) 0.1696
2023-12-01 16:50:00,723:INFO::Validation loss decreased (0.929512 --> 0.916128).  Saving model ...
2023-12-01 16:50:00,891:INFO::Epoch 00061 | lr 0.00050 |Train_Loss 0.8537 | Val_Loss 0.9027 | Time(s) 0.1676
2023-12-01 16:50:00,900:INFO::Validation loss decreased (0.916128 --> 0.902747).  Saving model ...
2023-12-01 16:50:01,076:INFO::Epoch 00062 | lr 0.00050 |Train_Loss 0.8378 | Val_Loss 0.8894 | Time(s) 0.1764
2023-12-01 16:50:01,086:INFO::Validation loss decreased (0.902747 --> 0.889374).  Saving model ...
2023-12-01 16:50:01,246:INFO::Epoch 00063 | lr 0.00050 |Train_Loss 0.8286 | Val_Loss 0.8760 | Time(s) 0.1602
2023-12-01 16:50:01,254:INFO::Validation loss decreased (0.889374 --> 0.876048).  Saving model ...
2023-12-01 16:50:01,419:INFO::Epoch 00064 | lr 0.00050 |Train_Loss 0.8070 | Val_Loss 0.8628 | Time(s) 0.1653
2023-12-01 16:50:01,429:INFO::Validation loss decreased (0.876048 --> 0.862769).  Saving model ...
2023-12-01 16:50:01,588:INFO::Epoch 00065 | lr 0.00050 |Train_Loss 0.7906 | Val_Loss 0.8496 | Time(s) 0.1576
2023-12-01 16:50:01,595:INFO::Validation loss decreased (0.862769 --> 0.849558).  Saving model ...
2023-12-01 16:50:01,750:INFO::Epoch 00066 | lr 0.00050 |Train_Loss 0.7732 | Val_Loss 0.8364 | Time(s) 0.1536
2023-12-01 16:50:01,759:INFO::Validation loss decreased (0.849558 --> 0.836431).  Saving model ...
2023-12-01 16:50:01,915:INFO::Epoch 00067 | lr 0.00050 |Train_Loss 0.7664 | Val_Loss 0.8234 | Time(s) 0.1556
2023-12-01 16:50:01,924:INFO::Validation loss decreased (0.836431 --> 0.823377).  Saving model ...
2023-12-01 16:50:02,090:INFO::Epoch 00068 | lr 0.00050 |Train_Loss 0.7466 | Val_Loss 0.8104 | Time(s) 0.1662
2023-12-01 16:50:02,099:INFO::Validation loss decreased (0.823377 --> 0.810411).  Saving model ...
2023-12-01 16:50:02,256:INFO::Epoch 00069 | lr 0.00050 |Train_Loss 0.7324 | Val_Loss 0.7975 | Time(s) 0.1566
2023-12-01 16:50:02,265:INFO::Validation loss decreased (0.810411 --> 0.797542).  Saving model ...
2023-12-01 16:50:02,441:INFO::Epoch 00070 | lr 0.00050 |Train_Loss 0.7057 | Val_Loss 0.7848 | Time(s) 0.1756
2023-12-01 16:50:02,455:INFO::Validation loss decreased (0.797542 --> 0.784789).  Saving model ...
2023-12-01 16:50:02,615:INFO::Epoch 00071 | lr 0.00050 |Train_Loss 0.6995 | Val_Loss 0.7722 | Time(s) 0.1586
2023-12-01 16:50:02,630:INFO::Validation loss decreased (0.784789 --> 0.772198).  Saving model ...
2023-12-01 16:50:02,785:INFO::Epoch 00072 | lr 0.00050 |Train_Loss 0.6857 | Val_Loss 0.7598 | Time(s) 0.1555
2023-12-01 16:50:02,794:INFO::Validation loss decreased (0.772198 --> 0.759766).  Saving model ...
2023-12-01 16:50:02,951:INFO::Epoch 00073 | lr 0.00050 |Train_Loss 0.6689 | Val_Loss 0.7475 | Time(s) 0.1556
2023-12-01 16:50:02,959:INFO::Validation loss decreased (0.759766 --> 0.747471).  Saving model ...
2023-12-01 16:50:03,117:INFO::Epoch 00074 | lr 0.00050 |Train_Loss 0.6579 | Val_Loss 0.7353 | Time(s) 0.1575
2023-12-01 16:50:03,129:INFO::Validation loss decreased (0.747471 --> 0.735319).  Saving model ...
2023-12-01 16:50:03,285:INFO::Epoch 00075 | lr 0.00050 |Train_Loss 0.6429 | Val_Loss 0.7233 | Time(s) 0.1546
2023-12-01 16:50:03,292:INFO::Validation loss decreased (0.735319 --> 0.723324).  Saving model ...
2023-12-01 16:50:03,460:INFO::Epoch 00076 | lr 0.00050 |Train_Loss 0.6329 | Val_Loss 0.7115 | Time(s) 0.1665
2023-12-01 16:50:03,468:INFO::Validation loss decreased (0.723324 --> 0.711516).  Saving model ...
2023-12-01 16:50:03,628:INFO::Epoch 00077 | lr 0.00050 |Train_Loss 0.6152 | Val_Loss 0.6999 | Time(s) 0.1588
2023-12-01 16:50:03,637:INFO::Validation loss decreased (0.711516 --> 0.699862).  Saving model ...
2023-12-01 16:50:03,795:INFO::Epoch 00078 | lr 0.00050 |Train_Loss 0.5999 | Val_Loss 0.6885 | Time(s) 0.1555
2023-12-01 16:50:03,803:INFO::Validation loss decreased (0.699862 --> 0.688451).  Saving model ...
2023-12-01 16:50:03,963:INFO::Epoch 00079 | lr 0.00050 |Train_Loss 0.5872 | Val_Loss 0.6772 | Time(s) 0.1586
2023-12-01 16:50:03,972:INFO::Validation loss decreased (0.688451 --> 0.677209).  Saving model ...
2023-12-01 16:50:04,133:INFO::Epoch 00080 | lr 0.00050 |Train_Loss 0.5741 | Val_Loss 0.6661 | Time(s) 0.1606
2023-12-01 16:50:04,141:INFO::Validation loss decreased (0.677209 --> 0.666128).  Saving model ...
2023-12-01 16:50:04,302:INFO::Epoch 00081 | lr 0.00050 |Train_Loss 0.5585 | Val_Loss 0.6552 | Time(s) 0.1613
2023-12-01 16:50:04,310:INFO::Validation loss decreased (0.666128 --> 0.655172).  Saving model ...
2023-12-01 16:50:04,487:INFO::Epoch 00082 | lr 0.00050 |Train_Loss 0.5547 | Val_Loss 0.6444 | Time(s) 0.1755
2023-12-01 16:50:04,495:INFO::Validation loss decreased (0.655172 --> 0.644380).  Saving model ...
2023-12-01 16:50:04,654:INFO::Epoch 00083 | lr 0.00050 |Train_Loss 0.5365 | Val_Loss 0.6338 | Time(s) 0.1596
2023-12-01 16:50:04,663:INFO::Validation loss decreased (0.644380 --> 0.633792).  Saving model ...
2023-12-01 16:50:04,820:INFO::Epoch 00084 | lr 0.00050 |Train_Loss 0.5201 | Val_Loss 0.6234 | Time(s) 0.1558
2023-12-01 16:50:04,828:INFO::Validation loss decreased (0.633792 --> 0.623409).  Saving model ...
2023-12-01 16:50:04,983:INFO::Epoch 00085 | lr 0.00050 |Train_Loss 0.5195 | Val_Loss 0.6133 | Time(s) 0.1556
2023-12-01 16:50:04,993:INFO::Validation loss decreased (0.623409 --> 0.613256).  Saving model ...
2023-12-01 16:50:05,149:INFO::Epoch 00086 | lr 0.00050 |Train_Loss 0.4979 | Val_Loss 0.6033 | Time(s) 0.1560
2023-12-01 16:50:05,157:INFO::Validation loss decreased (0.613256 --> 0.603349).  Saving model ...
2023-12-01 16:50:05,321:INFO::Epoch 00087 | lr 0.00050 |Train_Loss 0.4829 | Val_Loss 0.5937 | Time(s) 0.1636
2023-12-01 16:50:05,329:INFO::Validation loss decreased (0.603349 --> 0.593706).  Saving model ...
2023-12-01 16:50:05,517:INFO::Epoch 00088 | lr 0.00050 |Train_Loss 0.4817 | Val_Loss 0.5843 | Time(s) 0.1875
2023-12-01 16:50:05,529:INFO::Validation loss decreased (0.593706 --> 0.584285).  Saving model ...
2023-12-01 16:50:05,685:INFO::Epoch 00089 | lr 0.00050 |Train_Loss 0.4638 | Val_Loss 0.5752 | Time(s) 0.1559
2023-12-01 16:50:05,694:INFO::Validation loss decreased (0.584285 --> 0.575156).  Saving model ...
2023-12-01 16:50:05,848:INFO::Epoch 00090 | lr 0.00050 |Train_Loss 0.4500 | Val_Loss 0.5662 | Time(s) 0.1546
2023-12-01 16:50:05,856:INFO::Validation loss decreased (0.575156 --> 0.566226).  Saving model ...
2023-12-01 16:50:06,038:INFO::Epoch 00091 | lr 0.00050 |Train_Loss 0.4419 | Val_Loss 0.5576 | Time(s) 0.1805
2023-12-01 16:50:06,048:INFO::Validation loss decreased (0.566226 --> 0.557578).  Saving model ...
2023-12-01 16:50:06,216:INFO::Epoch 00092 | lr 0.00050 |Train_Loss 0.4267 | Val_Loss 0.5492 | Time(s) 0.1676
2023-12-01 16:50:06,225:INFO::Validation loss decreased (0.557578 --> 0.549206).  Saving model ...
2023-12-01 16:50:06,391:INFO::Epoch 00093 | lr 0.00050 |Train_Loss 0.4180 | Val_Loss 0.5411 | Time(s) 0.1655
2023-12-01 16:50:06,401:INFO::Validation loss decreased (0.549206 --> 0.541062).  Saving model ...
2023-12-01 16:50:06,566:INFO::Epoch 00094 | lr 0.00050 |Train_Loss 0.4153 | Val_Loss 0.5332 | Time(s) 0.1646
2023-12-01 16:50:06,631:INFO::Validation loss decreased (0.541062 --> 0.533174).  Saving model ...
2023-12-01 16:50:06,787:INFO::Epoch 00095 | lr 0.00050 |Train_Loss 0.4020 | Val_Loss 0.5256 | Time(s) 0.1556
2023-12-01 16:50:06,795:INFO::Validation loss decreased (0.533174 --> 0.525562).  Saving model ...
2023-12-01 16:50:06,953:INFO::Epoch 00096 | lr 0.00050 |Train_Loss 0.3943 | Val_Loss 0.5181 | Time(s) 0.1566
2023-12-01 16:50:06,965:INFO::Validation loss decreased (0.525562 --> 0.518073).  Saving model ...
2023-12-01 16:50:07,120:INFO::Epoch 00097 | lr 0.00050 |Train_Loss 0.3841 | Val_Loss 0.5108 | Time(s) 0.1536
2023-12-01 16:50:07,128:INFO::Validation loss decreased (0.518073 --> 0.510784).  Saving model ...
2023-12-01 16:50:07,283:INFO::Epoch 00098 | lr 0.00050 |Train_Loss 0.3707 | Val_Loss 0.5038 | Time(s) 0.1556
2023-12-01 16:50:07,293:INFO::Validation loss decreased (0.510784 --> 0.503763).  Saving model ...
2023-12-01 16:50:07,457:INFO::Epoch 00099 | lr 0.00050 |Train_Loss 0.3666 | Val_Loss 0.4970 | Time(s) 0.1636
2023-12-01 16:50:07,465:INFO::Validation loss decreased (0.503763 --> 0.496999).  Saving model ...
2023-12-01 16:50:07,633:INFO::Epoch 00100 | lr 0.00050 |Train_Loss 0.3536 | Val_Loss 0.4903 | Time(s) 0.1676
2023-12-01 16:50:07,641:INFO::Validation loss decreased (0.496999 --> 0.490339).  Saving model ...
2023-12-01 16:50:07,800:INFO::Epoch 00101 | lr 0.00050 |Train_Loss 0.3472 | Val_Loss 0.4838 | Time(s) 0.1567
2023-12-01 16:50:07,809:INFO::Validation loss decreased (0.490339 --> 0.483835).  Saving model ...
2023-12-01 16:50:07,968:INFO::Epoch 00102 | lr 0.00050 |Train_Loss 0.3305 | Val_Loss 0.4774 | Time(s) 0.1586
2023-12-01 16:50:08,011:INFO::Validation loss decreased (0.483835 --> 0.477391).  Saving model ...
2023-12-01 16:50:08,166:INFO::Epoch 00103 | lr 0.00050 |Train_Loss 0.3349 | Val_Loss 0.4711 | Time(s) 0.1546
2023-12-01 16:50:08,175:INFO::Validation loss decreased (0.477391 --> 0.471135).  Saving model ...
2023-12-01 16:50:08,331:INFO::Epoch 00104 | lr 0.00050 |Train_Loss 0.3159 | Val_Loss 0.4649 | Time(s) 0.1566
2023-12-01 16:50:08,339:INFO::Validation loss decreased (0.471135 --> 0.464915).  Saving model ...
2023-12-01 16:50:08,510:INFO::Epoch 00105 | lr 0.00050 |Train_Loss 0.3130 | Val_Loss 0.4590 | Time(s) 0.1706
2023-12-01 16:50:08,519:INFO::Validation loss decreased (0.464915 --> 0.458973).  Saving model ...
2023-12-01 16:50:08,683:INFO::Epoch 00106 | lr 0.00050 |Train_Loss 0.3109 | Val_Loss 0.4533 | Time(s) 0.1636
2023-12-01 16:50:08,692:INFO::Validation loss decreased (0.458973 --> 0.453311).  Saving model ...
2023-12-01 16:50:08,845:INFO::Epoch 00107 | lr 0.00050 |Train_Loss 0.2991 | Val_Loss 0.4479 | Time(s) 0.1516
2023-12-01 16:50:08,853:INFO::Validation loss decreased (0.453311 --> 0.447924).  Saving model ...
2023-12-01 16:50:09,009:INFO::Epoch 00108 | lr 0.00050 |Train_Loss 0.2898 | Val_Loss 0.4426 | Time(s) 0.1555
2023-12-01 16:50:09,018:INFO::Validation loss decreased (0.447924 --> 0.442636).  Saving model ...
2023-12-01 16:50:09,174:INFO::Epoch 00109 | lr 0.00050 |Train_Loss 0.2803 | Val_Loss 0.4375 | Time(s) 0.1566
2023-12-01 16:50:09,182:INFO::Validation loss decreased (0.442636 --> 0.437458).  Saving model ...
2023-12-01 16:50:09,341:INFO::Epoch 00110 | lr 0.00050 |Train_Loss 0.2714 | Val_Loss 0.4325 | Time(s) 0.1576
2023-12-01 16:50:09,351:INFO::Validation loss decreased (0.437458 --> 0.432520).  Saving model ...
2023-12-01 16:50:09,508:INFO::Epoch 00111 | lr 0.00050 |Train_Loss 0.2667 | Val_Loss 0.4277 | Time(s) 0.1576
2023-12-01 16:50:09,517:INFO::Validation loss decreased (0.432520 --> 0.427703).  Saving model ...
2023-12-01 16:50:09,681:INFO::Epoch 00112 | lr 0.00050 |Train_Loss 0.2634 | Val_Loss 0.4233 | Time(s) 0.1637
2023-12-01 16:50:09,692:INFO::Validation loss decreased (0.427703 --> 0.423272).  Saving model ...
2023-12-01 16:50:09,852:INFO::Epoch 00113 | lr 0.00050 |Train_Loss 0.2559 | Val_Loss 0.4190 | Time(s) 0.1602
2023-12-01 16:50:09,861:INFO::Validation loss decreased (0.423272 --> 0.419048).  Saving model ...
2023-12-01 16:50:10,019:INFO::Epoch 00114 | lr 0.00050 |Train_Loss 0.2524 | Val_Loss 0.4151 | Time(s) 0.1566
2023-12-01 16:50:10,027:INFO::Validation loss decreased (0.419048 --> 0.415107).  Saving model ...
2023-12-01 16:50:10,182:INFO::Epoch 00115 | lr 0.00050 |Train_Loss 0.2457 | Val_Loss 0.4113 | Time(s) 0.1546
2023-12-01 16:50:10,190:INFO::Validation loss decreased (0.415107 --> 0.411312).  Saving model ...
2023-12-01 16:50:10,351:INFO::Epoch 00116 | lr 0.00050 |Train_Loss 0.2340 | Val_Loss 0.4077 | Time(s) 0.1606
2023-12-01 16:50:10,362:INFO::Validation loss decreased (0.411312 --> 0.407658).  Saving model ...
2023-12-01 16:50:10,519:INFO::Epoch 00117 | lr 0.00050 |Train_Loss 0.2368 | Val_Loss 0.4043 | Time(s) 0.1576
2023-12-01 16:50:10,528:INFO::Validation loss decreased (0.407658 --> 0.404299).  Saving model ...
2023-12-01 16:50:10,689:INFO::Epoch 00118 | lr 0.00050 |Train_Loss 0.2300 | Val_Loss 0.4011 | Time(s) 0.1606
2023-12-01 16:50:10,699:INFO::Validation loss decreased (0.404299 --> 0.401092).  Saving model ...
2023-12-01 16:50:10,865:INFO::Epoch 00119 | lr 0.00050 |Train_Loss 0.2270 | Val_Loss 0.3979 | Time(s) 0.1666
2023-12-01 16:50:10,873:INFO::Validation loss decreased (0.401092 --> 0.397880).  Saving model ...
2023-12-01 16:50:11,041:INFO::Epoch 00120 | lr 0.00050 |Train_Loss 0.2204 | Val_Loss 0.3948 | Time(s) 0.1675
2023-12-01 16:50:11,053:INFO::Validation loss decreased (0.397880 --> 0.394789).  Saving model ...
2023-12-01 16:50:11,212:INFO::Epoch 00121 | lr 0.00050 |Train_Loss 0.2188 | Val_Loss 0.3917 | Time(s) 0.1586
2023-12-01 16:50:11,220:INFO::Validation loss decreased (0.394789 --> 0.391714).  Saving model ...
2023-12-01 16:50:11,385:INFO::Epoch 00122 | lr 0.00050 |Train_Loss 0.2074 | Val_Loss 0.3889 | Time(s) 0.1636
2023-12-01 16:50:11,395:INFO::Validation loss decreased (0.391714 --> 0.388937).  Saving model ...
2023-12-01 16:50:11,584:INFO::Epoch 00123 | lr 0.00050 |Train_Loss 0.2047 | Val_Loss 0.3862 | Time(s) 0.1895
2023-12-01 16:50:11,595:INFO::Validation loss decreased (0.388937 --> 0.386232).  Saving model ...
2023-12-01 16:50:11,770:INFO::Epoch 00124 | lr 0.00050 |Train_Loss 0.2038 | Val_Loss 0.3835 | Time(s) 0.1742
2023-12-01 16:50:11,779:INFO::Validation loss decreased (0.386232 --> 0.383497).  Saving model ...
2023-12-01 16:50:11,942:INFO::Epoch 00125 | lr 0.00050 |Train_Loss 0.1971 | Val_Loss 0.3805 | Time(s) 0.1636
2023-12-01 16:50:11,951:INFO::Validation loss decreased (0.383497 --> 0.380504).  Saving model ...
2023-12-01 16:50:12,110:INFO::Epoch 00126 | lr 0.00050 |Train_Loss 0.1929 | Val_Loss 0.3776 | Time(s) 0.1592
2023-12-01 16:50:12,120:INFO::Validation loss decreased (0.380504 --> 0.377572).  Saving model ...
2023-12-01 16:50:12,277:INFO::Epoch 00127 | lr 0.00050 |Train_Loss 0.1877 | Val_Loss 0.3747 | Time(s) 0.1567
2023-12-01 16:50:12,286:INFO::Validation loss decreased (0.377572 --> 0.374658).  Saving model ...
2023-12-01 16:50:12,448:INFO::Epoch 00128 | lr 0.00050 |Train_Loss 0.1813 | Val_Loss 0.3717 | Time(s) 0.1606
2023-12-01 16:50:12,455:INFO::Validation loss decreased (0.374658 --> 0.371709).  Saving model ...
2023-12-01 16:50:12,615:INFO::Epoch 00129 | lr 0.00050 |Train_Loss 0.1797 | Val_Loss 0.3688 | Time(s) 0.1596
2023-12-01 16:50:12,623:INFO::Validation loss decreased (0.371709 --> 0.368850).  Saving model ...
2023-12-01 16:50:12,784:INFO::Epoch 00130 | lr 0.00050 |Train_Loss 0.1710 | Val_Loss 0.3663 | Time(s) 0.1609
2023-12-01 16:50:12,792:INFO::Validation loss decreased (0.368850 --> 0.366261).  Saving model ...
2023-12-01 16:50:12,953:INFO::Epoch 00131 | lr 0.00050 |Train_Loss 0.1683 | Val_Loss 0.3641 | Time(s) 0.1586
2023-12-01 16:50:12,962:INFO::Validation loss decreased (0.366261 --> 0.364054).  Saving model ...
2023-12-01 16:50:13,118:INFO::Epoch 00132 | lr 0.00050 |Train_Loss 0.1720 | Val_Loss 0.3620 | Time(s) 0.1563
2023-12-01 16:50:13,125:INFO::Validation loss decreased (0.364054 --> 0.362015).  Saving model ...
2023-12-01 16:50:13,282:INFO::Epoch 00133 | lr 0.00050 |Train_Loss 0.1639 | Val_Loss 0.3603 | Time(s) 0.1547
2023-12-01 16:50:13,290:INFO::Validation loss decreased (0.362015 --> 0.360266).  Saving model ...
2023-12-01 16:50:13,467:INFO::Epoch 00134 | lr 0.00050 |Train_Loss 0.1631 | Val_Loss 0.3585 | Time(s) 0.1765
2023-12-01 16:50:13,476:INFO::Validation loss decreased (0.360266 --> 0.358454).  Saving model ...
2023-12-01 16:50:13,634:INFO::Epoch 00135 | lr 0.00050 |Train_Loss 0.1561 | Val_Loss 0.3569 | Time(s) 0.1566
2023-12-01 16:50:13,643:INFO::Validation loss decreased (0.358454 --> 0.356863).  Saving model ...
2023-12-01 16:50:13,801:INFO::Epoch 00136 | lr 0.00050 |Train_Loss 0.1530 | Val_Loss 0.3554 | Time(s) 0.1586
2023-12-01 16:50:13,809:INFO::Validation loss decreased (0.356863 --> 0.355367).  Saving model ...
2023-12-01 16:50:13,970:INFO::Epoch 00137 | lr 0.00050 |Train_Loss 0.1519 | Val_Loss 0.3542 | Time(s) 0.1593
2023-12-01 16:50:13,977:INFO::Validation loss decreased (0.355367 --> 0.354207).  Saving model ...
2023-12-01 16:50:14,137:INFO::Epoch 00138 | lr 0.00050 |Train_Loss 0.1449 | Val_Loss 0.3531 | Time(s) 0.1592
2023-12-01 16:50:14,145:INFO::Validation loss decreased (0.354207 --> 0.353066).  Saving model ...
2023-12-01 16:50:14,302:INFO::Epoch 00139 | lr 0.00050 |Train_Loss 0.1497 | Val_Loss 0.3520 | Time(s) 0.1573
2023-12-01 16:50:14,311:INFO::Validation loss decreased (0.353066 --> 0.351962).  Saving model ...
2023-12-01 16:50:14,475:INFO::Epoch 00140 | lr 0.00050 |Train_Loss 0.1456 | Val_Loss 0.3509 | Time(s) 0.1626
2023-12-01 16:50:14,483:INFO::Validation loss decreased (0.351962 --> 0.350887).  Saving model ...
2023-12-01 16:50:14,638:INFO::Epoch 00141 | lr 0.00050 |Train_Loss 0.1433 | Val_Loss 0.3497 | Time(s) 0.1556
2023-12-01 16:50:14,650:INFO::Validation loss decreased (0.350887 --> 0.349705).  Saving model ...
2023-12-01 16:50:14,809:INFO::Epoch 00142 | lr 0.00050 |Train_Loss 0.1314 | Val_Loss 0.3485 | Time(s) 0.1590
2023-12-01 16:50:14,818:INFO::Validation loss decreased (0.349705 --> 0.348531).  Saving model ...
2023-12-01 16:50:14,981:INFO::Epoch 00143 | lr 0.00050 |Train_Loss 0.1314 | Val_Loss 0.3474 | Time(s) 0.1626
2023-12-01 16:50:14,989:INFO::Validation loss decreased (0.348531 --> 0.347403).  Saving model ...
2023-12-01 16:50:15,148:INFO::Epoch 00144 | lr 0.00050 |Train_Loss 0.1334 | Val_Loss 0.3464 | Time(s) 0.1592
2023-12-01 16:50:15,156:INFO::Validation loss decreased (0.347403 --> 0.346377).  Saving model ...
2023-12-01 16:50:15,311:INFO::Epoch 00145 | lr 0.00050 |Train_Loss 0.1248 | Val_Loss 0.3453 | Time(s) 0.1553
2023-12-01 16:50:15,319:INFO::Validation loss decreased (0.346377 --> 0.345304).  Saving model ...
2023-12-01 16:50:15,480:INFO::Epoch 00146 | lr 0.00050 |Train_Loss 0.1237 | Val_Loss 0.3443 | Time(s) 0.1605
2023-12-01 16:50:15,487:INFO::Validation loss decreased (0.345304 --> 0.344261).  Saving model ...
2023-12-01 16:50:15,643:INFO::Epoch 00147 | lr 0.00050 |Train_Loss 0.1211 | Val_Loss 0.3433 | Time(s) 0.1556
2023-12-01 16:50:15,651:INFO::Validation loss decreased (0.344261 --> 0.343319).  Saving model ...
2023-12-01 16:50:15,808:INFO::Epoch 00148 | lr 0.00050 |Train_Loss 0.1215 | Val_Loss 0.3424 | Time(s) 0.1566
2023-12-01 16:50:15,817:INFO::Validation loss decreased (0.343319 --> 0.342420).  Saving model ...
2023-12-01 16:50:15,972:INFO::Epoch 00149 | lr 0.00050 |Train_Loss 0.1179 | Val_Loss 0.3415 | Time(s) 0.1556
2023-12-01 16:50:15,981:INFO::Validation loss decreased (0.342420 --> 0.341509).  Saving model ...
2023-12-01 16:50:16,144:INFO::Epoch 00150 | lr 0.00050 |Train_Loss 0.1219 | Val_Loss 0.3407 | Time(s) 0.1632
2023-12-01 16:50:16,153:INFO::Validation loss decreased (0.341509 --> 0.340678).  Saving model ...
2023-12-01 16:50:16,307:INFO::Epoch 00151 | lr 0.00050 |Train_Loss 0.1182 | Val_Loss 0.3399 | Time(s) 0.1539
2023-12-01 16:50:16,315:INFO::Validation loss decreased (0.340678 --> 0.339911).  Saving model ...
2023-12-01 16:50:16,488:INFO::Epoch 00152 | lr 0.00050 |Train_Loss 0.1107 | Val_Loss 0.3393 | Time(s) 0.1725
2023-12-01 16:50:16,496:INFO::Validation loss decreased (0.339911 --> 0.339299).  Saving model ...
2023-12-01 16:50:16,654:INFO::Epoch 00153 | lr 0.00050 |Train_Loss 0.1116 | Val_Loss 0.3388 | Time(s) 0.1582
2023-12-01 16:50:16,664:INFO::Validation loss decreased (0.339299 --> 0.338807).  Saving model ...
2023-12-01 16:50:16,829:INFO::Epoch 00154 | lr 0.00050 |Train_Loss 0.1105 | Val_Loss 0.3382 | Time(s) 0.1646
2023-12-01 16:50:16,839:INFO::Validation loss decreased (0.338807 --> 0.338195).  Saving model ...
2023-12-01 16:50:17,008:INFO::Epoch 00155 | lr 0.00050 |Train_Loss 0.1061 | Val_Loss 0.3375 | Time(s) 0.1695
2023-12-01 16:50:17,018:INFO::Validation loss decreased (0.338195 --> 0.337475).  Saving model ...
2023-12-01 16:50:17,196:INFO::Epoch 00156 | lr 0.00050 |Train_Loss 0.1065 | Val_Loss 0.3367 | Time(s) 0.1782
2023-12-01 16:50:17,204:INFO::Validation loss decreased (0.337475 --> 0.336681).  Saving model ...
2023-12-01 16:50:17,364:INFO::Epoch 00157 | lr 0.00050 |Train_Loss 0.1035 | Val_Loss 0.3358 | Time(s) 0.1592
2023-12-01 16:50:17,371:INFO::Validation loss decreased (0.336681 --> 0.335835).  Saving model ...
2023-12-01 16:50:17,530:INFO::Epoch 00158 | lr 0.00050 |Train_Loss 0.1044 | Val_Loss 0.3350 | Time(s) 0.1586
2023-12-01 16:50:17,538:INFO::Validation loss decreased (0.335835 --> 0.334955).  Saving model ...
2023-12-01 16:50:17,694:INFO::Epoch 00159 | lr 0.00050 |Train_Loss 0.0968 | Val_Loss 0.3342 | Time(s) 0.1556
2023-12-01 16:50:17,702:INFO::Validation loss decreased (0.334955 --> 0.334179).  Saving model ...
2023-12-01 16:50:17,856:INFO::Epoch 00160 | lr 0.00050 |Train_Loss 0.1035 | Val_Loss 0.3332 | Time(s) 0.1543
2023-12-01 16:50:17,865:INFO::Validation loss decreased (0.334179 --> 0.333202).  Saving model ...
2023-12-01 16:50:18,022:INFO::Epoch 00161 | lr 0.00050 |Train_Loss 0.0991 | Val_Loss 0.3324 | Time(s) 0.1572
2023-12-01 16:50:18,030:INFO::Validation loss decreased (0.333202 --> 0.332381).  Saving model ...
2023-12-01 16:50:18,193:INFO::Epoch 00162 | lr 0.00050 |Train_Loss 0.0952 | Val_Loss 0.3316 | Time(s) 0.1627
2023-12-01 16:50:18,201:INFO::Validation loss decreased (0.332381 --> 0.331633).  Saving model ...
2023-12-01 16:50:18,363:INFO::Epoch 00163 | lr 0.00050 |Train_Loss 0.0932 | Val_Loss 0.3310 | Time(s) 0.1622
2023-12-01 16:50:18,371:INFO::Validation loss decreased (0.331633 --> 0.330968).  Saving model ...
2023-12-01 16:50:18,542:INFO::Epoch 00164 | lr 0.00050 |Train_Loss 0.0942 | Val_Loss 0.3305 | Time(s) 0.1695
2023-12-01 16:50:18,551:INFO::Validation loss decreased (0.330968 --> 0.330544).  Saving model ...
2023-12-01 16:50:18,707:INFO::Epoch 00165 | lr 0.00050 |Train_Loss 0.0861 | Val_Loss 0.3301 | Time(s) 0.1556
2023-12-01 16:50:18,715:INFO::Validation loss decreased (0.330544 --> 0.330130).  Saving model ...
2023-12-01 16:50:18,874:INFO::Epoch 00166 | lr 0.00050 |Train_Loss 0.0901 | Val_Loss 0.3300 | Time(s) 0.1586
2023-12-01 16:50:18,882:INFO::Validation loss decreased (0.330130 --> 0.329954).  Saving model ...
2023-12-01 16:50:19,039:INFO::Epoch 00167 | lr 0.00050 |Train_Loss 0.0881 | Val_Loss 0.3302 | Time(s) 0.1566
2023-12-01 16:50:19,040:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:50:19,206:INFO::Epoch 00168 | lr 0.00050 |Train_Loss 0.0848 | Val_Loss 0.3302 | Time(s) 0.1662
2023-12-01 16:50:19,207:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:50:19,368:INFO::Epoch 00169 | lr 0.00050 |Train_Loss 0.0816 | Val_Loss 0.3304 | Time(s) 0.1612
2023-12-01 16:50:19,369:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:50:19,532:INFO::Epoch 00170 | lr 0.00050 |Train_Loss 0.0844 | Val_Loss 0.3307 | Time(s) 0.1616
2023-12-01 16:50:19,532:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 16:50:19,688:INFO::Epoch 00171 | lr 0.00050 |Train_Loss 0.0808 | Val_Loss 0.3309 | Time(s) 0.1566
2023-12-01 16:50:19,689:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 16:50:19,856:INFO::Epoch 00172 | lr 0.00050 |Train_Loss 0.0799 | Val_Loss 0.3313 | Time(s) 0.1666
2023-12-01 16:50:19,857:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 16:50:20,018:INFO::Epoch 00173 | lr 0.00050 |Train_Loss 0.0797 | Val_Loss 0.3316 | Time(s) 0.1606
2023-12-01 16:50:20,019:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 16:50:20,181:INFO::Epoch 00174 | lr 0.00050 |Train_Loss 0.0760 | Val_Loss 0.3316 | Time(s) 0.1622
2023-12-01 16:50:20,182:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 16:50:20,182:INFO::Eearly stopping!
2023-12-01 16:50:20,183:INFO::
testing...
2023-12-01 16:50:20,323:INFO::submit dir: submit/submit_gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:20,600:INFO::{'micro-f1': 0.8947183098591549, 'macro-f1': 0.8872197082471376}
2023-12-01 16:50:20,727:INFO::############### Retrain Stage Ends! #################
2023-12-01 16:50:20,728:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gcn', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-16-46-32', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=666, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=1, last_hidden_dim=64, logger=<Logger log_output (INFO)>)
2023-12-01 16:50:39,377:INFO::node_type_num: 4
2023-12-01 16:50:41,268:INFO::=============== Prepare basic data stage finish, use 20.539719343185425 time.
2023-12-01 16:50:42,285:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:52,012:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 16:50:52,154:INFO::its now!!!!!!!!5
2023-12-01 16:50:54,139:INFO::its now!!!!!!!!0
2023-12-01 16:50:54,402:INFO::its now!!!!!!!!3
2023-12-01 16:50:54,818:INFO::its now!!!!!!!!5
2023-12-01 16:50:55,406:INFO::its now!!!!!!!!
2023-12-01 16:50:55,407:INFO::its now!!!!!!!! on 
2023-12-01 16:50:55,647:INFO::its now!!!!!!!!5
2023-12-01 16:50:55,793:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:55,808:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.3559 | Train_Classification_Loss 1.3869 | Dmon_Loss -0.0621 | Val_Loss 1.3844 | Search Time(s) 4.4455 | Infer Time(s) 0.1466 | Time(s) 4.5921 
2023-12-01 16:50:55,948:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 2;	4: 0;	5: 1;	6: 0;	7: 1;	8: 0;	9: 1;	10: 0;	11: 0;	12: 0;	13: 3;	14: 3;	15: 0;	16: 0;	17: 0;	18: 1;	19: 2;	20: 2;	21: 2;	22: 3;	23: 3;	24: 3;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 1;	33: 0;	34: 0;	35: 1;	36: 3;	37: 0;	38: 2;	39: 0;	40: 1;	41: 0;	42: 3;	43: 3;	44
26098: 0;	26099: 2;	26100: 0;	26101: 1;	26102: 1;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 2;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:50:55,952:INFO::Epoch: 1
tensor([[0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.5050, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050]], device='cuda:0', requires_grad=True)
2023-12-01 16:50:55,954:INFO::its now!!!!!!!!5
2023-12-01 16:50:56,211:INFO::its now!!!!!!!!0
2023-12-01 16:50:56,212:INFO::its now!!!!!!!!3
2023-12-01 16:50:56,258:INFO::its now!!!!!!!!5
2023-12-01 16:50:56,424:INFO::its now!!!!!!!!
2023-12-01 16:50:56,425:INFO::its now!!!!!!!! on 
2023-12-01 16:50:56,460:INFO::its now!!!!!!!!5
2023-12-01 16:50:56,609:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:56,610:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3537 | Train_Classification_Loss 1.3850 | Dmon_Loss -0.0625 | Val_Loss 1.3838 | Search Time(s) 0.5037 | Infer Time(s) 0.1556 | Time(s) 0.6592 
2023-12-01 16:50:56,648:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 1;	4: 2;	5: 1;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 1;	25: 0;	26: 0;	27: 1;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 1;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 1;	26100: 1;	26101: 0;	26102: 0;	26103: 1;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 1;	26109: 3;	26110: 3;	26111: 3;	26112: 2;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 1;	26118: 1;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:50:56,649:INFO::Validation loss decreased (inf --> 1.383832).  Saving model ...
2023-12-01 16:50:56,652:INFO::Epoch: 2
tensor([[0.4997, 0.5071, 0.5099, 0.5099],
        [0.4997, 0.5078, 0.5099, 0.5099],
        [0.5097, 0.5078, 0.5099, 0.5099],
        [0.4997, 0.5067, 0.5099, 0.5099]], device='cuda:0', requires_grad=True)
2023-12-01 16:50:56,652:INFO::its now!!!!!!!!5
2023-12-01 16:50:56,811:INFO::its now!!!!!!!!0
2023-12-01 16:50:56,812:INFO::its now!!!!!!!!3
2023-12-01 16:50:56,838:INFO::its now!!!!!!!!5
2023-12-01 16:50:57,003:INFO::its now!!!!!!!!
2023-12-01 16:50:57,003:INFO::its now!!!!!!!! on 
2023-12-01 16:50:57,040:INFO::its now!!!!!!!!5
2023-12-01 16:50:57,187:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:57,188:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3499 | Train_Classification_Loss 1.3811 | Dmon_Loss -0.0625 | Val_Loss 1.3782 | Search Time(s) 0.3880 | Infer Time(s) 0.1506 | Time(s) 0.5386 
2023-12-01 16:50:57,345:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 0;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 0;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 1;	26109: 1;	26110: 1;	26111: 2;	26112: 2;	26113: 2;	26114: 0;	26115: 1;	26116: 0;	26117: 2;	26118: 1;	26119: 0;	26120: 0;	26121: 2;	26122: 3;	26123: 1;	26124: 1;	26125: 0;	26126: 1;	26127: 0;	
2023-12-01 16:50:57,347:INFO::Validation loss decreased (1.383832 --> 1.378152).  Saving model ...
2023-12-01 16:50:57,351:INFO::Epoch: 3
tensor([[0.5052, 0.5121, 0.5124, 0.5154],
        [0.5052, 0.5128, 0.5123, 0.5154],
        [0.5152, 0.5128, 0.5124, 0.5154],
        [0.5052, 0.5117, 0.5125, 0.5154]], device='cuda:0', requires_grad=True)
2023-12-01 16:50:57,352:INFO::its now!!!!!!!!5
2023-12-01 16:50:57,592:INFO::its now!!!!!!!!0
2023-12-01 16:50:57,593:INFO::its now!!!!!!!!3
2023-12-01 16:50:57,621:INFO::its now!!!!!!!!5
2023-12-01 16:50:57,773:INFO::its now!!!!!!!!
2023-12-01 16:50:57,774:INFO::its now!!!!!!!! on 
2023-12-01 16:50:57,812:INFO::its now!!!!!!!!5
2023-12-01 16:50:57,944:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:57,945:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3443 | Train_Classification_Loss 1.3755 | Dmon_Loss -0.0625 | Val_Loss 1.3744 | Search Time(s) 0.4628 | Infer Time(s) 0.1336 | Time(s) 0.5964 
2023-12-01 16:50:57,999:INFO::cluster info:
0: 1;	1: 0;	2: 0;	3: 1;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 1;	11: 0;	12: 0;	13: 0;	14: 1;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 0;	22: 0;	23: 0;	24: 2;	25: 0;	26: 1;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 0;	26112: 0;	26113: 1;	26114: 0;	26115: 2;	26116: 1;	26117: 2;	26118: 1;	26119: 0;	26120: 0;	26121: 0;	26122: 0;	26123: 1;	26124: 0;	26125: 1;	26126: 1;	26127: 0;	
2023-12-01 16:50:58,000:INFO::Validation loss decreased (1.378152 --> 1.374388).  Saving model ...
2023-12-01 16:50:58,003:INFO::Epoch: 4
tensor([[0.5108, 0.5177, 0.5176, 0.5184],
        [0.5108, 0.5184, 0.5174, 0.5185],
        [0.5208, 0.5184, 0.5176, 0.5184],
        [0.5108, 0.5172, 0.5178, 0.5184]], device='cuda:0', requires_grad=True)
2023-12-01 16:50:58,004:INFO::its now!!!!!!!!5
2023-12-01 16:50:58,155:INFO::its now!!!!!!!!0
2023-12-01 16:50:58,155:INFO::its now!!!!!!!!3
2023-12-01 16:50:58,187:INFO::its now!!!!!!!!5
2023-12-01 16:50:58,338:INFO::its now!!!!!!!!
2023-12-01 16:50:58,338:INFO::its now!!!!!!!! on 
2023-12-01 16:50:58,395:INFO::its now!!!!!!!!5
2023-12-01 16:50:58,538:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:58,539:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3422 | Train_Classification_Loss 1.3734 | Dmon_Loss -0.0624 | Val_Loss 1.3714 | Search Time(s) 0.3720 | Infer Time(s) 0.1666 | Time(s) 0.5386 
2023-12-01 16:50:58,593:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 0;	4: 1;	5: 2;	6: 0;	7: 0;	8: 0;	9: 2;	10: 0;	11: 0;	12: 3;	13: 0;	14: 0;	15: 2;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 0;	36: 1;	37: 0;	38: 0;	39: 0;	40: 1;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 1;	26101: 0;	26102: 1;	26103: 2;	26104: 1;	26105: 0;	26106: 3;	26107: 3;	26108: 1;	26109: 3;	26110: 2;	26111: 3;	26112: 1;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 2;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 1;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:50:58,595:INFO::Validation loss decreased (1.374388 --> 1.371398).  Saving model ...
2023-12-01 16:50:58,597:INFO::Epoch: 5
tensor([[0.5165, 0.5235, 0.5236, 0.5199],
        [0.5165, 0.5242, 0.5234, 0.5201],
        [0.5238, 0.5242, 0.5236, 0.5234],
        [0.5165, 0.5230, 0.5237, 0.5201]], device='cuda:0', requires_grad=True)
2023-12-01 16:50:58,598:INFO::its now!!!!!!!!5
2023-12-01 16:50:58,737:INFO::its now!!!!!!!!0
2023-12-01 16:50:58,738:INFO::its now!!!!!!!!3
2023-12-01 16:50:58,783:INFO::its now!!!!!!!!5
2023-12-01 16:50:58,952:INFO::its now!!!!!!!!
2023-12-01 16:50:58,952:INFO::its now!!!!!!!! on 
2023-12-01 16:50:59,006:INFO::its now!!!!!!!!5
2023-12-01 16:50:59,161:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:59,163:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3388 | Train_Classification_Loss 1.3700 | Dmon_Loss -0.0624 | Val_Loss 1.3674 | Search Time(s) 0.3900 | Infer Time(s) 0.1755 | Time(s) 0.5655 
2023-12-01 16:50:59,202:INFO::cluster info:
0: 1;	1: 2;	2: 3;	3: 0;	4: 0;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 0;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 2;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 1;	34: 0;	35: 1;	36: 0;	37: 1;	38: 1;	39: 0;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 1;	26099: 0;	26100: 1;	26101: 2;	26102: 0;	26103: 0;	26104: 0;	26105: 1;	26106: 1;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 1;	26112: 2;	26113: 3;	26114: 3;	26115: 3;	26116: 2;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:50:59,203:INFO::Validation loss decreased (1.371398 --> 1.367444).  Saving model ...
2023-12-01 16:50:59,206:INFO::Epoch: 6
tensor([[0.5191, 0.5261, 0.5267, 0.5201],
        [0.5191, 0.5274, 0.5260, 0.5203],
        [0.5249, 0.5274, 0.5262, 0.5255],
        [0.5191, 0.5256, 0.5269, 0.5203]], device='cuda:0', requires_grad=True)
2023-12-01 16:50:59,207:INFO::its now!!!!!!!!5
2023-12-01 16:50:59,366:INFO::its now!!!!!!!!0
2023-12-01 16:50:59,366:INFO::its now!!!!!!!!3
2023-12-01 16:50:59,412:INFO::its now!!!!!!!!5
2023-12-01 16:50:59,568:INFO::its now!!!!!!!!
2023-12-01 16:50:59,568:INFO::its now!!!!!!!! on 
2023-12-01 16:50:59,621:INFO::its now!!!!!!!!5
2023-12-01 16:50:59,772:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:50:59,775:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.3341 | Train_Classification_Loss 1.3652 | Dmon_Loss -0.0622 | Val_Loss 1.3638 | Search Time(s) 0.4009 | Infer Time(s) 0.1686 | Time(s) 0.5695 
2023-12-01 16:50:59,827:INFO::cluster info:
0: 1;	1: 0;	2: 0;	3: 3;	4: 0;	5: 0;	6: 1;	7: 0;	8: 0;	9: 0;	10: 1;	11: 1;	12: 0;	13: 2;	14: 3;	15: 2;	16: 0;	17: 0;	18: 3;	19: 1;	20: 0;	21: 0;	22: 2;	23: 2;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 1;	36: 3;	37: 0;	38: 0;	39: 0;	40: 1;	41: 0;	42: 3;	43: 0;	44
26098: 3;	26099: 0;	26100: 1;	26101: 1;	26102: 1;	26103: 0;	26104: 0;	26105: 0;	26106: 1;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 2;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 2;	26119: 3;	26120: 2;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 2;	26127: 1;	
2023-12-01 16:50:59,828:INFO::Validation loss decreased (1.367444 --> 1.363798).  Saving model ...
2023-12-01 16:50:59,832:INFO::Epoch: 7
tensor([[0.5236, 0.5308, 0.5284, 0.5245],
        [0.5236, 0.5290, 0.5310, 0.5247],
        [0.5292, 0.5291, 0.5312, 0.5301],
        [0.5237, 0.5303, 0.5286, 0.5247]], device='cuda:0', requires_grad=True)
2023-12-01 16:50:59,833:INFO::its now!!!!!!!!5
2023-12-01 16:51:00,063:INFO::its now!!!!!!!!0
2023-12-01 16:51:00,063:INFO::its now!!!!!!!!3
2023-12-01 16:51:00,108:INFO::its now!!!!!!!!5
2023-12-01 16:51:00,266:INFO::its now!!!!!!!!
2023-12-01 16:51:00,266:INFO::its now!!!!!!!! on 
2023-12-01 16:51:00,322:INFO::its now!!!!!!!!5
2023-12-01 16:51:00,463:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:00,464:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.3284 | Train_Classification_Loss 1.3595 | Dmon_Loss -0.0623 | Val_Loss 1.3602 | Search Time(s) 0.4907 | Infer Time(s) 0.1446 | Time(s) 0.6353 
2023-12-01 16:51:00,503:INFO::cluster info:
0: 0;	1: 1;	2: 0;	3: 3;	4: 0;	5: 1;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 0;	13: 0;	14: 2;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 0;	22: 0;	23: 1;	24: 1;	25: 1;	26: 0;	27: 0;	28: 2;	29: 1;	30: 0;	31: 0;	32: 0;	33: 0;	34: 1;	35: 1;	36: 0;	37: 0;	38: 0;	39: 0;	40: 1;	41: 0;	42: 1;	43: 0;	44
26098: 3;	26099: 0;	26100: 0;	26101: 2;	26102: 0;	26103: 1;	26104: 0;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 2;	26113: 3;	26114: 3;	26115: 3;	26116: 2;	26117: 3;	26118: 1;	26119: 3;	26120: 2;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 1;	26127: 0;	
2023-12-01 16:51:00,504:INFO::Validation loss decreased (1.363798 --> 1.360196).  Saving model ...
2023-12-01 16:51:00,507:INFO::Epoch: 8
tensor([[0.5275, 0.5334, 0.5313, 0.5288],
        [0.5275, 0.5318, 0.5336, 0.5290],
        [0.5331, 0.5318, 0.5338, 0.5342],
        [0.5276, 0.5328, 0.5316, 0.5290]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:00,508:INFO::its now!!!!!!!!5
2023-12-01 16:51:00,666:INFO::its now!!!!!!!!0
2023-12-01 16:51:00,667:INFO::its now!!!!!!!!3
2023-12-01 16:51:00,714:INFO::its now!!!!!!!!5
2023-12-01 16:51:00,858:INFO::its now!!!!!!!!
2023-12-01 16:51:00,858:INFO::its now!!!!!!!! on 
2023-12-01 16:51:00,913:INFO::its now!!!!!!!!5
2023-12-01 16:51:01,075:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:01,077:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.3263 | Train_Classification_Loss 1.3574 | Dmon_Loss -0.0623 | Val_Loss 1.3568 | Search Time(s) 0.4079 | Infer Time(s) 0.1626 | Time(s) 0.5705 
2023-12-01 16:51:01,136:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 2;	4: 0;	5: 2;	6: 0;	7: 0;	8: 2;	9: 1;	10: 0;	11: 0;	12: 0;	13: 0;	14: 1;	15: 0;	16: 0;	17: 0;	18: 0;	19: 2;	20: 0;	21: 0;	22: 0;	23: 0;	24: 1;	25: 0;	26: 0;	27: 1;	28: 0;	29: 2;	30: 0;	31: 2;	32: 0;	33: 0;	34: 0;	35: 0;	36: 0;	37: 0;	38: 1;	39: 0;	40: 0;	41: 0;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 1;	26107: 0;	26108: 3;	26109: 3;	26110: 2;	26111: 3;	26112: 2;	26113: 3;	26114: 1;	26115: 3;	26116: 2;	26117: 3;	26118: 3;	26119: 2;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:51:01,137:INFO::Validation loss decreased (1.360196 --> 1.356774).  Saving model ...
2023-12-01 16:51:01,140:INFO::Epoch: 9
tensor([[0.5301, 0.5347, 0.5336, 0.5316],
        [0.5301, 0.5338, 0.5350, 0.5318],
        [0.5357, 0.5339, 0.5358, 0.5364],
        [0.5301, 0.5341, 0.5339, 0.5318]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:01,141:INFO::its now!!!!!!!!5
2023-12-01 16:51:01,284:INFO::its now!!!!!!!!0
2023-12-01 16:51:01,285:INFO::its now!!!!!!!!3
2023-12-01 16:51:01,331:INFO::its now!!!!!!!!5
2023-12-01 16:51:01,492:INFO::its now!!!!!!!!
2023-12-01 16:51:01,492:INFO::its now!!!!!!!! on 
2023-12-01 16:51:01,546:INFO::its now!!!!!!!!5
2023-12-01 16:51:01,689:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:01,690:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.3210 | Train_Classification_Loss 1.3522 | Dmon_Loss -0.0625 | Val_Loss 1.3542 | Search Time(s) 0.3910 | Infer Time(s) 0.1606 | Time(s) 0.5515 
2023-12-01 16:51:01,726:INFO::cluster info:
0: 1;	1: 0;	2: 1;	3: 1;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 1;	10: 1;	11: 0;	12: 1;	13: 0;	14: 0;	15: 0;	16: 1;	17: 0;	18: 0;	19: 1;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 0;	36: 0;	37: 0;	38: 1;	39: 1;	40: 1;	41: 0;	42: 0;	43: 0;	44
26098: 1;	26099: 1;	26100: 1;	26101: 1;	26102: 0;	26103: 1;	26104: 1;	26105: 0;	26106: 0;	26107: 0;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 3;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 16:51:01,727:INFO::Validation loss decreased (1.356774 --> 1.354176).  Saving model ...
2023-12-01 16:51:01,730:INFO::Epoch: 10
tensor([[0.5356, 0.5354, 0.5398, 0.5380],
        [0.5357, 0.5397, 0.5357, 0.5382],
        [0.5417, 0.5397, 0.5415, 0.5375],
        [0.5357, 0.5348, 0.5401, 0.5382]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:01,730:INFO::its now!!!!!!!!5
2023-12-01 16:51:01,872:INFO::its now!!!!!!!!0
2023-12-01 16:51:01,873:INFO::its now!!!!!!!!3
2023-12-01 16:51:01,921:INFO::its now!!!!!!!!5
2023-12-01 16:51:02,073:INFO::its now!!!!!!!!
2023-12-01 16:51:02,073:INFO::its now!!!!!!!! on 
2023-12-01 16:51:02,110:INFO::its now!!!!!!!!5
2023-12-01 16:51:02,271:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:02,272:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.3172 | Train_Classification_Loss 1.3485 | Dmon_Loss -0.0626 | Val_Loss 1.3509 | Search Time(s) 0.3780 | Infer Time(s) 0.1656 | Time(s) 0.5436 
2023-12-01 16:51:02,310:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 1;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 1;	10: 2;	11: 0;	12: 0;	13: 0;	14: 0;	15: 2;	16: 0;	17: 0;	18: 0;	19: 1;	20: 0;	21: 1;	22: 1;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 1;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 1;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 1;	26100: 2;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 1;	26116: 2;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:02,311:INFO::Validation loss decreased (1.354176 --> 1.350880).  Saving model ...
2023-12-01 16:51:02,315:INFO::Epoch: 11
tensor([[0.5412, 0.5393, 0.5430, 0.5443],
        [0.5412, 0.5428, 0.5399, 0.5445],
        [0.5448, 0.5457, 0.5474, 0.5417],
        [0.5412, 0.5386, 0.5434, 0.5445]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:02,315:INFO::its now!!!!!!!!5
2023-12-01 16:51:02,465:INFO::its now!!!!!!!!0
2023-12-01 16:51:02,466:INFO::its now!!!!!!!!3
2023-12-01 16:51:02,493:INFO::its now!!!!!!!!5
2023-12-01 16:51:02,647:INFO::its now!!!!!!!!
2023-12-01 16:51:02,647:INFO::its now!!!!!!!! on 
2023-12-01 16:51:02,701:INFO::its now!!!!!!!!5
2023-12-01 16:51:02,863:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:02,864:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.3139 | Train_Classification_Loss 1.3451 | Dmon_Loss -0.0625 | Val_Loss 1.3471 | Search Time(s) 0.3710 | Infer Time(s) 0.1785 | Time(s) 0.5495 
2023-12-01 16:51:03,014:INFO::cluster info:
0: 0;	1: 2;	2: 0;	3: 0;	4: 0;	5: 0;	6: 1;	7: 0;	8: 0;	9: 1;	10: 1;	11: 0;	12: 1;	13: 2;	14: 0;	15: 0;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 1;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 1;	35: 1;	36: 1;	37: 0;	38: 0;	39: 0;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 1;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 1;	26109: 2;	26110: 1;	26111: 3;	26112: 1;	26113: 2;	26114: 3;	26115: 1;	26116: 2;	26117: 1;	26118: 1;	26119: 2;	26120: 1;	26121: 3;	26122: 3;	26123: 1;	26124: 3;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:03,016:INFO::Validation loss decreased (1.350880 --> 1.347071).  Saving model ...
2023-12-01 16:51:03,019:INFO::Epoch: 12
tensor([[0.5478, 0.5457, 0.5492, 0.5476],
        [0.5478, 0.5488, 0.5466, 0.5478],
        [0.5507, 0.5528, 0.5505, 0.5483],
        [0.5478, 0.5450, 0.5497, 0.5478]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:03,020:INFO::its now!!!!!!!!5
2023-12-01 16:51:03,271:INFO::its now!!!!!!!!0
2023-12-01 16:51:03,272:INFO::its now!!!!!!!!3
2023-12-01 16:51:03,320:INFO::its now!!!!!!!!5
2023-12-01 16:51:03,493:INFO::its now!!!!!!!!
2023-12-01 16:51:03,494:INFO::its now!!!!!!!! on 
2023-12-01 16:51:03,531:INFO::its now!!!!!!!!5
2023-12-01 16:51:03,688:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:03,689:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.3075 | Train_Classification_Loss 1.3387 | Dmon_Loss -0.0625 | Val_Loss 1.3414 | Search Time(s) 0.5066 | Infer Time(s) 0.1646 | Time(s) 0.6712 
2023-12-01 16:51:03,746:INFO::cluster info:
0: 0;	1: 1;	2: 0;	3: 1;	4: 0;	5: 1;	6: 0;	7: 0;	8: 0;	9: 0;	10: 1;	11: 1;	12: 1;	13: 0;	14: 1;	15: 0;	16: 1;	17: 1;	18: 0;	19: 1;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 1;	26: 2;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 1;	33: 0;	34: 1;	35: 1;	36: 1;	37: 0;	38: 1;	39: 0;	40: 1;	41: 1;	42: 1;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 2;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 1;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 2;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 16:51:03,747:INFO::Validation loss decreased (1.347071 --> 1.341436).  Saving model ...
2023-12-01 16:51:03,749:INFO::Epoch: 13
tensor([[0.5537, 0.5519, 0.5524, 0.5525],
        [0.5537, 0.5519, 0.5531, 0.5527],
        [0.5565, 0.5564, 0.5551, 0.5547],
        [0.5537, 0.5513, 0.5529, 0.5527]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:03,750:INFO::its now!!!!!!!!5
2023-12-01 16:51:03,893:INFO::its now!!!!!!!!0
2023-12-01 16:51:03,894:INFO::its now!!!!!!!!3
2023-12-01 16:51:03,922:INFO::its now!!!!!!!!5
2023-12-01 16:51:04,076:INFO::its now!!!!!!!!
2023-12-01 16:51:04,076:INFO::its now!!!!!!!! on 
2023-12-01 16:51:04,134:INFO::its now!!!!!!!!5
2023-12-01 16:51:04,300:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:04,302:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.3079 | Train_Classification_Loss 1.3392 | Dmon_Loss -0.0626 | Val_Loss 1.3407 | Search Time(s) 0.3840 | Infer Time(s) 0.1685 | Time(s) 0.5525 
2023-12-01 16:51:04,360:INFO::cluster info:
0: 1;	1: 0;	2: 0;	3: 0;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 1;	10: 0;	11: 1;	12: 0;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 1;	33: 1;	34: 0;	35: 0;	36: 0;	37: 0;	38: 0;	39: 0;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 1;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 1;	26110: 0;	26111: 0;	26112: 2;	26113: 1;	26114: 1;	26115: 1;	26116: 2;	26117: 1;	26118: 2;	26119: 1;	26120: 1;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:04,362:INFO::Validation loss decreased (1.341436 --> 1.340691).  Saving model ...
2023-12-01 16:51:04,364:INFO::Epoch: 14
tensor([[0.5568, 0.5572, 0.5564, 0.5574],
        [0.5569, 0.5557, 0.5587, 0.5575],
        [0.5595, 0.5604, 0.5598, 0.5601],
        [0.5568, 0.5566, 0.5570, 0.5575]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:04,365:INFO::its now!!!!!!!!5
2023-12-01 16:51:04,511:INFO::its now!!!!!!!!0
2023-12-01 16:51:04,512:INFO::its now!!!!!!!!3
2023-12-01 16:51:04,559:INFO::its now!!!!!!!!5
2023-12-01 16:51:04,706:INFO::its now!!!!!!!!
2023-12-01 16:51:04,706:INFO::its now!!!!!!!! on 
2023-12-01 16:51:04,763:INFO::its now!!!!!!!!5
2023-12-01 16:51:04,923:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:04,925:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.3033 | Train_Classification_Loss 1.3345 | Dmon_Loss -0.0625 | Val_Loss 1.3369 | Search Time(s) 0.3979 | Infer Time(s) 0.1636 | Time(s) 0.5615 
2023-12-01 16:51:04,970:INFO::cluster info:
0: 1;	1: 1;	2: 0;	3: 2;	4: 0;	5: 1;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 0;	13: 0;	14: 2;	15: 0;	16: 0;	17: 0;	18: 0;	19: 2;	20: 0;	21: 0;	22: 2;	23: 1;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 1;	30: 0;	31: 0;	32: 0;	33: 0;	34: 1;	35: 0;	36: 1;	37: 0;	38: 0;	39: 0;	40: 0;	41: 2;	42: 1;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 1;	26102: 1;	26103: 1;	26104: 1;	26105: 0;	26106: 0;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 1;	26119: 1;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:04,971:INFO::Validation loss decreased (1.340691 --> 1.336944).  Saving model ...
2023-12-01 16:51:04,974:INFO::Epoch: 15
tensor([[0.5622, 0.5641, 0.5628, 0.5598],
        [0.5623, 0.5619, 0.5616, 0.5643],
        [0.5651, 0.5625, 0.5664, 0.5670],
        [0.5622, 0.5634, 0.5634, 0.5600]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:04,975:INFO::its now!!!!!!!!5
2023-12-01 16:51:05,124:INFO::its now!!!!!!!!0
2023-12-01 16:51:05,125:INFO::its now!!!!!!!!3
2023-12-01 16:51:05,171:INFO::its now!!!!!!!!5
2023-12-01 16:51:05,324:INFO::its now!!!!!!!!
2023-12-01 16:51:05,324:INFO::its now!!!!!!!! on 
2023-12-01 16:51:05,380:INFO::its now!!!!!!!!5
2023-12-01 16:51:05,560:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:05,562:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.2964 | Train_Classification_Loss 1.3277 | Dmon_Loss -0.0627 | Val_Loss 1.3333 | Search Time(s) 0.4059 | Infer Time(s) 0.1825 | Time(s) 0.5884 
2023-12-01 16:51:05,613:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 3;	10: 0;	11: 0;	12: 0;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 0;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 0;	36: 0;	37: 2;	38: 0;	39: 0;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 0;	26103: 1;	26104: 0;	26105: 1;	26106: 2;	26107: 2;	26108: 2;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 1;	26114: 1;	26115: 1;	26116: 2;	26117: 2;	26118: 1;	26119: 1;	26120: 2;	26121: 2;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 0;	
2023-12-01 16:51:05,615:INFO::Validation loss decreased (1.336944 --> 1.333293).  Saving model ...
2023-12-01 16:51:05,681:INFO::Epoch: 16
tensor([[0.5664, 0.5676, 0.5678, 0.5630],
        [0.5666, 0.5668, 0.5649, 0.5679],
        [0.5696, 0.5653, 0.5714, 0.5706],
        [0.5664, 0.5685, 0.5668, 0.5632]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:05,681:INFO::its now!!!!!!!!5
2023-12-01 16:51:05,817:INFO::its now!!!!!!!!0
2023-12-01 16:51:05,818:INFO::its now!!!!!!!!3
2023-12-01 16:51:05,864:INFO::its now!!!!!!!!5
2023-12-01 16:51:06,025:INFO::its now!!!!!!!!
2023-12-01 16:51:06,026:INFO::its now!!!!!!!! on 
2023-12-01 16:51:06,078:INFO::its now!!!!!!!!5
2023-12-01 16:51:06,246:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:06,248:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 1.2930 | Train_Classification_Loss 1.3243 | Dmon_Loss -0.0626 | Val_Loss 1.3303 | Search Time(s) 0.4438 | Infer Time(s) 0.1872 | Time(s) 0.6310 
2023-12-01 16:51:06,301:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 1;	4: 1;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 2;	32: 0;	33: 1;	34: 0;	35: 1;	36: 0;	37: 0;	38: 1;	39: 0;	40: 1;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 3;	26101: 0;	26102: 1;	26103: 0;	26104: 1;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 1;	26110: 0;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 2;	26117: 1;	26118: 2;	26119: 1;	26120: 2;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 0;	26127: 0;	
2023-12-01 16:51:06,302:INFO::Validation loss decreased (1.333293 --> 1.330292).  Saving model ...
2023-12-01 16:51:06,305:INFO::Epoch: 17
tensor([[0.5693, 0.5702, 0.5703, 0.5656],
        [0.5695, 0.5701, 0.5675, 0.5697],
        [0.5727, 0.5676, 0.5740, 0.5732],
        [0.5693, 0.5711, 0.5693, 0.5658]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:06,306:INFO::its now!!!!!!!!5
2023-12-01 16:51:06,435:INFO::its now!!!!!!!!0
2023-12-01 16:51:06,436:INFO::its now!!!!!!!!3
2023-12-01 16:51:06,480:INFO::its now!!!!!!!!5
2023-12-01 16:51:06,632:INFO::its now!!!!!!!!
2023-12-01 16:51:06,632:INFO::its now!!!!!!!! on 
2023-12-01 16:51:06,689:INFO::its now!!!!!!!!5
2023-12-01 16:51:06,838:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:06,839:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 1.2886 | Train_Classification_Loss 1.3199 | Dmon_Loss -0.0626 | Val_Loss 1.3266 | Search Time(s) 0.3830 | Infer Time(s) 0.1536 | Time(s) 0.5365 
2023-12-01 16:51:06,887:INFO::cluster info:
0: 2;	1: 1;	2: 0;	3: 1;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 1;	14: 2;	15: 0;	16: 0;	17: 0;	18: 2;	19: 2;	20: 0;	21: 0;	22: 1;	23: 0;	24: 0;	25: 0;	26: 2;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 1;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 0;	40: 1;	41: 0;	42: 1;	43: 0;	44
26098: 1;	26099: 0;	26100: 1;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 2;	26110: 1;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:06,888:INFO::Validation loss decreased (1.330292 --> 1.326633).  Saving model ...
2023-12-01 16:51:06,892:INFO::Epoch: 18
tensor([[0.5748, 0.5759, 0.5717, 0.5720],
        [0.5750, 0.5717, 0.5737, 0.5752],
        [0.5785, 0.5735, 0.5753, 0.5790],
        [0.5748, 0.5724, 0.5753, 0.5721]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:06,893:INFO::its now!!!!!!!!5
2023-12-01 16:51:07,029:INFO::its now!!!!!!!!0
2023-12-01 16:51:07,030:INFO::its now!!!!!!!!3
2023-12-01 16:51:07,078:INFO::its now!!!!!!!!5
2023-12-01 16:51:07,236:INFO::its now!!!!!!!!
2023-12-01 16:51:07,236:INFO::its now!!!!!!!! on 
2023-12-01 16:51:07,271:INFO::its now!!!!!!!!5
2023-12-01 16:51:07,447:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:07,449:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 1.2817 | Train_Classification_Loss 1.3130 | Dmon_Loss -0.0627 | Val_Loss 1.3191 | Search Time(s) 0.3753 | Infer Time(s) 0.1821 | Time(s) 0.5574 
2023-12-01 16:51:07,511:INFO::cluster info:
0: 0;	1: 1;	2: 1;	3: 1;	4: 0;	5: 1;	6: 0;	7: 0;	8: 2;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 1;	15: 0;	16: 0;	17: 1;	18: 2;	19: 1;	20: 1;	21: 1;	22: 2;	23: 2;	24: 0;	25: 0;	26: 1;	27: 0;	28: 1;	29: 1;	30: 1;	31: 2;	32: 0;	33: 0;	34: 1;	35: 1;	36: 0;	37: 1;	38: 1;	39: 0;	40: 1;	41: 1;	42: 1;	43: 0;	44
26098: 1;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 2;	26113: 1;	26114: 1;	26115: 2;	26116: 2;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 16:51:07,512:INFO::Validation loss decreased (1.326633 --> 1.319118).  Saving model ...
2023-12-01 16:51:07,514:INFO::Epoch: 19
tensor([[0.5807, 0.5789, 0.5764, 0.5789],
        [0.5809, 0.5764, 0.5806, 0.5781],
        [0.5848, 0.5800, 0.5799, 0.5820],
        [0.5807, 0.5769, 0.5783, 0.5791]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:07,515:INFO::its now!!!!!!!!5
2023-12-01 16:51:07,647:INFO::its now!!!!!!!!0
2023-12-01 16:51:07,648:INFO::its now!!!!!!!!3
2023-12-01 16:51:07,675:INFO::its now!!!!!!!!5
2023-12-01 16:51:07,824:INFO::its now!!!!!!!!
2023-12-01 16:51:07,824:INFO::its now!!!!!!!! on 
2023-12-01 16:51:07,866:INFO::its now!!!!!!!!5
2023-12-01 16:51:08,025:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:08,026:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 1.2779 | Train_Classification_Loss 1.3092 | Dmon_Loss -0.0628 | Val_Loss 1.3178 | Search Time(s) 0.3501 | Infer Time(s) 0.1636 | Time(s) 0.5136 
2023-12-01 16:51:08,064:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 0;	4: 0;	5: 1;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 2;	19: 0;	20: 0;	21: 0;	22: 0;	23: 0;	24: 0;	25: 0;	26: 2;	27: 0;	28: 0;	29: 0;	30: 0;	31: 1;	32: 0;	33: 0;	34: 0;	35: 1;	36: 0;	37: 2;	38: 0;	39: 0;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 1;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 1;	26121: 2;	26122: 1;	26123: 1;	26124: 1;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:08,065:INFO::Validation loss decreased (1.319118 --> 1.317829).  Saving model ...
2023-12-01 16:51:08,068:INFO::Epoch: 20
tensor([[0.5838, 0.5814, 0.5799, 0.5836],
        [0.5841, 0.5799, 0.5852, 0.5806],
        [0.5880, 0.5844, 0.5833, 0.5846],
        [0.5838, 0.5802, 0.5809, 0.5838]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:08,069:INFO::its now!!!!!!!!5
2023-12-01 16:51:08,199:INFO::its now!!!!!!!!0
2023-12-01 16:51:08,200:INFO::its now!!!!!!!!3
2023-12-01 16:51:08,232:INFO::its now!!!!!!!!5
2023-12-01 16:51:08,395:INFO::its now!!!!!!!!
2023-12-01 16:51:08,395:INFO::its now!!!!!!!! on 
2023-12-01 16:51:08,457:INFO::its now!!!!!!!!5
2023-12-01 16:51:08,589:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:08,591:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 1.2770 | Train_Classification_Loss 1.3084 | Dmon_Loss -0.0628 | Val_Loss 1.3142 | Search Time(s) 0.3891 | Infer Time(s) 0.1346 | Time(s) 0.5238 
2023-12-01 16:51:08,638:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 1;	4: 1;	5: 1;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 1;	26: 0;	27: 1;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 1;	39: 1;	40: 1;	41: 1;	42: 1;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 1;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:08,639:INFO::Validation loss decreased (1.317829 --> 1.314220).  Saving model ...
2023-12-01 16:51:08,641:INFO::Epoch: 21
tensor([[0.5855, 0.5884, 0.5876, 0.5917],
        [0.5908, 0.5874, 0.5876, 0.5878],
        [0.5897, 0.5922, 0.5908, 0.5916],
        [0.5904, 0.5876, 0.5882, 0.5862]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:08,641:INFO::its now!!!!!!!!5
2023-12-01 16:51:08,790:INFO::its now!!!!!!!!0
2023-12-01 16:51:08,790:INFO::its now!!!!!!!!3
2023-12-01 16:51:08,840:INFO::its now!!!!!!!!5
2023-12-01 16:51:09,004:INFO::its now!!!!!!!!
2023-12-01 16:51:09,004:INFO::its now!!!!!!!! on 
2023-12-01 16:51:09,043:INFO::its now!!!!!!!!5
2023-12-01 16:51:09,192:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:09,194:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 1.2720 | Train_Classification_Loss 1.3034 | Dmon_Loss -0.0629 | Val_Loss 1.3133 | Search Time(s) 0.3999 | Infer Time(s) 0.1531 | Time(s) 0.5531 
2023-12-01 16:51:09,243:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 2;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 2;	32: 0;	33: 1;	34: 1;	35: 1;	36: 0;	37: 0;	38: 0;	39: 0;	40: 1;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:51:09,244:INFO::Validation loss decreased (1.314220 --> 1.313316).  Saving model ...
2023-12-01 16:51:09,246:INFO::Epoch: 22
tensor([[0.5902, 0.5956, 0.5954, 0.5959],
        [0.5943, 0.5951, 0.5934, 0.5953],
        [0.5948, 0.5962, 0.5985, 0.5989],
        [0.5938, 0.5952, 0.5957, 0.5920]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:09,247:INFO::its now!!!!!!!!5
2023-12-01 16:51:09,396:INFO::its now!!!!!!!!0
2023-12-01 16:51:09,396:INFO::its now!!!!!!!!3
2023-12-01 16:51:09,423:INFO::its now!!!!!!!!5
2023-12-01 16:51:09,571:INFO::its now!!!!!!!!
2023-12-01 16:51:09,572:INFO::its now!!!!!!!! on 
2023-12-01 16:51:09,625:INFO::its now!!!!!!!!5
2023-12-01 16:51:09,788:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:09,790:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 1.2686 | Train_Classification_Loss 1.3000 | Dmon_Loss -0.0628 | Val_Loss 1.3053 | Search Time(s) 0.3626 | Infer Time(s) 0.1815 | Time(s) 0.5441 
2023-12-01 16:51:09,833:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 0;	4: 1;	5: 0;	6: 1;	7: 0;	8: 0;	9: 2;	10: 0;	11: 0;	12: 2;	13: 2;	14: 0;	15: 1;	16: 1;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 0;	34: 1;	35: 1;	36: 1;	37: 0;	38: 0;	39: 0;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 1;	26102: 0;	26103: 2;	26104: 0;	26105: 1;	26106: 1;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 1;	26114: 1;	26115: 2;	26116: 2;	26117: 2;	26118: 1;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 1;	26125: 1;	26126: 0;	26127: 0;	
2023-12-01 16:51:09,834:INFO::Validation loss decreased (1.313316 --> 1.305320).  Saving model ...
2023-12-01 16:51:09,837:INFO::Epoch: 23
tensor([[0.5973, 0.6038, 0.6040, 0.5980],
        [0.6006, 0.6036, 0.6016, 0.5992],
        [0.6022, 0.6031, 0.6070, 0.6027],
        [0.6001, 0.6036, 0.5995, 0.6002]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:09,838:INFO::its now!!!!!!!!5
2023-12-01 16:51:09,979:INFO::its now!!!!!!!!0
2023-12-01 16:51:09,979:INFO::its now!!!!!!!!3
2023-12-01 16:51:10,024:INFO::its now!!!!!!!!5
2023-12-01 16:51:10,190:INFO::its now!!!!!!!!
2023-12-01 16:51:10,190:INFO::its now!!!!!!!! on 
2023-12-01 16:51:10,243:INFO::its now!!!!!!!!5
2023-12-01 16:51:10,419:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:10,421:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 1.2638 | Train_Classification_Loss 1.2952 | Dmon_Loss -0.0628 | Val_Loss 1.3024 | Search Time(s) 0.3877 | Infer Time(s) 0.1970 | Time(s) 0.5847 
2023-12-01 16:51:10,461:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 2;	4: 0;	5: 1;	6: 2;	7: 0;	8: 0;	9: 1;	10: 1;	11: 0;	12: 0;	13: 0;	14: 2;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 2;	26: 0;	27: 1;	28: 0;	29: 2;	30: 0;	31: 0;	32: 2;	33: 0;	34: 1;	35: 1;	36: 0;	37: 0;	38: 1;	39: 1;	40: 1;	41: 1;	42: 2;	43: 2;	44
26098: 0;	26099: 1;	26100: 1;	26101: 0;	26102: 1;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 1;	26108: 1;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:10,462:INFO::Validation loss decreased (1.305320 --> 1.302397).  Saving model ...
2023-12-01 16:51:10,464:INFO::Epoch: 24
tensor([[0.6029, 0.6100, 0.6085, 0.6015],
        [0.6057, 0.6079, 0.6079, 0.6033],
        [0.6080, 0.6086, 0.6113, 0.6067],
        [0.6051, 0.6078, 0.6037, 0.6067]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:10,465:INFO::its now!!!!!!!!5
2023-12-01 16:51:10,599:INFO::its now!!!!!!!!0
2023-12-01 16:51:10,600:INFO::its now!!!!!!!!3
2023-12-01 16:51:10,645:INFO::its now!!!!!!!!5
2023-12-01 16:51:10,797:INFO::its now!!!!!!!!
2023-12-01 16:51:10,797:INFO::its now!!!!!!!! on 
2023-12-01 16:51:10,856:INFO::its now!!!!!!!!5
2023-12-01 16:51:11,057:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:11,058:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 1.2551 | Train_Classification_Loss 1.2865 | Dmon_Loss -0.0627 | Val_Loss 1.2970 | Search Time(s) 0.3910 | Infer Time(s) 0.2035 | Time(s) 0.5944 
2023-12-01 16:51:11,122:INFO::cluster info:
0: 2;	1: 0;	2: 2;	3: 0;	4: 2;	5: 2;	6: 2;	7: 1;	8: 0;	9: 1;	10: 0;	11: 0;	12: 0;	13: 1;	14: 2;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 2;	21: 1;	22: 0;	23: 2;	24: 0;	25: 0;	26: 1;	27: 3;	28: 2;	29: 2;	30: 2;	31: 0;	32: 1;	33: 1;	34: 0;	35: 0;	36: 1;	37: 0;	38: 2;	39: 2;	40: 1;	41: 2;	42: 2;	43: 1;	44
26098: 0;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 1;	26108: 1;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 1;	26114: 1;	26115: 1;	26116: 2;	26117: 2;	26118: 1;	26119: 2;	26120: 2;	26121: 2;	26122: 1;	26123: 1;	26124: 1;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:51:11,123:INFO::Validation loss decreased (1.302397 --> 1.296981).  Saving model ...
2023-12-01 16:51:11,126:INFO::Epoch: 25
tensor([[0.6086, 0.6131, 0.6137, 0.6066],
        [0.6110, 0.6129, 0.6113, 0.6085],
        [0.6138, 0.6144, 0.6136, 0.6118],
        [0.6104, 0.6100, 0.6088, 0.6131]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:11,127:INFO::its now!!!!!!!!5
2023-12-01 16:51:11,271:INFO::its now!!!!!!!!0
2023-12-01 16:51:11,272:INFO::its now!!!!!!!!3
2023-12-01 16:51:11,319:INFO::its now!!!!!!!!5
2023-12-01 16:51:11,483:INFO::its now!!!!!!!!
2023-12-01 16:51:11,484:INFO::its now!!!!!!!! on 
2023-12-01 16:51:11,538:INFO::its now!!!!!!!!5
2023-12-01 16:51:11,683:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:11,684:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 1.2538 | Train_Classification_Loss 1.2854 | Dmon_Loss -0.0631 | Val_Loss 1.2953 | Search Time(s) 0.4105 | Infer Time(s) 0.1486 | Time(s) 0.5591 
2023-12-01 16:51:11,745:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 1;	4: 0;	5: 1;	6: 2;	7: 0;	8: 1;	9: 0;	10: 2;	11: 0;	12: 2;	13: 2;	14: 2;	15: 0;	16: 1;	17: 1;	18: 2;	19: 2;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 1;	26: 0;	27: 0;	28: 1;	29: 2;	30: 0;	31: 2;	32: 1;	33: 0;	34: 1;	35: 1;	36: 1;	37: 0;	38: 0;	39: 0;	40: 1;	41: 1;	42: 2;	43: 0;	44
26098: 1;	26099: 0;	26100: 0;	26101: 0;	26102: 1;	26103: 1;	26104: 1;	26105: 2;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 1;	26114: 2;	26115: 1;	26116: 2;	26117: 2;	26118: 1;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:11,746:INFO::Validation loss decreased (1.296981 --> 1.295313).  Saving model ...
2023-12-01 16:51:11,749:INFO::Epoch: 26
tensor([[0.6133, 0.6166, 0.6165, 0.6113],
        [0.6154, 0.6155, 0.6151, 0.6132],
        [0.6187, 0.6173, 0.6166, 0.6164],
        [0.6148, 0.6131, 0.6135, 0.6163]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:11,750:INFO::its now!!!!!!!!5
2023-12-01 16:51:11,904:INFO::its now!!!!!!!!0
2023-12-01 16:51:11,904:INFO::its now!!!!!!!!3
2023-12-01 16:51:11,951:INFO::its now!!!!!!!!5
2023-12-01 16:51:12,085:INFO::its now!!!!!!!!
2023-12-01 16:51:12,085:INFO::its now!!!!!!!! on 
2023-12-01 16:51:12,124:INFO::its now!!!!!!!!5
2023-12-01 16:51:12,289:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:12,290:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 1.2390 | Train_Classification_Loss 1.2706 | Dmon_Loss -0.0632 | Val_Loss 1.2824 | Search Time(s) 0.3755 | Infer Time(s) 0.1671 | Time(s) 0.5427 
2023-12-01 16:51:12,325:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 1;	4: 0;	5: 2;	6: 2;	7: 2;	8: 0;	9: 2;	10: 1;	11: 0;	12: 1;	13: 2;	14: 1;	15: 0;	16: 0;	17: 2;	18: 1;	19: 2;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 2;	27: 0;	28: 0;	29: 2;	30: 1;	31: 0;	32: 0;	33: 0;	34: 1;	35: 0;	36: 2;	37: 2;	38: 1;	39: 0;	40: 1;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 1;	26103: 1;	26104: 0;	26105: 0;	26106: 1;	26107: 0;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 16:51:12,326:INFO::Validation loss decreased (1.295313 --> 1.282422).  Saving model ...
2023-12-01 16:51:12,329:INFO::Epoch: 27
tensor([[0.6163, 0.6184, 0.6185, 0.6144],
        [0.6183, 0.6167, 0.6177, 0.6162],
        [0.6214, 0.6194, 0.6188, 0.6193],
        [0.6177, 0.6152, 0.6165, 0.6180]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:12,330:INFO::its now!!!!!!!!5
2023-12-01 16:51:12,519:INFO::its now!!!!!!!!0
2023-12-01 16:51:12,520:INFO::its now!!!!!!!!3
2023-12-01 16:51:12,550:INFO::its now!!!!!!!!5
2023-12-01 16:51:12,722:INFO::its now!!!!!!!!
2023-12-01 16:51:12,722:INFO::its now!!!!!!!! on 
2023-12-01 16:51:12,780:INFO::its now!!!!!!!!5
2023-12-01 16:51:12,916:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 1.2418 | Train_Classification_Loss 1.2733 | Dmon_Loss -0.0630 | Val_Loss 1.2835 | Search Time(s) 0.4518 | Infer Time(s) 0.1376 | Time(s) 0.5894 
2023-12-01 16:51:12,960:INFO::cluster info:
0: 0;	1: 2;	2: 0;	3: 2;	4: 0;	5: 2;	6: 0;	7: 0;	8: 2;	9: 1;	10: 0;	11: 0;	12: 0;	13: 2;	14: 2;	15: 2;	16: 1;	17: 0;	18: 0;	19: 2;	20: 0;	21: 0;	22: 2;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 0;	29: 0;	30: 2;	31: 0;	32: 0;	33: 0;	34: 1;	35: 0;	36: 0;	37: 1;	38: 1;	39: 0;	40: 0;	41: 0;	42: 0;	43: 0;	44
26098: 1;	26099: 2;	26100: 1;	26101: 0;	26102: 0;	26103: 1;	26104: 0;	26105: 1;	26106: 0;	26107: 0;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:12,961:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:12,966:INFO::Epoch: 28
tensor([[0.6221, 0.6238, 0.6196, 0.6209],
        [0.6199, 0.6219, 0.6240, 0.6224],
        [0.6229, 0.6250, 0.6245, 0.6254],
        [0.6232, 0.6208, 0.6227, 0.6188]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:12,967:INFO::its now!!!!!!!!5
2023-12-01 16:51:13,123:INFO::its now!!!!!!!!0
2023-12-01 16:51:13,124:INFO::its now!!!!!!!!3
2023-12-01 16:51:13,172:INFO::its now!!!!!!!!5
2023-12-01 16:51:13,315:INFO::its now!!!!!!!!
2023-12-01 16:51:13,315:INFO::its now!!!!!!!! on 
2023-12-01 16:51:13,373:INFO::its now!!!!!!!!5
2023-12-01 16:51:13,536:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:13,538:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 1.2406 | Train_Classification_Loss 1.2721 | Dmon_Loss -0.0631 | Val_Loss 1.2793 | Search Time(s) 0.4090 | Infer Time(s) 0.1666 | Time(s) 0.5756 
2023-12-01 16:51:13,581:INFO::cluster info:
0: 1;	1: 2;	2: 0;	3: 2;	4: 0;	5: 1;	6: 2;	7: 0;	8: 0;	9: 1;	10: 0;	11: 1;	12: 0;	13: 2;	14: 0;	15: 0;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 2;	24: 2;	25: 0;	26: 0;	27: 2;	28: 1;	29: 0;	30: 1;	31: 0;	32: 0;	33: 0;	34: 1;	35: 0;	36: 2;	37: 0;	38: 2;	39: 0;	40: 1;	41: 1;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 1;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 1;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 1;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:51:13,582:INFO::Validation loss decreased (1.282422 --> 1.279262).  Saving model ...
2023-12-01 16:51:13,585:INFO::Epoch: 29
tensor([[0.6278, 0.6264, 0.6234, 0.6273],
        [0.6236, 0.6273, 0.6272, 0.6286],
        [0.6267, 0.6307, 0.6302, 0.6285],
        [0.6261, 0.6265, 0.6289, 0.6227]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:13,585:INFO::its now!!!!!!!!5
2023-12-01 16:51:13,751:INFO::its now!!!!!!!!0
2023-12-01 16:51:13,768:INFO::its now!!!!!!!!3
2023-12-01 16:51:13,818:INFO::its now!!!!!!!!5
2023-12-01 16:51:13,972:INFO::its now!!!!!!!!
2023-12-01 16:51:13,972:INFO::its now!!!!!!!! on 
2023-12-01 16:51:14,027:INFO::its now!!!!!!!!5
2023-12-01 16:51:14,167:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:14,168:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 1.2374 | Train_Classification_Loss 1.2689 | Dmon_Loss -0.0630 | Val_Loss 1.2790 | Search Time(s) 0.4408 | Infer Time(s) 0.1432 | Time(s) 0.5840 
2023-12-01 16:51:14,211:INFO::cluster info:
0: 0;	1: 1;	2: 2;	3: 2;	4: 1;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 2;	15: 0;	16: 0;	17: 0;	18: 0;	19: 2;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 0;	29: 2;	30: 0;	31: 0;	32: 0;	33: 0;	34: 0;	35: 1;	36: 0;	37: 0;	38: 0;	39: 0;	40: 0;	41: 1;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 2;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:51:14,213:INFO::Validation loss decreased (1.279262 --> 1.278967).  Saving model ...
2023-12-01 16:51:14,215:INFO::Epoch: 30
tensor([[0.6308, 0.6327, 0.6303, 0.6357],
        [0.6302, 0.6349, 0.6342, 0.6317],
        [0.6337, 0.6336, 0.6380, 0.6351],
        [0.6322, 0.6341, 0.6320, 0.6301]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:14,216:INFO::its now!!!!!!!!5
2023-12-01 16:51:14,380:INFO::its now!!!!!!!!0
2023-12-01 16:51:14,381:INFO::its now!!!!!!!!3
2023-12-01 16:51:14,430:INFO::its now!!!!!!!!5
2023-12-01 16:51:14,601:INFO::its now!!!!!!!!
2023-12-01 16:51:14,601:INFO::its now!!!!!!!! on 
2023-12-01 16:51:14,641:INFO::its now!!!!!!!!5
2023-12-01 16:51:14,779:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:14,781:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 1.2210 | Train_Classification_Loss 1.2525 | Dmon_Loss -0.0631 | Val_Loss 1.2705 | Search Time(s) 0.4264 | Infer Time(s) 0.1396 | Time(s) 0.5660 
2023-12-01 16:51:14,825:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 0;	5: 1;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 0;	13: 0;	14: 2;	15: 1;	16: 0;	17: 0;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 2;	24: 0;	25: 0;	26: 2;	27: 1;	28: 2;	29: 2;	30: 0;	31: 0;	32: 0;	33: 0;	34: 1;	35: 2;	36: 0;	37: 0;	38: 1;	39: 0;	40: 0;	41: 1;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 1;	26104: 0;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:14,826:INFO::Validation loss decreased (1.278967 --> 1.270549).  Saving model ...
2023-12-01 16:51:14,829:INFO::Epoch: 31
tensor([[0.6363, 0.6396, 0.6378, 0.6400],
        [0.6373, 0.6387, 0.6418, 0.6375],
        [0.6412, 0.6392, 0.6419, 0.6424],
        [0.6389, 0.6380, 0.6378, 0.6380]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:14,830:INFO::its now!!!!!!!!5
2023-12-01 16:51:14,992:INFO::its now!!!!!!!!0
2023-12-01 16:51:14,993:INFO::its now!!!!!!!!3
2023-12-01 16:51:15,025:INFO::its now!!!!!!!!5
2023-12-01 16:51:15,203:INFO::its now!!!!!!!!
2023-12-01 16:51:15,204:INFO::its now!!!!!!!! on 
2023-12-01 16:51:15,261:INFO::its now!!!!!!!!5
2023-12-01 16:51:15,422:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:15,423:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 1.2157 | Train_Classification_Loss 1.2474 | Dmon_Loss -0.0635 | Val_Loss 1.2599 | Search Time(s) 0.4304 | Infer Time(s) 0.1641 | Time(s) 0.5945 
2023-12-01 16:51:15,459:INFO::cluster info:
0: 1;	1: 2;	2: 1;	3: 2;	4: 0;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 2;	13: 2;	14: 1;	15: 2;	16: 0;	17: 1;	18: 2;	19: 0;	20: 1;	21: 1;	22: 0;	23: 2;	24: 1;	25: 2;	26: 0;	27: 0;	28: 2;	29: 0;	30: 0;	31: 2;	32: 2;	33: 2;	34: 1;	35: 1;	36: 2;	37: 0;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 1;	26099: 0;	26100: 1;	26101: 1;	26102: 1;	26103: 0;	26104: 2;	26105: 2;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:51:15,460:INFO::Validation loss decreased (1.270549 --> 1.259886).  Saving model ...
2023-12-01 16:51:15,463:INFO::Epoch: 32
tensor([[0.6410, 0.6450, 0.6436, 0.6422],
        [0.6427, 0.6425, 0.6457, 0.6426],
        [0.6469, 0.6440, 0.6459, 0.6461],
        [0.6423, 0.6420, 0.6428, 0.6441]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:15,463:INFO::its now!!!!!!!!5
2023-12-01 16:51:15,617:INFO::its now!!!!!!!!0
2023-12-01 16:51:15,618:INFO::its now!!!!!!!!3
2023-12-01 16:51:15,668:INFO::its now!!!!!!!!5
2023-12-01 16:51:15,822:INFO::its now!!!!!!!!
2023-12-01 16:51:15,822:INFO::its now!!!!!!!! on 
2023-12-01 16:51:15,859:INFO::its now!!!!!!!!5
2023-12-01 16:51:15,997:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:15,998:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 1.2126 | Train_Classification_Loss 1.2442 | Dmon_Loss -0.0632 | Val_Loss 1.2592 | Search Time(s) 0.3959 | Infer Time(s) 0.1396 | Time(s) 0.5356 
2023-12-01 16:51:16,034:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 0;	13: 2;	14: 2;	15: 1;	16: 0;	17: 0;	18: 2;	19: 0;	20: 2;	21: 1;	22: 2;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 0;	29: 0;	30: 0;	31: 0;	32: 0;	33: 1;	34: 1;	35: 1;	36: 2;	37: 0;	38: 0;	39: 1;	40: 1;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:51:16,035:INFO::Validation loss decreased (1.259886 --> 1.259206).  Saving model ...
2023-12-01 16:51:16,038:INFO::Epoch: 33
tensor([[0.6491, 0.6477, 0.6522, 0.6495],
        [0.6508, 0.6502, 0.6478, 0.6510],
        [0.6501, 0.6523, 0.6537, 0.6537],
        [0.6494, 0.6496, 0.6513, 0.6472]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:16,039:INFO::its now!!!!!!!!5
2023-12-01 16:51:16,179:INFO::its now!!!!!!!!0
2023-12-01 16:51:16,180:INFO::its now!!!!!!!!3
2023-12-01 16:51:16,211:INFO::its now!!!!!!!!5
2023-12-01 16:51:16,384:INFO::its now!!!!!!!!
2023-12-01 16:51:16,384:INFO::its now!!!!!!!! on 
2023-12-01 16:51:16,446:INFO::its now!!!!!!!!5
2023-12-01 16:51:16,609:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:16,611:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 1.1971 | Train_Classification_Loss 1.2287 | Dmon_Loss -0.0633 | Val_Loss 1.2447 | Search Time(s) 0.3952 | Infer Time(s) 0.1775 | Time(s) 0.5727 
2023-12-01 16:51:16,656:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 2;	9: 0;	10: 0;	11: 0;	12: 0;	13: 2;	14: 0;	15: 0;	16: 0;	17: 0;	18: 2;	19: 0;	20: 0;	21: 1;	22: 2;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 0;	29: 2;	30: 2;	31: 0;	32: 0;	33: 0;	34: 1;	35: 0;	36: 2;	37: 0;	38: 0;	39: 0;	40: 1;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 1;	26101: 2;	26102: 2;	26103: 1;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 1;	26110: 0;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:16,657:INFO::Validation loss decreased (1.259206 --> 1.244670).  Saving model ...
2023-12-01 16:51:16,660:INFO::Epoch: 34
tensor([[0.6557, 0.6519, 0.6568, 0.6560],
        [0.6574, 0.6567, 0.6519, 0.6554],
        [0.6546, 0.6591, 0.6603, 0.6576],
        [0.6554, 0.6561, 0.6556, 0.6518]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:16,661:INFO::its now!!!!!!!!5
2023-12-01 16:51:16,818:INFO::its now!!!!!!!!0
2023-12-01 16:51:16,818:INFO::its now!!!!!!!!3
2023-12-01 16:51:16,864:INFO::its now!!!!!!!!5
2023-12-01 16:51:17,015:INFO::its now!!!!!!!!
2023-12-01 16:51:17,015:INFO::its now!!!!!!!! on 
2023-12-01 16:51:17,069:INFO::its now!!!!!!!!5
2023-12-01 16:51:17,238:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 1.2046 | Train_Classification_Loss 1.2362 | Dmon_Loss -0.0632 | Val_Loss 1.2544 | Search Time(s) 0.4089 | Infer Time(s) 0.1711 | Time(s) 0.5800 
2023-12-01 16:51:17,284:INFO::cluster info:
0: 1;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 0;	7: 0;	8: 1;	9: 0;	10: 1;	11: 2;	12: 0;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 0;	19: 2;	20: 1;	21: 0;	22: 2;	23: 0;	24: 0;	25: 0;	26: 2;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 2;	33: 0;	34: 2;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 1;	26100: 2;	26101: 0;	26102: 2;	26103: 0;	26104: 0;	26105: 0;	26106: 1;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:17,285:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:17,290:INFO::Epoch: 35
tensor([[0.6641, 0.6594, 0.6594, 0.6646],
        [0.6609, 0.6649, 0.6598, 0.6629],
        [0.6625, 0.6676, 0.6637, 0.6648],
        [0.6633, 0.6594, 0.6632, 0.6600]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:17,290:INFO::its now!!!!!!!!5
2023-12-01 16:51:17,446:INFO::its now!!!!!!!!0
2023-12-01 16:51:17,446:INFO::its now!!!!!!!!3
2023-12-01 16:51:17,497:INFO::its now!!!!!!!!5
2023-12-01 16:51:17,651:INFO::its now!!!!!!!!
2023-12-01 16:51:17,651:INFO::its now!!!!!!!! on 
2023-12-01 16:51:17,708:INFO::its now!!!!!!!!5
2023-12-01 16:51:17,850:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 1.1981 | Train_Classification_Loss 1.2297 | Dmon_Loss -0.0633 | Val_Loss 1.2473 | Search Time(s) 0.4184 | Infer Time(s) 0.1466 | Time(s) 0.5650 
2023-12-01 16:51:17,899:INFO::cluster info:
0: 2;	1: 2;	2: 2;	3: 2;	4: 0;	5: 1;	6: 0;	7: 0;	8: 2;	9: 1;	10: 1;	11: 1;	12: 1;	13: 2;	14: 2;	15: 0;	16: 0;	17: 2;	18: 1;	19: 2;	20: 2;	21: 0;	22: 2;	23: 0;	24: 0;	25: 0;	26: 1;	27: 2;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 0;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 0;	41: 2;	42: 2;	43: 2;	44
26098: 1;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 1;	26104: 0;	26105: 2;	26106: 1;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:51:17,900:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:17,903:INFO::Epoch: 36
tensor([[0.6681, 0.6629, 0.6604, 0.6690],
        [0.6625, 0.6691, 0.6635, 0.6665],
        [0.6661, 0.6720, 0.6652, 0.6682],
        [0.6673, 0.6608, 0.6668, 0.6639]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:17,904:INFO::its now!!!!!!!!5
2023-12-01 16:51:18,061:INFO::its now!!!!!!!!0
2023-12-01 16:51:18,062:INFO::its now!!!!!!!!3
2023-12-01 16:51:18,113:INFO::its now!!!!!!!!5
2023-12-01 16:51:18,267:INFO::its now!!!!!!!!
2023-12-01 16:51:18,268:INFO::its now!!!!!!!! on 
2023-12-01 16:51:18,328:INFO::its now!!!!!!!!5
2023-12-01 16:51:18,486:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:18,488:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 1.1862 | Train_Classification_Loss 1.2178 | Dmon_Loss -0.0633 | Val_Loss 1.2362 | Search Time(s) 0.4240 | Infer Time(s) 0.1616 | Time(s) 0.5856 
2023-12-01 16:51:18,535:INFO::cluster info:
0: 1;	1: 0;	2: 2;	3: 2;	4: 1;	5: 0;	6: 1;	7: 1;	8: 2;	9: 0;	10: 2;	11: 0;	12: 0;	13: 2;	14: 0;	15: 2;	16: 2;	17: 2;	18: 2;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 1;	34: 2;	35: 0;	36: 1;	37: 0;	38: 1;	39: 2;	40: 1;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 1;	26101: 2;	26102: 2;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 1;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:18,536:INFO::Validation loss decreased (1.244670 --> 1.236216).  Saving model ...
2023-12-01 16:51:18,538:INFO::Epoch: 37
tensor([[0.6733, 0.6680, 0.6645, 0.6713],
        [0.6666, 0.6712, 0.6689, 0.6717],
        [0.6715, 0.6743, 0.6694, 0.6732],
        [0.6693, 0.6650, 0.6720, 0.6695]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:18,539:INFO::its now!!!!!!!!5
2023-12-01 16:51:18,692:INFO::its now!!!!!!!!0
2023-12-01 16:51:18,693:INFO::its now!!!!!!!!3
2023-12-01 16:51:18,742:INFO::its now!!!!!!!!5
2023-12-01 16:51:18,900:INFO::its now!!!!!!!!
2023-12-01 16:51:18,900:INFO::its now!!!!!!!! on 
2023-12-01 16:51:18,953:INFO::its now!!!!!!!!5
2023-12-01 16:51:19,120:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 1.1863 | Train_Classification_Loss 1.2180 | Dmon_Loss -0.0635 | Val_Loss 1.2371 | Search Time(s) 0.4139 | Infer Time(s) 0.1691 | Time(s) 0.5830 
2023-12-01 16:51:19,162:INFO::cluster info:
0: 1;	1: 2;	2: 0;	3: 2;	4: 1;	5: 2;	6: 2;	7: 0;	8: 0;	9: 1;	10: 0;	11: 0;	12: 0;	13: 2;	14: 2;	15: 0;	16: 0;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 0;	29: 0;	30: 2;	31: 0;	32: 0;	33: 0;	34: 0;	35: 1;	36: 2;	37: 2;	38: 0;	39: 0;	40: 0;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 2;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:19,163:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:19,165:INFO::Epoch: 38
tensor([[0.6761, 0.6757, 0.6719, 0.6777],
        [0.6736, 0.6773, 0.6771, 0.6744],
        [0.6794, 0.6755, 0.6767, 0.6807],
        [0.6752, 0.6723, 0.6746, 0.6777]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:19,257:INFO::its now!!!!!!!!5
2023-12-01 16:51:19,493:INFO::its now!!!!!!!!0
2023-12-01 16:51:19,494:INFO::its now!!!!!!!!3
2023-12-01 16:51:19,524:INFO::its now!!!!!!!!5
2023-12-01 16:51:19,690:INFO::its now!!!!!!!!
2023-12-01 16:51:19,690:INFO::its now!!!!!!!! on 
2023-12-01 16:51:19,730:INFO::its now!!!!!!!!5
2023-12-01 16:51:19,868:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:19,870:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 1.1665 | Train_Classification_Loss 1.1982 | Dmon_Loss -0.0635 | Val_Loss 1.2241 | Search Time(s) 0.5631 | Infer Time(s) 0.1426 | Time(s) 0.7057 
2023-12-01 16:51:19,914:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 1;	10: 2;	11: 0;	12: 0;	13: 2;	14: 0;	15: 2;	16: 0;	17: 1;	18: 2;	19: 0;	20: 2;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 0;	34: 1;	35: 1;	36: 0;	37: 2;	38: 2;	39: 2;	40: 0;	41: 1;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:19,914:INFO::Validation loss decreased (1.236216 --> 1.224136).  Saving model ...
2023-12-01 16:51:19,916:INFO::Epoch: 39
tensor([[0.6822, 0.6840, 0.6758, 0.6857],
        [0.6773, 0.6848, 0.6859, 0.6807],
        [0.6880, 0.6811, 0.6805, 0.6889],
        [0.6824, 0.6805, 0.6809, 0.6819]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:19,917:INFO::its now!!!!!!!!5
2023-12-01 16:51:20,067:INFO::its now!!!!!!!!0
2023-12-01 16:51:20,068:INFO::its now!!!!!!!!3
2023-12-01 16:51:20,103:INFO::its now!!!!!!!!5
2023-12-01 16:51:20,258:INFO::its now!!!!!!!!
2023-12-01 16:51:20,258:INFO::its now!!!!!!!! on 
2023-12-01 16:51:20,316:INFO::its now!!!!!!!!5
2023-12-01 16:51:20,478:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:20,479:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 1.1630 | Train_Classification_Loss 1.1951 | Dmon_Loss -0.0642 | Val_Loss 1.2122 | Search Time(s) 0.3842 | Infer Time(s) 0.1785 | Time(s) 0.5627 
2023-12-01 16:51:20,537:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 0;	8: 2;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 2;	15: 0;	16: 0;	17: 2;	18: 0;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 0;	25: 0;	26: 2;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 1;	33: 2;	34: 0;	35: 0;	36: 2;	37: 0;	38: 2;	39: 0;	40: 1;	41: 2;	42: 2;	43: 0;	44
26098: 1;	26099: 2;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:51:20,538:INFO::Validation loss decreased (1.224136 --> 1.212233).  Saving model ...
2023-12-01 16:51:20,541:INFO::Epoch: 40
tensor([[0.6890, 0.6919, 0.6819, 0.6898],
        [0.6830, 0.6923, 0.6906, 0.6878],
        [0.6961, 0.6878, 0.6865, 0.6931],
        [0.6861, 0.6884, 0.6880, 0.6882]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:20,542:INFO::its now!!!!!!!!5
2023-12-01 16:51:20,713:INFO::its now!!!!!!!!0
2023-12-01 16:51:20,713:INFO::its now!!!!!!!!3
2023-12-01 16:51:20,756:INFO::its now!!!!!!!!5
2023-12-01 16:51:20,908:INFO::its now!!!!!!!!
2023-12-01 16:51:20,908:INFO::its now!!!!!!!! on 
2023-12-01 16:51:20,944:INFO::its now!!!!!!!!5
2023-12-01 16:51:21,114:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:21,115:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 1.1362 | Train_Classification_Loss 1.1685 | Dmon_Loss -0.0646 | Val_Loss 1.1901 | Search Time(s) 0.3979 | Infer Time(s) 0.1771 | Time(s) 0.5751 
2023-12-01 16:51:21,160:INFO::cluster info:
0: 0;	1: 2;	2: 0;	3: 2;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 1;	11: 2;	12: 0;	13: 0;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 2;	23: 2;	24: 2;	25: 0;	26: 2;	27: 1;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 0;	34: 1;	35: 2;	36: 2;	37: 0;	38: 2;	39: 0;	40: 1;	41: 2;	42: 2;	43: 0;	44
26098: 2;	26099: 2;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:21,161:INFO::Validation loss decreased (1.212233 --> 1.190079).  Saving model ...
2023-12-01 16:51:21,163:INFO::Epoch: 41
tensor([[0.6963, 0.6960, 0.6890, 0.6958],
        [0.6897, 0.6961, 0.6971, 0.6954],
        [0.7007, 0.6951, 0.6935, 0.6990],
        [0.6917, 0.6925, 0.6956, 0.6956]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:21,164:INFO::its now!!!!!!!!5
2023-12-01 16:51:21,315:INFO::its now!!!!!!!!0
2023-12-01 16:51:21,316:INFO::its now!!!!!!!!3
2023-12-01 16:51:21,366:INFO::its now!!!!!!!!5
2023-12-01 16:51:21,537:INFO::its now!!!!!!!!
2023-12-01 16:51:21,537:INFO::its now!!!!!!!! on 
2023-12-01 16:51:21,576:INFO::its now!!!!!!!!5
2023-12-01 16:51:21,756:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:21,758:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 1.1335 | Train_Classification_Loss 1.1658 | Dmon_Loss -0.0646 | Val_Loss 1.1871 | Search Time(s) 0.4115 | Infer Time(s) 0.1835 | Time(s) 0.5950 
2023-12-01 16:51:21,807:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 0;	13: 0;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 2;	20: 0;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 2;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 1;	34: 2;	35: 0;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 0;	26103: 1;	26104: 2;	26105: 0;	26106: 0;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:21,809:INFO::Validation loss decreased (1.190079 --> 1.187120).  Saving model ...
2023-12-01 16:51:21,811:INFO::Epoch: 42
tensor([[0.7001, 0.7012, 0.6960, 0.7022],
        [0.6964, 0.6980, 0.7038, 0.7025],
        [0.7063, 0.7021, 0.6973, 0.7052],
        [0.6976, 0.6978, 0.7027, 0.6993]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:21,812:INFO::its now!!!!!!!!5
2023-12-01 16:51:21,994:INFO::its now!!!!!!!!0
2023-12-01 16:51:21,995:INFO::its now!!!!!!!!3
2023-12-01 16:51:22,023:INFO::its now!!!!!!!!5
2023-12-01 16:51:22,183:INFO::its now!!!!!!!!
2023-12-01 16:51:22,183:INFO::its now!!!!!!!! on 
2023-12-01 16:51:22,236:INFO::its now!!!!!!!!5
2023-12-01 16:51:22,380:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 1.1458 | Train_Classification_Loss 1.1777 | Dmon_Loss -0.0637 | Val_Loss 1.2032 | Search Time(s) 0.4234 | Infer Time(s) 0.1466 | Time(s) 0.5700 
2023-12-01 16:51:22,422:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 0;	13: 2;	14: 2;	15: 0;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 2;	23: 2;	24: 0;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 0;	34: 2;	35: 1;	36: 2;	37: 3;	38: 2;	39: 0;	40: 1;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 1;	26101: 1;	26102: 1;	26103: 2;	26104: 0;	26105: 0;	26106: 0;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:22,423:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:22,427:INFO::Epoch: 43
tensor([[0.7059, 0.7077, 0.7035, 0.7055],
        [0.7035, 0.7028, 0.7075, 0.7100],
        [0.7095, 0.7094, 0.7032, 0.7121],
        [0.7042, 0.7043, 0.7063, 0.7054]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:22,428:INFO::its now!!!!!!!!5
2023-12-01 16:51:22,595:INFO::its now!!!!!!!!0
2023-12-01 16:51:22,596:INFO::its now!!!!!!!!3
2023-12-01 16:51:22,641:INFO::its now!!!!!!!!5
2023-12-01 16:51:22,796:INFO::its now!!!!!!!!
2023-12-01 16:51:22,796:INFO::its now!!!!!!!! on 
2023-12-01 16:51:22,855:INFO::its now!!!!!!!!5
2023-12-01 16:51:23,024:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:23,026:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 1.1259 | Train_Classification_Loss 1.1578 | Dmon_Loss -0.0639 | Val_Loss 1.1794 | Search Time(s) 0.4279 | Infer Time(s) 0.1725 | Time(s) 0.6004 
2023-12-01 16:51:23,071:INFO::cluster info:
0: 0;	1: 2;	2: 0;	3: 2;	4: 1;	5: 0;	6: 2;	7: 0;	8: 2;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 0;	19: 2;	20: 2;	21: 1;	22: 0;	23: 2;	24: 2;	25: 0;	26: 2;	27: 1;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 2;	35: 0;	36: 0;	37: 0;	38: 1;	39: 0;	40: 0;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 3;	26102: 0;	26103: 2;	26104: 0;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:51:23,072:INFO::Validation loss decreased (1.187120 --> 1.179362).  Saving model ...
2023-12-01 16:51:23,074:INFO::Epoch: 44
tensor([[0.7149, 0.7110, 0.7135, 0.7137],
        [0.7131, 0.7115, 0.7159, 0.7138],
        [0.7177, 0.7193, 0.7126, 0.7156],
        [0.7134, 0.7138, 0.7081, 0.7151]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:23,075:INFO::its now!!!!!!!!5
2023-12-01 16:51:23,224:INFO::its now!!!!!!!!0
2023-12-01 16:51:23,225:INFO::its now!!!!!!!!3
2023-12-01 16:51:23,274:INFO::its now!!!!!!!!5
2023-12-01 16:51:23,440:INFO::its now!!!!!!!!
2023-12-01 16:51:23,440:INFO::its now!!!!!!!! on 
2023-12-01 16:51:23,496:INFO::its now!!!!!!!!5
2023-12-01 16:51:23,639:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:23,640:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 1.0931 | Train_Classification_Loss 1.1256 | Dmon_Loss -0.0651 | Val_Loss 1.1523 | Search Time(s) 0.4040 | Infer Time(s) 0.1636 | Time(s) 0.5676 
2023-12-01 16:51:23,678:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 0;	5: 2;	6: 2;	7: 0;	8: 2;	9: 0;	10: 0;	11: 2;	12: 0;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 2;	20: 0;	21: 1;	22: 2;	23: 2;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:23,679:INFO::Validation loss decreased (1.179362 --> 1.152254).  Saving model ...
2023-12-01 16:51:23,682:INFO::Epoch: 45
tensor([[0.7197, 0.7189, 0.7243, 0.7236],
        [0.7236, 0.7215, 0.7206, 0.7220],
        [0.7277, 0.7243, 0.7231, 0.7234],
        [0.7234, 0.7242, 0.7156, 0.7200]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:23,683:INFO::its now!!!!!!!!5
2023-12-01 16:51:23,821:INFO::its now!!!!!!!!0
2023-12-01 16:51:23,822:INFO::its now!!!!!!!!3
2023-12-01 16:51:23,869:INFO::its now!!!!!!!!5
2023-12-01 16:51:24,043:INFO::its now!!!!!!!!
2023-12-01 16:51:24,043:INFO::its now!!!!!!!! on 
2023-12-01 16:51:24,080:INFO::its now!!!!!!!!5
2023-12-01 16:51:24,219:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 1.1011 | Train_Classification_Loss 1.1338 | Dmon_Loss -0.0652 | Val_Loss 1.1642 | Search Time(s) 0.3979 | Infer Time(s) 0.1422 | Time(s) 0.5401 
2023-12-01 16:51:24,267:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 2;	5: 2;	6: 2;	7: 0;	8: 0;	9: 1;	10: 0;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 2;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 1;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 1;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:24,268:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:24,271:INFO::Epoch: 46
tensor([[0.7266, 0.7274, 0.7300, 0.7331],
        [0.7291, 0.7307, 0.7278, 0.7307],
        [0.7332, 0.7315, 0.7327, 0.7318],
        [0.7325, 0.7295, 0.7241, 0.7273]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:24,272:INFO::its now!!!!!!!!5
2023-12-01 16:51:24,420:INFO::its now!!!!!!!!0
2023-12-01 16:51:24,421:INFO::its now!!!!!!!!3
2023-12-01 16:51:24,452:INFO::its now!!!!!!!!5
2023-12-01 16:51:24,631:INFO::its now!!!!!!!!
2023-12-01 16:51:24,631:INFO::its now!!!!!!!! on 
2023-12-01 16:51:24,689:INFO::its now!!!!!!!!5
2023-12-01 16:51:24,828:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 1.1072 | Train_Classification_Loss 1.1391 | Dmon_Loss -0.0639 | Val_Loss 1.1678 | Search Time(s) 0.4175 | Infer Time(s) 0.1426 | Time(s) 0.5601 
2023-12-01 16:51:24,878:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 0;	13: 2;	14: 0;	15: 1;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 1;	22: 2;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 1;	29: 2;	30: 2;	31: 0;	32: 0;	33: 1;	34: 0;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 0;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 1;	26101: 0;	26102: 1;	26103: 1;	26104: 2;	26105: 2;	26106: 0;	26107: 1;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:24,880:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:24,882:INFO::Epoch: 47
tensor([[0.7346, 0.7361, 0.7373, 0.7378],
        [0.7362, 0.7395, 0.7360, 0.7352],
        [0.7366, 0.7395, 0.7419, 0.7404],
        [0.7371, 0.7365, 0.7330, 0.7357]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:24,883:INFO::its now!!!!!!!!5
2023-12-01 16:51:25,021:INFO::its now!!!!!!!!0
2023-12-01 16:51:25,021:INFO::its now!!!!!!!!3
2023-12-01 16:51:25,069:INFO::its now!!!!!!!!5
2023-12-01 16:51:25,221:INFO::its now!!!!!!!!
2023-12-01 16:51:25,221:INFO::its now!!!!!!!! on 
2023-12-01 16:51:25,258:INFO::its now!!!!!!!!5
2023-12-01 16:51:25,417:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:25,419:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 1.0756 | Train_Classification_Loss 1.1076 | Dmon_Loss -0.0640 | Val_Loss 1.1421 | Search Time(s) 0.3736 | Infer Time(s) 0.1631 | Time(s) 0.5367 
2023-12-01 16:51:25,465:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 2;	5: 0;	6: 2;	7: 1;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 2;	15: 1;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 2;	27: 1;	28: 0;	29: 2;	30: 0;	31: 0;	32: 0;	33: 2;	34: 1;	35: 2;	36: 0;	37: 0;	38: 0;	39: 0;	40: 1;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 1;	26103: 0;	26104: 0;	26105: 0;	26106: 2;	26107: 1;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:25,466:INFO::Validation loss decreased (1.152254 --> 1.142084).  Saving model ...
2023-12-01 16:51:25,468:INFO::Epoch: 48
tensor([[0.7432, 0.7450, 0.7457, 0.7403],
        [0.7443, 0.7440, 0.7450, 0.7424],
        [0.7432, 0.7482, 0.7466, 0.7493],
        [0.7395, 0.7446, 0.7422, 0.7448]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:25,468:INFO::its now!!!!!!!!5
2023-12-01 16:51:25,617:INFO::its now!!!!!!!!0
2023-12-01 16:51:25,618:INFO::its now!!!!!!!!3
2023-12-01 16:51:25,645:INFO::its now!!!!!!!!5
2023-12-01 16:51:25,821:INFO::its now!!!!!!!!
2023-12-01 16:51:25,821:INFO::its now!!!!!!!! on 
2023-12-01 16:51:25,875:INFO::its now!!!!!!!!5
2023-12-01 16:51:26,034:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 1.0868 | Train_Classification_Loss 1.1192 | Dmon_Loss -0.0647 | Val_Loss 1.1453 | Search Time(s) 0.3910 | Infer Time(s) 0.1775 | Time(s) 0.5685 
2023-12-01 16:51:26,077:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 0;	5: 2;	6: 2;	7: 0;	8: 2;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 2;	20: 1;	21: 1;	22: 2;	23: 2;	24: 2;	25: 2;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 0;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 2;	40: 1;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 2;	26100: 0;	26101: 1;	26102: 0;	26103: 0;	26104: 2;	26105: 2;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:26,078:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:26,081:INFO::Epoch: 49
tensor([[0.7524, 0.7544, 0.7502, 0.7468],
        [0.7531, 0.7511, 0.7499, 0.7512],
        [0.7517, 0.7576, 0.7541, 0.7538],
        [0.7456, 0.7535, 0.7519, 0.7494]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:26,082:INFO::its now!!!!!!!!5
2023-12-01 16:51:26,256:INFO::its now!!!!!!!!0
2023-12-01 16:51:26,257:INFO::its now!!!!!!!!3
2023-12-01 16:51:26,284:INFO::its now!!!!!!!!5
2023-12-01 16:51:26,429:INFO::its now!!!!!!!!
2023-12-01 16:51:26,429:INFO::its now!!!!!!!! on 
2023-12-01 16:51:26,479:INFO::its now!!!!!!!!5
2023-12-01 16:51:26,618:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 1.0834 | Train_Classification_Loss 1.1157 | Dmon_Loss -0.0645 | Val_Loss 1.1488 | Search Time(s) 0.3971 | Infer Time(s) 0.1416 | Time(s) 0.5387 
2023-12-01 16:51:26,672:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 1;	5: 2;	6: 2;	7: 0;	8: 2;	9: 1;	10: 2;	11: 1;	12: 0;	13: 2;	14: 2;	15: 1;	16: 2;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 1;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 1;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 2;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 1;	26104: 1;	26105: 2;	26106: 0;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:26,673:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:26,677:INFO::Epoch: 50
tensor([[0.7623, 0.7645, 0.7581, 0.7501],
        [0.7579, 0.7600, 0.7583, 0.7611],
        [0.7566, 0.7676, 0.7632, 0.7616],
        [0.7487, 0.7633, 0.7622, 0.7576]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:26,678:INFO::its now!!!!!!!!5
2023-12-01 16:51:26,834:INFO::its now!!!!!!!!0
2023-12-01 16:51:26,834:INFO::its now!!!!!!!!3
2023-12-01 16:51:26,883:INFO::its now!!!!!!!!5
2023-12-01 16:51:27,036:INFO::its now!!!!!!!!
2023-12-01 16:51:27,036:INFO::its now!!!!!!!! on 
2023-12-01 16:51:27,093:INFO::its now!!!!!!!!5
2023-12-01 16:51:27,266:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:27,268:INFO::Epoch 00050 | lr 0.00050 | Train_Loss 1.0807 | Train_Classification_Loss 1.1131 | Dmon_Loss -0.0648 | Val_Loss 1.1362 | Search Time(s) 0.4010 | Infer Time(s) 0.1920 | Time(s) 0.5930 
2023-12-01 16:51:27,313:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 1;	25: 0;	26: 2;	27: 0;	28: 2;	29: 0;	30: 2;	31: 2;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 2;	26106: 2;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:51:27,313:INFO::Validation loss decreased (1.142084 --> 1.136203).  Saving model ...
2023-12-01 16:51:27,315:INFO::Epoch: 51
tensor([[0.7707, 0.7696, 0.7657, 0.7555],
        [0.7638, 0.7678, 0.7661, 0.7662],
        [0.7628, 0.7727, 0.7712, 0.7691],
        [0.7538, 0.7682, 0.7709, 0.7655]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:27,316:INFO::its now!!!!!!!!5
2023-12-01 16:51:27,499:INFO::its now!!!!!!!!0
2023-12-01 16:51:27,500:INFO::its now!!!!!!!!3
2023-12-01 16:51:27,544:INFO::its now!!!!!!!!5
2023-12-01 16:51:27,692:INFO::its now!!!!!!!!
2023-12-01 16:51:27,692:INFO::its now!!!!!!!! on 
2023-12-01 16:51:27,746:INFO::its now!!!!!!!!5
2023-12-01 16:51:27,907:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:27,909:INFO::Epoch 00051 | lr 0.00050 | Train_Loss 1.0400 | Train_Classification_Loss 1.0723 | Dmon_Loss -0.0646 | Val_Loss 1.1077 | Search Time(s) 0.4109 | Infer Time(s) 0.1825 | Time(s) 0.5934 
2023-12-01 16:51:27,963:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 0;	6: 2;	7: 0;	8: 2;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 0;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 1;	34: 1;	35: 0;	36: 2;	37: 1;	38: 2;	39: 0;	40: 1;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 1;	26102: 0;	26103: 2;	26104: 2;	26105: 1;	26106: 0;	26107: 1;	26108: 2;	26109: 1;	26110: 0;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:27,963:INFO::Validation loss decreased (1.136203 --> 1.107672).  Saving model ...
2023-12-01 16:51:27,966:INFO::Epoch: 52
tensor([[0.7751, 0.7771, 0.7745, 0.7636],
        [0.7718, 0.7717, 0.7753, 0.7739],
        [0.7712, 0.7754, 0.7802, 0.7778],
        [0.7614, 0.7756, 0.7753, 0.7746]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:27,966:INFO::its now!!!!!!!!5
2023-12-01 16:51:28,122:INFO::its now!!!!!!!!0
2023-12-01 16:51:28,122:INFO::its now!!!!!!!!3
2023-12-01 16:51:28,170:INFO::its now!!!!!!!!5
2023-12-01 16:51:28,308:INFO::its now!!!!!!!!
2023-12-01 16:51:28,308:INFO::its now!!!!!!!! on 
2023-12-01 16:51:28,363:INFO::its now!!!!!!!!5
2023-12-01 16:51:28,526:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:28,527:INFO::Epoch 00052 | lr 0.00050 | Train_Loss 1.0323 | Train_Classification_Loss 1.0647 | Dmon_Loss -0.0648 | Val_Loss 1.0982 | Search Time(s) 0.3960 | Infer Time(s) 0.1656 | Time(s) 0.5616 
2023-12-01 16:51:28,575:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 2;	6: 1;	7: 0;	8: 0;	9: 2;	10: 1;	11: 1;	12: 1;	13: 2;	14: 2;	15: 0;	16: 0;	17: 2;	18: 2;	19: 2;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 1;	35: 1;	36: 2;	37: 2;	38: 2;	39: 2;	40: 1;	41: 2;	42: 2;	43: 0;	44
26098: 2;	26099: 2;	26100: 1;	26101: 2;	26102: 2;	26103: 1;	26104: 0;	26105: 2;	26106: 2;	26107: 1;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:28,577:INFO::Validation loss decreased (1.107672 --> 1.098243).  Saving model ...
2023-12-01 16:51:28,581:INFO::Epoch: 53
tensor([[0.7818, 0.7853, 0.7793, 0.7722],
        [0.7762, 0.7782, 0.7844, 0.7823],
        [0.7800, 0.7768, 0.7889, 0.7866],
        [0.7652, 0.7836, 0.7821, 0.7838]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:28,582:INFO::its now!!!!!!!!5
2023-12-01 16:51:28,735:INFO::its now!!!!!!!!0
2023-12-01 16:51:28,736:INFO::its now!!!!!!!!3
2023-12-01 16:51:28,782:INFO::its now!!!!!!!!5
2023-12-01 16:51:28,944:INFO::its now!!!!!!!!
2023-12-01 16:51:28,945:INFO::its now!!!!!!!! on 
2023-12-01 16:51:29,001:INFO::its now!!!!!!!!5
2023-12-01 16:51:29,160:INFO::Epoch 00053 | lr 0.00050 | Train_Loss 1.0420 | Train_Classification_Loss 1.0744 | Dmon_Loss -0.0647 | Val_Loss 1.1149 | Search Time(s) 0.4219 | Infer Time(s) 0.1602 | Time(s) 0.5820 
2023-12-01 16:51:29,201:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 0;	4: 0;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 0;	21: 1;	22: 2;	23: 0;	24: 0;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 1;	34: 2;	35: 2;	36: 0;	37: 1;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 1;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:29,202:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:29,205:INFO::Epoch: 54
tensor([[0.7894, 0.7894, 0.7861, 0.7810],
        [0.7827, 0.7856, 0.7894, 0.7908],
        [0.7887, 0.7821, 0.7937, 0.7951],
        [0.7715, 0.7917, 0.7899, 0.7885]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:29,206:INFO::its now!!!!!!!!5
2023-12-01 16:51:29,353:INFO::its now!!!!!!!!0
2023-12-01 16:51:29,354:INFO::its now!!!!!!!!3
2023-12-01 16:51:29,399:INFO::its now!!!!!!!!5
2023-12-01 16:51:29,563:INFO::its now!!!!!!!!
2023-12-01 16:51:29,563:INFO::its now!!!!!!!! on 
2023-12-01 16:51:29,613:INFO::its now!!!!!!!!5
2023-12-01 16:51:29,780:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:29,782:INFO::Epoch 00054 | lr 0.00050 | Train_Loss 1.0084 | Train_Classification_Loss 1.0411 | Dmon_Loss -0.0653 | Val_Loss 1.0818 | Search Time(s) 0.3935 | Infer Time(s) 0.1845 | Time(s) 0.5780 
2023-12-01 16:51:29,829:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 2;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 2;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 1;	35: 1;	36: 2;	37: 2;	38: 1;	39: 2;	40: 1;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 0;	26100: 1;	26101: 2;	26102: 2;	26103: 2;	26104: 0;	26105: 1;	26106: 2;	26107: 0;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:29,830:INFO::Validation loss decreased (1.098243 --> 1.081829).  Saving model ...
2023-12-01 16:51:29,833:INFO::Epoch: 55
tensor([[0.7936, 0.7955, 0.7936, 0.7895],
        [0.7900, 0.7932, 0.7961, 0.7951],
        [0.7972, 0.7890, 0.8001, 0.7994],
        [0.7787, 0.7958, 0.7978, 0.7951]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:29,834:INFO::its now!!!!!!!!5
2023-12-01 16:51:29,978:INFO::its now!!!!!!!!0
2023-12-01 16:51:29,979:INFO::its now!!!!!!!!3
2023-12-01 16:51:30,024:INFO::its now!!!!!!!!5
2023-12-01 16:51:30,180:INFO::its now!!!!!!!!
2023-12-01 16:51:30,180:INFO::its now!!!!!!!! on 
2023-12-01 16:51:30,217:INFO::its now!!!!!!!!5
2023-12-01 16:51:30,372:INFO::Epoch 00055 | lr 0.00050 | Train_Loss 1.0127 | Train_Classification_Loss 1.0452 | Dmon_Loss -0.0650 | Val_Loss 1.0893 | Search Time(s) 0.3825 | Infer Time(s) 0.1591 | Time(s) 0.5417 
2023-12-01 16:51:30,411:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 1;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 2;	26104: 2;	26105: 0;	26106: 2;	26107: 1;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:30,412:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:30,415:INFO::Epoch: 56
tensor([[0.8002, 0.7987, 0.8019, 0.7983],
        [0.7981, 0.8014, 0.8000, 0.8019],
        [0.8060, 0.7970, 0.8036, 0.8061],
        [0.7867, 0.8022, 0.8019, 0.8030]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:30,417:INFO::its now!!!!!!!!5
2023-12-01 16:51:30,556:INFO::its now!!!!!!!!0
2023-12-01 16:51:30,557:INFO::its now!!!!!!!!3
2023-12-01 16:51:30,602:INFO::its now!!!!!!!!5
2023-12-01 16:51:30,756:INFO::its now!!!!!!!!
2023-12-01 16:51:30,757:INFO::its now!!!!!!!! on 
2023-12-01 16:51:30,795:INFO::its now!!!!!!!!5
2023-12-01 16:51:30,930:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:30,932:INFO::Epoch 00056 | lr 0.00050 | Train_Loss 0.9950 | Train_Classification_Loss 1.0276 | Dmon_Loss -0.0652 | Val_Loss 1.0768 | Search Time(s) 0.3800 | Infer Time(s) 0.1376 | Time(s) 0.5176 
2023-12-01 16:51:30,980:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 2;	10: 2;	11: 0;	12: 0;	13: 2;	14: 0;	15: 0;	16: 0;	17: 2;	18: 0;	19: 2;	20: 0;	21: 1;	22: 0;	23: 0;	24: 1;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 1;	34: 2;	35: 1;	36: 2;	37: 1;	38: 1;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 2;	26103: 0;	26104: 0;	26105: 2;	26106: 1;	26107: 0;	26108: 2;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 0;	
2023-12-01 16:51:30,981:INFO::Validation loss decreased (1.081829 --> 1.076814).  Saving model ...
2023-12-01 16:51:30,985:INFO::Epoch: 57
tensor([[0.8075, 0.8004, 0.8100, 0.8067],
        [0.8061, 0.8055, 0.8061, 0.8093],
        [0.8111, 0.8051, 0.8093, 0.8133],
        [0.7947, 0.8055, 0.8080, 0.8111]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:30,986:INFO::its now!!!!!!!!5
2023-12-01 16:51:31,156:INFO::its now!!!!!!!!0
2023-12-01 16:51:31,156:INFO::its now!!!!!!!!3
2023-12-01 16:51:31,186:INFO::its now!!!!!!!!5
2023-12-01 16:51:31,355:INFO::its now!!!!!!!!
2023-12-01 16:51:31,356:INFO::its now!!!!!!!! on 
2023-12-01 16:51:31,396:INFO::its now!!!!!!!!5
2023-12-01 16:51:31,539:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:31,541:INFO::Epoch 00057 | lr 0.00050 | Train_Loss 0.9485 | Train_Classification_Loss 0.9829 | Dmon_Loss -0.0689 | Val_Loss 1.0234 | Search Time(s) 0.4080 | Infer Time(s) 0.1506 | Time(s) 0.5586 
2023-12-01 16:51:31,604:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 2;	23: 2;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 0;	26106: 1;	26107: 0;	26108: 0;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:31,606:INFO::Validation loss decreased (1.076814 --> 1.023391).  Saving model ...
2023-12-01 16:51:31,609:INFO::Epoch: 58
tensor([[0.8167, 0.8072, 0.8144, 0.8166],
        [0.8157, 0.8132, 0.8152, 0.8131],
        [0.8194, 0.8149, 0.8179, 0.8170],
        [0.8043, 0.8128, 0.8169, 0.8152]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:31,609:INFO::its now!!!!!!!!5
2023-12-01 16:51:31,775:INFO::its now!!!!!!!!0
2023-12-01 16:51:31,776:INFO::its now!!!!!!!!3
2023-12-01 16:51:31,806:INFO::its now!!!!!!!!5
2023-12-01 16:51:31,977:INFO::its now!!!!!!!!
2023-12-01 16:51:31,977:INFO::its now!!!!!!!! on 
2023-12-01 16:51:32,019:INFO::its now!!!!!!!!5
2023-12-01 16:51:32,151:INFO::Epoch 00058 | lr 0.00050 | Train_Loss 0.9535 | Train_Classification_Loss 0.9869 | Dmon_Loss -0.0667 | Val_Loss 1.0342 | Search Time(s) 0.4089 | Infer Time(s) 0.1352 | Time(s) 0.5441 
2023-12-01 16:51:32,190:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 1;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 1;	16: 0;	17: 2;	18: 2;	19: 0;	20: 1;	21: 1;	22: 2;	23: 0;	24: 1;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 1;	26101: 1;	26102: 2;	26103: 3;	26104: 0;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:32,191:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:32,194:INFO::Epoch: 59
tensor([[0.8217, 0.8153, 0.8215, 0.8262],
        [0.8208, 0.8216, 0.8245, 0.8199],
        [0.8243, 0.8245, 0.8268, 0.8237],
        [0.8137, 0.8211, 0.8214, 0.8223]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:32,194:INFO::its now!!!!!!!!5
2023-12-01 16:51:32,353:INFO::its now!!!!!!!!0
2023-12-01 16:51:32,353:INFO::its now!!!!!!!!3
2023-12-01 16:51:32,385:INFO::its now!!!!!!!!5
2023-12-01 16:51:32,550:INFO::its now!!!!!!!!
2023-12-01 16:51:32,550:INFO::its now!!!!!!!! on 
2023-12-01 16:51:32,604:INFO::its now!!!!!!!!5
2023-12-01 16:51:32,790:INFO::Epoch 00059 | lr 0.00050 | Train_Loss 0.9907 | Train_Classification_Loss 1.0242 | Dmon_Loss -0.0669 | Val_Loss 1.0674 | Search Time(s) 0.4115 | Infer Time(s) 0.1865 | Time(s) 0.5980 
2023-12-01 16:51:32,853:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 2;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 0;	23: 2;	24: 2;	25: 1;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 2;	33: 2;	34: 2;	35: 2;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 1;	26099: 2;	26100: 1;	26101: 0;	26102: 2;	26103: 2;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:51:32,854:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:32,857:INFO::Epoch: 60
tensor([[0.8300, 0.8251, 0.8309, 0.8310],
        [0.8291, 0.8313, 0.8298, 0.8292],
        [0.8327, 0.8349, 0.8318, 0.8328],
        [0.8239, 0.8308, 0.8295, 0.8258]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:32,858:INFO::its now!!!!!!!!5
2023-12-01 16:51:33,034:INFO::its now!!!!!!!!0
2023-12-01 16:51:33,034:INFO::its now!!!!!!!!3
2023-12-01 16:51:33,082:INFO::its now!!!!!!!!5
2023-12-01 16:51:33,240:INFO::its now!!!!!!!!
2023-12-01 16:51:33,240:INFO::its now!!!!!!!! on 
2023-12-01 16:51:33,280:INFO::its now!!!!!!!!5
2023-12-01 16:51:33,435:INFO::Epoch 00060 | lr 0.00050 | Train_Loss 0.9602 | Train_Classification_Loss 0.9933 | Dmon_Loss -0.0661 | Val_Loss 1.0465 | Search Time(s) 0.4224 | Infer Time(s) 0.1591 | Time(s) 0.5815 
2023-12-01 16:51:33,475:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 1;	12: 1;	13: 2;	14: 0;	15: 0;	16: 0;	17: 2;	18: 2;	19: 2;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 1;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 0;	26100: 0;	26101: 2;	26102: 0;	26103: 2;	26104: 2;	26105: 0;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:33,476:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:51:33,478:INFO::Epoch: 61
tensor([[0.8397, 0.8357, 0.8413, 0.8335],
        [0.8388, 0.8362, 0.8384, 0.8396],
        [0.8426, 0.8403, 0.8401, 0.8430],
        [0.8344, 0.8356, 0.8394, 0.8339]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:33,479:INFO::its now!!!!!!!!5
2023-12-01 16:51:33,666:INFO::its now!!!!!!!!0
2023-12-01 16:51:33,667:INFO::its now!!!!!!!!3
2023-12-01 16:51:33,699:INFO::its now!!!!!!!!5
2023-12-01 16:51:33,859:INFO::its now!!!!!!!!
2023-12-01 16:51:33,859:INFO::its now!!!!!!!! on 
2023-12-01 16:51:33,897:INFO::its now!!!!!!!!5
2023-12-01 16:51:34,055:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:34,057:INFO::Epoch 00061 | lr 0.00050 | Train_Loss 0.8975 | Train_Classification_Loss 0.9331 | Dmon_Loss -0.0712 | Val_Loss 0.9771 | Search Time(s) 0.4149 | Infer Time(s) 0.1638 | Time(s) 0.5787 
2023-12-01 16:51:34,100:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 0;	4: 0;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 0;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:34,101:INFO::Validation loss decreased (1.023391 --> 0.977054).  Saving model ...
2023-12-01 16:51:34,103:INFO::Epoch: 62
tensor([[0.8494, 0.8457, 0.8469, 0.8399],
        [0.8485, 0.8436, 0.8479, 0.8450],
        [0.8525, 0.8481, 0.8491, 0.8482],
        [0.8443, 0.8430, 0.8443, 0.8431]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:34,104:INFO::its now!!!!!!!!5
2023-12-01 16:51:34,232:INFO::its now!!!!!!!!0
2023-12-01 16:51:34,232:INFO::its now!!!!!!!!3
2023-12-01 16:51:34,262:INFO::its now!!!!!!!!5
2023-12-01 16:51:34,418:INFO::its now!!!!!!!!
2023-12-01 16:51:34,418:INFO::its now!!!!!!!! on 
2023-12-01 16:51:34,473:INFO::its now!!!!!!!!5
2023-12-01 16:51:34,624:INFO::Epoch 00062 | lr 0.00050 | Train_Loss 0.8995 | Train_Classification_Loss 0.9337 | Dmon_Loss -0.0684 | Val_Loss 0.9876 | Search Time(s) 0.3512 | Infer Time(s) 0.1715 | Time(s) 0.5227 
2023-12-01 16:51:34,668:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 2;	10: 2;	11: 0;	12: 1;	13: 2;	14: 2;	15: 1;	16: 0;	17: 2;	18: 2;	19: 2;	20: 1;	21: 1;	22: 0;	23: 2;	24: 2;	25: 0;	26: 2;	27: 1;	28: 2;	29: 0;	30: 2;	31: 2;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 0;	26103: 2;	26104: 2;	26105: 0;	26106: 1;	26107: 2;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:34,669:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:34,671:INFO::Epoch: 63
tensor([[0.8546, 0.8562, 0.8555, 0.8490],
        [0.8587, 0.8528, 0.8583, 0.8477],
        [0.8581, 0.8576, 0.8592, 0.8564],
        [0.8546, 0.8522, 0.8468, 0.8536]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:34,672:INFO::its now!!!!!!!!5
2023-12-01 16:51:34,825:INFO::its now!!!!!!!!0
2023-12-01 16:51:34,826:INFO::its now!!!!!!!!3
2023-12-01 16:51:34,874:INFO::its now!!!!!!!!5
2023-12-01 16:51:35,044:INFO::its now!!!!!!!!
2023-12-01 16:51:35,044:INFO::its now!!!!!!!! on 
2023-12-01 16:51:35,100:INFO::its now!!!!!!!!5
2023-12-01 16:51:35,268:INFO::Epoch 00063 | lr 0.00050 | Train_Loss 0.8918 | Train_Classification_Loss 0.9263 | Dmon_Loss -0.0689 | Val_Loss 0.9774 | Search Time(s) 0.4269 | Infer Time(s) 0.1722 | Time(s) 0.5991 
2023-12-01 16:51:35,321:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 2;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 2;	20: 0;	21: 1;	22: 2;	23: 2;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 3;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 1;	26102: 0;	26103: 1;	26104: 2;	26105: 1;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:35,323:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:35,325:INFO::Epoch: 64
tensor([[0.8611, 0.8615, 0.8636, 0.8575],
        [0.8643, 0.8611, 0.8674, 0.8532],
        [0.8648, 0.8661, 0.8648, 0.8644],
        [0.8598, 0.8606, 0.8522, 0.8627]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:35,326:INFO::its now!!!!!!!!5
2023-12-01 16:51:35,475:INFO::its now!!!!!!!!0
2023-12-01 16:51:35,476:INFO::its now!!!!!!!!3
2023-12-01 16:51:35,525:INFO::its now!!!!!!!!5
2023-12-01 16:51:35,681:INFO::its now!!!!!!!!
2023-12-01 16:51:35,681:INFO::its now!!!!!!!! on 
2023-12-01 16:51:35,736:INFO::its now!!!!!!!!5
2023-12-01 16:51:35,887:INFO::Epoch 00064 | lr 0.00050 | Train_Loss 0.9021 | Train_Classification_Loss 0.9359 | Dmon_Loss -0.0677 | Val_Loss 0.9918 | Search Time(s) 0.4099 | Infer Time(s) 0.1536 | Time(s) 0.5635 
2023-12-01 16:51:35,930:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 0;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 0;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 1;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 0;	26101: 3;	26102: 2;	26103: 0;	26104: 2;	26105: 0;	26106: 0;	26107: 2;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 2;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:35,931:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:51:35,933:INFO::Epoch: 65
tensor([[0.8698, 0.8696, 0.8679, 0.8673],
        [0.8725, 0.8706, 0.8724, 0.8617],
        [0.8738, 0.8706, 0.8731, 0.8738],
        [0.8677, 0.8701, 0.8606, 0.8673]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:35,934:INFO::its now!!!!!!!!5
2023-12-01 16:51:36,090:INFO::its now!!!!!!!!0
2023-12-01 16:51:36,091:INFO::its now!!!!!!!!3
2023-12-01 16:51:36,141:INFO::its now!!!!!!!!5
2023-12-01 16:51:36,303:INFO::its now!!!!!!!!
2023-12-01 16:51:36,303:INFO::its now!!!!!!!! on 
2023-12-01 16:51:36,361:INFO::its now!!!!!!!!5
2023-12-01 16:51:36,513:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:36,514:INFO::Epoch 00065 | lr 0.00050 | Train_Loss 0.8913 | Train_Classification_Loss 0.9268 | Dmon_Loss -0.0711 | Val_Loss 0.9736 | Search Time(s) 0.4085 | Infer Time(s) 0.1735 | Time(s) 0.5820 
2023-12-01 16:51:36,564:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 0;	8: 2;	9: 2;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 2;	17: 2;	18: 0;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 2;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 2;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 2;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 2;	
2023-12-01 16:51:36,565:INFO::Validation loss decreased (0.977054 --> 0.973622).  Saving model ...
2023-12-01 16:51:36,568:INFO::Epoch: 66
tensor([[0.8746, 0.8769, 0.8736, 0.8756],
        [0.8771, 0.8786, 0.8784, 0.8695],
        [0.8817, 0.8762, 0.8806, 0.8786],
        [0.8748, 0.8749, 0.8684, 0.8732]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:36,568:INFO::its now!!!!!!!!5
2023-12-01 16:51:36,709:INFO::its now!!!!!!!!0
2023-12-01 16:51:36,710:INFO::its now!!!!!!!!3
2023-12-01 16:51:36,757:INFO::its now!!!!!!!!5
2023-12-01 16:51:36,914:INFO::its now!!!!!!!!
2023-12-01 16:51:36,914:INFO::its now!!!!!!!! on 
2023-12-01 16:51:36,958:INFO::its now!!!!!!!!5
2023-12-01 16:51:37,123:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:37,124:INFO::Epoch 00066 | lr 0.00050 | Train_Loss 0.8390 | Train_Classification_Loss 0.8744 | Dmon_Loss -0.0708 | Val_Loss 0.9317 | Search Time(s) 0.3919 | Infer Time(s) 0.1656 | Time(s) 0.5575 
2023-12-01 16:51:37,175:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 0;	4: 2;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 2;	23: 2;	24: 2;	25: 0;	26: 2;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 1;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 0;	26102: 0;	26103: 3;	26104: 2;	26105: 1;	26106: 0;	26107: 1;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:37,176:INFO::Validation loss decreased (0.973622 --> 0.931715).  Saving model ...
2023-12-01 16:51:37,178:INFO::Epoch: 67
tensor([[0.8813, 0.8807, 0.8808, 0.8840],
        [0.8836, 0.8826, 0.8859, 0.8778],
        [0.8868, 0.8835, 0.8885, 0.8853],
        [0.8825, 0.8773, 0.8767, 0.8807]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:37,179:INFO::its now!!!!!!!!5
2023-12-01 16:51:37,346:INFO::its now!!!!!!!!0
2023-12-01 16:51:37,347:INFO::its now!!!!!!!!3
2023-12-01 16:51:37,380:INFO::its now!!!!!!!!5
2023-12-01 16:51:37,551:INFO::its now!!!!!!!!
2023-12-01 16:51:37,551:INFO::its now!!!!!!!! on 
2023-12-01 16:51:37,585:INFO::its now!!!!!!!!5
2023-12-01 16:51:37,725:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:37,726:INFO::Epoch 00067 | lr 0.00050 | Train_Loss 0.8236 | Train_Classification_Loss 0.8592 | Dmon_Loss -0.0712 | Val_Loss 0.9216 | Search Time(s) 0.4069 | Infer Time(s) 0.1426 | Time(s) 0.5495 
2023-12-01 16:51:37,769:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 2;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 1;	21: 1;	22: 2;	23: 2;	24: 2;	25: 1;	26: 2;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 1;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 1;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:37,770:INFO::Validation loss decreased (0.931715 --> 0.921644).  Saving model ...
2023-12-01 16:51:37,773:INFO::Epoch: 68
tensor([[0.8879, 0.8857, 0.8878, 0.8883],
        [0.8900, 0.8878, 0.8901, 0.8853],
        [0.8926, 0.8904, 0.8931, 0.8918],
        [0.8863, 0.8818, 0.8841, 0.8878]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:37,774:INFO::its now!!!!!!!!5
2023-12-01 16:51:37,921:INFO::its now!!!!!!!!0
2023-12-01 16:51:37,922:INFO::its now!!!!!!!!3
2023-12-01 16:51:37,949:INFO::its now!!!!!!!!5
2023-12-01 16:51:38,111:INFO::its now!!!!!!!!
2023-12-01 16:51:38,112:INFO::its now!!!!!!!! on 
2023-12-01 16:51:38,151:INFO::its now!!!!!!!!5
2023-12-01 16:51:38,334:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:38,340:INFO::Epoch 00068 | lr 0.00050 | Train_Loss 0.7941 | Train_Classification_Loss 0.8319 | Dmon_Loss -0.0755 | Val_Loss 0.8850 | Search Time(s) 0.3750 | Infer Time(s) 0.1895 | Time(s) 0.5645 
2023-12-01 16:51:38,397:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 1;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 1;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:38,399:INFO::Validation loss decreased (0.921644 --> 0.884994).  Saving model ...
2023-12-01 16:51:38,402:INFO::Epoch: 69
tensor([[0.8961, 0.8931, 0.8962, 0.8905],
        [0.8979, 0.8952, 0.8928, 0.8940],
        [0.9006, 0.8988, 0.8960, 0.8999],
        [0.8930, 0.8889, 0.8929, 0.8914]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:38,403:INFO::its now!!!!!!!!5
2023-12-01 16:51:38,597:INFO::its now!!!!!!!!0
2023-12-01 16:51:38,597:INFO::its now!!!!!!!!3
2023-12-01 16:51:38,628:INFO::its now!!!!!!!!5
2023-12-01 16:51:38,766:INFO::its now!!!!!!!!
2023-12-01 16:51:38,767:INFO::its now!!!!!!!! on 
2023-12-01 16:51:38,807:INFO::its now!!!!!!!!5
2023-12-01 16:51:38,957:INFO::Epoch 00069 | lr 0.00050 | Train_Loss 0.8311 | Train_Classification_Loss 0.8661 | Dmon_Loss -0.0699 | Val_Loss 0.9257 | Search Time(s) 0.4040 | Infer Time(s) 0.1535 | Time(s) 0.5575 
2023-12-01 16:51:39,007:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 0;	4: 2;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 2;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 0;	26104: 0;	26105: 1;	26106: 2;	26107: 2;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:39,008:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:39,010:INFO::Epoch: 70
tensor([[0.9006, 0.8985, 0.9021, 0.8932],
        [0.9035, 0.9005, 0.8959, 0.8985],
        [0.9053, 0.9046, 0.8992, 0.9056],
        [0.8963, 0.8941, 0.8990, 0.8949]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:39,011:INFO::its now!!!!!!!!5
2023-12-01 16:51:39,158:INFO::its now!!!!!!!!0
2023-12-01 16:51:39,158:INFO::its now!!!!!!!!3
2023-12-01 16:51:39,189:INFO::its now!!!!!!!!5
2023-12-01 16:51:39,358:INFO::its now!!!!!!!!
2023-12-01 16:51:39,358:INFO::its now!!!!!!!! on 
2023-12-01 16:51:39,413:INFO::its now!!!!!!!!5
2023-12-01 16:51:39,566:INFO::Epoch 00070 | lr 0.00050 | Train_Loss 0.8072 | Train_Classification_Loss 0.8452 | Dmon_Loss -0.0759 | Val_Loss 0.9013 | Search Time(s) 0.3860 | Infer Time(s) 0.1705 | Time(s) 0.5565 
2023-12-01 16:51:39,609:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 2;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 0;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 2;	26123: 0;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:39,610:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:39,613:INFO::Epoch: 71
tensor([[0.9091, 0.9073, 0.9055, 0.9012],
        [0.9068, 0.9094, 0.9042, 0.9072],
        [0.9140, 0.9139, 0.9072, 0.9085],
        [0.9041, 0.9029, 0.9020, 0.9035]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:39,614:INFO::its now!!!!!!!!5
2023-12-01 16:51:39,785:INFO::its now!!!!!!!!0
2023-12-01 16:51:39,786:INFO::its now!!!!!!!!3
2023-12-01 16:51:39,828:INFO::its now!!!!!!!!5
2023-12-01 16:51:39,988:INFO::its now!!!!!!!!
2023-12-01 16:51:39,989:INFO::its now!!!!!!!! on 
2023-12-01 16:51:40,042:INFO::its now!!!!!!!!5
2023-12-01 16:51:40,187:INFO::Epoch 00071 | lr 0.00050 | Train_Loss 0.8558 | Train_Classification_Loss 0.8915 | Dmon_Loss -0.0714 | Val_Loss 0.9428 | Search Time(s) 0.4289 | Infer Time(s) 0.1486 | Time(s) 0.5775 
2023-12-01 16:51:40,245:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 1;	16: 0;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 0;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:51:40,246:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:51:40,248:INFO::Epoch: 72
tensor([[0.9140, 0.9151, 0.9108, 0.9087],
        [0.9120, 0.9138, 0.9120, 0.9151],
        [0.9192, 0.9219, 0.9146, 0.9135],
        [0.9080, 0.9107, 0.9072, 0.9114]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:40,249:INFO::its now!!!!!!!!5
2023-12-01 16:51:40,404:INFO::its now!!!!!!!!0
2023-12-01 16:51:40,405:INFO::its now!!!!!!!!3
2023-12-01 16:51:40,449:INFO::its now!!!!!!!!5
2023-12-01 16:51:40,618:INFO::its now!!!!!!!!
2023-12-01 16:51:40,618:INFO::its now!!!!!!!! on 
2023-12-01 16:51:40,674:INFO::its now!!!!!!!!5
2023-12-01 16:51:40,833:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:40,834:INFO::Epoch 00072 | lr 0.00050 | Train_Loss 0.7241 | Train_Classification_Loss 0.7639 | Dmon_Loss -0.0795 | Val_Loss 0.8277 | Search Time(s) 0.4049 | Infer Time(s) 0.1815 | Time(s) 0.5864 
2023-12-01 16:51:40,875:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 2;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:40,876:INFO::Validation loss decreased (0.884994 --> 0.827687).  Saving model ...
2023-12-01 16:51:40,879:INFO::Epoch: 73
tensor([[0.9209, 0.9191, 0.9181, 0.9170],
        [0.9191, 0.9204, 0.9205, 0.9191],
        [0.9264, 0.9262, 0.9228, 0.9206],
        [0.9143, 0.9190, 0.9146, 0.9154]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:40,880:INFO::its now!!!!!!!!5
2023-12-01 16:51:41,052:INFO::its now!!!!!!!!0
2023-12-01 16:51:41,053:INFO::its now!!!!!!!!3
2023-12-01 16:51:41,087:INFO::its now!!!!!!!!5
2023-12-01 16:51:41,253:INFO::its now!!!!!!!!
2023-12-01 16:51:41,253:INFO::its now!!!!!!!! on 
2023-12-01 16:51:41,308:INFO::its now!!!!!!!!5
2023-12-01 16:51:41,455:INFO::Epoch 00073 | lr 0.00050 | Train_Loss 0.7675 | Train_Classification_Loss 0.8068 | Dmon_Loss -0.0785 | Val_Loss 0.8601 | Search Time(s) 0.4109 | Infer Time(s) 0.1675 | Time(s) 0.5785 
2023-12-01 16:51:41,505:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 0;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 0;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:41,506:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:41,509:INFO::Epoch: 74
tensor([[0.9298, 0.9266, 0.9276, 0.9212],
        [0.9282, 0.9291, 0.9254, 0.9268],
        [0.9356, 0.9340, 0.9324, 0.9241],
        [0.9174, 0.9285, 0.9240, 0.9233]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:41,509:INFO::its now!!!!!!!!5
2023-12-01 16:51:41,664:INFO::its now!!!!!!!!0
2023-12-01 16:51:41,664:INFO::its now!!!!!!!!3
2023-12-01 16:51:41,706:INFO::its now!!!!!!!!5
2023-12-01 16:51:41,842:INFO::its now!!!!!!!!
2023-12-01 16:51:41,842:INFO::its now!!!!!!!! on 
2023-12-01 16:51:41,896:INFO::its now!!!!!!!!5
2023-12-01 16:51:42,061:INFO::Epoch 00074 | lr 0.00050 | Train_Loss 0.7619 | Train_Classification_Loss 0.7994 | Dmon_Loss -0.0749 | Val_Loss 0.8636 | Search Time(s) 0.3661 | Infer Time(s) 0.1885 | Time(s) 0.5545 
2023-12-01 16:51:42,111:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 0;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 1;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:42,112:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:42,114:INFO::Epoch: 75
tensor([[0.9349, 0.9347, 0.9368, 0.9279],
        [0.9370, 0.9335, 0.9325, 0.9351],
        [0.9410, 0.9423, 0.9416, 0.9305],
        [0.9234, 0.9333, 0.9333, 0.9319]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:42,115:INFO::its now!!!!!!!!5
2023-12-01 16:51:42,254:INFO::its now!!!!!!!!0
2023-12-01 16:51:42,255:INFO::its now!!!!!!!!3
2023-12-01 16:51:42,303:INFO::its now!!!!!!!!5
2023-12-01 16:51:42,469:INFO::its now!!!!!!!!
2023-12-01 16:51:42,469:INFO::its now!!!!!!!! on 
2023-12-01 16:51:42,505:INFO::its now!!!!!!!!5
2023-12-01 16:51:42,647:INFO::Epoch 00075 | lr 0.00050 | Train_Loss 0.7219 | Train_Classification_Loss 0.7603 | Dmon_Loss -0.0767 | Val_Loss 0.8371 | Search Time(s) 0.3910 | Infer Time(s) 0.1436 | Time(s) 0.5346 
2023-12-01 16:51:42,698:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 2;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:42,699:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:51:42,701:INFO::Epoch: 76
tensor([[0.9406, 0.9418, 0.9419, 0.9345],
        [0.9420, 0.9388, 0.9394, 0.9425],
        [0.9469, 0.9466, 0.9492, 0.9370],
        [0.9294, 0.9358, 0.9411, 0.9395]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:42,702:INFO::its now!!!!!!!!5
2023-12-01 16:51:42,851:INFO::its now!!!!!!!!0
2023-12-01 16:51:42,852:INFO::its now!!!!!!!!3
2023-12-01 16:51:42,880:INFO::its now!!!!!!!!5
2023-12-01 16:51:43,064:INFO::its now!!!!!!!!
2023-12-01 16:51:43,064:INFO::its now!!!!!!!! on 
2023-12-01 16:51:43,121:INFO::its now!!!!!!!!5
2023-12-01 16:51:43,265:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:43,266:INFO::Epoch 00076 | lr 0.00050 | Train_Loss 0.7081 | Train_Classification_Loss 0.7475 | Dmon_Loss -0.0790 | Val_Loss 0.8152 | Search Time(s) 0.4189 | Infer Time(s) 0.1476 | Time(s) 0.5665 
2023-12-01 16:51:43,314:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 0;	4: 2;	5: 0;	6: 2;	7: 0;	8: 2;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 1;	16: 0;	17: 2;	18: 2;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 3;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 2;	26103: 0;	26104: 2;	26105: 2;	26106: 0;	26107: 2;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:43,315:INFO::Validation loss decreased (0.827687 --> 0.815242).  Saving model ...
2023-12-01 16:51:43,316:INFO::Epoch: 77
tensor([[0.9471, 0.9489, 0.9449, 0.9415],
        [0.9481, 0.9450, 0.9466, 0.9462],
        [0.9535, 0.9524, 0.9538, 0.9439],
        [0.9360, 0.9406, 0.9451, 0.9470]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:43,317:INFO::its now!!!!!!!!5
2023-12-01 16:51:43,473:INFO::its now!!!!!!!!0
2023-12-01 16:51:43,474:INFO::its now!!!!!!!!3
2023-12-01 16:51:43,522:INFO::its now!!!!!!!!5
2023-12-01 16:51:43,692:INFO::its now!!!!!!!!
2023-12-01 16:51:43,693:INFO::its now!!!!!!!! on 
2023-12-01 16:51:43,730:INFO::its now!!!!!!!!5
2023-12-01 16:51:43,908:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:43,910:INFO::Epoch 00077 | lr 0.00050 | Train_Loss 0.6519 | Train_Classification_Loss 0.6938 | Dmon_Loss -0.0839 | Val_Loss 0.7682 | Search Time(s) 0.4089 | Infer Time(s) 0.1845 | Time(s) 0.5934 
2023-12-01 16:51:43,965:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:43,966:INFO::Validation loss decreased (0.815242 --> 0.768224).  Saving model ...
2023-12-01 16:51:43,969:INFO::Epoch: 78
tensor([[0.9546, 0.9525, 0.9509, 0.9495],
        [0.9516, 0.9524, 0.9548, 0.9526],
        [0.9612, 0.9597, 0.9568, 0.9519],
        [0.9435, 0.9473, 0.9516, 0.9508]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:43,970:INFO::its now!!!!!!!!5
2023-12-01 16:51:44,136:INFO::its now!!!!!!!!0
2023-12-01 16:51:44,137:INFO::its now!!!!!!!!3
2023-12-01 16:51:44,163:INFO::its now!!!!!!!!5
2023-12-01 16:51:44,313:INFO::its now!!!!!!!!
2023-12-01 16:51:44,313:INFO::its now!!!!!!!! on 
2023-12-01 16:51:44,369:INFO::its now!!!!!!!!5
2023-12-01 16:51:44,515:INFO::Epoch 00078 | lr 0.00050 | Train_Loss 0.7345 | Train_Classification_Loss 0.7730 | Dmon_Loss -0.0771 | Val_Loss 0.8420 | Search Time(s) 0.3999 | Infer Time(s) 0.1486 | Time(s) 0.5486 
2023-12-01 16:51:44,560:INFO::cluster info:
0: 0;	1: 0;	2: 0;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 2;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 0;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 0;	26124: 2;	26125: 2;	26126: 0;	26127: 0;	
2023-12-01 16:51:44,561:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:44,562:INFO::Epoch: 79
tensor([[0.9589, 0.9587, 0.9585, 0.9579],
        [0.9578, 0.9603, 0.9594, 0.9601],
        [0.9658, 0.9677, 0.9627, 0.9603],
        [0.9515, 0.9549, 0.9548, 0.9573]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:44,563:INFO::its now!!!!!!!!5
2023-12-01 16:51:44,713:INFO::its now!!!!!!!!0
2023-12-01 16:51:44,714:INFO::its now!!!!!!!!3
2023-12-01 16:51:44,760:INFO::its now!!!!!!!!5
2023-12-01 16:51:44,922:INFO::its now!!!!!!!!
2023-12-01 16:51:44,922:INFO::its now!!!!!!!! on 
2023-12-01 16:51:44,979:INFO::its now!!!!!!!!5
2023-12-01 16:51:45,111:INFO::Epoch 00079 | lr 0.00050 | Train_Loss 0.6526 | Train_Classification_Loss 0.6956 | Dmon_Loss -0.0861 | Val_Loss 0.7739 | Search Time(s) 0.4149 | Infer Time(s) 0.1356 | Time(s) 0.5505 
2023-12-01 16:51:45,152:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 2;	21: 2;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 2;	26102: 0;	26103: 2;	26104: 0;	26105: 0;	26106: 2;	26107: 1;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:45,153:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:45,156:INFO::Epoch: 80
tensor([[0.9619, 0.9659, 0.9665, 0.9664],
        [0.9650, 0.9643, 0.9662, 0.9681],
        [0.9724, 0.9718, 0.9699, 0.9687],
        [0.9595, 0.9629, 0.9609, 0.9606]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:45,156:INFO::its now!!!!!!!!5
2023-12-01 16:51:45,322:INFO::its now!!!!!!!!0
2023-12-01 16:51:45,323:INFO::its now!!!!!!!!3
2023-12-01 16:51:45,372:INFO::its now!!!!!!!!5
2023-12-01 16:51:45,535:INFO::its now!!!!!!!!
2023-12-01 16:51:45,535:INFO::its now!!!!!!!! on 
2023-12-01 16:51:45,590:INFO::its now!!!!!!!!5
2023-12-01 16:51:45,746:INFO::Epoch 00080 | lr 0.00050 | Train_Loss 0.7008 | Train_Classification_Loss 0.7404 | Dmon_Loss -0.0793 | Val_Loss 0.8208 | Search Time(s) 0.4338 | Infer Time(s) 0.1586 | Time(s) 0.5924 
2023-12-01 16:51:45,784:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 1;	5: 2;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 2;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 2;	26102: 2;	26103: 0;	26104: 2;	26105: 2;	26106: 2;	26107: 2;	26108: 2;	26109: 1;	26110: 2;	26111: 1;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:45,784:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:51:45,786:INFO::Epoch: 81
tensor([[0.9661, 0.9721, 0.9709, 0.9733],
        [0.9714, 0.9690, 0.9724, 0.9722],
        [0.9766, 0.9766, 0.9762, 0.9757],
        [0.9662, 0.9669, 0.9667, 0.9651]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:45,787:INFO::its now!!!!!!!!5
2023-12-01 16:51:45,965:INFO::its now!!!!!!!!0
2023-12-01 16:51:45,966:INFO::its now!!!!!!!!3
2023-12-01 16:51:46,016:INFO::its now!!!!!!!!5
2023-12-01 16:51:46,163:INFO::its now!!!!!!!!
2023-12-01 16:51:46,164:INFO::its now!!!!!!!! on 
2023-12-01 16:51:46,221:INFO::its now!!!!!!!!5
2023-12-01 16:51:46,377:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:46,378:INFO::Epoch 00081 | lr 0.00050 | Train_Loss 0.6237 | Train_Classification_Loss 0.6661 | Dmon_Loss -0.0847 | Val_Loss 0.7479 | Search Time(s) 0.4139 | Infer Time(s) 0.1775 | Time(s) 0.5914 
2023-12-01 16:51:46,433:INFO::cluster info:
0: 0;	1: 2;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 1;	26101: 3;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 0;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:46,434:INFO::Validation loss decreased (0.768224 --> 0.747941).  Saving model ...
2023-12-01 16:51:46,436:INFO::Epoch: 82
tensor([[0.9745, 0.9813, 0.9794, 0.9768],
        [0.9806, 0.9773, 0.9760, 0.9804],
        [0.9849, 0.9793, 0.9854, 0.9853],
        [0.9754, 0.9689, 0.9759, 0.9738]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:46,437:INFO::its now!!!!!!!!5
2023-12-01 16:51:46,580:INFO::its now!!!!!!!!0
2023-12-01 16:51:46,581:INFO::its now!!!!!!!!3
2023-12-01 16:51:46,629:INFO::its now!!!!!!!!5
2023-12-01 16:51:46,778:INFO::its now!!!!!!!!
2023-12-01 16:51:46,778:INFO::its now!!!!!!!! on 
2023-12-01 16:51:46,819:INFO::its now!!!!!!!!5
2023-12-01 16:51:46,973:INFO::Epoch 00082 | lr 0.00050 | Train_Loss 0.7000 | Train_Classification_Loss 0.7384 | Dmon_Loss -0.0770 | Val_Loss 0.8205 | Search Time(s) 0.3830 | Infer Time(s) 0.1566 | Time(s) 0.5396 
2023-12-01 16:51:47,019:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 2;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:47,020:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:47,022:INFO::Epoch: 83
tensor([[0.9815, 0.9860, 0.9865, 0.9815],
        [0.9857, 0.9843, 0.9809, 0.9874],
        [0.9920, 0.9836, 0.9908, 0.9929],
        [0.9827, 0.9727, 0.9806, 0.9811]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:47,023:INFO::its now!!!!!!!!5
2023-12-01 16:51:47,164:INFO::its now!!!!!!!!0
2023-12-01 16:51:47,165:INFO::its now!!!!!!!!3
2023-12-01 16:51:47,196:INFO::its now!!!!!!!!5
2023-12-01 16:51:47,336:INFO::its now!!!!!!!!
2023-12-01 16:51:47,336:INFO::its now!!!!!!!! on 
2023-12-01 16:51:47,393:INFO::its now!!!!!!!!5
2023-12-01 16:51:47,567:INFO::Epoch 00083 | lr 0.00050 | Train_Loss 0.6557 | Train_Classification_Loss 0.6989 | Dmon_Loss -0.0864 | Val_Loss 0.7694 | Search Time(s) 0.3690 | Infer Time(s) 0.1765 | Time(s) 0.5455 
2023-12-01 16:51:47,615:INFO::cluster info:
0: 0;	1: 2;	2: 2;	3: 2;	4: 2;	5: 2;	6: 2;	7: 0;	8: 0;	9: 2;	10: 2;	11: 2;	12: 1;	13: 2;	14: 2;	15: 2;	16: 0;	17: 2;	18: 2;	19: 2;	20: 2;	21: 1;	22: 2;	23: 0;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 2;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 2;	43: 2;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 2;	26109: 2;	26110: 2;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 2;	26116: 0;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:51:47,616:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:51:47,618:INFO::Epoch: 84
tensor([[0.9875, 0.9908, 0.9907, 0.9865],
        [0.9908, 0.9902, 0.9861, 0.9909],
        [0.9980, 0.9884, 0.9960, 0.9967],
        [0.9864, 0.9772, 0.9855, 0.9874]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:47,619:INFO::its now!!!!!!!!5
2023-12-01 16:51:47,760:INFO::its now!!!!!!!!0
2023-12-01 16:51:47,761:INFO::its now!!!!!!!!3
2023-12-01 16:51:47,813:INFO::its now!!!!!!!!5
2023-12-01 16:51:47,996:INFO::its now!!!!!!!!
2023-12-01 16:51:47,997:INFO::its now!!!!!!!! on 
2023-12-01 16:51:48,035:INFO::its now!!!!!!!!5
2023-12-01 16:51:48,183:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:48,185:INFO::Epoch 00084 | lr 0.00050 | Train_Loss 0.5585 | Train_Classification_Loss 0.6065 | Dmon_Loss -0.0959 | Val_Loss 0.6806 | Search Time(s) 0.4139 | Infer Time(s) 0.1536 | Time(s) 0.5675 
2023-12-01 16:51:48,229:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 2;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:48,230:INFO::Validation loss decreased (0.747941 --> 0.680631).  Saving model ...
2023-12-01 16:51:48,233:INFO::Epoch: 85
tensor([[0.9936, 0.9934, 0.9959, 0.9922],
        [0.9964, 0.9962, 0.9920, 0.9928],
        [1.0000, 0.9939, 1.0000, 1.0000],
        [0.9911, 0.9826, 0.9911, 0.9906]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:48,233:INFO::its now!!!!!!!!5
2023-12-01 16:51:48,382:INFO::its now!!!!!!!!0
2023-12-01 16:51:48,383:INFO::its now!!!!!!!!3
2023-12-01 16:51:48,413:INFO::its now!!!!!!!!5
2023-12-01 16:51:48,577:INFO::its now!!!!!!!!
2023-12-01 16:51:48,578:INFO::its now!!!!!!!! on 
2023-12-01 16:51:48,632:INFO::its now!!!!!!!!5
2023-12-01 16:51:48,774:INFO::Epoch 00085 | lr 0.00050 | Train_Loss 0.5956 | Train_Classification_Loss 0.6424 | Dmon_Loss -0.0935 | Val_Loss 0.7169 | Search Time(s) 0.3800 | Infer Time(s) 0.1636 | Time(s) 0.5435 
2023-12-01 16:51:48,832:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 0;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 0;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:51:48,833:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:51:48,862:INFO::Epoch: 86
tensor([[1.0000, 0.9985, 0.9990, 0.9990],
        [0.9997, 1.0000, 0.9991, 0.9976],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9973, 0.9892, 0.9940, 0.9963]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:48,863:INFO::its now!!!!!!!!5
2023-12-01 16:51:49,051:INFO::its now!!!!!!!!0
2023-12-01 16:51:49,051:INFO::its now!!!!!!!!3
2023-12-01 16:51:49,095:INFO::its now!!!!!!!!5
2023-12-01 16:51:49,322:INFO::its now!!!!!!!!
2023-12-01 16:51:49,322:INFO::its now!!!!!!!! on 
2023-12-01 16:51:49,356:INFO::its now!!!!!!!!5
2023-12-01 16:51:49,541:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:49,542:INFO::Epoch 00086 | lr 0.00050 | Train_Loss 0.5277 | Train_Classification_Loss 0.5781 | Dmon_Loss -0.1009 | Val_Loss 0.6649 | Search Time(s) 0.5186 | Infer Time(s) 0.1885 | Time(s) 0.7071 
2023-12-01 16:51:49,586:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:49,587:INFO::Validation loss decreased (0.680631 --> 0.664940).  Saving model ...
2023-12-01 16:51:49,591:INFO::Epoch: 87
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 0.9948, 0.9977, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:49,591:INFO::its now!!!!!!!!5
2023-12-01 16:51:49,744:INFO::its now!!!!!!!!0
2023-12-01 16:51:49,744:INFO::its now!!!!!!!!3
2023-12-01 16:51:49,769:INFO::its now!!!!!!!!5
2023-12-01 16:51:49,920:INFO::its now!!!!!!!!
2023-12-01 16:51:49,920:INFO::its now!!!!!!!! on 
2023-12-01 16:51:49,954:INFO::its now!!!!!!!!5
2023-12-01 16:51:50,106:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:50,108:INFO::Epoch 00087 | lr 0.00050 | Train_Loss 0.5188 | Train_Classification_Loss 0.5701 | Dmon_Loss -0.1026 | Val_Loss 0.6530 | Search Time(s) 0.3610 | Infer Time(s) 0.1576 | Time(s) 0.5186 
2023-12-01 16:51:50,154:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:50,155:INFO::Validation loss decreased (0.664940 --> 0.653009).  Saving model ...
2023-12-01 16:51:50,158:INFO::Epoch: 88
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:50,159:INFO::its now!!!!!!!!5
2023-12-01 16:51:50,315:INFO::its now!!!!!!!!0
2023-12-01 16:51:50,316:INFO::its now!!!!!!!!3
2023-12-01 16:51:50,341:INFO::its now!!!!!!!!5
2023-12-01 16:51:50,523:INFO::its now!!!!!!!!
2023-12-01 16:51:50,523:INFO::its now!!!!!!!! on 
2023-12-01 16:51:50,556:INFO::its now!!!!!!!!5
2023-12-01 16:51:50,714:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:50,715:INFO::Epoch 00088 | lr 0.00050 | Train_Loss 0.4986 | Train_Classification_Loss 0.5507 | Dmon_Loss -0.1041 | Val_Loss 0.6412 | Search Time(s) 0.3950 | Infer Time(s) 0.1646 | Time(s) 0.5595 
2023-12-01 16:51:50,761:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 2;	44
26098: 0;	26099: 0;	26100: 0;	26101: 2;	26102: 0;	26103: 0;	26104: 2;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:50,762:INFO::Validation loss decreased (0.653009 --> 0.641152).  Saving model ...
2023-12-01 16:51:50,768:INFO::Epoch: 89
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:50,768:INFO::its now!!!!!!!!5
2023-12-01 16:51:50,924:INFO::its now!!!!!!!!0
2023-12-01 16:51:50,924:INFO::its now!!!!!!!!3
2023-12-01 16:51:50,952:INFO::its now!!!!!!!!5
2023-12-01 16:51:51,146:INFO::its now!!!!!!!!
2023-12-01 16:51:51,147:INFO::its now!!!!!!!! on 
2023-12-01 16:51:51,181:INFO::its now!!!!!!!!5
2023-12-01 16:51:51,334:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:51,336:INFO::Epoch 00089 | lr 0.00050 | Train_Loss 0.4838 | Train_Classification_Loss 0.5364 | Dmon_Loss -0.1051 | Val_Loss 0.6294 | Search Time(s) 0.4129 | Infer Time(s) 0.1586 | Time(s) 0.5715 
2023-12-01 16:51:51,382:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 2;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:51,383:INFO::Validation loss decreased (0.641152 --> 0.629443).  Saving model ...
2023-12-01 16:51:51,389:INFO::Epoch: 90
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:51,390:INFO::its now!!!!!!!!5
2023-12-01 16:51:51,532:INFO::its now!!!!!!!!0
2023-12-01 16:51:51,532:INFO::its now!!!!!!!!3
2023-12-01 16:51:51,562:INFO::its now!!!!!!!!5
2023-12-01 16:51:51,740:INFO::its now!!!!!!!!
2023-12-01 16:51:51,740:INFO::its now!!!!!!!! on 
2023-12-01 16:51:51,776:INFO::its now!!!!!!!!5
2023-12-01 16:51:51,932:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:51,934:INFO::Epoch 00090 | lr 0.00050 | Train_Loss 0.4702 | Train_Classification_Loss 0.5248 | Dmon_Loss -0.1093 | Val_Loss 0.6179 | Search Time(s) 0.3860 | Infer Time(s) 0.1606 | Time(s) 0.5465 
2023-12-01 16:51:51,982:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 2;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:51,983:INFO::Validation loss decreased (0.629443 --> 0.617913).  Saving model ...
2023-12-01 16:51:51,987:INFO::Epoch: 91
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:51,987:INFO::its now!!!!!!!!5
2023-12-01 16:51:52,135:INFO::its now!!!!!!!!0
2023-12-01 16:51:52,135:INFO::its now!!!!!!!!3
2023-12-01 16:51:52,162:INFO::its now!!!!!!!!5
2023-12-01 16:51:52,342:INFO::its now!!!!!!!!
2023-12-01 16:51:52,342:INFO::its now!!!!!!!! on 
2023-12-01 16:51:52,375:INFO::its now!!!!!!!!5
2023-12-01 16:51:52,529:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:52,531:INFO::Epoch 00091 | lr 0.00050 | Train_Loss 0.4627 | Train_Classification_Loss 0.5177 | Dmon_Loss -0.1100 | Val_Loss 0.6066 | Search Time(s) 0.3852 | Infer Time(s) 0.1606 | Time(s) 0.5458 
2023-12-01 16:51:52,567:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 2;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:52,569:INFO::Validation loss decreased (0.617913 --> 0.606572).  Saving model ...
2023-12-01 16:51:52,573:INFO::Epoch: 92
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:52,573:INFO::its now!!!!!!!!5
2023-12-01 16:51:52,728:INFO::its now!!!!!!!!0
2023-12-01 16:51:52,729:INFO::its now!!!!!!!!3
2023-12-01 16:51:52,755:INFO::its now!!!!!!!!5
2023-12-01 16:51:52,909:INFO::its now!!!!!!!!
2023-12-01 16:51:52,909:INFO::its now!!!!!!!! on 
2023-12-01 16:51:52,944:INFO::its now!!!!!!!!5
2023-12-01 16:51:53,090:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:53,092:INFO::Epoch 00092 | lr 0.00050 | Train_Loss 0.4481 | Train_Classification_Loss 0.5041 | Dmon_Loss -0.1121 | Val_Loss 0.5954 | Search Time(s) 0.3680 | Infer Time(s) 0.1536 | Time(s) 0.5216 
2023-12-01 16:51:53,135:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:53,136:INFO::Validation loss decreased (0.606572 --> 0.595436).  Saving model ...
2023-12-01 16:51:53,141:INFO::Epoch: 93
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:53,141:INFO::its now!!!!!!!!5
2023-12-01 16:51:53,302:INFO::its now!!!!!!!!0
2023-12-01 16:51:53,302:INFO::its now!!!!!!!!3
2023-12-01 16:51:53,332:INFO::its now!!!!!!!!5
2023-12-01 16:51:53,487:INFO::its now!!!!!!!!
2023-12-01 16:51:53,487:INFO::its now!!!!!!!! on 
2023-12-01 16:51:53,525:INFO::its now!!!!!!!!5
2023-12-01 16:51:53,695:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:53,697:INFO::Epoch 00093 | lr 0.00050 | Train_Loss 0.4323 | Train_Classification_Loss 0.4900 | Dmon_Loss -0.1154 | Val_Loss 0.5845 | Search Time(s) 0.3826 | Infer Time(s) 0.1765 | Time(s) 0.5591 
2023-12-01 16:51:53,735:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:53,736:INFO::Validation loss decreased (0.595436 --> 0.584538).  Saving model ...
2023-12-01 16:51:53,740:INFO::Epoch: 94
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:53,741:INFO::its now!!!!!!!!5
2023-12-01 16:51:53,893:INFO::its now!!!!!!!!0
2023-12-01 16:51:53,894:INFO::its now!!!!!!!!3
2023-12-01 16:51:53,918:INFO::its now!!!!!!!!5
2023-12-01 16:51:54,058:INFO::its now!!!!!!!!
2023-12-01 16:51:54,058:INFO::its now!!!!!!!! on 
2023-12-01 16:51:54,091:INFO::its now!!!!!!!!5
2023-12-01 16:51:54,246:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:54,248:INFO::Epoch 00094 | lr 0.00050 | Train_Loss 0.4150 | Train_Classification_Loss 0.4737 | Dmon_Loss -0.1174 | Val_Loss 0.5739 | Search Time(s) 0.3471 | Infer Time(s) 0.1622 | Time(s) 0.5093 
2023-12-01 16:51:54,290:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 2;	26100: 2;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:54,291:INFO::Validation loss decreased (0.584538 --> 0.573882).  Saving model ...
2023-12-01 16:51:54,295:INFO::Epoch: 95
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:54,295:INFO::its now!!!!!!!!5
2023-12-01 16:51:54,471:INFO::its now!!!!!!!!0
2023-12-01 16:51:54,471:INFO::its now!!!!!!!!3
2023-12-01 16:51:54,501:INFO::its now!!!!!!!!5
2023-12-01 16:51:54,673:INFO::its now!!!!!!!!
2023-12-01 16:51:54,673:INFO::its now!!!!!!!! on 
2023-12-01 16:51:54,711:INFO::its now!!!!!!!!5
2023-12-01 16:51:54,912:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:54,914:INFO::Epoch 00095 | lr 0.00050 | Train_Loss 0.4048 | Train_Classification_Loss 0.4645 | Dmon_Loss -0.1192 | Val_Loss 0.5635 | Search Time(s) 0.4153 | Infer Time(s) 0.2045 | Time(s) 0.6197 
2023-12-01 16:51:54,969:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:54,970:INFO::Validation loss decreased (0.573882 --> 0.563473).  Saving model ...
2023-12-01 16:51:54,975:INFO::Epoch: 96
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:54,976:INFO::its now!!!!!!!!5
2023-12-01 16:51:55,140:INFO::its now!!!!!!!!0
2023-12-01 16:51:55,140:INFO::its now!!!!!!!!3
2023-12-01 16:51:55,168:INFO::its now!!!!!!!!5
2023-12-01 16:51:55,332:INFO::its now!!!!!!!!
2023-12-01 16:51:55,332:INFO::its now!!!!!!!! on 
2023-12-01 16:51:55,368:INFO::its now!!!!!!!!5
2023-12-01 16:51:55,523:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:55,524:INFO::Epoch 00096 | lr 0.00050 | Train_Loss 0.3937 | Train_Classification_Loss 0.4544 | Dmon_Loss -0.1215 | Val_Loss 0.5533 | Search Time(s) 0.3911 | Infer Time(s) 0.1606 | Time(s) 0.5517 
2023-12-01 16:51:55,566:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:55,567:INFO::Validation loss decreased (0.563473 --> 0.553330).  Saving model ...
2023-12-01 16:51:55,570:INFO::Epoch: 97
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:55,571:INFO::its now!!!!!!!!5
2023-12-01 16:51:55,709:INFO::its now!!!!!!!!0
2023-12-01 16:51:55,710:INFO::its now!!!!!!!!3
2023-12-01 16:51:55,735:INFO::its now!!!!!!!!5
2023-12-01 16:51:55,896:INFO::its now!!!!!!!!
2023-12-01 16:51:55,896:INFO::its now!!!!!!!! on 
2023-12-01 16:51:55,930:INFO::its now!!!!!!!!5
2023-12-01 16:51:56,101:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:56,102:INFO::Epoch 00097 | lr 0.00050 | Train_Loss 0.3752 | Train_Classification_Loss 0.4376 | Dmon_Loss -0.1247 | Val_Loss 0.5435 | Search Time(s) 0.3550 | Infer Time(s) 0.1781 | Time(s) 0.5332 
2023-12-01 16:51:56,160:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:56,162:INFO::Validation loss decreased (0.553330 --> 0.543457).  Saving model ...
2023-12-01 16:51:56,165:INFO::Epoch: 98
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:56,166:INFO::its now!!!!!!!!5
2023-12-01 16:51:56,313:INFO::its now!!!!!!!!0
2023-12-01 16:51:56,314:INFO::its now!!!!!!!!3
2023-12-01 16:51:56,340:INFO::its now!!!!!!!!5
2023-12-01 16:51:56,510:INFO::its now!!!!!!!!
2023-12-01 16:51:56,510:INFO::its now!!!!!!!! on 
2023-12-01 16:51:56,544:INFO::its now!!!!!!!!5
2023-12-01 16:51:56,700:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:56,701:INFO::Epoch 00098 | lr 0.00050 | Train_Loss 0.3587 | Train_Classification_Loss 0.4227 | Dmon_Loss -0.1281 | Val_Loss 0.5338 | Search Time(s) 0.3775 | Infer Time(s) 0.1606 | Time(s) 0.5381 
2023-12-01 16:51:56,739:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:56,740:INFO::Validation loss decreased (0.543457 --> 0.533837).  Saving model ...
2023-12-01 16:51:56,743:INFO::Epoch: 99
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:56,744:INFO::its now!!!!!!!!5
2023-12-01 16:51:56,899:INFO::its now!!!!!!!!0
2023-12-01 16:51:56,900:INFO::its now!!!!!!!!3
2023-12-01 16:51:56,925:INFO::its now!!!!!!!!5
2023-12-01 16:51:57,093:INFO::its now!!!!!!!!
2023-12-01 16:51:57,093:INFO::its now!!!!!!!! on 
2023-12-01 16:51:57,127:INFO::its now!!!!!!!!5
2023-12-01 16:51:57,272:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:57,274:INFO::Epoch 00099 | lr 0.00050 | Train_Loss 0.3595 | Train_Classification_Loss 0.4241 | Dmon_Loss -0.1291 | Val_Loss 0.5245 | Search Time(s) 0.3816 | Infer Time(s) 0.1506 | Time(s) 0.5322 
2023-12-01 16:51:57,311:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 2;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:57,312:INFO::Validation loss decreased (0.533837 --> 0.524516).  Saving model ...
2023-12-01 16:51:57,315:INFO::Epoch: 100
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:57,316:INFO::its now!!!!!!!!5
2023-12-01 16:51:57,487:INFO::its now!!!!!!!!0
2023-12-01 16:51:57,488:INFO::its now!!!!!!!!3
2023-12-01 16:51:57,514:INFO::its now!!!!!!!!5
2023-12-01 16:51:57,673:INFO::its now!!!!!!!!
2023-12-01 16:51:57,673:INFO::its now!!!!!!!! on 
2023-12-01 16:51:57,726:INFO::its now!!!!!!!!5
2023-12-01 16:51:57,871:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:57,873:INFO::Epoch 00100 | lr 0.00050 | Train_Loss 0.3503 | Train_Classification_Loss 0.4161 | Dmon_Loss -0.1315 | Val_Loss 0.5155 | Search Time(s) 0.3930 | Infer Time(s) 0.1655 | Time(s) 0.5585 
2023-12-01 16:51:57,911:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:57,912:INFO::Validation loss decreased (0.524516 --> 0.515476).  Saving model ...
2023-12-01 16:51:57,916:INFO::Epoch: 101
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:57,916:INFO::its now!!!!!!!!5
2023-12-01 16:51:58,059:INFO::its now!!!!!!!!0
2023-12-01 16:51:58,059:INFO::its now!!!!!!!!3
2023-12-01 16:51:58,103:INFO::its now!!!!!!!!5
2023-12-01 16:51:58,251:INFO::its now!!!!!!!!
2023-12-01 16:51:58,251:INFO::its now!!!!!!!! on 
2023-12-01 16:51:58,284:INFO::its now!!!!!!!!5
2023-12-01 16:51:58,416:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:58,418:INFO::Epoch 00101 | lr 0.00050 | Train_Loss 0.3407 | Train_Classification_Loss 0.4076 | Dmon_Loss -0.1338 | Val_Loss 0.5067 | Search Time(s) 0.3656 | Infer Time(s) 0.1392 | Time(s) 0.5048 
2023-12-01 16:51:58,467:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:58,468:INFO::Validation loss decreased (0.515476 --> 0.506731).  Saving model ...
2023-12-01 16:51:58,472:INFO::Epoch: 102
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:58,474:INFO::its now!!!!!!!!5
2023-12-01 16:51:58,620:INFO::its now!!!!!!!!0
2023-12-01 16:51:58,621:INFO::its now!!!!!!!!3
2023-12-01 16:51:58,649:INFO::its now!!!!!!!!5
2023-12-01 16:51:58,821:INFO::its now!!!!!!!!
2023-12-01 16:51:58,821:INFO::its now!!!!!!!! on 
2023-12-01 16:51:58,859:INFO::its now!!!!!!!!5
2023-12-01 16:51:59,022:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:59,024:INFO::Epoch 00102 | lr 0.00050 | Train_Loss 0.3198 | Train_Classification_Loss 0.3881 | Dmon_Loss -0.1365 | Val_Loss 0.4983 | Search Time(s) 0.3835 | Infer Time(s) 0.1705 | Time(s) 0.5540 
2023-12-01 16:51:59,078:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:59,079:INFO::Validation loss decreased (0.506731 --> 0.498265).  Saving model ...
2023-12-01 16:51:59,082:INFO::Epoch: 103
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:59,083:INFO::its now!!!!!!!!5
2023-12-01 16:51:59,231:INFO::its now!!!!!!!!0
2023-12-01 16:51:59,231:INFO::its now!!!!!!!!3
2023-12-01 16:51:59,276:INFO::its now!!!!!!!!5
2023-12-01 16:51:59,437:INFO::its now!!!!!!!!
2023-12-01 16:51:59,437:INFO::its now!!!!!!!! on 
2023-12-01 16:51:59,469:INFO::its now!!!!!!!!5
2023-12-01 16:51:59,649:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:51:59,650:INFO::Epoch 00103 | lr 0.00050 | Train_Loss 0.3003 | Train_Classification_Loss 0.3700 | Dmon_Loss -0.1396 | Val_Loss 0.4901 | Search Time(s) 0.3825 | Infer Time(s) 0.1875 | Time(s) 0.5700 
2023-12-01 16:51:59,696:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 2;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:51:59,697:INFO::Validation loss decreased (0.498265 --> 0.490100).  Saving model ...
2023-12-01 16:51:59,700:INFO::Epoch: 104
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:51:59,700:INFO::its now!!!!!!!!5
2023-12-01 16:51:59,846:INFO::its now!!!!!!!!0
2023-12-01 16:51:59,846:INFO::its now!!!!!!!!3
2023-12-01 16:51:59,876:INFO::its now!!!!!!!!5
2023-12-01 16:52:00,052:INFO::its now!!!!!!!!
2023-12-01 16:52:00,053:INFO::its now!!!!!!!! on 
2023-12-01 16:52:00,092:INFO::its now!!!!!!!!5
2023-12-01 16:52:00,280:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:00,282:INFO::Epoch 00104 | lr 0.00050 | Train_Loss 0.2891 | Train_Classification_Loss 0.3604 | Dmon_Loss -0.1427 | Val_Loss 0.4822 | Search Time(s) 0.3880 | Infer Time(s) 0.1946 | Time(s) 0.5826 
2023-12-01 16:52:00,333:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:00,334:INFO::Validation loss decreased (0.490100 --> 0.482192).  Saving model ...
2023-12-01 16:52:00,338:INFO::Epoch: 105
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:00,338:INFO::its now!!!!!!!!5
2023-12-01 16:52:00,567:INFO::its now!!!!!!!!0
2023-12-01 16:52:00,568:INFO::its now!!!!!!!!3
2023-12-01 16:52:00,593:INFO::its now!!!!!!!!5
2023-12-01 16:52:00,762:INFO::its now!!!!!!!!
2023-12-01 16:52:00,762:INFO::its now!!!!!!!! on 
2023-12-01 16:52:00,795:INFO::its now!!!!!!!!5
2023-12-01 16:52:00,929:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:00,931:INFO::Epoch 00105 | lr 0.00050 | Train_Loss 0.2832 | Train_Classification_Loss 0.3554 | Dmon_Loss -0.1444 | Val_Loss 0.4745 | Search Time(s) 0.4546 | Infer Time(s) 0.1397 | Time(s) 0.5943 
2023-12-01 16:52:00,980:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:00,981:INFO::Validation loss decreased (0.482192 --> 0.474549).  Saving model ...
2023-12-01 16:52:00,985:INFO::Epoch: 106
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:00,986:INFO::its now!!!!!!!!5
2023-12-01 16:52:01,168:INFO::its now!!!!!!!!0
2023-12-01 16:52:01,169:INFO::its now!!!!!!!!3
2023-12-01 16:52:01,198:INFO::its now!!!!!!!!5
2023-12-01 16:52:01,367:INFO::its now!!!!!!!!
2023-12-01 16:52:01,367:INFO::its now!!!!!!!! on 
2023-12-01 16:52:01,405:INFO::its now!!!!!!!!5
2023-12-01 16:52:01,562:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:01,563:INFO::Epoch 00106 | lr 0.00050 | Train_Loss 0.2753 | Train_Classification_Loss 0.3484 | Dmon_Loss -0.1463 | Val_Loss 0.4672 | Search Time(s) 0.4180 | Infer Time(s) 0.1636 | Time(s) 0.5816 
2023-12-01 16:52:01,611:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:01,612:INFO::Validation loss decreased (0.474549 --> 0.467177).  Saving model ...
2023-12-01 16:52:01,616:INFO::Epoch: 107
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:01,616:INFO::its now!!!!!!!!5
2023-12-01 16:52:01,783:INFO::its now!!!!!!!!0
2023-12-01 16:52:01,783:INFO::its now!!!!!!!!3
2023-12-01 16:52:01,810:INFO::its now!!!!!!!!5
2023-12-01 16:52:01,972:INFO::its now!!!!!!!!
2023-12-01 16:52:01,972:INFO::its now!!!!!!!! on 
2023-12-01 16:52:02,007:INFO::its now!!!!!!!!5
2023-12-01 16:52:02,171:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:02,173:INFO::Epoch 00107 | lr 0.00050 | Train_Loss 0.2642 | Train_Classification_Loss 0.3388 | Dmon_Loss -0.1492 | Val_Loss 0.4601 | Search Time(s) 0.3880 | Infer Time(s) 0.1701 | Time(s) 0.5581 
2023-12-01 16:52:02,221:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:02,223:INFO::Validation loss decreased (0.467177 --> 0.460078).  Saving model ...
2023-12-01 16:52:02,228:INFO::Epoch: 108
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:02,229:INFO::its now!!!!!!!!5
2023-12-01 16:52:02,384:INFO::its now!!!!!!!!0
2023-12-01 16:52:02,384:INFO::its now!!!!!!!!3
2023-12-01 16:52:02,414:INFO::its now!!!!!!!!5
2023-12-01 16:52:02,588:INFO::its now!!!!!!!!
2023-12-01 16:52:02,589:INFO::its now!!!!!!!! on 
2023-12-01 16:52:02,625:INFO::its now!!!!!!!!5
2023-12-01 16:52:02,762:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:02,763:INFO::Epoch 00108 | lr 0.00050 | Train_Loss 0.2543 | Train_Classification_Loss 0.3301 | Dmon_Loss -0.1515 | Val_Loss 0.4532 | Search Time(s) 0.3965 | Infer Time(s) 0.1426 | Time(s) 0.5391 
2023-12-01 16:52:02,812:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:02,814:INFO::Validation loss decreased (0.460078 --> 0.453250).  Saving model ...
2023-12-01 16:52:02,818:INFO::Epoch: 109
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:02,819:INFO::its now!!!!!!!!5
2023-12-01 16:52:02,975:INFO::its now!!!!!!!!0
2023-12-01 16:52:02,976:INFO::its now!!!!!!!!3
2023-12-01 16:52:03,001:INFO::its now!!!!!!!!5
2023-12-01 16:52:03,154:INFO::its now!!!!!!!!
2023-12-01 16:52:03,154:INFO::its now!!!!!!!! on 
2023-12-01 16:52:03,188:INFO::its now!!!!!!!!5
2023-12-01 16:52:03,337:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:03,338:INFO::Epoch 00109 | lr 0.00050 | Train_Loss 0.2398 | Train_Classification_Loss 0.3170 | Dmon_Loss -0.1545 | Val_Loss 0.4467 | Search Time(s) 0.3676 | Infer Time(s) 0.1552 | Time(s) 0.5228 
2023-12-01 16:52:03,391:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:03,392:INFO::Validation loss decreased (0.453250 --> 0.446692).  Saving model ...
2023-12-01 16:52:03,396:INFO::Epoch: 110
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:03,397:INFO::its now!!!!!!!!5
2023-12-01 16:52:03,544:INFO::its now!!!!!!!!0
2023-12-01 16:52:03,545:INFO::its now!!!!!!!!3
2023-12-01 16:52:03,571:INFO::its now!!!!!!!!5
2023-12-01 16:52:03,730:INFO::its now!!!!!!!!
2023-12-01 16:52:03,730:INFO::its now!!!!!!!! on 
2023-12-01 16:52:03,764:INFO::its now!!!!!!!!5
2023-12-01 16:52:03,901:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:03,903:INFO::Epoch 00110 | lr 0.00050 | Train_Loss 0.2305 | Train_Classification_Loss 0.3089 | Dmon_Loss -0.1567 | Val_Loss 0.4404 | Search Time(s) 0.3666 | Infer Time(s) 0.1426 | Time(s) 0.5092 
2023-12-01 16:52:03,945:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 2;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:03,946:INFO::Validation loss decreased (0.446692 --> 0.440429).  Saving model ...
2023-12-01 16:52:03,950:INFO::Epoch: 111
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:03,951:INFO::its now!!!!!!!!5
2023-12-01 16:52:04,113:INFO::its now!!!!!!!!0
2023-12-01 16:52:04,114:INFO::its now!!!!!!!!3
2023-12-01 16:52:04,138:INFO::its now!!!!!!!!5
2023-12-01 16:52:04,317:INFO::its now!!!!!!!!
2023-12-01 16:52:04,317:INFO::its now!!!!!!!! on 
2023-12-01 16:52:04,352:INFO::its now!!!!!!!!5
2023-12-01 16:52:04,488:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:04,490:INFO::Epoch 00111 | lr 0.00050 | Train_Loss 0.2249 | Train_Classification_Loss 0.3044 | Dmon_Loss -0.1591 | Val_Loss 0.4344 | Search Time(s) 0.3980 | Infer Time(s) 0.1436 | Time(s) 0.5417 
2023-12-01 16:52:04,542:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:04,543:INFO::Validation loss decreased (0.440429 --> 0.434409).  Saving model ...
2023-12-01 16:52:04,546:INFO::Epoch: 112
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:04,547:INFO::its now!!!!!!!!5
2023-12-01 16:52:04,697:INFO::its now!!!!!!!!0
2023-12-01 16:52:04,698:INFO::its now!!!!!!!!3
2023-12-01 16:52:04,723:INFO::its now!!!!!!!!5
2023-12-01 16:52:04,892:INFO::its now!!!!!!!!
2023-12-01 16:52:04,893:INFO::its now!!!!!!!! on 
2023-12-01 16:52:04,926:INFO::its now!!!!!!!!5
2023-12-01 16:52:05,085:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:05,086:INFO::Epoch 00112 | lr 0.00050 | Train_Loss 0.2121 | Train_Classification_Loss 0.2937 | Dmon_Loss -0.1632 | Val_Loss 0.4286 | Search Time(s) 0.3760 | Infer Time(s) 0.1656 | Time(s) 0.5415 
2023-12-01 16:52:05,122:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:05,124:INFO::Validation loss decreased (0.434409 --> 0.428633).  Saving model ...
2023-12-01 16:52:05,129:INFO::Epoch: 113
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:05,129:INFO::its now!!!!!!!!5
2023-12-01 16:52:05,267:INFO::its now!!!!!!!!0
2023-12-01 16:52:05,268:INFO::its now!!!!!!!!3
2023-12-01 16:52:05,293:INFO::its now!!!!!!!!5
2023-12-01 16:52:05,457:INFO::its now!!!!!!!!
2023-12-01 16:52:05,457:INFO::its now!!!!!!!! on 
2023-12-01 16:52:05,490:INFO::its now!!!!!!!!5
2023-12-01 16:52:05,682:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:05,683:INFO::Epoch 00113 | lr 0.00050 | Train_Loss 0.2084 | Train_Classification_Loss 0.2903 | Dmon_Loss -0.1637 | Val_Loss 0.4231 | Search Time(s) 0.3586 | Infer Time(s) 0.1989 | Time(s) 0.5575 
2023-12-01 16:52:05,748:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 3;	26101: 0;	26102: 0;	26103: 3;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:05,749:INFO::Validation loss decreased (0.428633 --> 0.423147).  Saving model ...
2023-12-01 16:52:05,754:INFO::Epoch: 114
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:05,755:INFO::its now!!!!!!!!5
2023-12-01 16:52:05,973:INFO::its now!!!!!!!!0
2023-12-01 16:52:05,974:INFO::its now!!!!!!!!3
2023-12-01 16:52:06,005:INFO::its now!!!!!!!!5
2023-12-01 16:52:06,172:INFO::its now!!!!!!!!
2023-12-01 16:52:06,173:INFO::its now!!!!!!!! on 
2023-12-01 16:52:06,212:INFO::its now!!!!!!!!5
2023-12-01 16:52:06,380:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:06,382:INFO::Epoch 00114 | lr 0.00050 | Train_Loss 0.2012 | Train_Classification_Loss 0.2843 | Dmon_Loss -0.1661 | Val_Loss 0.4179 | Search Time(s) 0.4573 | Infer Time(s) 0.1731 | Time(s) 0.6305 
2023-12-01 16:52:06,424:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:06,424:INFO::Validation loss decreased (0.423147 --> 0.417868).  Saving model ...
2023-12-01 16:52:06,435:INFO::Epoch: 115
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:06,437:INFO::its now!!!!!!!!5
2023-12-01 16:52:06,583:INFO::its now!!!!!!!!0
2023-12-01 16:52:06,583:INFO::its now!!!!!!!!3
2023-12-01 16:52:06,608:INFO::its now!!!!!!!!5
2023-12-01 16:52:06,784:INFO::its now!!!!!!!!
2023-12-01 16:52:06,784:INFO::its now!!!!!!!! on 
2023-12-01 16:52:06,819:INFO::its now!!!!!!!!5
2023-12-01 16:52:06,966:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:06,967:INFO::Epoch 00115 | lr 0.00050 | Train_Loss 0.1875 | Train_Classification_Loss 0.2727 | Dmon_Loss -0.1704 | Val_Loss 0.4128 | Search Time(s) 0.3870 | Infer Time(s) 0.1546 | Time(s) 0.5415 
2023-12-01 16:52:07,006:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:07,007:INFO::Validation loss decreased (0.417868 --> 0.412761).  Saving model ...
2023-12-01 16:52:07,012:INFO::Epoch: 116
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:07,013:INFO::its now!!!!!!!!5
2023-12-01 16:52:07,184:INFO::its now!!!!!!!!0
2023-12-01 16:52:07,185:INFO::its now!!!!!!!!3
2023-12-01 16:52:07,210:INFO::its now!!!!!!!!5
2023-12-01 16:52:07,380:INFO::its now!!!!!!!!
2023-12-01 16:52:07,380:INFO::its now!!!!!!!! on 
2023-12-01 16:52:07,412:INFO::its now!!!!!!!!5
2023-12-01 16:52:07,538:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:07,540:INFO::Epoch 00116 | lr 0.00050 | Train_Loss 0.1812 | Train_Classification_Loss 0.2671 | Dmon_Loss -0.1717 | Val_Loss 0.4078 | Search Time(s) 0.3981 | Infer Time(s) 0.1326 | Time(s) 0.5307 
2023-12-01 16:52:07,591:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 2;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:07,592:INFO::Validation loss decreased (0.412761 --> 0.407832).  Saving model ...
2023-12-01 16:52:07,595:INFO::Epoch: 117
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:07,596:INFO::its now!!!!!!!!5
2023-12-01 16:52:07,750:INFO::its now!!!!!!!!0
2023-12-01 16:52:07,751:INFO::its now!!!!!!!!3
2023-12-01 16:52:07,776:INFO::its now!!!!!!!!5
2023-12-01 16:52:07,941:INFO::its now!!!!!!!!
2023-12-01 16:52:07,941:INFO::its now!!!!!!!! on 
2023-12-01 16:52:07,974:INFO::its now!!!!!!!!5
2023-12-01 16:52:08,114:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:08,115:INFO::Epoch 00117 | lr 0.00050 | Train_Loss 0.1684 | Train_Classification_Loss 0.2557 | Dmon_Loss -0.1745 | Val_Loss 0.4031 | Search Time(s) 0.3780 | Infer Time(s) 0.1432 | Time(s) 0.5212 
2023-12-01 16:52:08,155:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:08,156:INFO::Validation loss decreased (0.407832 --> 0.403074).  Saving model ...
2023-12-01 16:52:08,159:INFO::Epoch: 118
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:08,160:INFO::its now!!!!!!!!5
2023-12-01 16:52:08,325:INFO::its now!!!!!!!!0
2023-12-01 16:52:08,326:INFO::its now!!!!!!!!3
2023-12-01 16:52:08,351:INFO::its now!!!!!!!!5
2023-12-01 16:52:08,511:INFO::its now!!!!!!!!
2023-12-01 16:52:08,511:INFO::its now!!!!!!!! on 
2023-12-01 16:52:08,563:INFO::its now!!!!!!!!5
2023-12-01 16:52:08,721:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:08,722:INFO::Epoch 00118 | lr 0.00050 | Train_Loss 0.1700 | Train_Classification_Loss 0.2574 | Dmon_Loss -0.1749 | Val_Loss 0.3984 | Search Time(s) 0.3895 | Infer Time(s) 0.1745 | Time(s) 0.5640 
2023-12-01 16:52:08,764:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:08,765:INFO::Validation loss decreased (0.403074 --> 0.398415).  Saving model ...
2023-12-01 16:52:08,769:INFO::Epoch: 119
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:08,770:INFO::its now!!!!!!!!5
2023-12-01 16:52:08,926:INFO::its now!!!!!!!!0
2023-12-01 16:52:08,927:INFO::its now!!!!!!!!3
2023-12-01 16:52:08,969:INFO::its now!!!!!!!!5
2023-12-01 16:52:09,129:INFO::its now!!!!!!!!
2023-12-01 16:52:09,129:INFO::its now!!!!!!!! on 
2023-12-01 16:52:09,162:INFO::its now!!!!!!!!5
2023-12-01 16:52:09,298:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:09,299:INFO::Epoch 00119 | lr 0.00050 | Train_Loss 0.1571 | Train_Classification_Loss 0.2461 | Dmon_Loss -0.1780 | Val_Loss 0.3939 | Search Time(s) 0.3915 | Infer Time(s) 0.1412 | Time(s) 0.5327 
2023-12-01 16:52:09,336:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 2;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:09,337:INFO::Validation loss decreased (0.398415 --> 0.393894).  Saving model ...
2023-12-01 16:52:09,340:INFO::Epoch: 120
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:09,341:INFO::its now!!!!!!!!5
2023-12-01 16:52:09,495:INFO::its now!!!!!!!!0
2023-12-01 16:52:09,496:INFO::its now!!!!!!!!3
2023-12-01 16:52:09,524:INFO::its now!!!!!!!!5
2023-12-01 16:52:09,679:INFO::its now!!!!!!!!
2023-12-01 16:52:09,679:INFO::its now!!!!!!!! on 
2023-12-01 16:52:09,718:INFO::its now!!!!!!!!5
2023-12-01 16:52:09,884:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:09,886:INFO::Epoch 00120 | lr 0.00050 | Train_Loss 0.1489 | Train_Classification_Loss 0.2390 | Dmon_Loss -0.1803 | Val_Loss 0.3895 | Search Time(s) 0.3749 | Infer Time(s) 0.1716 | Time(s) 0.5465 
2023-12-01 16:52:09,942:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:09,943:INFO::Validation loss decreased (0.393894 --> 0.389507).  Saving model ...
2023-12-01 16:52:09,949:INFO::Epoch: 121
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:09,950:INFO::its now!!!!!!!!5
2023-12-01 16:52:10,129:INFO::its now!!!!!!!!0
2023-12-01 16:52:10,130:INFO::its now!!!!!!!!3
2023-12-01 16:52:10,159:INFO::its now!!!!!!!!5
2023-12-01 16:52:10,308:INFO::its now!!!!!!!!
2023-12-01 16:52:10,308:INFO::its now!!!!!!!! on 
2023-12-01 16:52:10,346:INFO::its now!!!!!!!!5
2023-12-01 16:52:10,494:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:10,495:INFO::Epoch 00121 | lr 0.00050 | Train_Loss 0.1499 | Train_Classification_Loss 0.2405 | Dmon_Loss -0.1812 | Val_Loss 0.3853 | Search Time(s) 0.3962 | Infer Time(s) 0.1536 | Time(s) 0.5498 
2023-12-01 16:52:10,532:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:10,533:INFO::Validation loss decreased (0.389507 --> 0.385263).  Saving model ...
2023-12-01 16:52:10,536:INFO::Epoch: 122
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:10,536:INFO::its now!!!!!!!!5
2023-12-01 16:52:10,718:INFO::its now!!!!!!!!0
2023-12-01 16:52:10,718:INFO::its now!!!!!!!!3
2023-12-01 16:52:10,744:INFO::its now!!!!!!!!5
2023-12-01 16:52:10,889:INFO::its now!!!!!!!!
2023-12-01 16:52:10,889:INFO::its now!!!!!!!! on 
2023-12-01 16:52:10,923:INFO::its now!!!!!!!!5
2023-12-01 16:52:11,100:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:11,101:INFO::Epoch 00122 | lr 0.00050 | Train_Loss 0.1442 | Train_Classification_Loss 0.2356 | Dmon_Loss -0.1827 | Val_Loss 0.3812 | Search Time(s) 0.3846 | Infer Time(s) 0.1815 | Time(s) 0.5662 
2023-12-01 16:52:11,140:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 2;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 1;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:11,141:INFO::Validation loss decreased (0.385263 --> 0.381221).  Saving model ...
2023-12-01 16:52:11,145:INFO::Epoch: 123
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:11,146:INFO::its now!!!!!!!!5
2023-12-01 16:52:11,367:INFO::its now!!!!!!!!0
2023-12-01 16:52:11,368:INFO::its now!!!!!!!!3
2023-12-01 16:52:11,393:INFO::its now!!!!!!!!5
2023-12-01 16:52:11,582:INFO::its now!!!!!!!!
2023-12-01 16:52:11,582:INFO::its now!!!!!!!! on 
2023-12-01 16:52:11,614:INFO::its now!!!!!!!!5
2023-12-01 16:52:11,765:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:11,766:INFO::Epoch 00123 | lr 0.00050 | Train_Loss 0.1299 | Train_Classification_Loss 0.2225 | Dmon_Loss -0.1851 | Val_Loss 0.3774 | Search Time(s) 0.4673 | Infer Time(s) 0.1566 | Time(s) 0.6239 
2023-12-01 16:52:11,815:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:11,816:INFO::Validation loss decreased (0.381221 --> 0.377396).  Saving model ...
2023-12-01 16:52:11,819:INFO::Epoch: 124
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:11,819:INFO::its now!!!!!!!!5
2023-12-01 16:52:11,964:INFO::its now!!!!!!!!0
2023-12-01 16:52:11,965:INFO::its now!!!!!!!!3
2023-12-01 16:52:11,994:INFO::its now!!!!!!!!5
2023-12-01 16:52:12,140:INFO::its now!!!!!!!!
2023-12-01 16:52:12,140:INFO::its now!!!!!!!! on 
2023-12-01 16:52:12,177:INFO::its now!!!!!!!!5
2023-12-01 16:52:12,321:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:12,322:INFO::Epoch 00124 | lr 0.00050 | Train_Loss 0.1277 | Train_Classification_Loss 0.2216 | Dmon_Loss -0.1879 | Val_Loss 0.3737 | Search Time(s) 0.3576 | Infer Time(s) 0.1471 | Time(s) 0.5048 
2023-12-01 16:52:12,368:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:12,369:INFO::Validation loss decreased (0.377396 --> 0.373743).  Saving model ...
2023-12-01 16:52:12,373:INFO::Epoch: 125
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:12,374:INFO::its now!!!!!!!!5
2023-12-01 16:52:12,517:INFO::its now!!!!!!!!0
2023-12-01 16:52:12,518:INFO::its now!!!!!!!!3
2023-12-01 16:52:12,549:INFO::its now!!!!!!!!5
2023-12-01 16:52:12,737:INFO::its now!!!!!!!!
2023-12-01 16:52:12,737:INFO::its now!!!!!!!! on 
2023-12-01 16:52:12,775:INFO::its now!!!!!!!!5
2023-12-01 16:52:12,944:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:12,946:INFO::Epoch 00125 | lr 0.00050 | Train_Loss 0.1146 | Train_Classification_Loss 0.2101 | Dmon_Loss -0.1910 | Val_Loss 0.3702 | Search Time(s) 0.3999 | Infer Time(s) 0.1745 | Time(s) 0.5745 
2023-12-01 16:52:12,984:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:12,985:INFO::Validation loss decreased (0.373743 --> 0.370237).  Saving model ...
2023-12-01 16:52:12,989:INFO::Epoch: 126
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:12,990:INFO::its now!!!!!!!!5
2023-12-01 16:52:13,138:INFO::its now!!!!!!!!0
2023-12-01 16:52:13,139:INFO::its now!!!!!!!!3
2023-12-01 16:52:13,163:INFO::its now!!!!!!!!5
2023-12-01 16:52:13,335:INFO::its now!!!!!!!!
2023-12-01 16:52:13,335:INFO::its now!!!!!!!! on 
2023-12-01 16:52:13,369:INFO::its now!!!!!!!!5
2023-12-01 16:52:13,528:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:13,530:INFO::Epoch 00126 | lr 0.00050 | Train_Loss 0.1062 | Train_Classification_Loss 0.2025 | Dmon_Loss -0.1925 | Val_Loss 0.3669 | Search Time(s) 0.3782 | Infer Time(s) 0.1656 | Time(s) 0.5437 
2023-12-01 16:52:13,569:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:13,570:INFO::Validation loss decreased (0.370237 --> 0.366873).  Saving model ...
2023-12-01 16:52:13,575:INFO::Epoch: 127
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:13,575:INFO::its now!!!!!!!!5
2023-12-01 16:52:13,726:INFO::its now!!!!!!!!0
2023-12-01 16:52:13,727:INFO::its now!!!!!!!!3
2023-12-01 16:52:13,757:INFO::its now!!!!!!!!5
2023-12-01 16:52:13,923:INFO::its now!!!!!!!!
2023-12-01 16:52:13,923:INFO::its now!!!!!!!! on 
2023-12-01 16:52:13,960:INFO::its now!!!!!!!!5
2023-12-01 16:52:14,115:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:14,116:INFO::Epoch 00127 | lr 0.00050 | Train_Loss 0.1041 | Train_Classification_Loss 0.2011 | Dmon_Loss -0.1939 | Val_Loss 0.3636 | Search Time(s) 0.3830 | Infer Time(s) 0.1602 | Time(s) 0.5432 
2023-12-01 16:52:14,162:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:14,163:INFO::Validation loss decreased (0.366873 --> 0.363639).  Saving model ...
2023-12-01 16:52:14,168:INFO::Epoch: 128
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:14,169:INFO::its now!!!!!!!!5
2023-12-01 16:52:14,323:INFO::its now!!!!!!!!0
2023-12-01 16:52:14,324:INFO::its now!!!!!!!!3
2023-12-01 16:52:14,348:INFO::its now!!!!!!!!5
2023-12-01 16:52:14,505:INFO::its now!!!!!!!!
2023-12-01 16:52:14,505:INFO::its now!!!!!!!! on 
2023-12-01 16:52:14,537:INFO::its now!!!!!!!!5
2023-12-01 16:52:14,709:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:14,710:INFO::Epoch 00128 | lr 0.00050 | Train_Loss 0.1032 | Train_Classification_Loss 0.2005 | Dmon_Loss -0.1948 | Val_Loss 0.3606 | Search Time(s) 0.3666 | Infer Time(s) 0.1781 | Time(s) 0.5447 
2023-12-01 16:52:14,762:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:14,763:INFO::Validation loss decreased (0.363639 --> 0.360589).  Saving model ...
2023-12-01 16:52:14,767:INFO::Epoch: 129
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:14,768:INFO::its now!!!!!!!!5
2023-12-01 16:52:14,916:INFO::its now!!!!!!!!0
2023-12-01 16:52:14,916:INFO::its now!!!!!!!!3
2023-12-01 16:52:14,941:INFO::its now!!!!!!!!5
2023-12-01 16:52:15,114:INFO::its now!!!!!!!!
2023-12-01 16:52:15,114:INFO::its now!!!!!!!! on 
2023-12-01 16:52:15,149:INFO::its now!!!!!!!!5
2023-12-01 16:52:15,295:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:15,296:INFO::Epoch 00129 | lr 0.00050 | Train_Loss 0.0976 | Train_Classification_Loss 0.1957 | Dmon_Loss -0.1962 | Val_Loss 0.3577 | Search Time(s) 0.3786 | Infer Time(s) 0.1522 | Time(s) 0.5308 
2023-12-01 16:52:15,361:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:15,362:INFO::Validation loss decreased (0.360589 --> 0.357731).  Saving model ...
2023-12-01 16:52:15,364:INFO::Epoch: 130
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:15,364:INFO::its now!!!!!!!!5
2023-12-01 16:52:15,526:INFO::its now!!!!!!!!0
2023-12-01 16:52:15,527:INFO::its now!!!!!!!!3
2023-12-01 16:52:15,556:INFO::its now!!!!!!!!5
2023-12-01 16:52:15,696:INFO::its now!!!!!!!!
2023-12-01 16:52:15,696:INFO::its now!!!!!!!! on 
2023-12-01 16:52:15,732:INFO::its now!!!!!!!!5
2023-12-01 16:52:15,884:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:15,886:INFO::Epoch 00130 | lr 0.00050 | Train_Loss 0.0896 | Train_Classification_Loss 0.1894 | Dmon_Loss -0.1996 | Val_Loss 0.3550 | Search Time(s) 0.3650 | Infer Time(s) 0.1576 | Time(s) 0.5226 
2023-12-01 16:52:15,931:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:15,932:INFO::Validation loss decreased (0.357731 --> 0.355012).  Saving model ...
2023-12-01 16:52:15,936:INFO::Epoch: 131
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:15,937:INFO::its now!!!!!!!!5
2023-12-01 16:52:16,068:INFO::its now!!!!!!!!0
2023-12-01 16:52:16,068:INFO::its now!!!!!!!!3
2023-12-01 16:52:16,094:INFO::its now!!!!!!!!5
2023-12-01 16:52:16,238:INFO::its now!!!!!!!!
2023-12-01 16:52:16,239:INFO::its now!!!!!!!! on 
2023-12-01 16:52:16,290:INFO::its now!!!!!!!!5
2023-12-01 16:52:16,445:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:16,447:INFO::Epoch 00131 | lr 0.00050 | Train_Loss 0.0891 | Train_Classification_Loss 0.1885 | Dmon_Loss -0.1989 | Val_Loss 0.3524 | Search Time(s) 0.3367 | Infer Time(s) 0.1751 | Time(s) 0.5118 
2023-12-01 16:52:16,509:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:16,649:INFO::Validation loss decreased (0.355012 --> 0.352439).  Saving model ...
2023-12-01 16:52:16,664:INFO::Epoch: 132
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:16,667:INFO::its now!!!!!!!!5
2023-12-01 16:52:17,031:INFO::its now!!!!!!!!0
2023-12-01 16:52:17,032:INFO::its now!!!!!!!!3
2023-12-01 16:52:17,083:INFO::its now!!!!!!!!5
2023-12-01 16:52:17,262:INFO::its now!!!!!!!!
2023-12-01 16:52:17,262:INFO::its now!!!!!!!! on 
2023-12-01 16:52:17,304:INFO::its now!!!!!!!!5
2023-12-01 16:52:17,466:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:17,468:INFO::Epoch 00132 | lr 0.00050 | Train_Loss 0.0802 | Train_Classification_Loss 0.1805 | Dmon_Loss -0.2006 | Val_Loss 0.3500 | Search Time(s) 0.6454 | Infer Time(s) 0.1695 | Time(s) 0.8150 
2023-12-01 16:52:17,522:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:17,524:INFO::Validation loss decreased (0.352439 --> 0.349993).  Saving model ...
2023-12-01 16:52:17,527:INFO::Epoch: 133
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:17,528:INFO::its now!!!!!!!!5
2023-12-01 16:52:17,700:INFO::its now!!!!!!!!0
2023-12-01 16:52:17,701:INFO::its now!!!!!!!!3
2023-12-01 16:52:17,727:INFO::its now!!!!!!!!5
2023-12-01 16:52:17,890:INFO::its now!!!!!!!!
2023-12-01 16:52:17,890:INFO::its now!!!!!!!! on 
2023-12-01 16:52:17,924:INFO::its now!!!!!!!!5
2023-12-01 16:52:18,059:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:18,060:INFO::Epoch 00133 | lr 0.00050 | Train_Loss 0.0816 | Train_Classification_Loss 0.1828 | Dmon_Loss -0.2025 | Val_Loss 0.3476 | Search Time(s) 0.3919 | Infer Time(s) 0.1416 | Time(s) 0.5336 
2023-12-01 16:52:18,098:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:18,099:INFO::Validation loss decreased (0.349993 --> 0.347617).  Saving model ...
2023-12-01 16:52:18,102:INFO::Epoch: 134
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:18,103:INFO::its now!!!!!!!!5
2023-12-01 16:52:18,262:INFO::its now!!!!!!!!0
2023-12-01 16:52:18,263:INFO::its now!!!!!!!!3
2023-12-01 16:52:18,293:INFO::its now!!!!!!!!5
2023-12-01 16:52:18,463:INFO::its now!!!!!!!!
2023-12-01 16:52:18,463:INFO::its now!!!!!!!! on 
2023-12-01 16:52:18,501:INFO::its now!!!!!!!!5
2023-12-01 16:52:18,685:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:18,687:INFO::Epoch 00134 | lr 0.00050 | Train_Loss 0.0759 | Train_Classification_Loss 0.1772 | Dmon_Loss -0.2026 | Val_Loss 0.3454 | Search Time(s) 0.3961 | Infer Time(s) 0.1905 | Time(s) 0.5866 
2023-12-01 16:52:18,730:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:18,731:INFO::Validation loss decreased (0.347617 --> 0.345365).  Saving model ...
2023-12-01 16:52:18,735:INFO::Epoch: 135
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:18,735:INFO::its now!!!!!!!!5
2023-12-01 16:52:18,881:INFO::its now!!!!!!!!0
2023-12-01 16:52:18,882:INFO::its now!!!!!!!!3
2023-12-01 16:52:18,926:INFO::its now!!!!!!!!5
2023-12-01 16:52:19,083:INFO::its now!!!!!!!!
2023-12-01 16:52:19,083:INFO::its now!!!!!!!! on 
2023-12-01 16:52:19,117:INFO::its now!!!!!!!!5
2023-12-01 16:52:19,255:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:19,257:INFO::Epoch 00135 | lr 0.00050 | Train_Loss 0.0666 | Train_Classification_Loss 0.1692 | Dmon_Loss -0.2053 | Val_Loss 0.3432 | Search Time(s) 0.3816 | Infer Time(s) 0.1426 | Time(s) 0.5242 
2023-12-01 16:52:19,304:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:19,305:INFO::Validation loss decreased (0.345365 --> 0.343163).  Saving model ...
2023-12-01 16:52:19,309:INFO::Epoch: 136
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:19,309:INFO::its now!!!!!!!!5
2023-12-01 16:52:19,474:INFO::its now!!!!!!!!0
2023-12-01 16:52:19,474:INFO::its now!!!!!!!!3
2023-12-01 16:52:19,499:INFO::its now!!!!!!!!5
2023-12-01 16:52:19,656:INFO::its now!!!!!!!!
2023-12-01 16:52:19,656:INFO::its now!!!!!!!! on 
2023-12-01 16:52:19,691:INFO::its now!!!!!!!!5
2023-12-01 16:52:19,830:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:19,832:INFO::Epoch 00136 | lr 0.00050 | Train_Loss 0.0582 | Train_Classification_Loss 0.1620 | Dmon_Loss -0.2075 | Val_Loss 0.3410 | Search Time(s) 0.3790 | Infer Time(s) 0.1456 | Time(s) 0.5246 
2023-12-01 16:52:19,878:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 2;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:19,879:INFO::Validation loss decreased (0.343163 --> 0.341039).  Saving model ...
2023-12-01 16:52:19,883:INFO::Epoch: 137
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:19,884:INFO::its now!!!!!!!!5
2023-12-01 16:52:20,045:INFO::its now!!!!!!!!0
2023-12-01 16:52:20,046:INFO::its now!!!!!!!!3
2023-12-01 16:52:20,072:INFO::its now!!!!!!!!5
2023-12-01 16:52:20,253:INFO::its now!!!!!!!!
2023-12-01 16:52:20,253:INFO::its now!!!!!!!! on 
2023-12-01 16:52:20,288:INFO::its now!!!!!!!!5
2023-12-01 16:52:20,438:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:20,440:INFO::Epoch 00137 | lr 0.00050 | Train_Loss 0.0603 | Train_Classification_Loss 0.1641 | Dmon_Loss -0.2077 | Val_Loss 0.3390 | Search Time(s) 0.4025 | Infer Time(s) 0.1561 | Time(s) 0.5586 
2023-12-01 16:52:20,491:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:20,492:INFO::Validation loss decreased (0.341039 --> 0.339020).  Saving model ...
2023-12-01 16:52:20,495:INFO::Epoch: 138
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:20,496:INFO::its now!!!!!!!!5
2023-12-01 16:52:20,645:INFO::its now!!!!!!!!0
2023-12-01 16:52:20,646:INFO::its now!!!!!!!!3
2023-12-01 16:52:20,693:INFO::its now!!!!!!!!5
2023-12-01 16:52:20,850:INFO::its now!!!!!!!!
2023-12-01 16:52:20,850:INFO::its now!!!!!!!! on 
2023-12-01 16:52:20,906:INFO::its now!!!!!!!!5
2023-12-01 16:52:21,078:INFO::Epoch 00138 | lr 0.00050 | Train_Loss 0.1150 | Train_Classification_Loss 0.2114 | Dmon_Loss -0.1928 | Val_Loss 0.3774 | Search Time(s) 0.3959 | Infer Time(s) 0.1905 | Time(s) 0.5864 
2023-12-01 16:52:21,130:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:52:21,130:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:52:21,133:INFO::Epoch: 139
tensor([[1.0000, 0.9994, 0.9998, 0.9998],
        [0.9987, 1.0000, 0.9998, 0.9994],
        [1.0000, 0.9998, 0.9998, 0.9994],
        [0.9981, 1.0000, 0.9998, 0.9998]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:21,133:INFO::its now!!!!!!!!5
2023-12-01 16:52:21,276:INFO::its now!!!!!!!!0
2023-12-01 16:52:21,277:INFO::its now!!!!!!!!3
2023-12-01 16:52:21,323:INFO::its now!!!!!!!!5
2023-12-01 16:52:21,493:INFO::its now!!!!!!!!
2023-12-01 16:52:21,493:INFO::its now!!!!!!!! on 
2023-12-01 16:52:21,545:INFO::its now!!!!!!!!5
2023-12-01 16:52:21,704:INFO::Epoch 00139 | lr 0.00050 | Train_Loss 0.0736 | Train_Classification_Loss 0.1762 | Dmon_Loss -0.2051 | Val_Loss 0.3564 | Search Time(s) 0.3965 | Infer Time(s) 0.1765 | Time(s) 0.5730 
2023-12-01 16:52:21,742:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:21,742:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:52:21,744:INFO::Epoch: 140
tensor([[1.0000, 0.9998, 1.0000, 1.0000],
        [0.9988, 1.0000, 1.0000, 0.9997],
        [1.0000, 1.0000, 1.0000, 0.9997],
        [0.9979, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:21,745:INFO::its now!!!!!!!!5
2023-12-01 16:52:21,908:INFO::its now!!!!!!!!0
2023-12-01 16:52:21,909:INFO::its now!!!!!!!!3
2023-12-01 16:52:21,957:INFO::its now!!!!!!!!5
2023-12-01 16:52:22,104:INFO::its now!!!!!!!!
2023-12-01 16:52:22,104:INFO::its now!!!!!!!! on 
2023-12-01 16:52:22,159:INFO::its now!!!!!!!!5
2023-12-01 16:52:22,371:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:22,373:INFO::Epoch 00140 | lr 0.00050 | Train_Loss 0.0508 | Train_Classification_Loss 0.1567 | Dmon_Loss -0.2116 | Val_Loss 0.3362 | Search Time(s) 0.3965 | Infer Time(s) 0.2320 | Time(s) 0.6285 
2023-12-01 16:52:22,445:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:22,446:INFO::Validation loss decreased (0.339020 --> 0.336228).  Saving model ...
2023-12-01 16:52:22,450:INFO::Epoch: 141
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [0.9992, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:22,451:INFO::its now!!!!!!!!5
2023-12-01 16:52:22,649:INFO::its now!!!!!!!!0
2023-12-01 16:52:22,650:INFO::its now!!!!!!!!3
2023-12-01 16:52:22,698:INFO::its now!!!!!!!!5
2023-12-01 16:52:22,871:INFO::its now!!!!!!!!
2023-12-01 16:52:22,871:INFO::its now!!!!!!!! on 
2023-12-01 16:52:22,909:INFO::its now!!!!!!!!5
2023-12-01 16:52:23,046:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:23,047:INFO::Epoch 00141 | lr 0.00050 | Train_Loss 0.0512 | Train_Classification_Loss 0.1569 | Dmon_Loss -0.2113 | Val_Loss 0.3353 | Search Time(s) 0.4568 | Infer Time(s) 0.1436 | Time(s) 0.6004 
2023-12-01 16:52:23,111:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:23,112:INFO::Validation loss decreased (0.336228 --> 0.335304).  Saving model ...
2023-12-01 16:52:23,117:INFO::Epoch: 142
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:23,117:INFO::its now!!!!!!!!5
2023-12-01 16:52:23,279:INFO::its now!!!!!!!!0
2023-12-01 16:52:23,299:INFO::its now!!!!!!!!3
2023-12-01 16:52:23,329:INFO::its now!!!!!!!!5
2023-12-01 16:52:23,490:INFO::its now!!!!!!!!
2023-12-01 16:52:23,490:INFO::its now!!!!!!!! on 
2023-12-01 16:52:23,526:INFO::its now!!!!!!!!5
2023-12-01 16:52:23,669:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:23,671:INFO::Epoch 00142 | lr 0.00050 | Train_Loss 0.0472 | Train_Classification_Loss 0.1532 | Dmon_Loss -0.2120 | Val_Loss 0.3341 | Search Time(s) 0.4066 | Infer Time(s) 0.1496 | Time(s) 0.5562 
2023-12-01 16:52:23,716:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:23,718:INFO::Validation loss decreased (0.335304 --> 0.334115).  Saving model ...
2023-12-01 16:52:23,722:INFO::Epoch: 143
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:23,723:INFO::its now!!!!!!!!5
2023-12-01 16:52:23,892:INFO::its now!!!!!!!!0
2023-12-01 16:52:23,893:INFO::its now!!!!!!!!3
2023-12-01 16:52:23,922:INFO::its now!!!!!!!!5
2023-12-01 16:52:24,075:INFO::its now!!!!!!!!
2023-12-01 16:52:24,076:INFO::its now!!!!!!!! on 
2023-12-01 16:52:24,112:INFO::its now!!!!!!!!5
2023-12-01 16:52:24,276:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:24,278:INFO::Epoch 00143 | lr 0.00050 | Train_Loss 0.0385 | Train_Classification_Loss 0.1457 | Dmon_Loss -0.2144 | Val_Loss 0.3325 | Search Time(s) 0.3875 | Infer Time(s) 0.1705 | Time(s) 0.5581 
2023-12-01 16:52:24,321:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 1;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:24,322:INFO::Validation loss decreased (0.334115 --> 0.332527).  Saving model ...
2023-12-01 16:52:24,327:INFO::Epoch: 144
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:24,328:INFO::its now!!!!!!!!5
2023-12-01 16:52:24,482:INFO::its now!!!!!!!!0
2023-12-01 16:52:24,483:INFO::its now!!!!!!!!3
2023-12-01 16:52:24,511:INFO::its now!!!!!!!!5
2023-12-01 16:52:24,665:INFO::its now!!!!!!!!
2023-12-01 16:52:24,666:INFO::its now!!!!!!!! on 
2023-12-01 16:52:24,704:INFO::its now!!!!!!!!5
2023-12-01 16:52:24,927:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:24,929:INFO::Epoch 00144 | lr 0.00050 | Train_Loss 0.0340 | Train_Classification_Loss 0.1418 | Dmon_Loss -0.2156 | Val_Loss 0.3308 | Search Time(s) 0.3760 | Infer Time(s) 0.2284 | Time(s) 0.6044 
2023-12-01 16:52:24,971:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 2;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:24,972:INFO::Validation loss decreased (0.332527 --> 0.330770).  Saving model ...
2023-12-01 16:52:24,976:INFO::Epoch: 145
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:24,977:INFO::its now!!!!!!!!5
2023-12-01 16:52:25,138:INFO::its now!!!!!!!!0
2023-12-01 16:52:25,139:INFO::its now!!!!!!!!3
2023-12-01 16:52:25,171:INFO::its now!!!!!!!!5
2023-12-01 16:52:25,333:INFO::its now!!!!!!!!
2023-12-01 16:52:25,333:INFO::its now!!!!!!!! on 
2023-12-01 16:52:25,372:INFO::its now!!!!!!!!5
2023-12-01 16:52:25,540:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:25,542:INFO::Epoch 00145 | lr 0.00050 | Train_Loss 0.0307 | Train_Classification_Loss 0.1387 | Dmon_Loss -0.2160 | Val_Loss 0.3288 | Search Time(s) 0.3953 | Infer Time(s) 0.1725 | Time(s) 0.5679 
2023-12-01 16:52:25,589:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 0;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:25,590:INFO::Validation loss decreased (0.330770 --> 0.328802).  Saving model ...
2023-12-01 16:52:25,594:INFO::Epoch: 146
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:25,594:INFO::its now!!!!!!!!5
2023-12-01 16:52:25,781:INFO::its now!!!!!!!!0
2023-12-01 16:52:25,781:INFO::its now!!!!!!!!3
2023-12-01 16:52:25,812:INFO::its now!!!!!!!!5
2023-12-01 16:52:25,979:INFO::its now!!!!!!!!
2023-12-01 16:52:25,979:INFO::its now!!!!!!!! on 
2023-12-01 16:52:26,018:INFO::its now!!!!!!!!5
2023-12-01 16:52:26,157:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:26,157:INFO::Epoch 00146 | lr 0.00050 | Train_Loss 0.0287 | Train_Classification_Loss 0.1366 | Dmon_Loss -0.2157 | Val_Loss 0.3267 | Search Time(s) 0.4219 | Infer Time(s) 0.1442 | Time(s) 0.5661 
2023-12-01 16:52:26,200:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:26,201:INFO::Validation loss decreased (0.328802 --> 0.326657).  Saving model ...
2023-12-01 16:52:26,206:INFO::Epoch: 147
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:26,206:INFO::its now!!!!!!!!5
2023-12-01 16:52:26,350:INFO::its now!!!!!!!!0
2023-12-01 16:52:26,351:INFO::its now!!!!!!!!3
2023-12-01 16:52:26,376:INFO::its now!!!!!!!!5
2023-12-01 16:52:26,552:INFO::its now!!!!!!!!
2023-12-01 16:52:26,552:INFO::its now!!!!!!!! on 
2023-12-01 16:52:26,585:INFO::its now!!!!!!!!5
2023-12-01 16:52:26,747:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:26,748:INFO::Epoch 00147 | lr 0.00050 | Train_Loss 0.0248 | Train_Classification_Loss 0.1337 | Dmon_Loss -0.2180 | Val_Loss 0.3245 | Search Time(s) 0.3766 | Infer Time(s) 0.1676 | Time(s) 0.5442 
2023-12-01 16:52:26,794:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:26,794:INFO::Validation loss decreased (0.326657 --> 0.324533).  Saving model ...
2023-12-01 16:52:26,797:INFO::Epoch: 148
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:26,798:INFO::its now!!!!!!!!5
2023-12-01 16:52:26,979:INFO::its now!!!!!!!!0
2023-12-01 16:52:26,980:INFO::its now!!!!!!!!3
2023-12-01 16:52:27,009:INFO::its now!!!!!!!!5
2023-12-01 16:52:27,158:INFO::its now!!!!!!!!
2023-12-01 16:52:27,158:INFO::its now!!!!!!!! on 
2023-12-01 16:52:27,196:INFO::its now!!!!!!!!5
2023-12-01 16:52:27,334:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:27,336:INFO::Epoch 00148 | lr 0.00050 | Train_Loss 0.0194 | Train_Classification_Loss 0.1289 | Dmon_Loss -0.2190 | Val_Loss 0.3224 | Search Time(s) 0.3966 | Infer Time(s) 0.1422 | Time(s) 0.5388 
2023-12-01 16:52:27,393:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:27,394:INFO::Validation loss decreased (0.324533 --> 0.322428).  Saving model ...
2023-12-01 16:52:27,398:INFO::Epoch: 149
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:27,399:INFO::its now!!!!!!!!5
2023-12-01 16:52:27,556:INFO::its now!!!!!!!!0
2023-12-01 16:52:27,557:INFO::its now!!!!!!!!3
2023-12-01 16:52:27,584:INFO::its now!!!!!!!!5
2023-12-01 16:52:27,741:INFO::its now!!!!!!!!
2023-12-01 16:52:27,741:INFO::its now!!!!!!!! on 
2023-12-01 16:52:27,779:INFO::its now!!!!!!!!5
2023-12-01 16:52:27,971:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:27,972:INFO::Epoch 00149 | lr 0.00050 | Train_Loss 0.0206 | Train_Classification_Loss 0.1301 | Dmon_Loss -0.2189 | Val_Loss 0.3205 | Search Time(s) 0.3790 | Infer Time(s) 0.1974 | Time(s) 0.5764 
2023-12-01 16:52:28,030:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 0;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:28,031:INFO::Validation loss decreased (0.322428 --> 0.320519).  Saving model ...
2023-12-01 16:52:28,034:INFO::Epoch: 150
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:28,035:INFO::its now!!!!!!!!5
2023-12-01 16:52:28,197:INFO::its now!!!!!!!!0
2023-12-01 16:52:28,197:INFO::its now!!!!!!!!3
2023-12-01 16:52:28,226:INFO::its now!!!!!!!!5
2023-12-01 16:52:28,403:INFO::its now!!!!!!!!
2023-12-01 16:52:28,403:INFO::its now!!!!!!!! on 
2023-12-01 16:52:28,446:INFO::its now!!!!!!!!5
2023-12-01 16:52:28,606:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:28,608:INFO::Epoch 00150 | lr 0.00050 | Train_Loss 0.0121 | Train_Classification_Loss 0.1224 | Dmon_Loss -0.2206 | Val_Loss 0.3187 | Search Time(s) 0.4091 | Infer Time(s) 0.1656 | Time(s) 0.5746 
2023-12-01 16:52:28,650:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 1;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:28,651:INFO::Validation loss decreased (0.320519 --> 0.318727).  Saving model ...
2023-12-01 16:52:28,654:INFO::Epoch: 151
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:28,655:INFO::its now!!!!!!!!5
2023-12-01 16:52:28,807:INFO::its now!!!!!!!!0
2023-12-01 16:52:28,808:INFO::its now!!!!!!!!3
2023-12-01 16:52:28,838:INFO::its now!!!!!!!!5
2023-12-01 16:52:29,009:INFO::its now!!!!!!!!
2023-12-01 16:52:29,010:INFO::its now!!!!!!!! on 
2023-12-01 16:52:29,049:INFO::its now!!!!!!!!5
2023-12-01 16:52:29,205:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:29,207:INFO::Epoch 00151 | lr 0.00050 | Train_Loss 0.0094 | Train_Classification_Loss 0.1200 | Dmon_Loss -0.2212 | Val_Loss 0.3172 | Search Time(s) 0.3939 | Infer Time(s) 0.1602 | Time(s) 0.5541 
2023-12-01 16:52:29,250:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:29,251:INFO::Validation loss decreased (0.318727 --> 0.317200).  Saving model ...
2023-12-01 16:52:29,254:INFO::Epoch: 152
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:29,254:INFO::its now!!!!!!!!5
2023-12-01 16:52:29,416:INFO::its now!!!!!!!!0
2023-12-01 16:52:29,417:INFO::its now!!!!!!!!3
2023-12-01 16:52:29,445:INFO::its now!!!!!!!!5
2023-12-01 16:52:29,597:INFO::its now!!!!!!!!
2023-12-01 16:52:29,598:INFO::its now!!!!!!!! on 
2023-12-01 16:52:29,635:INFO::its now!!!!!!!!5
2023-12-01 16:52:29,771:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:29,773:INFO::Epoch 00152 | lr 0.00050 | Train_Loss 0.0129 | Train_Classification_Loss 0.1232 | Dmon_Loss -0.2207 | Val_Loss 0.3158 | Search Time(s) 0.3776 | Infer Time(s) 0.1426 | Time(s) 0.5202 
2023-12-01 16:52:29,816:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 3;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 2;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:29,817:INFO::Validation loss decreased (0.317200 --> 0.315849).  Saving model ...
2023-12-01 16:52:29,823:INFO::Epoch: 153
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:29,824:INFO::its now!!!!!!!!5
2023-12-01 16:52:29,987:INFO::its now!!!!!!!!0
2023-12-01 16:52:29,988:INFO::its now!!!!!!!!3
2023-12-01 16:52:30,018:INFO::its now!!!!!!!!5
2023-12-01 16:52:30,187:INFO::its now!!!!!!!!
2023-12-01 16:52:30,187:INFO::its now!!!!!!!! on 
2023-12-01 16:52:30,224:INFO::its now!!!!!!!!5
2023-12-01 16:52:30,380:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:30,381:INFO::Epoch 00153 | lr 0.00050 | Train_Loss 0.0050 | Train_Classification_Loss 0.1160 | Dmon_Loss -0.2221 | Val_Loss 0.3147 | Search Time(s) 0.3995 | Infer Time(s) 0.1631 | Time(s) 0.5626 
2023-12-01 16:52:30,423:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:30,424:INFO::Validation loss decreased (0.315849 --> 0.314690).  Saving model ...
2023-12-01 16:52:30,430:INFO::Epoch: 154
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:30,431:INFO::its now!!!!!!!!5
2023-12-01 16:52:30,579:INFO::its now!!!!!!!!0
2023-12-01 16:52:30,580:INFO::its now!!!!!!!!3
2023-12-01 16:52:30,610:INFO::its now!!!!!!!!5
2023-12-01 16:52:30,778:INFO::its now!!!!!!!!
2023-12-01 16:52:30,778:INFO::its now!!!!!!!! on 
2023-12-01 16:52:30,834:INFO::its now!!!!!!!!5
2023-12-01 16:52:30,983:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:30,985:INFO::Epoch 00154 | lr 0.00050 | Train_Loss 0.0052 | Train_Classification_Loss 0.1165 | Dmon_Loss -0.2226 | Val_Loss 0.3137 | Search Time(s) 0.3929 | Infer Time(s) 0.1656 | Time(s) 0.5585 
2023-12-01 16:52:31,058:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:31,059:INFO::Validation loss decreased (0.314690 --> 0.313664).  Saving model ...
2023-12-01 16:52:31,064:INFO::Epoch: 155
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:31,065:INFO::its now!!!!!!!!5
2023-12-01 16:52:31,217:INFO::its now!!!!!!!!0
2023-12-01 16:52:31,218:INFO::its now!!!!!!!!3
2023-12-01 16:52:31,261:INFO::its now!!!!!!!!5
2023-12-01 16:52:31,399:INFO::its now!!!!!!!!
2023-12-01 16:52:31,399:INFO::its now!!!!!!!! on 
2023-12-01 16:52:31,450:INFO::its now!!!!!!!!5
2023-12-01 16:52:31,601:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:31,602:INFO::Epoch 00155 | lr 0.00050 | Train_Loss -0.0046 | Train_Classification_Loss 0.1075 | Dmon_Loss -0.2242 | Val_Loss 0.3128 | Search Time(s) 0.3713 | Infer Time(s) 0.1705 | Time(s) 0.5418 
2023-12-01 16:52:31,644:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:31,645:INFO::Validation loss decreased (0.313664 --> 0.312762).  Saving model ...
2023-12-01 16:52:31,648:INFO::Epoch: 156
tensor([[1.0000, 0.9998, 0.9998, 0.9998],
        [1.0000, 0.9998, 0.9998, 0.9998],
        [1.0000, 0.9998, 0.9998, 0.9998],
        [0.9991, 1.0000, 0.9998, 0.9998]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:31,648:INFO::its now!!!!!!!!5
2023-12-01 16:52:31,804:INFO::its now!!!!!!!!0
2023-12-01 16:52:31,805:INFO::its now!!!!!!!!3
2023-12-01 16:52:31,852:INFO::its now!!!!!!!!5
2023-12-01 16:52:32,008:INFO::its now!!!!!!!!
2023-12-01 16:52:32,008:INFO::its now!!!!!!!! on 
2023-12-01 16:52:32,045:INFO::its now!!!!!!!!5
2023-12-01 16:52:32,190:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:32,192:INFO::Epoch 00156 | lr 0.00050 | Train_Loss -0.0014 | Train_Classification_Loss 0.1109 | Dmon_Loss -0.2247 | Val_Loss 0.3121 | Search Time(s) 0.3949 | Infer Time(s) 0.1492 | Time(s) 0.5441 
2023-12-01 16:52:32,232:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:32,233:INFO::Validation loss decreased (0.312762 --> 0.312095).  Saving model ...
2023-12-01 16:52:32,236:INFO::Epoch: 157
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:32,237:INFO::its now!!!!!!!!5
2023-12-01 16:52:32,389:INFO::its now!!!!!!!!0
2023-12-01 16:52:32,390:INFO::its now!!!!!!!!3
2023-12-01 16:52:32,419:INFO::its now!!!!!!!!5
2023-12-01 16:52:32,606:INFO::its now!!!!!!!!
2023-12-01 16:52:32,606:INFO::its now!!!!!!!! on 
2023-12-01 16:52:32,642:INFO::its now!!!!!!!!5
2023-12-01 16:52:32,771:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:32,773:INFO::Epoch 00157 | lr 0.00050 | Train_Loss -0.0043 | Train_Classification_Loss 0.1082 | Dmon_Loss -0.2250 | Val_Loss 0.3116 | Search Time(s) 0.4015 | Infer Time(s) 0.1366 | Time(s) 0.5382 
2023-12-01 16:52:32,814:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:32,815:INFO::Validation loss decreased (0.312095 --> 0.311557).  Saving model ...
2023-12-01 16:52:32,818:INFO::Epoch: 158
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:32,819:INFO::its now!!!!!!!!5
2023-12-01 16:52:32,970:INFO::its now!!!!!!!!0
2023-12-01 16:52:32,971:INFO::its now!!!!!!!!3
2023-12-01 16:52:33,000:INFO::its now!!!!!!!!5
2023-12-01 16:52:33,147:INFO::its now!!!!!!!!
2023-12-01 16:52:33,147:INFO::its now!!!!!!!! on 
2023-12-01 16:52:33,184:INFO::its now!!!!!!!!5
2023-12-01 16:52:33,364:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:33,365:INFO::Epoch 00158 | lr 0.00050 | Train_Loss -0.0046 | Train_Classification_Loss 0.1086 | Dmon_Loss -0.2264 | Val_Loss 0.3111 | Search Time(s) 0.3626 | Infer Time(s) 0.1861 | Time(s) 0.5487 
2023-12-01 16:52:33,428:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:33,429:INFO::Validation loss decreased (0.311557 --> 0.311137).  Saving model ...
2023-12-01 16:52:33,434:INFO::Epoch: 159
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:33,435:INFO::its now!!!!!!!!5
2023-12-01 16:52:33,656:INFO::its now!!!!!!!!0
2023-12-01 16:52:33,657:INFO::its now!!!!!!!!3
2023-12-01 16:52:33,687:INFO::its now!!!!!!!!5
2023-12-01 16:52:33,852:INFO::its now!!!!!!!!
2023-12-01 16:52:33,852:INFO::its now!!!!!!!! on 
2023-12-01 16:52:33,890:INFO::its now!!!!!!!!5
2023-12-01 16:52:34,076:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:34,077:INFO::Epoch 00159 | lr 0.00050 | Train_Loss -0.0074 | Train_Classification_Loss 0.1056 | Dmon_Loss -0.2260 | Val_Loss 0.3110 | Search Time(s) 0.4528 | Infer Time(s) 0.1931 | Time(s) 0.6459 
2023-12-01 16:52:34,120:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:34,121:INFO::Validation loss decreased (0.311137 --> 0.310950).  Saving model ...
2023-12-01 16:52:34,124:INFO::Epoch: 160
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 0.9999, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:34,124:INFO::its now!!!!!!!!5
2023-12-01 16:52:34,279:INFO::its now!!!!!!!!0
2023-12-01 16:52:34,280:INFO::its now!!!!!!!!3
2023-12-01 16:52:34,325:INFO::its now!!!!!!!!5
2023-12-01 16:52:34,510:INFO::its now!!!!!!!!
2023-12-01 16:52:34,510:INFO::its now!!!!!!!! on 
2023-12-01 16:52:34,543:INFO::its now!!!!!!!!5
2023-12-01 16:52:34,680:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:34,681:INFO::Epoch 00160 | lr 0.00050 | Train_Loss -0.0095 | Train_Classification_Loss 0.1043 | Dmon_Loss -0.2277 | Val_Loss 0.3108 | Search Time(s) 0.4174 | Infer Time(s) 0.1416 | Time(s) 0.5591 
2023-12-01 16:52:34,736:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:34,737:INFO::Validation loss decreased (0.310950 --> 0.310758).  Saving model ...
2023-12-01 16:52:34,740:INFO::Epoch: 161
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 0.9999, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:34,741:INFO::its now!!!!!!!!5
2023-12-01 16:52:34,889:INFO::its now!!!!!!!!0
2023-12-01 16:52:34,890:INFO::its now!!!!!!!!3
2023-12-01 16:52:34,914:INFO::its now!!!!!!!!5
2023-12-01 16:52:35,071:INFO::its now!!!!!!!!
2023-12-01 16:52:35,071:INFO::its now!!!!!!!! on 
2023-12-01 16:52:35,104:INFO::its now!!!!!!!!5
2023-12-01 16:52:35,279:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:35,281:INFO::Epoch 00161 | lr 0.00050 | Train_Loss -0.0130 | Train_Classification_Loss 0.1010 | Dmon_Loss -0.2279 | Val_Loss 0.3105 | Search Time(s) 0.3620 | Infer Time(s) 0.1795 | Time(s) 0.5416 
2023-12-01 16:52:35,325:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 0;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 2;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:35,326:INFO::Validation loss decreased (0.310758 --> 0.310518).  Saving model ...
2023-12-01 16:52:35,329:INFO::Epoch: 162
tensor([[1.0000, 0.9990, 0.9990, 0.9990],
        [1.0000, 0.9990, 0.9987, 0.9990],
        [1.0000, 0.9988, 0.9990, 0.9990],
        [1.0000, 0.9986, 0.9990, 0.9990]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:35,330:INFO::its now!!!!!!!!5
2023-12-01 16:52:35,505:INFO::its now!!!!!!!!0
2023-12-01 16:52:35,506:INFO::its now!!!!!!!!3
2023-12-01 16:52:35,532:INFO::its now!!!!!!!!5
2023-12-01 16:52:35,693:INFO::its now!!!!!!!!
2023-12-01 16:52:35,693:INFO::its now!!!!!!!! on 
2023-12-01 16:52:35,727:INFO::its now!!!!!!!!5
2023-12-01 16:52:35,901:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:35,902:INFO::Epoch 00162 | lr 0.00050 | Train_Loss -0.0164 | Train_Classification_Loss 0.0977 | Dmon_Loss -0.2282 | Val_Loss 0.3104 | Search Time(s) 0.3959 | Infer Time(s) 0.1785 | Time(s) 0.5744 
2023-12-01 16:52:35,940:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:35,941:INFO::Validation loss decreased (0.310518 --> 0.310396).  Saving model ...
2023-12-01 16:52:35,945:INFO::Epoch: 163
tensor([[1.0000, 0.9995, 0.9995, 0.9995],
        [1.0000, 0.9995, 0.9991, 0.9995],
        [1.0000, 0.9992, 0.9995, 0.9995],
        [1.0000, 0.9989, 0.9995, 0.9995]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:35,945:INFO::its now!!!!!!!!5
2023-12-01 16:52:36,093:INFO::its now!!!!!!!!0
2023-12-01 16:52:36,094:INFO::its now!!!!!!!!3
2023-12-01 16:52:36,123:INFO::its now!!!!!!!!5
2023-12-01 16:52:36,281:INFO::its now!!!!!!!!
2023-12-01 16:52:36,281:INFO::its now!!!!!!!! on 
2023-12-01 16:52:36,319:INFO::its now!!!!!!!!5
2023-12-01 16:52:36,473:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:36,474:INFO::Epoch 00163 | lr 0.00050 | Train_Loss -0.0184 | Train_Classification_Loss 0.0957 | Dmon_Loss -0.2282 | Val_Loss 0.3102 | Search Time(s) 0.3720 | Infer Time(s) 0.1606 | Time(s) 0.5326 
2023-12-01 16:52:36,518:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 2;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:36,519:INFO::Validation loss decreased (0.310396 --> 0.310235).  Saving model ...
2023-12-01 16:52:36,521:INFO::Epoch: 164
tensor([[1.0000, 0.9990, 0.9989, 0.9989],
        [1.0000, 0.9990, 0.9985, 0.9990],
        [1.0000, 0.9986, 0.9990, 0.9990],
        [1.0000, 0.9983, 0.9989, 0.9989]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:36,522:INFO::its now!!!!!!!!5
2023-12-01 16:52:36,680:INFO::its now!!!!!!!!0
2023-12-01 16:52:36,681:INFO::its now!!!!!!!!3
2023-12-01 16:52:36,711:INFO::its now!!!!!!!!5
2023-12-01 16:52:36,880:INFO::its now!!!!!!!!
2023-12-01 16:52:36,880:INFO::its now!!!!!!!! on 
2023-12-01 16:52:36,919:INFO::its now!!!!!!!!5
2023-12-01 16:52:37,062:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:37,064:INFO::Epoch 00164 | lr 0.00050 | Train_Loss -0.0171 | Train_Classification_Loss 0.0979 | Dmon_Loss -0.2299 | Val_Loss 0.3100 | Search Time(s) 0.3929 | Infer Time(s) 0.1496 | Time(s) 0.5426 
2023-12-01 16:52:37,121:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:37,122:INFO::Validation loss decreased (0.310235 --> 0.309981).  Saving model ...
2023-12-01 16:52:37,125:INFO::Epoch: 165
tensor([[1.0000, 0.9986, 0.9985, 0.9985],
        [1.0000, 0.9986, 0.9980, 0.9986],
        [1.0000, 0.9982, 0.9986, 0.9986],
        [1.0000, 0.9978, 0.9985, 0.9985]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:37,125:INFO::its now!!!!!!!!5
2023-12-01 16:52:37,284:INFO::its now!!!!!!!!0
2023-12-01 16:52:37,284:INFO::its now!!!!!!!!3
2023-12-01 16:52:37,309:INFO::its now!!!!!!!!5
2023-12-01 16:52:37,472:INFO::its now!!!!!!!!
2023-12-01 16:52:37,473:INFO::its now!!!!!!!! on 
2023-12-01 16:52:37,506:INFO::its now!!!!!!!!5
2023-12-01 16:52:37,630:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:37,632:INFO::Epoch 00165 | lr 0.00050 | Train_Loss -0.0191 | Train_Classification_Loss 0.0962 | Dmon_Loss -0.2306 | Val_Loss 0.3095 | Search Time(s) 0.3780 | Infer Time(s) 0.1297 | Time(s) 0.5076 
2023-12-01 16:52:37,668:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:37,669:INFO::Validation loss decreased (0.309981 --> 0.309470).  Saving model ...
2023-12-01 16:52:37,672:INFO::Epoch: 166
tensor([[1.0000, 0.9993, 0.9993, 0.9993],
        [1.0000, 0.9993, 0.9988, 0.9993],
        [1.0000, 0.9989, 0.9993, 0.9993],
        [1.0000, 0.9986, 0.9993, 0.9993]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:37,673:INFO::its now!!!!!!!!5
2023-12-01 16:52:37,828:INFO::its now!!!!!!!!0
2023-12-01 16:52:37,829:INFO::its now!!!!!!!!3
2023-12-01 16:52:37,853:INFO::its now!!!!!!!!5
2023-12-01 16:52:37,999:INFO::its now!!!!!!!!
2023-12-01 16:52:38,000:INFO::its now!!!!!!!! on 
2023-12-01 16:52:38,034:INFO::its now!!!!!!!!5
2023-12-01 16:52:38,188:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:38,190:INFO::Epoch 00166 | lr 0.00050 | Train_Loss -0.0253 | Train_Classification_Loss 0.0903 | Dmon_Loss -0.2313 | Val_Loss 0.3087 | Search Time(s) 0.3580 | Infer Time(s) 0.1606 | Time(s) 0.5186 
2023-12-01 16:52:38,227:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:38,228:INFO::Validation loss decreased (0.309470 --> 0.308711).  Saving model ...
2023-12-01 16:52:38,231:INFO::Epoch: 167
tensor([[1.0000, 0.9992, 0.9992, 0.9992],
        [1.0000, 0.9992, 0.9987, 0.9992],
        [1.0000, 0.9988, 0.9992, 0.9992],
        [1.0000, 0.9984, 0.9992, 0.9992]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:38,231:INFO::its now!!!!!!!!5
2023-12-01 16:52:38,373:INFO::its now!!!!!!!!0
2023-12-01 16:52:38,374:INFO::its now!!!!!!!!3
2023-12-01 16:52:38,398:INFO::its now!!!!!!!!5
2023-12-01 16:52:38,589:INFO::its now!!!!!!!!
2023-12-01 16:52:38,589:INFO::its now!!!!!!!! on 
2023-12-01 16:52:38,623:INFO::its now!!!!!!!!5
2023-12-01 16:52:38,776:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:38,778:INFO::Epoch 00167 | lr 0.00050 | Train_Loss -0.0255 | Train_Classification_Loss 0.0902 | Dmon_Loss -0.2314 | Val_Loss 0.3078 | Search Time(s) 0.3880 | Infer Time(s) 0.1606 | Time(s) 0.5486 
2023-12-01 16:52:38,832:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 2;	26108: 0;	26109: 1;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:38,833:INFO::Validation loss decreased (0.308711 --> 0.307834).  Saving model ...
2023-12-01 16:52:38,839:INFO::Epoch: 168
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9998, 1.0000],
        [1.0000, 0.9999, 1.0000, 1.0000],
        [1.0000, 0.9995, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:38,840:INFO::its now!!!!!!!!5
2023-12-01 16:52:39,028:INFO::its now!!!!!!!!0
2023-12-01 16:52:39,028:INFO::its now!!!!!!!!3
2023-12-01 16:52:39,053:INFO::its now!!!!!!!!5
2023-12-01 16:52:39,234:INFO::its now!!!!!!!!
2023-12-01 16:52:39,234:INFO::its now!!!!!!!! on 
2023-12-01 16:52:39,285:INFO::its now!!!!!!!!5
2023-12-01 16:52:39,439:INFO::Epoch 00168 | lr 0.00050 | Train_Loss 0.0262 | Train_Classification_Loss 0.1328 | Dmon_Loss -0.2132 | Val_Loss 0.3338 | Search Time(s) 0.4308 | Infer Time(s) 0.1745 | Time(s) 0.6054 
2023-12-01 16:52:39,490:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 0;	
2023-12-01 16:52:39,491:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:52:39,494:INFO::Epoch: 169
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9999, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:39,495:INFO::its now!!!!!!!!5
2023-12-01 16:52:39,663:INFO::its now!!!!!!!!0
2023-12-01 16:52:39,664:INFO::its now!!!!!!!!3
2023-12-01 16:52:39,707:INFO::its now!!!!!!!!5
2023-12-01 16:52:39,855:INFO::its now!!!!!!!!
2023-12-01 16:52:39,855:INFO::its now!!!!!!!! on 
2023-12-01 16:52:39,905:INFO::its now!!!!!!!!5
2023-12-01 16:52:40,057:INFO::Epoch 00169 | lr 0.00050 | Train_Loss -0.0058 | Train_Classification_Loss 0.1067 | Dmon_Loss -0.2250 | Val_Loss 0.3233 | Search Time(s) 0.3929 | Infer Time(s) 0.1715 | Time(s) 0.5645 
2023-12-01 16:52:40,114:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:40,115:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:52:40,118:INFO::Epoch: 170
tensor([[1.0000, 0.9984, 0.9984, 0.9984],
        [0.9975, 1.0000, 0.9983, 0.9984],
        [1.0000, 0.9984, 0.9984, 0.9984],
        [1.0000, 0.9984, 0.9984, 0.9983]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:40,118:INFO::its now!!!!!!!!5
2023-12-01 16:52:40,271:INFO::its now!!!!!!!!0
2023-12-01 16:52:40,272:INFO::its now!!!!!!!!3
2023-12-01 16:52:40,319:INFO::its now!!!!!!!!5
2023-12-01 16:52:40,489:INFO::its now!!!!!!!!
2023-12-01 16:52:40,489:INFO::its now!!!!!!!! on 
2023-12-01 16:52:40,545:INFO::its now!!!!!!!!5
2023-12-01 16:52:40,702:INFO::Epoch 00170 | lr 0.00050 | Train_Loss 0.0199 | Train_Classification_Loss 0.1276 | Dmon_Loss -0.2154 | Val_Loss 0.3265 | Search Time(s) 0.4129 | Infer Time(s) 0.1745 | Time(s) 0.5874 
2023-12-01 16:52:40,752:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 0;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 2;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 2;	26127: 1;	
2023-12-01 16:52:40,753:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:52:40,756:INFO::Epoch: 171
tensor([[1.0000, 0.9960, 0.9959, 0.9960],
        [0.9943, 1.0000, 0.9959, 0.9960],
        [1.0000, 0.9959, 0.9961, 0.9960],
        [1.0000, 0.9960, 0.9959, 0.9959]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:40,757:INFO::its now!!!!!!!!5
2023-12-01 16:52:40,907:INFO::its now!!!!!!!!0
2023-12-01 16:52:40,908:INFO::its now!!!!!!!!3
2023-12-01 16:52:40,955:INFO::its now!!!!!!!!5
2023-12-01 16:52:41,162:INFO::its now!!!!!!!!
2023-12-01 16:52:41,162:INFO::its now!!!!!!!! on 
2023-12-01 16:52:41,216:INFO::its now!!!!!!!!5
2023-12-01 16:52:41,371:INFO::Epoch 00171 | lr 0.00050 | Train_Loss -0.0014 | Train_Classification_Loss 0.1112 | Dmon_Loss -0.2252 | Val_Loss 0.3262 | Search Time(s) 0.4418 | Infer Time(s) 0.1755 | Time(s) 0.6173 
2023-12-01 16:52:41,428:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:41,429:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 16:52:41,433:INFO::Epoch: 172
tensor([[1.0000, 0.9951, 0.9949, 0.9950],
        [0.9931, 1.0000, 0.9949, 0.9950],
        [1.0000, 0.9949, 0.9951, 0.9950],
        [1.0000, 0.9950, 0.9949, 0.9949]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:41,434:INFO::its now!!!!!!!!5
2023-12-01 16:52:41,572:INFO::its now!!!!!!!!0
2023-12-01 16:52:41,573:INFO::its now!!!!!!!!3
2023-12-01 16:52:41,600:INFO::its now!!!!!!!!5
2023-12-01 16:52:41,767:INFO::its now!!!!!!!!
2023-12-01 16:52:41,768:INFO::its now!!!!!!!! on 
2023-12-01 16:52:41,820:INFO::its now!!!!!!!!5
2023-12-01 16:52:41,962:INFO::Epoch 00172 | lr 0.00050 | Train_Loss 0.0125 | Train_Classification_Loss 0.1215 | Dmon_Loss -0.2180 | Val_Loss 0.3254 | Search Time(s) 0.3700 | Infer Time(s) 0.1626 | Time(s) 0.5326 
2023-12-01 16:52:42,000:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 0;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:42,001:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 16:52:42,004:INFO::Epoch: 173
tensor([[1.0000, 0.9997, 0.9949, 0.9997],
        [0.9921, 1.0000, 0.9997, 0.9997],
        [1.0000, 0.9997, 0.9997, 0.9945],
        [1.0000, 0.9997, 0.9945, 0.9997]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:42,005:INFO::its now!!!!!!!!5
2023-12-01 16:52:42,151:INFO::its now!!!!!!!!0
2023-12-01 16:52:42,151:INFO::its now!!!!!!!!3
2023-12-01 16:52:42,196:INFO::its now!!!!!!!!5
2023-12-01 16:52:42,353:INFO::its now!!!!!!!!
2023-12-01 16:52:42,353:INFO::its now!!!!!!!! on 
2023-12-01 16:52:42,406:INFO::its now!!!!!!!!5
2023-12-01 16:52:42,539:INFO::Epoch 00173 | lr 0.00050 | Train_Loss -0.0080 | Train_Classification_Loss 0.1043 | Dmon_Loss -0.2245 | Val_Loss 0.3240 | Search Time(s) 0.3880 | Infer Time(s) 0.1506 | Time(s) 0.5386 
2023-12-01 16:52:42,588:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 3;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:42,589:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 16:52:42,591:INFO::Epoch: 174
tensor([[1.0000, 1.0000, 0.9958, 1.0000],
        [0.9926, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9951],
        [1.0000, 1.0000, 0.9951, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:42,591:INFO::its now!!!!!!!!5
2023-12-01 16:52:42,764:INFO::its now!!!!!!!!0
2023-12-01 16:52:42,765:INFO::its now!!!!!!!!3
2023-12-01 16:52:42,812:INFO::its now!!!!!!!!5
2023-12-01 16:52:43,002:INFO::its now!!!!!!!!
2023-12-01 16:52:43,002:INFO::its now!!!!!!!! on 
2023-12-01 16:52:43,057:INFO::its now!!!!!!!!5
2023-12-01 16:52:43,209:INFO::Epoch 00174 | lr 0.00050 | Train_Loss 0.0017 | Train_Classification_Loss 0.1111 | Dmon_Loss -0.2189 | Val_Loss 0.3258 | Search Time(s) 0.4478 | Infer Time(s) 0.1725 | Time(s) 0.6203 
2023-12-01 16:52:43,253:INFO::cluster info:
0: 0;	1: 0;	2: 2;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 0;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 2;	37: 0;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 1;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:43,254:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 16:52:43,258:INFO::Epoch: 175
tensor([[1.0000, 1.0000, 0.9954, 1.0000],
        [0.9920, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9946],
        [1.0000, 1.0000, 0.9946, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:52:43,258:INFO::its now!!!!!!!!5
2023-12-01 16:52:43,407:INFO::its now!!!!!!!!0
2023-12-01 16:52:43,408:INFO::its now!!!!!!!!3
2023-12-01 16:52:43,461:INFO::its now!!!!!!!!5
2023-12-01 16:52:43,626:INFO::its now!!!!!!!!
2023-12-01 16:52:43,626:INFO::its now!!!!!!!! on 
2023-12-01 16:52:43,683:INFO::its now!!!!!!!!5
2023-12-01 16:52:43,850:INFO::Epoch 00175 | lr 0.00050 | Train_Loss -0.0030 | Train_Classification_Loss 0.1087 | Dmon_Loss -0.2234 | Val_Loss 0.3281 | Search Time(s) 0.4089 | Infer Time(s) 0.1855 | Time(s) 0.5944 
2023-12-01 16:52:43,901:INFO::cluster info:
0: 0;	1: 0;	2: 1;	3: 0;	4: 0;	5: 0;	6: 0;	7: 0;	8: 0;	9: 0;	10: 0;	11: 0;	12: 1;	13: 2;	14: 0;	15: 2;	16: 0;	17: 2;	18: 0;	19: 0;	20: 1;	21: 1;	22: 0;	23: 0;	24: 0;	25: 0;	26: 0;	27: 1;	28: 2;	29: 0;	30: 2;	31: 0;	32: 0;	33: 2;	34: 2;	35: 1;	36: 0;	37: 2;	38: 2;	39: 0;	40: 2;	41: 2;	42: 0;	43: 0;	44
26098: 1;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 2;	26106: 0;	26107: 0;	26108: 0;	26109: 2;	26110: 0;	26111: 1;	26112: 0;	26113: 2;	26114: 2;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 2;	26122: 0;	26123: 1;	26124: 2;	26125: 2;	26126: 1;	26127: 1;	
2023-12-01 16:52:43,903:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 16:52:43,903:INFO::Eearly stopping!
2023-12-01 16:52:45,376:INFO::############### Search Stage Ends! ###############
2023-12-01 16:52:45,500:INFO::=============== Retrain Stage Starts:
2023-12-01 16:52:45,500:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:45,524:INFO::node_assign_Counter:
Counter({-1: 14328, 0: 5080, 2: 4383, 1: 2337})
2023-12-01 16:52:45,524:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:52:45,912:INFO::============= repeat round: 1; seed: 666
2023-12-01 16:52:45,992:INFO::arch_weights:
[[1.         1.         1.         1.        ]
 [1.         1.         0.99978215 1.        ]
 [1.         0.9998998  1.         1.        ]
 [1.         0.9995219  1.         1.        ]]
2023-12-01 16:52:45,993:INFO::arch_weights_softmax:
[[0.25       0.25       0.25       0.25      ]
 [0.25001362 0.25001362 0.24995917 0.25001362]
 [0.25000626 0.24998122 0.25000626 0.25000626]
 [0.2500299  0.24991037 0.2500299  0.2500299 ]]
2023-12-01 16:52:45,993:INFO::genotype choice:
['gcn', 'gcn', 'gcn', 'gcn']
2023-12-01 16:52:46,623:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.3852 | Val_Loss 1.3801 | Time(s) 0.5937
2023-12-01 16:52:47,152:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3816 | Val_Loss 1.3761 | Time(s) 0.2374
2023-12-01 16:52:47,160:INFO::Validation loss decreased (inf --> 1.376142).  Saving model ...
2023-12-01 16:52:47,312:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3768 | Val_Loss 1.3723 | Time(s) 0.1516
2023-12-01 16:52:47,321:INFO::Validation loss decreased (1.376142 --> 1.372250).  Saving model ...
2023-12-01 16:52:47,477:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.3726 | Val_Loss 1.3684 | Time(s) 0.1566
2023-12-01 16:52:47,486:INFO::Validation loss decreased (1.372250 --> 1.368428).  Saving model ...
2023-12-01 16:52:47,640:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.3653 | Val_Loss 1.3646 | Time(s) 0.1536
2023-12-01 16:52:47,648:INFO::Validation loss decreased (1.368428 --> 1.364631).  Saving model ...
2023-12-01 16:52:47,801:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.3635 | Val_Loss 1.3608 | Time(s) 0.1535
2023-12-01 16:52:47,812:INFO::Validation loss decreased (1.364631 --> 1.360843).  Saving model ...
2023-12-01 16:52:47,962:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.3607 | Val_Loss 1.3571 | Time(s) 0.1499
2023-12-01 16:52:47,972:INFO::Validation loss decreased (1.360843 --> 1.357064).  Saving model ...
2023-12-01 16:52:48,124:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.3533 | Val_Loss 1.3533 | Time(s) 0.1516
2023-12-01 16:52:48,132:INFO::Validation loss decreased (1.357064 --> 1.353263).  Saving model ...
2023-12-01 16:52:48,282:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.3514 | Val_Loss 1.3494 | Time(s) 0.1508
2023-12-01 16:52:48,290:INFO::Validation loss decreased (1.353263 --> 1.349438).  Saving model ...
2023-12-01 16:52:48,446:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.3444 | Val_Loss 1.3456 | Time(s) 0.1556
2023-12-01 16:52:48,455:INFO::Validation loss decreased (1.349438 --> 1.345556).  Saving model ...
2023-12-01 16:52:48,610:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.3413 | Val_Loss 1.3416 | Time(s) 0.1536
2023-12-01 16:52:48,618:INFO::Validation loss decreased (1.345556 --> 1.341604).  Saving model ...
2023-12-01 16:52:48,768:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.3375 | Val_Loss 1.3376 | Time(s) 0.1509
2023-12-01 16:52:48,776:INFO::Validation loss decreased (1.341604 --> 1.337584).  Saving model ...
2023-12-01 16:52:48,926:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 1.3324 | Val_Loss 1.3335 | Time(s) 0.1496
2023-12-01 16:52:48,934:INFO::Validation loss decreased (1.337584 --> 1.333494).  Saving model ...
2023-12-01 16:52:49,092:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 1.3283 | Val_Loss 1.3293 | Time(s) 0.1576
2023-12-01 16:52:49,101:INFO::Validation loss decreased (1.333494 --> 1.329314).  Saving model ...
2023-12-01 16:52:49,251:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 1.3247 | Val_Loss 1.3250 | Time(s) 0.1496
2023-12-01 16:52:49,258:INFO::Validation loss decreased (1.329314 --> 1.325017).  Saving model ...
2023-12-01 16:52:49,409:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 1.3185 | Val_Loss 1.3206 | Time(s) 0.1506
2023-12-01 16:52:49,438:INFO::Validation loss decreased (1.325017 --> 1.320603).  Saving model ...
2023-12-01 16:52:49,591:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 1.3117 | Val_Loss 1.3161 | Time(s) 0.1536
2023-12-01 16:52:49,600:INFO::Validation loss decreased (1.320603 --> 1.316053).  Saving model ...
2023-12-01 16:52:49,759:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 1.3063 | Val_Loss 1.3114 | Time(s) 0.1596
2023-12-01 16:52:49,768:INFO::Validation loss decreased (1.316053 --> 1.311375).  Saving model ...
2023-12-01 16:52:49,928:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 1.3025 | Val_Loss 1.3065 | Time(s) 0.1596
2023-12-01 16:52:49,938:INFO::Validation loss decreased (1.311375 --> 1.306542).  Saving model ...
2023-12-01 16:52:50,094:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 1.2962 | Val_Loss 1.3016 | Time(s) 0.1566
2023-12-01 16:52:50,103:INFO::Validation loss decreased (1.306542 --> 1.301553).  Saving model ...
2023-12-01 16:52:50,253:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 1.2907 | Val_Loss 1.2964 | Time(s) 0.1486
2023-12-01 16:52:50,260:INFO::Validation loss decreased (1.301553 --> 1.296394).  Saving model ...
2023-12-01 16:52:50,413:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 1.2855 | Val_Loss 1.2911 | Time(s) 0.1536
2023-12-01 16:52:50,422:INFO::Validation loss decreased (1.296394 --> 1.291051).  Saving model ...
2023-12-01 16:52:50,572:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 1.2770 | Val_Loss 1.2855 | Time(s) 0.1496
2023-12-01 16:52:50,580:INFO::Validation loss decreased (1.291051 --> 1.285518).  Saving model ...
2023-12-01 16:52:50,732:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 1.2752 | Val_Loss 1.2798 | Time(s) 0.1516
2023-12-01 16:52:50,740:INFO::Validation loss decreased (1.285518 --> 1.279794).  Saving model ...
2023-12-01 16:52:50,890:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 1.2684 | Val_Loss 1.2739 | Time(s) 0.1496
2023-12-01 16:52:50,898:INFO::Validation loss decreased (1.279794 --> 1.273862).  Saving model ...
2023-12-01 16:52:51,067:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 1.2568 | Val_Loss 1.2677 | Time(s) 0.1685
2023-12-01 16:52:51,077:INFO::Validation loss decreased (1.273862 --> 1.267695).  Saving model ...
2023-12-01 16:52:51,236:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 1.2552 | Val_Loss 1.2613 | Time(s) 0.1596
2023-12-01 16:52:51,244:INFO::Validation loss decreased (1.267695 --> 1.261298).  Saving model ...
2023-12-01 16:52:51,412:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 1.2449 | Val_Loss 1.2547 | Time(s) 0.1676
2023-12-01 16:52:51,421:INFO::Validation loss decreased (1.261298 --> 1.254670).  Saving model ...
2023-12-01 16:52:51,589:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 1.2339 | Val_Loss 1.2478 | Time(s) 0.1685
2023-12-01 16:52:51,597:INFO::Validation loss decreased (1.254670 --> 1.247800).  Saving model ...
2023-12-01 16:52:51,756:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 1.2268 | Val_Loss 1.2407 | Time(s) 0.1586
2023-12-01 16:52:51,764:INFO::Validation loss decreased (1.247800 --> 1.240692).  Saving model ...
2023-12-01 16:52:51,930:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 1.2209 | Val_Loss 1.2333 | Time(s) 0.1665
2023-12-01 16:52:52,046:INFO::Validation loss decreased (1.240692 --> 1.233339).  Saving model ...
2023-12-01 16:52:52,260:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 1.2105 | Val_Loss 1.2257 | Time(s) 0.2144
2023-12-01 16:52:52,275:INFO::Validation loss decreased (1.233339 --> 1.225737).  Saving model ...
2023-12-01 16:52:52,453:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 1.2028 | Val_Loss 1.2179 | Time(s) 0.1785
2023-12-01 16:52:52,462:INFO::Validation loss decreased (1.225737 --> 1.217881).  Saving model ...
2023-12-01 16:52:52,652:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 1.1967 | Val_Loss 1.2098 | Time(s) 0.1885
2023-12-01 16:52:52,661:INFO::Validation loss decreased (1.217881 --> 1.209775).  Saving model ...
2023-12-01 16:52:52,823:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 1.1850 | Val_Loss 1.2014 | Time(s) 0.1613
2023-12-01 16:52:52,833:INFO::Validation loss decreased (1.209775 --> 1.201419).  Saving model ...
2023-12-01 16:52:52,991:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 1.1748 | Val_Loss 1.1928 | Time(s) 0.1586
2023-12-01 16:52:52,999:INFO::Validation loss decreased (1.201419 --> 1.192812).  Saving model ...
2023-12-01 16:52:53,155:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 1.1647 | Val_Loss 1.1839 | Time(s) 0.1553
2023-12-01 16:52:53,176:INFO::Validation loss decreased (1.192812 --> 1.183939).  Saving model ...
2023-12-01 16:52:53,337:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 1.1583 | Val_Loss 1.1748 | Time(s) 0.1612
2023-12-01 16:52:53,345:INFO::Validation loss decreased (1.183939 --> 1.174818).  Saving model ...
2023-12-01 16:52:53,510:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 1.1451 | Val_Loss 1.1654 | Time(s) 0.1645
2023-12-01 16:52:53,517:INFO::Validation loss decreased (1.174818 --> 1.165434).  Saving model ...
2023-12-01 16:52:53,674:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 1.1323 | Val_Loss 1.1558 | Time(s) 0.1553
2023-12-01 16:52:53,682:INFO::Validation loss decreased (1.165434 --> 1.155795).  Saving model ...
2023-12-01 16:52:53,838:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 1.1232 | Val_Loss 1.1459 | Time(s) 0.1556
2023-12-01 16:52:53,846:INFO::Validation loss decreased (1.155795 --> 1.145898).  Saving model ...
2023-12-01 16:52:54,004:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 1.1129 | Val_Loss 1.1357 | Time(s) 0.1576
2023-12-01 16:52:54,012:INFO::Validation loss decreased (1.145898 --> 1.135750).  Saving model ...
2023-12-01 16:52:54,169:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 1.0999 | Val_Loss 1.1254 | Time(s) 0.1572
2023-12-01 16:52:54,177:INFO::Validation loss decreased (1.135750 --> 1.125359).  Saving model ...
2023-12-01 16:52:54,350:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 1.0877 | Val_Loss 1.1147 | Time(s) 0.1732
2023-12-01 16:52:54,363:INFO::Validation loss decreased (1.125359 --> 1.114721).  Saving model ...
2023-12-01 16:52:54,525:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 1.0720 | Val_Loss 1.1038 | Time(s) 0.1607
2023-12-01 16:52:54,535:INFO::Validation loss decreased (1.114721 --> 1.103837).  Saving model ...
2023-12-01 16:52:54,702:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 1.0629 | Val_Loss 1.0927 | Time(s) 0.1659
2023-12-01 16:52:54,711:INFO::Validation loss decreased (1.103837 --> 1.092728).  Saving model ...
2023-12-01 16:52:54,871:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 1.0509 | Val_Loss 1.0814 | Time(s) 0.1606
2023-12-01 16:52:54,880:INFO::Validation loss decreased (1.092728 --> 1.081392).  Saving model ...
2023-12-01 16:52:55,041:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 1.0371 | Val_Loss 1.0698 | Time(s) 0.1586
2023-12-01 16:52:55,065:INFO::Validation loss decreased (1.081392 --> 1.069843).  Saving model ...
2023-12-01 16:52:55,258:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 1.0208 | Val_Loss 1.0581 | Time(s) 0.1931
2023-12-01 16:52:55,269:INFO::Validation loss decreased (1.069843 --> 1.058082).  Saving model ...
2023-12-01 16:52:55,442:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 1.0084 | Val_Loss 1.0461 | Time(s) 0.1732
2023-12-01 16:52:55,451:INFO::Validation loss decreased (1.058082 --> 1.046127).  Saving model ...
2023-12-01 16:52:55,613:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 0.9948 | Val_Loss 1.0340 | Time(s) 0.1616
2023-12-01 16:52:55,622:INFO::Validation loss decreased (1.046127 --> 1.033986).  Saving model ...
2023-12-01 16:52:55,778:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.9823 | Val_Loss 1.0217 | Time(s) 0.1546
2023-12-01 16:52:55,787:INFO::Validation loss decreased (1.033986 --> 1.021682).  Saving model ...
2023-12-01 16:52:55,944:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.9662 | Val_Loss 1.0092 | Time(s) 0.1573
2023-12-01 16:52:55,955:INFO::Validation loss decreased (1.021682 --> 1.009220).  Saving model ...
2023-12-01 16:52:56,109:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 0.9568 | Val_Loss 0.9966 | Time(s) 0.1532
2023-12-01 16:52:56,117:INFO::Validation loss decreased (1.009220 --> 0.996614).  Saving model ...
2023-12-01 16:52:56,275:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.9357 | Val_Loss 0.9839 | Time(s) 0.1576
2023-12-01 16:52:56,283:INFO::Validation loss decreased (0.996614 --> 0.983875).  Saving model ...
2023-12-01 16:52:56,453:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.9242 | Val_Loss 0.9711 | Time(s) 0.1703
2023-12-01 16:52:56,465:INFO::Validation loss decreased (0.983875 --> 0.971053).  Saving model ...
2023-12-01 16:52:56,631:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.9086 | Val_Loss 0.9581 | Time(s) 0.1656
2023-12-01 16:52:56,639:INFO::Validation loss decreased (0.971053 --> 0.958147).  Saving model ...
2023-12-01 16:52:56,799:INFO::Epoch 00057 | lr 0.00050 |Train_Loss 0.8918 | Val_Loss 0.9452 | Time(s) 0.1589
2023-12-01 16:52:56,806:INFO::Validation loss decreased (0.958147 --> 0.945186).  Saving model ...
2023-12-01 16:52:56,964:INFO::Epoch 00058 | lr 0.00050 |Train_Loss 0.8815 | Val_Loss 0.9322 | Time(s) 0.1566
2023-12-01 16:52:56,973:INFO::Validation loss decreased (0.945186 --> 0.932192).  Saving model ...
2023-12-01 16:52:57,127:INFO::Epoch 00059 | lr 0.00050 |Train_Loss 0.8654 | Val_Loss 0.9192 | Time(s) 0.1542
2023-12-01 16:52:57,135:INFO::Validation loss decreased (0.932192 --> 0.919153).  Saving model ...
2023-12-01 16:52:57,292:INFO::Epoch 00060 | lr 0.00050 |Train_Loss 0.8480 | Val_Loss 0.9061 | Time(s) 0.1566
2023-12-01 16:52:57,302:INFO::Validation loss decreased (0.919153 --> 0.906088).  Saving model ...
2023-12-01 16:52:57,478:INFO::Epoch 00061 | lr 0.00050 |Train_Loss 0.8262 | Val_Loss 0.8930 | Time(s) 0.1755
2023-12-01 16:52:57,494:INFO::Validation loss decreased (0.906088 --> 0.893015).  Saving model ...
2023-12-01 16:52:57,663:INFO::Epoch 00062 | lr 0.00050 |Train_Loss 0.8193 | Val_Loss 0.8800 | Time(s) 0.1691
2023-12-01 16:52:57,671:INFO::Validation loss decreased (0.893015 --> 0.879973).  Saving model ...
2023-12-01 16:52:57,831:INFO::Epoch 00063 | lr 0.00050 |Train_Loss 0.8020 | Val_Loss 0.8670 | Time(s) 0.1595
2023-12-01 16:52:57,838:INFO::Validation loss decreased (0.879973 --> 0.866970).  Saving model ...
2023-12-01 16:52:57,995:INFO::Epoch 00064 | lr 0.00050 |Train_Loss 0.7853 | Val_Loss 0.8540 | Time(s) 0.1556
2023-12-01 16:52:58,006:INFO::Validation loss decreased (0.866970 --> 0.854016).  Saving model ...
2023-12-01 16:52:58,162:INFO::Epoch 00065 | lr 0.00050 |Train_Loss 0.7840 | Val_Loss 0.8411 | Time(s) 0.1552
2023-12-01 16:52:58,169:INFO::Validation loss decreased (0.854016 --> 0.841139).  Saving model ...
2023-12-01 16:52:58,333:INFO::Epoch 00066 | lr 0.00050 |Train_Loss 0.7585 | Val_Loss 0.8283 | Time(s) 0.1642
2023-12-01 16:52:58,343:INFO::Validation loss decreased (0.841139 --> 0.828331).  Saving model ...
2023-12-01 16:52:58,508:INFO::Epoch 00067 | lr 0.00050 |Train_Loss 0.7448 | Val_Loss 0.8156 | Time(s) 0.1646
2023-12-01 16:52:58,516:INFO::Validation loss decreased (0.828331 --> 0.815627).  Saving model ...
2023-12-01 16:52:58,682:INFO::Epoch 00068 | lr 0.00050 |Train_Loss 0.7231 | Val_Loss 0.8030 | Time(s) 0.1656
2023-12-01 16:52:58,691:INFO::Validation loss decreased (0.815627 --> 0.803045).  Saving model ...
2023-12-01 16:52:58,848:INFO::Epoch 00069 | lr 0.00050 |Train_Loss 0.7156 | Val_Loss 0.7906 | Time(s) 0.1556
2023-12-01 16:52:58,858:INFO::Validation loss decreased (0.803045 --> 0.790592).  Saving model ...
2023-12-01 16:52:59,017:INFO::Epoch 00070 | lr 0.00050 |Train_Loss 0.7011 | Val_Loss 0.7783 | Time(s) 0.1596
2023-12-01 16:52:59,025:INFO::Validation loss decreased (0.790592 --> 0.778280).  Saving model ...
2023-12-01 16:52:59,237:INFO::Epoch 00071 | lr 0.00050 |Train_Loss 0.6862 | Val_Loss 0.7661 | Time(s) 0.2107
2023-12-01 16:52:59,245:INFO::Validation loss decreased (0.778280 --> 0.766098).  Saving model ...
2023-12-01 16:52:59,408:INFO::Epoch 00072 | lr 0.00050 |Train_Loss 0.6694 | Val_Loss 0.7541 | Time(s) 0.1635
2023-12-01 16:52:59,418:INFO::Validation loss decreased (0.766098 --> 0.754072).  Saving model ...
2023-12-01 16:52:59,592:INFO::Epoch 00073 | lr 0.00050 |Train_Loss 0.6617 | Val_Loss 0.7422 | Time(s) 0.1736
2023-12-01 16:52:59,604:INFO::Validation loss decreased (0.754072 --> 0.742218).  Saving model ...
2023-12-01 16:52:59,763:INFO::Epoch 00074 | lr 0.00050 |Train_Loss 0.6315 | Val_Loss 0.7305 | Time(s) 0.1586
2023-12-01 16:52:59,771:INFO::Validation loss decreased (0.742218 --> 0.730524).  Saving model ...
2023-12-01 16:52:59,931:INFO::Epoch 00075 | lr 0.00050 |Train_Loss 0.6256 | Val_Loss 0.7190 | Time(s) 0.1606
2023-12-01 16:52:59,939:INFO::Validation loss decreased (0.730524 --> 0.719010).  Saving model ...
2023-12-01 16:53:00,099:INFO::Epoch 00076 | lr 0.00050 |Train_Loss 0.6194 | Val_Loss 0.7077 | Time(s) 0.1592
2023-12-01 16:53:00,107:INFO::Validation loss decreased (0.719010 --> 0.707681).  Saving model ...
2023-12-01 16:53:00,268:INFO::Epoch 00077 | lr 0.00050 |Train_Loss 0.6033 | Val_Loss 0.6965 | Time(s) 0.1606
2023-12-01 16:53:00,277:INFO::Validation loss decreased (0.707681 --> 0.696523).  Saving model ...
2023-12-01 16:53:00,449:INFO::Epoch 00078 | lr 0.00050 |Train_Loss 0.5865 | Val_Loss 0.6855 | Time(s) 0.1721
2023-12-01 16:53:00,458:INFO::Validation loss decreased (0.696523 --> 0.685520).  Saving model ...
2023-12-01 16:53:00,633:INFO::Epoch 00079 | lr 0.00050 |Train_Loss 0.5793 | Val_Loss 0.6747 | Time(s) 0.1745
2023-12-01 16:53:00,643:INFO::Validation loss decreased (0.685520 --> 0.674676).  Saving model ...
2023-12-01 16:53:00,825:INFO::Epoch 00080 | lr 0.00050 |Train_Loss 0.5728 | Val_Loss 0.6640 | Time(s) 0.1816
2023-12-01 16:53:00,834:INFO::Validation loss decreased (0.674676 --> 0.663993).  Saving model ...
2023-12-01 16:53:00,997:INFO::Epoch 00081 | lr 0.00050 |Train_Loss 0.5469 | Val_Loss 0.6535 | Time(s) 0.1626
2023-12-01 16:53:01,008:INFO::Validation loss decreased (0.663993 --> 0.653522).  Saving model ...
2023-12-01 16:53:01,182:INFO::Epoch 00082 | lr 0.00050 |Train_Loss 0.5445 | Val_Loss 0.6432 | Time(s) 0.1735
2023-12-01 16:53:01,192:INFO::Validation loss decreased (0.653522 --> 0.643240).  Saving model ...
2023-12-01 16:53:01,347:INFO::Epoch 00083 | lr 0.00050 |Train_Loss 0.5244 | Val_Loss 0.6332 | Time(s) 0.1552
2023-12-01 16:53:01,358:INFO::Validation loss decreased (0.643240 --> 0.633157).  Saving model ...
2023-12-01 16:53:01,528:INFO::Epoch 00084 | lr 0.00050 |Train_Loss 0.5181 | Val_Loss 0.6233 | Time(s) 0.1695
2023-12-01 16:53:01,539:INFO::Validation loss decreased (0.633157 --> 0.623272).  Saving model ...
2023-12-01 16:53:01,698:INFO::Epoch 00085 | lr 0.00050 |Train_Loss 0.4943 | Val_Loss 0.6136 | Time(s) 0.1596
2023-12-01 16:53:01,708:INFO::Validation loss decreased (0.623272 --> 0.613566).  Saving model ...
2023-12-01 16:53:01,869:INFO::Epoch 00086 | lr 0.00050 |Train_Loss 0.4898 | Val_Loss 0.6040 | Time(s) 0.1610
2023-12-01 16:53:01,877:INFO::Validation loss decreased (0.613566 --> 0.604044).  Saving model ...
2023-12-01 16:53:02,039:INFO::Epoch 00087 | lr 0.00050 |Train_Loss 0.4792 | Val_Loss 0.5947 | Time(s) 0.1606
2023-12-01 16:53:02,047:INFO::Validation loss decreased (0.604044 --> 0.594721).  Saving model ...
2023-12-01 16:53:02,219:INFO::Epoch 00088 | lr 0.00050 |Train_Loss 0.4726 | Val_Loss 0.5856 | Time(s) 0.1712
2023-12-01 16:53:02,228:INFO::Validation loss decreased (0.594721 --> 0.585605).  Saving model ...
2023-12-01 16:53:02,391:INFO::Epoch 00089 | lr 0.00050 |Train_Loss 0.4588 | Val_Loss 0.5767 | Time(s) 0.1638
2023-12-01 16:53:02,400:INFO::Validation loss decreased (0.585605 --> 0.576678).  Saving model ...
2023-12-01 16:53:02,558:INFO::Epoch 00090 | lr 0.00050 |Train_Loss 0.4480 | Val_Loss 0.5680 | Time(s) 0.1576
2023-12-01 16:53:02,566:INFO::Validation loss decreased (0.576678 --> 0.567957).  Saving model ...
2023-12-01 16:53:02,722:INFO::Epoch 00091 | lr 0.00050 |Train_Loss 0.4288 | Val_Loss 0.5594 | Time(s) 0.1562
2023-12-01 16:53:02,752:INFO::Validation loss decreased (0.567957 --> 0.559425).  Saving model ...
2023-12-01 16:53:02,916:INFO::Epoch 00092 | lr 0.00050 |Train_Loss 0.4322 | Val_Loss 0.5511 | Time(s) 0.1635
2023-12-01 16:53:02,924:INFO::Validation loss decreased (0.559425 --> 0.551090).  Saving model ...
2023-12-01 16:53:03,085:INFO::Epoch 00093 | lr 0.00050 |Train_Loss 0.4232 | Val_Loss 0.5429 | Time(s) 0.1596
2023-12-01 16:53:03,094:INFO::Validation loss decreased (0.551090 --> 0.542943).  Saving model ...
2023-12-01 16:53:03,252:INFO::Epoch 00094 | lr 0.00050 |Train_Loss 0.4027 | Val_Loss 0.5350 | Time(s) 0.1577
2023-12-01 16:53:03,262:INFO::Validation loss decreased (0.542943 --> 0.535010).  Saving model ...
2023-12-01 16:53:03,431:INFO::Epoch 00095 | lr 0.00050 |Train_Loss 0.3949 | Val_Loss 0.5273 | Time(s) 0.1682
2023-12-01 16:53:03,442:INFO::Validation loss decreased (0.535010 --> 0.527277).  Saving model ...
2023-12-01 16:53:03,598:INFO::Epoch 00096 | lr 0.00050 |Train_Loss 0.3898 | Val_Loss 0.5197 | Time(s) 0.1556
2023-12-01 16:53:03,606:INFO::Validation loss decreased (0.527277 --> 0.519737).  Saving model ...
2023-12-01 16:53:03,763:INFO::Epoch 00097 | lr 0.00050 |Train_Loss 0.3732 | Val_Loss 0.5124 | Time(s) 0.1562
2023-12-01 16:53:03,773:INFO::Validation loss decreased (0.519737 --> 0.512385).  Saving model ...
2023-12-01 16:53:03,929:INFO::Epoch 00098 | lr 0.00050 |Train_Loss 0.3630 | Val_Loss 0.5052 | Time(s) 0.1566
2023-12-01 16:53:03,938:INFO::Validation loss decreased (0.512385 --> 0.505231).  Saving model ...
2023-12-01 16:53:04,095:INFO::Epoch 00099 | lr 0.00050 |Train_Loss 0.3551 | Val_Loss 0.4983 | Time(s) 0.1566
2023-12-01 16:53:04,105:INFO::Validation loss decreased (0.505231 --> 0.498273).  Saving model ...
2023-12-01 16:53:04,257:INFO::Epoch 00100 | lr 0.00050 |Train_Loss 0.3577 | Val_Loss 0.4915 | Time(s) 0.1523
2023-12-01 16:53:04,265:INFO::Validation loss decreased (0.498273 --> 0.491522).  Saving model ...
2023-12-01 16:53:04,424:INFO::Epoch 00101 | lr 0.00050 |Train_Loss 0.3367 | Val_Loss 0.4850 | Time(s) 0.1582
2023-12-01 16:53:04,437:INFO::Validation loss decreased (0.491522 --> 0.484979).  Saving model ...
2023-12-01 16:53:04,595:INFO::Epoch 00102 | lr 0.00050 |Train_Loss 0.3247 | Val_Loss 0.4786 | Time(s) 0.1576
2023-12-01 16:53:04,603:INFO::Validation loss decreased (0.484979 --> 0.478599).  Saving model ...
2023-12-01 16:53:04,780:INFO::Epoch 00103 | lr 0.00050 |Train_Loss 0.3270 | Val_Loss 0.4724 | Time(s) 0.1765
2023-12-01 16:53:04,789:INFO::Validation loss decreased (0.478599 --> 0.472407).  Saving model ...
2023-12-01 16:53:04,950:INFO::Epoch 00104 | lr 0.00050 |Train_Loss 0.3215 | Val_Loss 0.4664 | Time(s) 0.1606
2023-12-01 16:53:04,959:INFO::Validation loss decreased (0.472407 --> 0.466393).  Saving model ...
2023-12-01 16:53:05,115:INFO::Epoch 00105 | lr 0.00050 |Train_Loss 0.3134 | Val_Loss 0.4606 | Time(s) 0.1563
2023-12-01 16:53:05,125:INFO::Validation loss decreased (0.466393 --> 0.460560).  Saving model ...
2023-12-01 16:53:05,289:INFO::Epoch 00106 | lr 0.00050 |Train_Loss 0.3005 | Val_Loss 0.4549 | Time(s) 0.1644
2023-12-01 16:53:05,298:INFO::Validation loss decreased (0.460560 --> 0.454925).  Saving model ...
2023-12-01 16:53:05,463:INFO::Epoch 00107 | lr 0.00050 |Train_Loss 0.2975 | Val_Loss 0.4495 | Time(s) 0.1656
2023-12-01 16:53:05,472:INFO::Validation loss decreased (0.454925 --> 0.449456).  Saving model ...
2023-12-01 16:53:05,628:INFO::Epoch 00108 | lr 0.00050 |Train_Loss 0.2873 | Val_Loss 0.4442 | Time(s) 0.1555
2023-12-01 16:53:05,637:INFO::Validation loss decreased (0.449456 --> 0.444167).  Saving model ...
2023-12-01 16:53:05,796:INFO::Epoch 00109 | lr 0.00050 |Train_Loss 0.2808 | Val_Loss 0.4390 | Time(s) 0.1596
2023-12-01 16:53:05,804:INFO::Validation loss decreased (0.444167 --> 0.439047).  Saving model ...
2023-12-01 16:53:05,962:INFO::Epoch 00110 | lr 0.00050 |Train_Loss 0.2800 | Val_Loss 0.4341 | Time(s) 0.1576
2023-12-01 16:53:05,974:INFO::Validation loss decreased (0.439047 --> 0.434072).  Saving model ...
2023-12-01 16:53:06,158:INFO::Epoch 00111 | lr 0.00050 |Train_Loss 0.2666 | Val_Loss 0.4293 | Time(s) 0.1833
2023-12-01 16:53:06,168:INFO::Validation loss decreased (0.434072 --> 0.429261).  Saving model ...
2023-12-01 16:53:06,335:INFO::Epoch 00112 | lr 0.00050 |Train_Loss 0.2624 | Val_Loss 0.4246 | Time(s) 0.1672
2023-12-01 16:53:06,344:INFO::Validation loss decreased (0.429261 --> 0.424589).  Saving model ...
2023-12-01 16:53:06,524:INFO::Epoch 00113 | lr 0.00050 |Train_Loss 0.2491 | Val_Loss 0.4201 | Time(s) 0.1785
2023-12-01 16:53:06,533:INFO::Validation loss decreased (0.424589 --> 0.420089).  Saving model ...
2023-12-01 16:53:06,688:INFO::Epoch 00114 | lr 0.00050 |Train_Loss 0.2562 | Val_Loss 0.4157 | Time(s) 0.1556
2023-12-01 16:53:06,696:INFO::Validation loss decreased (0.420089 --> 0.415743).  Saving model ...
2023-12-01 16:53:06,852:INFO::Epoch 00115 | lr 0.00050 |Train_Loss 0.2462 | Val_Loss 0.4116 | Time(s) 0.1556
2023-12-01 16:53:06,860:INFO::Validation loss decreased (0.415743 --> 0.411562).  Saving model ...
2023-12-01 16:53:07,024:INFO::Epoch 00116 | lr 0.00050 |Train_Loss 0.2399 | Val_Loss 0.4075 | Time(s) 0.1640
2023-12-01 16:53:07,035:INFO::Validation loss decreased (0.411562 --> 0.407529).  Saving model ...
2023-12-01 16:53:07,199:INFO::Epoch 00117 | lr 0.00050 |Train_Loss 0.2368 | Val_Loss 0.4037 | Time(s) 0.1632
2023-12-01 16:53:07,207:INFO::Validation loss decreased (0.407529 --> 0.403659).  Saving model ...
2023-12-01 16:53:07,366:INFO::Epoch 00118 | lr 0.00050 |Train_Loss 0.2250 | Val_Loss 0.3999 | Time(s) 0.1587
2023-12-01 16:53:07,375:INFO::Validation loss decreased (0.403659 --> 0.399925).  Saving model ...
2023-12-01 16:53:07,537:INFO::Epoch 00119 | lr 0.00050 |Train_Loss 0.2193 | Val_Loss 0.3964 | Time(s) 0.1625
2023-12-01 16:53:07,545:INFO::Validation loss decreased (0.399925 --> 0.396354).  Saving model ...
2023-12-01 16:53:07,703:INFO::Epoch 00120 | lr 0.00050 |Train_Loss 0.2222 | Val_Loss 0.3929 | Time(s) 0.1576
2023-12-01 16:53:07,713:INFO::Validation loss decreased (0.396354 --> 0.392950).  Saving model ...
2023-12-01 16:53:07,870:INFO::Epoch 00121 | lr 0.00050 |Train_Loss 0.2085 | Val_Loss 0.3896 | Time(s) 0.1572
2023-12-01 16:53:07,880:INFO::Validation loss decreased (0.392950 --> 0.389636).  Saving model ...
2023-12-01 16:53:08,038:INFO::Epoch 00122 | lr 0.00050 |Train_Loss 0.2009 | Val_Loss 0.3864 | Time(s) 0.1576
2023-12-01 16:53:08,045:INFO::Validation loss decreased (0.389636 --> 0.386433).  Saving model ...
2023-12-01 16:53:08,208:INFO::Epoch 00123 | lr 0.00050 |Train_Loss 0.2045 | Val_Loss 0.3834 | Time(s) 0.1630
2023-12-01 16:53:08,216:INFO::Validation loss decreased (0.386433 --> 0.383391).  Saving model ...
2023-12-01 16:53:08,377:INFO::Epoch 00124 | lr 0.00050 |Train_Loss 0.1956 | Val_Loss 0.3804 | Time(s) 0.1613
2023-12-01 16:53:08,385:INFO::Validation loss decreased (0.383391 --> 0.380443).  Saving model ...
2023-12-01 16:53:08,559:INFO::Epoch 00125 | lr 0.00050 |Train_Loss 0.1996 | Val_Loss 0.3775 | Time(s) 0.1745
2023-12-01 16:53:08,567:INFO::Validation loss decreased (0.380443 --> 0.377509).  Saving model ...
2023-12-01 16:53:08,722:INFO::Epoch 00126 | lr 0.00050 |Train_Loss 0.1910 | Val_Loss 0.3747 | Time(s) 0.1545
2023-12-01 16:53:08,730:INFO::Validation loss decreased (0.377509 --> 0.374701).  Saving model ...
2023-12-01 16:53:08,892:INFO::Epoch 00127 | lr 0.00050 |Train_Loss 0.1862 | Val_Loss 0.3720 | Time(s) 0.1608
2023-12-01 16:53:08,900:INFO::Validation loss decreased (0.374701 --> 0.371969).  Saving model ...
2023-12-01 16:53:09,057:INFO::Epoch 00128 | lr 0.00050 |Train_Loss 0.1818 | Val_Loss 0.3693 | Time(s) 0.1572
2023-12-01 16:53:09,067:INFO::Validation loss decreased (0.371969 --> 0.369319).  Saving model ...
2023-12-01 16:53:09,228:INFO::Epoch 00129 | lr 0.00050 |Train_Loss 0.1754 | Val_Loss 0.3668 | Time(s) 0.1612
2023-12-01 16:53:09,238:INFO::Validation loss decreased (0.369319 --> 0.366789).  Saving model ...
2023-12-01 16:53:09,395:INFO::Epoch 00130 | lr 0.00050 |Train_Loss 0.1789 | Val_Loss 0.3643 | Time(s) 0.1572
2023-12-01 16:53:09,415:INFO::Validation loss decreased (0.366789 --> 0.364348).  Saving model ...
2023-12-01 16:53:09,573:INFO::Epoch 00131 | lr 0.00050 |Train_Loss 0.1671 | Val_Loss 0.3620 | Time(s) 0.1586
2023-12-01 16:53:09,582:INFO::Validation loss decreased (0.364348 --> 0.361962).  Saving model ...
2023-12-01 16:53:09,738:INFO::Epoch 00132 | lr 0.00050 |Train_Loss 0.1638 | Val_Loss 0.3597 | Time(s) 0.1556
2023-12-01 16:53:09,746:INFO::Validation loss decreased (0.361962 --> 0.359732).  Saving model ...
2023-12-01 16:53:09,903:INFO::Epoch 00133 | lr 0.00050 |Train_Loss 0.1711 | Val_Loss 0.3576 | Time(s) 0.1566
2023-12-01 16:53:09,911:INFO::Validation loss decreased (0.359732 --> 0.357580).  Saving model ...
2023-12-01 16:53:10,068:INFO::Epoch 00134 | lr 0.00050 |Train_Loss 0.1579 | Val_Loss 0.3555 | Time(s) 0.1576
2023-12-01 16:53:10,076:INFO::Validation loss decreased (0.357580 --> 0.355534).  Saving model ...
2023-12-01 16:53:10,245:INFO::Epoch 00135 | lr 0.00050 |Train_Loss 0.1579 | Val_Loss 0.3536 | Time(s) 0.1662
2023-12-01 16:53:10,253:INFO::Validation loss decreased (0.355534 --> 0.353612).  Saving model ...
2023-12-01 16:53:10,425:INFO::Epoch 00136 | lr 0.00050 |Train_Loss 0.1604 | Val_Loss 0.3517 | Time(s) 0.1711
2023-12-01 16:53:10,435:INFO::Validation loss decreased (0.353612 --> 0.351735).  Saving model ...
2023-12-01 16:53:10,594:INFO::Epoch 00137 | lr 0.00050 |Train_Loss 0.1491 | Val_Loss 0.3499 | Time(s) 0.1596
2023-12-01 16:53:10,602:INFO::Validation loss decreased (0.351735 --> 0.349942).  Saving model ...
2023-12-01 16:53:10,757:INFO::Epoch 00138 | lr 0.00050 |Train_Loss 0.1509 | Val_Loss 0.3482 | Time(s) 0.1546
2023-12-01 16:53:10,765:INFO::Validation loss decreased (0.349942 --> 0.348205).  Saving model ...
2023-12-01 16:53:10,922:INFO::Epoch 00139 | lr 0.00050 |Train_Loss 0.1487 | Val_Loss 0.3466 | Time(s) 0.1576
2023-12-01 16:53:10,930:INFO::Validation loss decreased (0.348205 --> 0.346568).  Saving model ...
2023-12-01 16:53:11,102:INFO::Epoch 00140 | lr 0.00050 |Train_Loss 0.1473 | Val_Loss 0.3450 | Time(s) 0.1721
2023-12-01 16:53:11,111:INFO::Validation loss decreased (0.346568 --> 0.345004).  Saving model ...
2023-12-01 16:53:11,289:INFO::Epoch 00141 | lr 0.00050 |Train_Loss 0.1382 | Val_Loss 0.3436 | Time(s) 0.1774
2023-12-01 16:53:11,300:INFO::Validation loss decreased (0.345004 --> 0.343552).  Saving model ...
2023-12-01 16:53:11,487:INFO::Epoch 00142 | lr 0.00050 |Train_Loss 0.1343 | Val_Loss 0.3422 | Time(s) 0.1864
2023-12-01 16:53:11,497:INFO::Validation loss decreased (0.343552 --> 0.342235).  Saving model ...
2023-12-01 16:53:11,675:INFO::Epoch 00143 | lr 0.00050 |Train_Loss 0.1387 | Val_Loss 0.3410 | Time(s) 0.1775
2023-12-01 16:53:11,684:INFO::Validation loss decreased (0.342235 --> 0.340996).  Saving model ...
2023-12-01 16:53:11,851:INFO::Epoch 00144 | lr 0.00050 |Train_Loss 0.1346 | Val_Loss 0.3398 | Time(s) 0.1665
2023-12-01 16:53:11,858:INFO::Validation loss decreased (0.340996 --> 0.339790).  Saving model ...
2023-12-01 16:53:12,015:INFO::Epoch 00145 | lr 0.00050 |Train_Loss 0.1262 | Val_Loss 0.3386 | Time(s) 0.1564
2023-12-01 16:53:12,025:INFO::Validation loss decreased (0.339790 --> 0.338583).  Saving model ...
2023-12-01 16:53:12,181:INFO::Epoch 00146 | lr 0.00050 |Train_Loss 0.1266 | Val_Loss 0.3374 | Time(s) 0.1552
2023-12-01 16:53:12,190:INFO::Validation loss decreased (0.338583 --> 0.337422).  Saving model ...
2023-12-01 16:53:12,359:INFO::Epoch 00147 | lr 0.00050 |Train_Loss 0.1229 | Val_Loss 0.3363 | Time(s) 0.1672
2023-12-01 16:53:12,369:INFO::Validation loss decreased (0.337422 --> 0.336317).  Saving model ...
2023-12-01 16:53:12,534:INFO::Epoch 00148 | lr 0.00050 |Train_Loss 0.1258 | Val_Loss 0.3352 | Time(s) 0.1656
2023-12-01 16:53:12,542:INFO::Validation loss decreased (0.336317 --> 0.335208).  Saving model ...
2023-12-01 16:53:12,699:INFO::Epoch 00149 | lr 0.00050 |Train_Loss 0.1189 | Val_Loss 0.3342 | Time(s) 0.1563
2023-12-01 16:53:12,707:INFO::Validation loss decreased (0.335208 --> 0.334158).  Saving model ...
2023-12-01 16:53:12,862:INFO::Epoch 00150 | lr 0.00050 |Train_Loss 0.1220 | Val_Loss 0.3331 | Time(s) 0.1546
2023-12-01 16:53:12,872:INFO::Validation loss decreased (0.334158 --> 0.333076).  Saving model ...
2023-12-01 16:53:13,031:INFO::Epoch 00151 | lr 0.00050 |Train_Loss 0.1183 | Val_Loss 0.3321 | Time(s) 0.1596
2023-12-01 16:53:13,040:INFO::Validation loss decreased (0.333076 --> 0.332050).  Saving model ...
2023-12-01 16:53:13,202:INFO::Epoch 00152 | lr 0.00050 |Train_Loss 0.1139 | Val_Loss 0.3312 | Time(s) 0.1622
2023-12-01 16:53:13,244:INFO::Validation loss decreased (0.332050 --> 0.331178).  Saving model ...
2023-12-01 16:53:13,410:INFO::Epoch 00153 | lr 0.00050 |Train_Loss 0.1095 | Val_Loss 0.3304 | Time(s) 0.1652
2023-12-01 16:53:13,419:INFO::Validation loss decreased (0.331178 --> 0.330353).  Saving model ...
2023-12-01 16:53:13,582:INFO::Epoch 00154 | lr 0.00050 |Train_Loss 0.1065 | Val_Loss 0.3294 | Time(s) 0.1626
2023-12-01 16:53:13,591:INFO::Validation loss decreased (0.330353 --> 0.329406).  Saving model ...
2023-12-01 16:53:13,749:INFO::Epoch 00155 | lr 0.00050 |Train_Loss 0.1122 | Val_Loss 0.3284 | Time(s) 0.1586
2023-12-01 16:53:13,761:INFO::Validation loss decreased (0.329406 --> 0.328424).  Saving model ...
2023-12-01 16:53:13,922:INFO::Epoch 00156 | lr 0.00050 |Train_Loss 0.1033 | Val_Loss 0.3274 | Time(s) 0.1597
2023-12-01 16:53:13,930:INFO::Validation loss decreased (0.328424 --> 0.327406).  Saving model ...
2023-12-01 16:53:14,085:INFO::Epoch 00157 | lr 0.00050 |Train_Loss 0.1035 | Val_Loss 0.3265 | Time(s) 0.1546
2023-12-01 16:53:14,094:INFO::Validation loss decreased (0.327406 --> 0.326472).  Saving model ...
2023-12-01 16:53:14,256:INFO::Epoch 00158 | lr 0.00050 |Train_Loss 0.1006 | Val_Loss 0.3256 | Time(s) 0.1612
2023-12-01 16:53:14,265:INFO::Validation loss decreased (0.326472 --> 0.325587).  Saving model ...
2023-12-01 16:53:14,429:INFO::Epoch 00159 | lr 0.00050 |Train_Loss 0.1044 | Val_Loss 0.3248 | Time(s) 0.1642
2023-12-01 16:53:14,439:INFO::Validation loss decreased (0.325587 --> 0.324751).  Saving model ...
2023-12-01 16:53:14,606:INFO::Epoch 00160 | lr 0.00050 |Train_Loss 0.1020 | Val_Loss 0.3241 | Time(s) 0.1677
2023-12-01 16:53:14,616:INFO::Validation loss decreased (0.324751 --> 0.324113).  Saving model ...
2023-12-01 16:53:14,775:INFO::Epoch 00161 | lr 0.00050 |Train_Loss 0.0995 | Val_Loss 0.3236 | Time(s) 0.1586
2023-12-01 16:53:14,783:INFO::Validation loss decreased (0.324113 --> 0.323556).  Saving model ...
2023-12-01 16:53:14,944:INFO::Epoch 00162 | lr 0.00050 |Train_Loss 0.1005 | Val_Loss 0.3231 | Time(s) 0.1611
2023-12-01 16:53:14,954:INFO::Validation loss decreased (0.323556 --> 0.323104).  Saving model ...
2023-12-01 16:53:15,131:INFO::Epoch 00163 | lr 0.00050 |Train_Loss 0.0930 | Val_Loss 0.3227 | Time(s) 0.1771
2023-12-01 16:53:15,143:INFO::Validation loss decreased (0.323104 --> 0.322665).  Saving model ...
2023-12-01 16:53:15,303:INFO::Epoch 00164 | lr 0.00050 |Train_Loss 0.0961 | Val_Loss 0.3222 | Time(s) 0.1593
2023-12-01 16:53:15,310:INFO::Validation loss decreased (0.322665 --> 0.322247).  Saving model ...
2023-12-01 16:53:15,477:INFO::Epoch 00165 | lr 0.00050 |Train_Loss 0.0918 | Val_Loss 0.3219 | Time(s) 0.1666
2023-12-01 16:53:15,486:INFO::Validation loss decreased (0.322247 --> 0.321869).  Saving model ...
2023-12-01 16:53:15,662:INFO::Epoch 00166 | lr 0.00050 |Train_Loss 0.0925 | Val_Loss 0.3215 | Time(s) 0.1755
2023-12-01 16:53:15,669:INFO::Validation loss decreased (0.321869 --> 0.321482).  Saving model ...
2023-12-01 16:53:15,825:INFO::Epoch 00167 | lr 0.00050 |Train_Loss 0.0884 | Val_Loss 0.3211 | Time(s) 0.1546
2023-12-01 16:53:15,833:INFO::Validation loss decreased (0.321482 --> 0.321142).  Saving model ...
2023-12-01 16:53:15,988:INFO::Epoch 00168 | lr 0.00050 |Train_Loss 0.0876 | Val_Loss 0.3209 | Time(s) 0.1556
2023-12-01 16:53:15,996:INFO::Validation loss decreased (0.321142 --> 0.320940).  Saving model ...
2023-12-01 16:53:16,151:INFO::Epoch 00169 | lr 0.00050 |Train_Loss 0.0818 | Val_Loss 0.3208 | Time(s) 0.1542
2023-12-01 16:53:16,160:INFO::Validation loss decreased (0.320940 --> 0.320819).  Saving model ...
2023-12-01 16:53:16,320:INFO::Epoch 00170 | lr 0.00050 |Train_Loss 0.0850 | Val_Loss 0.3207 | Time(s) 0.1599
2023-12-01 16:53:16,329:INFO::Validation loss decreased (0.320819 --> 0.320729).  Saving model ...
2023-12-01 16:53:16,500:INFO::Epoch 00171 | lr 0.00050 |Train_Loss 0.0869 | Val_Loss 0.3207 | Time(s) 0.1701
2023-12-01 16:53:16,690:INFO::Validation loss decreased (0.320729 --> 0.320704).  Saving model ...
2023-12-01 16:53:17,054:INFO::Epoch 00172 | lr 0.00050 |Train_Loss 0.0864 | Val_Loss 0.3206 | Time(s) 0.3630
2023-12-01 16:53:17,062:INFO::Validation loss decreased (0.320704 --> 0.320598).  Saving model ...
2023-12-01 16:53:17,228:INFO::Epoch 00173 | lr 0.00050 |Train_Loss 0.0782 | Val_Loss 0.3203 | Time(s) 0.1652
2023-12-01 16:53:17,236:INFO::Validation loss decreased (0.320598 --> 0.320329).  Saving model ...
2023-12-01 16:53:17,392:INFO::Epoch 00174 | lr 0.00050 |Train_Loss 0.0817 | Val_Loss 0.3199 | Time(s) 0.1555
2023-12-01 16:53:17,400:INFO::Validation loss decreased (0.320329 --> 0.319885).  Saving model ...
2023-12-01 16:53:17,553:INFO::Epoch 00175 | lr 0.00050 |Train_Loss 0.0807 | Val_Loss 0.3193 | Time(s) 0.1536
2023-12-01 16:53:17,560:INFO::Validation loss decreased (0.319885 --> 0.319295).  Saving model ...
2023-12-01 16:53:17,712:INFO::Epoch 00176 | lr 0.00050 |Train_Loss 0.0786 | Val_Loss 0.3186 | Time(s) 0.1521
2023-12-01 16:53:17,720:INFO::Validation loss decreased (0.319295 --> 0.318622).  Saving model ...
2023-12-01 16:53:17,874:INFO::Epoch 00177 | lr 0.00050 |Train_Loss 0.0781 | Val_Loss 0.3180 | Time(s) 0.1534
2023-12-01 16:53:17,882:INFO::Validation loss decreased (0.318622 --> 0.318009).  Saving model ...
2023-12-01 16:53:18,035:INFO::Epoch 00178 | lr 0.00050 |Train_Loss 0.0752 | Val_Loss 0.3174 | Time(s) 0.1526
2023-12-01 16:53:18,043:INFO::Validation loss decreased (0.318009 --> 0.317380).  Saving model ...
2023-12-01 16:53:18,193:INFO::Epoch 00179 | lr 0.00050 |Train_Loss 0.0731 | Val_Loss 0.3168 | Time(s) 0.1492
2023-12-01 16:53:18,200:INFO::Validation loss decreased (0.317380 --> 0.316762).  Saving model ...
2023-12-01 16:53:18,359:INFO::Epoch 00180 | lr 0.00050 |Train_Loss 0.0730 | Val_Loss 0.3163 | Time(s) 0.1583
2023-12-01 16:53:18,367:INFO::Validation loss decreased (0.316762 --> 0.316339).  Saving model ...
2023-12-01 16:53:18,526:INFO::Epoch 00181 | lr 0.00050 |Train_Loss 0.0751 | Val_Loss 0.3160 | Time(s) 0.1596
2023-12-01 16:53:18,536:INFO::Validation loss decreased (0.316339 --> 0.315982).  Saving model ...
2023-12-01 16:53:18,690:INFO::Epoch 00182 | lr 0.00050 |Train_Loss 0.0722 | Val_Loss 0.3158 | Time(s) 0.1546
2023-12-01 16:53:18,697:INFO::Validation loss decreased (0.315982 --> 0.315777).  Saving model ...
2023-12-01 16:53:18,850:INFO::Epoch 00183 | lr 0.00050 |Train_Loss 0.0707 | Val_Loss 0.3155 | Time(s) 0.1514
2023-12-01 16:53:18,857:INFO::Validation loss decreased (0.315777 --> 0.315523).  Saving model ...
2023-12-01 16:53:19,008:INFO::Epoch 00184 | lr 0.00050 |Train_Loss 0.0678 | Val_Loss 0.3154 | Time(s) 0.1506
2023-12-01 16:53:19,016:INFO::Validation loss decreased (0.315523 --> 0.315420).  Saving model ...
2023-12-01 16:53:19,167:INFO::Epoch 00185 | lr 0.00050 |Train_Loss 0.0719 | Val_Loss 0.3154 | Time(s) 0.1502
2023-12-01 16:53:19,167:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:53:19,318:INFO::Epoch 00186 | lr 0.00050 |Train_Loss 0.0709 | Val_Loss 0.3156 | Time(s) 0.1512
2023-12-01 16:53:19,318:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:53:19,473:INFO::Epoch 00187 | lr 0.00050 |Train_Loss 0.0712 | Val_Loss 0.3157 | Time(s) 0.1526
2023-12-01 16:53:19,473:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:53:19,640:INFO::Epoch 00188 | lr 0.00050 |Train_Loss 0.0673 | Val_Loss 0.3158 | Time(s) 0.1666
2023-12-01 16:53:19,641:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 16:53:19,795:INFO::Epoch 00189 | lr 0.00050 |Train_Loss 0.0664 | Val_Loss 0.3159 | Time(s) 0.1546
2023-12-01 16:53:19,796:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 16:53:19,949:INFO::Epoch 00190 | lr 0.00050 |Train_Loss 0.0654 | Val_Loss 0.3160 | Time(s) 0.1525
2023-12-01 16:53:19,950:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 16:53:20,101:INFO::Epoch 00191 | lr 0.00050 |Train_Loss 0.0633 | Val_Loss 0.3161 | Time(s) 0.1516
2023-12-01 16:53:20,101:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 16:53:20,255:INFO::Epoch 00192 | lr 0.00050 |Train_Loss 0.0648 | Val_Loss 0.3162 | Time(s) 0.1531
2023-12-01 16:53:20,256:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 16:53:20,256:INFO::Eearly stopping!
2023-12-01 16:53:20,256:INFO::
testing...
2023-12-01 16:53:20,316:INFO::submit dir: submit/submit_gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:20,486:INFO::{'micro-f1': 0.8880281690140845, 'macro-f1': 0.8810159130479176}
2023-12-01 16:53:20,614:INFO::############### Retrain Stage Ends! #################
2023-12-01 16:53:20,628:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gcn', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-16-46-32', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=1233, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=2, last_hidden_dim=64, logger=<Logger log_output (INFO)>)
2023-12-01 16:53:40,469:INFO::node_type_num: 4
2023-12-01 16:53:40,498:INFO::=============== Prepare basic data stage finish, use 19.870100736618042 time.
2023-12-01 16:53:40,637:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:42,228:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:42,231:INFO::its now!!!!!!!!5
2023-12-01 16:53:42,632:INFO::its now!!!!!!!!0
2023-12-01 16:53:42,633:INFO::its now!!!!!!!!3
2023-12-01 16:53:42,668:INFO::its now!!!!!!!!5
2023-12-01 16:53:42,963:INFO::its now!!!!!!!!
2023-12-01 16:53:42,964:INFO::its now!!!!!!!! on 
2023-12-01 16:53:43,026:INFO::its now!!!!!!!!5
2023-12-01 16:53:43,297:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:43,328:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.3591 | Train_Classification_Loss 1.3902 | Dmon_Loss -0.0622 | Val_Loss 1.3851 | Search Time(s) 0.7855 | Infer Time(s) 0.2913 | Time(s) 1.0768 
2023-12-01 16:53:43,406:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 1;	27: 3;	28: 3;	29: 1;	30: 1;	31: 1;	32: 1;	33: 1;	34: 3;	35: 1;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 1;	26103: 3;	26104: 1;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 0;	26127: 3;	
2023-12-01 16:53:43,410:INFO::Epoch: 1
tensor([[0.4950, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.5050, 0.5050, 0.5050, 0.5050],
        [0.5050, 0.5050, 0.5050, 0.5050]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:43,411:INFO::its now!!!!!!!!5
2023-12-01 16:53:43,662:INFO::its now!!!!!!!!0
2023-12-01 16:53:43,663:INFO::its now!!!!!!!!3
2023-12-01 16:53:43,709:INFO::its now!!!!!!!!5
2023-12-01 16:53:43,965:INFO::its now!!!!!!!!
2023-12-01 16:53:43,965:INFO::its now!!!!!!!! on 
2023-12-01 16:53:44,001:INFO::its now!!!!!!!!5
2023-12-01 16:53:44,262:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:44,264:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3536 | Train_Classification_Loss 1.3847 | Dmon_Loss -0.0622 | Val_Loss 1.3803 | Search Time(s) 0.5924 | Infer Time(s) 0.2629 | Time(s) 0.8553 
2023-12-01 16:53:44,345:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 2;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:44,347:INFO::Validation loss decreased (inf --> 1.380293).  Saving model ...
2023-12-01 16:53:44,351:INFO::Epoch: 2
tensor([[0.4997, 0.5074, 0.5101, 0.5101],
        [0.4997, 0.5073, 0.5101, 0.5101],
        [0.5097, 0.5074, 0.5101, 0.5101],
        [0.5097, 0.5072, 0.5101, 0.5101]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:44,352:INFO::its now!!!!!!!!5
2023-12-01 16:53:44,622:INFO::its now!!!!!!!!0
2023-12-01 16:53:44,623:INFO::its now!!!!!!!!3
2023-12-01 16:53:44,651:INFO::its now!!!!!!!!5
2023-12-01 16:53:44,892:INFO::its now!!!!!!!!
2023-12-01 16:53:44,892:INFO::its now!!!!!!!! on 
2023-12-01 16:53:44,931:INFO::its now!!!!!!!!5
2023-12-01 16:53:45,167:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:45,169:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3504 | Train_Classification_Loss 1.3817 | Dmon_Loss -0.0625 | Val_Loss 1.3796 | Search Time(s) 0.5824 | Infer Time(s) 0.2369 | Time(s) 0.8194 
2023-12-01 16:53:45,241:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 3;	5: 3;	6: 3;	7: 1;	8: 1;	9: 3;	10: 3;	11: 1;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 1;	26: 1;	27: 1;	28: 3;	29: 3;	30: 3;	31: 1;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 1;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 1;	26105: 2;	26106: 1;	26107: 1;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 0;	26115: 0;	26116: 3;	26117: 0;	26118: 1;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 2;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:53:45,254:INFO::Validation loss decreased (1.380293 --> 1.379593).  Saving model ...
2023-12-01 16:53:45,257:INFO::Epoch: 3
tensor([[0.5030, 0.5115, 0.5128, 0.5136],
        [0.5031, 0.5114, 0.5128, 0.5136],
        [0.5131, 0.5115, 0.5128, 0.5136],
        [0.5131, 0.5112, 0.5128, 0.5136]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:45,258:INFO::its now!!!!!!!!5
2023-12-01 16:53:45,513:INFO::its now!!!!!!!!0
2023-12-01 16:53:45,514:INFO::its now!!!!!!!!3
2023-12-01 16:53:45,541:INFO::its now!!!!!!!!5
2023-12-01 16:53:45,784:INFO::its now!!!!!!!!
2023-12-01 16:53:45,784:INFO::its now!!!!!!!! on 
2023-12-01 16:53:45,822:INFO::its now!!!!!!!!5
2023-12-01 16:53:46,061:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:46,064:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3445 | Train_Classification_Loss 1.3758 | Dmon_Loss -0.0625 | Val_Loss 1.3749 | Search Time(s) 0.5651 | Infer Time(s) 0.2424 | Time(s) 0.8075 
2023-12-01 16:53:46,122:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 2;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 3;	26: 1;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 2;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 2;	26110: 3;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 3;	26116: 2;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 2;	26122: 3;	26123: 3;	26124: 2;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:46,124:INFO::Validation loss decreased (1.379593 --> 1.374920).  Saving model ...
2023-12-01 16:53:46,127:INFO::Epoch: 4
tensor([[0.5084, 0.5172, 0.5179, 0.5156],
        [0.5084, 0.5171, 0.5180, 0.5155],
        [0.5184, 0.5172, 0.5179, 0.5155],
        [0.5184, 0.5169, 0.5179, 0.5155]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:46,129:INFO::its now!!!!!!!!5
2023-12-01 16:53:46,388:INFO::its now!!!!!!!!0
2023-12-01 16:53:46,389:INFO::its now!!!!!!!!3
2023-12-01 16:53:46,420:INFO::its now!!!!!!!!5
2023-12-01 16:53:46,676:INFO::its now!!!!!!!!
2023-12-01 16:53:46,676:INFO::its now!!!!!!!! on 
2023-12-01 16:53:46,731:INFO::its now!!!!!!!!5
2023-12-01 16:53:46,981:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:46,983:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3405 | Train_Classification_Loss 1.3717 | Dmon_Loss -0.0623 | Val_Loss 1.3707 | Search Time(s) 0.5910 | Infer Time(s) 0.2653 | Time(s) 0.8563 
2023-12-01 16:53:47,043:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 1;	9: 2;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 1;	25: 3;	26: 1;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 3;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:47,045:INFO::Validation loss decreased (1.374920 --> 1.370734).  Saving model ...
2023-12-01 16:53:47,048:INFO::Epoch: 5
tensor([[0.5141, 0.5232, 0.5207, 0.5206],
        [0.5141, 0.5231, 0.5207, 0.5206],
        [0.5213, 0.5232, 0.5235, 0.5206],
        [0.5214, 0.5230, 0.5235, 0.5206]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:47,050:INFO::its now!!!!!!!!5
2023-12-01 16:53:47,324:INFO::its now!!!!!!!!0
2023-12-01 16:53:47,325:INFO::its now!!!!!!!!3
2023-12-01 16:53:47,370:INFO::its now!!!!!!!!5
2023-12-01 16:53:47,601:INFO::its now!!!!!!!!
2023-12-01 16:53:47,602:INFO::its now!!!!!!!! on 
2023-12-01 16:53:47,654:INFO::its now!!!!!!!!5
2023-12-01 16:53:47,903:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:47,905:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3390 | Train_Classification_Loss 1.3702 | Dmon_Loss -0.0623 | Val_Loss 1.3696 | Search Time(s) 0.5996 | Infer Time(s) 0.2593 | Time(s) 0.8589 
2023-12-01 16:53:47,968:INFO::cluster info:
0: 3;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 3;	7: 1;	8: 3;	9: 3;	10: 3;	11: 1;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 1;	21: 1;	22: 3;	23: 3;	24: 3;	25: 1;	26: 1;	27: 3;	28: 3;	29: 3;	30: 3;	31: 1;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 1;	39: 3;	40: 1;	41: 3;	42: 3;	43: 1;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 1;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:53:47,970:INFO::Validation loss decreased (1.370734 --> 1.369594).  Saving model ...
2023-12-01 16:53:47,972:INFO::Epoch: 6
tensor([[0.5188, 0.5265, 0.5242, 0.5254],
        [0.5188, 0.5264, 0.5243, 0.5254],
        [0.5250, 0.5284, 0.5265, 0.5254],
        [0.5250, 0.5281, 0.5265, 0.5254]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:47,973:INFO::its now!!!!!!!!5
2023-12-01 16:53:48,226:INFO::its now!!!!!!!!0
2023-12-01 16:53:48,226:INFO::its now!!!!!!!!3
2023-12-01 16:53:48,270:INFO::its now!!!!!!!!5
2023-12-01 16:53:48,512:INFO::its now!!!!!!!!
2023-12-01 16:53:48,512:INFO::its now!!!!!!!! on 
2023-12-01 16:53:48,568:INFO::its now!!!!!!!!5
2023-12-01 16:53:48,818:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:48,820:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.3361 | Train_Classification_Loss 1.3673 | Dmon_Loss -0.0624 | Val_Loss 1.3670 | Search Time(s) 0.5968 | Infer Time(s) 0.2513 | Time(s) 0.8481 
2023-12-01 16:53:48,884:INFO::cluster info:
0: 2;	1: 3;	2: 1;	3: 3;	4: 3;	5: 3;	6: 3;	7: 1;	8: 3;	9: 0;	10: 3;	11: 1;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 1;	26: 1;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 1;	39: 3;	40: 1;	41: 3;	42: 3;	43: 3;	44
26098: 1;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 1;	26106: 1;	26107: 3;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:48,885:INFO::Validation loss decreased (1.369594 --> 1.367028).  Saving model ...
2023-12-01 16:53:48,888:INFO::Epoch: 7
tensor([[0.5224, 0.5283, 0.5274, 0.5293],
        [0.5224, 0.5282, 0.5275, 0.5293],
        [0.5282, 0.5311, 0.5292, 0.5293],
        [0.5282, 0.5309, 0.5293, 0.5293]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:48,889:INFO::its now!!!!!!!!5
2023-12-01 16:53:49,160:INFO::its now!!!!!!!!0
2023-12-01 16:53:49,160:INFO::its now!!!!!!!!3
2023-12-01 16:53:49,206:INFO::its now!!!!!!!!5
2023-12-01 16:53:49,442:INFO::its now!!!!!!!!
2023-12-01 16:53:49,442:INFO::its now!!!!!!!! on 
2023-12-01 16:53:49,496:INFO::its now!!!!!!!!5
2023-12-01 16:53:49,736:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:49,738:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.3311 | Train_Classification_Loss 1.3624 | Dmon_Loss -0.0626 | Val_Loss 1.3645 | Search Time(s) 0.6086 | Infer Time(s) 0.2414 | Time(s) 0.8499 
2023-12-01 16:53:49,816:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 1;	8: 3;	9: 1;	10: 3;	11: 1;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 1;	35: 1;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 0;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 3;	26124: 3;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:53:49,817:INFO::Validation loss decreased (1.367028 --> 1.364497).  Saving model ...
2023-12-01 16:53:49,820:INFO::Epoch: 8
tensor([[0.5267, 0.5320, 0.5318, 0.5314],
        [0.5267, 0.5319, 0.5319, 0.5314],
        [0.5326, 0.5326, 0.5332, 0.5342],
        [0.5326, 0.5323, 0.5332, 0.5342]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:49,821:INFO::its now!!!!!!!!5
2023-12-01 16:53:50,101:INFO::its now!!!!!!!!0
2023-12-01 16:53:50,101:INFO::its now!!!!!!!!3
2023-12-01 16:53:50,148:INFO::its now!!!!!!!!5
2023-12-01 16:53:50,411:INFO::its now!!!!!!!!
2023-12-01 16:53:50,411:INFO::its now!!!!!!!! on 
2023-12-01 16:53:50,449:INFO::its now!!!!!!!!5
2023-12-01 16:53:50,686:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:50,688:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.3256 | Train_Classification_Loss 1.3568 | Dmon_Loss -0.0624 | Val_Loss 1.3586 | Search Time(s) 0.6275 | Infer Time(s) 0.2404 | Time(s) 0.8679 
2023-12-01 16:53:50,761:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:50,762:INFO::Validation loss decreased (1.364497 --> 1.358636).  Saving model ...
2023-12-01 16:53:50,765:INFO::Epoch: 9
tensor([[0.5314, 0.5340, 0.5369, 0.5357],
        [0.5314, 0.5339, 0.5369, 0.5357],
        [0.5377, 0.5363, 0.5377, 0.5368],
        [0.5377, 0.5361, 0.5378, 0.5368]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:50,766:INFO::its now!!!!!!!!5
2023-12-01 16:53:51,045:INFO::its now!!!!!!!!0
2023-12-01 16:53:51,045:INFO::its now!!!!!!!!3
2023-12-01 16:53:51,073:INFO::its now!!!!!!!!5
2023-12-01 16:53:51,322:INFO::its now!!!!!!!!
2023-12-01 16:53:51,323:INFO::its now!!!!!!!! on 
2023-12-01 16:53:51,360:INFO::its now!!!!!!!!5
2023-12-01 16:53:51,602:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:51,604:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.3237 | Train_Classification_Loss 1.3549 | Dmon_Loss -0.0626 | Val_Loss 1.3576 | Search Time(s) 0.5947 | Infer Time(s) 0.2453 | Time(s) 0.8400 
2023-12-01 16:53:51,667:INFO::cluster info:
0: 1;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 1;	26107: 1;	26108: 2;	26109: 2;	26110: 3;	26111: 3;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:53:51,668:INFO::Validation loss decreased (1.358636 --> 1.357616).  Saving model ...
2023-12-01 16:53:51,670:INFO::Epoch: 10
tensor([[0.5342, 0.5355, 0.5395, 0.5385],
        [0.5342, 0.5354, 0.5396, 0.5384],
        [0.5408, 0.5387, 0.5402, 0.5387],
        [0.5408, 0.5385, 0.5403, 0.5387]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:51,671:INFO::its now!!!!!!!!5
2023-12-01 16:53:51,906:INFO::its now!!!!!!!!0
2023-12-01 16:53:51,907:INFO::its now!!!!!!!!3
2023-12-01 16:53:51,936:INFO::its now!!!!!!!!5
2023-12-01 16:53:52,204:INFO::its now!!!!!!!!
2023-12-01 16:53:52,205:INFO::its now!!!!!!!! on 
2023-12-01 16:53:52,242:INFO::its now!!!!!!!!5
2023-12-01 16:53:52,490:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:52,492:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.3199 | Train_Classification_Loss 1.3511 | Dmon_Loss -0.0624 | Val_Loss 1.3539 | Search Time(s) 0.5720 | Infer Time(s) 0.2499 | Time(s) 0.8219 
2023-12-01 16:53:52,551:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 1;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:52,552:INFO::Validation loss decreased (1.357616 --> 1.353877).  Saving model ...
2023-12-01 16:53:52,555:INFO::Epoch: 11
tensor([[0.5382, 0.5394, 0.5409, 0.5430],
        [0.5382, 0.5393, 0.5411, 0.5430],
        [0.5424, 0.5429, 0.5441, 0.5428],
        [0.5424, 0.5427, 0.5442, 0.5428]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:52,556:INFO::its now!!!!!!!!5
2023-12-01 16:53:52,797:INFO::its now!!!!!!!!0
2023-12-01 16:53:52,799:INFO::its now!!!!!!!!3
2023-12-01 16:53:52,828:INFO::its now!!!!!!!!5
2023-12-01 16:53:53,072:INFO::its now!!!!!!!!
2023-12-01 16:53:53,072:INFO::its now!!!!!!!! on 
2023-12-01 16:53:53,109:INFO::its now!!!!!!!!5
2023-12-01 16:53:53,366:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:53,368:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.3171 | Train_Classification_Loss 1.3484 | Dmon_Loss -0.0624 | Val_Loss 1.3508 | Search Time(s) 0.5551 | Infer Time(s) 0.2579 | Time(s) 0.8129 
2023-12-01 16:53:53,439:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 1;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:53,440:INFO::Validation loss decreased (1.353877 --> 1.350768).  Saving model ...
2023-12-01 16:53:53,442:INFO::Epoch: 12
tensor([[0.5409, 0.5421, 0.5424, 0.5454],
        [0.5410, 0.5421, 0.5426, 0.5454],
        [0.5440, 0.5457, 0.5461, 0.5458],
        [0.5440, 0.5455, 0.5464, 0.5458]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:53,443:INFO::its now!!!!!!!!5
2023-12-01 16:53:53,684:INFO::its now!!!!!!!!0
2023-12-01 16:53:53,684:INFO::its now!!!!!!!!3
2023-12-01 16:53:53,713:INFO::its now!!!!!!!!5
2023-12-01 16:53:53,962:INFO::its now!!!!!!!!
2023-12-01 16:53:53,963:INFO::its now!!!!!!!! on 
2023-12-01 16:53:54,018:INFO::its now!!!!!!!!5
2023-12-01 16:53:54,260:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.3148 | Train_Classification_Loss 1.3461 | Dmon_Loss -0.0626 | Val_Loss 1.3516 | Search Time(s) 0.5775 | Infer Time(s) 0.2419 | Time(s) 0.8194 
2023-12-01 16:53:54,323:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 1;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 2;	26108: 0;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 0;	26126: 3;	26127: 2;	
2023-12-01 16:53:54,324:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:53:54,327:INFO::Epoch: 13
tensor([[0.5450, 0.5467, 0.5463, 0.5467],
        [0.5450, 0.5466, 0.5465, 0.5466],
        [0.5479, 0.5502, 0.5472, 0.5505],
        [0.5480, 0.5500, 0.5476, 0.5505]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:54,327:INFO::its now!!!!!!!!5
2023-12-01 16:53:54,586:INFO::its now!!!!!!!!0
2023-12-01 16:53:54,586:INFO::its now!!!!!!!!3
2023-12-01 16:53:54,635:INFO::its now!!!!!!!!5
2023-12-01 16:53:54,868:INFO::its now!!!!!!!!
2023-12-01 16:53:54,869:INFO::its now!!!!!!!! on 
2023-12-01 16:53:54,922:INFO::its now!!!!!!!!5
2023-12-01 16:53:55,176:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:55,178:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.3115 | Train_Classification_Loss 1.3428 | Dmon_Loss -0.0625 | Val_Loss 1.3480 | Search Time(s) 0.5850 | Infer Time(s) 0.2659 | Time(s) 0.8509 
2023-12-01 16:53:55,261:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 1;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:55,263:INFO::Validation loss decreased (1.350768 --> 1.348018).  Saving model ...
2023-12-01 16:53:55,267:INFO::Epoch: 14
tensor([[0.5492, 0.5490, 0.5508, 0.5501],
        [0.5493, 0.5515, 0.5510, 0.5472],
        [0.5524, 0.5550, 0.5501, 0.5530],
        [0.5525, 0.5548, 0.5506, 0.5530]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:55,268:INFO::its now!!!!!!!!5
2023-12-01 16:53:55,532:INFO::its now!!!!!!!!0
2023-12-01 16:53:55,533:INFO::its now!!!!!!!!3
2023-12-01 16:53:55,562:INFO::its now!!!!!!!!5
2023-12-01 16:53:55,815:INFO::its now!!!!!!!!
2023-12-01 16:53:55,815:INFO::its now!!!!!!!! on 
2023-12-01 16:53:55,870:INFO::its now!!!!!!!!5
2023-12-01 16:53:56,114:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:56,116:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.3084 | Train_Classification_Loss 1.3396 | Dmon_Loss -0.0626 | Val_Loss 1.3454 | Search Time(s) 0.6059 | Infer Time(s) 0.2449 | Time(s) 0.8509 
2023-12-01 16:53:56,176:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 1;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 1;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 0;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:56,177:INFO::Validation loss decreased (1.348018 --> 1.345392).  Saving model ...
2023-12-01 16:53:56,181:INFO::Epoch: 15
tensor([[0.5540, 0.5534, 0.5531, 0.5552],
        [0.5515, 0.5569, 0.5562, 0.5510],
        [0.5577, 0.5603, 0.5516, 0.5574],
        [0.5578, 0.5601, 0.5522, 0.5574]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:56,183:INFO::its now!!!!!!!!5
2023-12-01 16:53:56,439:INFO::its now!!!!!!!!0
2023-12-01 16:53:56,440:INFO::its now!!!!!!!!3
2023-12-01 16:53:56,485:INFO::its now!!!!!!!!5
2023-12-01 16:53:56,713:INFO::its now!!!!!!!!
2023-12-01 16:53:56,713:INFO::its now!!!!!!!! on 
2023-12-01 16:53:56,751:INFO::its now!!!!!!!!5
2023-12-01 16:53:57,088:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:57,089:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.3045 | Train_Classification_Loss 1.3359 | Dmon_Loss -0.0627 | Val_Loss 1.3410 | Search Time(s) 0.5680 | Infer Time(s) 0.3421 | Time(s) 0.9101 
2023-12-01 16:53:57,153:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 1;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 1;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 2;	26120: 2;	26121: 3;	26122: 3;	26123: 3;	26124: 2;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:57,155:INFO::Validation loss decreased (1.345392 --> 1.340989).  Saving model ...
2023-12-01 16:53:57,158:INFO::Epoch: 16
tensor([[0.5605, 0.5602, 0.5590, 0.5578],
        [0.5568, 0.5597, 0.5633, 0.5579],
        [0.5648, 0.5630, 0.5569, 0.5644],
        [0.5649, 0.5628, 0.5576, 0.5644]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:57,160:INFO::its now!!!!!!!!5
2023-12-01 16:53:57,429:INFO::its now!!!!!!!!0
2023-12-01 16:53:57,430:INFO::its now!!!!!!!!3
2023-12-01 16:53:57,461:INFO::its now!!!!!!!!5
2023-12-01 16:53:57,736:INFO::its now!!!!!!!!
2023-12-01 16:53:57,736:INFO::its now!!!!!!!! on 
2023-12-01 16:53:57,795:INFO::its now!!!!!!!!5
2023-12-01 16:53:58,055:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:58,057:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 1.3001 | Train_Classification_Loss 1.3314 | Dmon_Loss -0.0627 | Val_Loss 1.3399 | Search Time(s) 0.6389 | Infer Time(s) 0.2613 | Time(s) 0.9002 
2023-12-01 16:53:58,138:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 1;	26107: 3;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:58,139:INFO::Validation loss decreased (1.340989 --> 1.339873).  Saving model ...
2023-12-01 16:53:58,143:INFO::Epoch: 17
tensor([[0.5638, 0.5655, 0.5639, 0.5613],
        [0.5613, 0.5632, 0.5670, 0.5634],
        [0.5685, 0.5664, 0.5614, 0.5699],
        [0.5686, 0.5662, 0.5621, 0.5699]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:58,144:INFO::its now!!!!!!!!5
2023-12-01 16:53:58,405:INFO::its now!!!!!!!!0
2023-12-01 16:53:58,406:INFO::its now!!!!!!!!3
2023-12-01 16:53:58,456:INFO::its now!!!!!!!!5
2023-12-01 16:53:58,693:INFO::its now!!!!!!!!
2023-12-01 16:53:58,693:INFO::its now!!!!!!!! on 
2023-12-01 16:53:58,752:INFO::its now!!!!!!!!5
2023-12-01 16:53:59,018:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:53:59,020:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 1.2955 | Train_Classification_Loss 1.3269 | Dmon_Loss -0.0627 | Val_Loss 1.3376 | Search Time(s) 0.6109 | Infer Time(s) 0.2673 | Time(s) 0.8782 
2023-12-01 16:53:59,107:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 3;	26: 1;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 2;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:53:59,109:INFO::Validation loss decreased (1.339873 --> 1.337580).  Saving model ...
2023-12-01 16:53:59,113:INFO::Epoch: 18
tensor([[0.5667, 0.5683, 0.5679, 0.5648],
        [0.5648, 0.5666, 0.5689, 0.5677],
        [0.5718, 0.5696, 0.5650, 0.5727],
        [0.5719, 0.5695, 0.5657, 0.5727]], device='cuda:0', requires_grad=True)
2023-12-01 16:53:59,114:INFO::its now!!!!!!!!5
2023-12-01 16:53:59,389:INFO::its now!!!!!!!!0
2023-12-01 16:53:59,390:INFO::its now!!!!!!!!3
2023-12-01 16:53:59,441:INFO::its now!!!!!!!!5
2023-12-01 16:53:59,708:INFO::its now!!!!!!!!
2023-12-01 16:53:59,709:INFO::its now!!!!!!!! on 
2023-12-01 16:53:59,751:INFO::its now!!!!!!!!5
2023-12-01 16:54:00,012:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:00,014:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 1.2932 | Train_Classification_Loss 1.3246 | Dmon_Loss -0.0628 | Val_Loss 1.3334 | Search Time(s) 0.6409 | Infer Time(s) 0.2623 | Time(s) 0.9032 
2023-12-01 16:54:00,089:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 2;	26125: 2;	26126: 0;	26127: 3;	
2023-12-01 16:54:00,091:INFO::Validation loss decreased (1.337580 --> 1.333401).  Saving model ...
2023-12-01 16:54:00,095:INFO::Epoch: 19
tensor([[0.5711, 0.5697, 0.5731, 0.5703],
        [0.5695, 0.5717, 0.5699, 0.5732],
        [0.5766, 0.5746, 0.5699, 0.5741],
        [0.5767, 0.5745, 0.5707, 0.5741]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:00,096:INFO::its now!!!!!!!!5
2023-12-01 16:54:00,360:INFO::its now!!!!!!!!0
2023-12-01 16:54:00,361:INFO::its now!!!!!!!!3
2023-12-01 16:54:00,394:INFO::its now!!!!!!!!5
2023-12-01 16:54:00,669:INFO::its now!!!!!!!!
2023-12-01 16:54:00,669:INFO::its now!!!!!!!! on 
2023-12-01 16:54:00,726:INFO::its now!!!!!!!!5
2023-12-01 16:54:00,975:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:00,977:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 1.2907 | Train_Classification_Loss 1.3221 | Dmon_Loss -0.0627 | Val_Loss 1.3317 | Search Time(s) 0.6335 | Infer Time(s) 0.2493 | Time(s) 0.8829 
2023-12-01 16:54:01,064:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 1;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 1;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 0;	26118: 0;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:01,066:INFO::Validation loss decreased (1.333401 --> 1.331658).  Saving model ...
2023-12-01 16:54:01,069:INFO::Epoch: 20
tensor([[0.5757, 0.5732, 0.5757, 0.5761],
        [0.5743, 0.5772, 0.5732, 0.5761],
        [0.5791, 0.5800, 0.5749, 0.5777],
        [0.5793, 0.5798, 0.5757, 0.5777]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:01,071:INFO::its now!!!!!!!!5
2023-12-01 16:54:01,360:INFO::its now!!!!!!!!0
2023-12-01 16:54:01,361:INFO::its now!!!!!!!!3
2023-12-01 16:54:01,407:INFO::its now!!!!!!!!5
2023-12-01 16:54:01,667:INFO::its now!!!!!!!!
2023-12-01 16:54:01,667:INFO::its now!!!!!!!! on 
2023-12-01 16:54:01,707:INFO::its now!!!!!!!!5
2023-12-01 16:54:01,963:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:01,965:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 1.2834 | Train_Classification_Loss 1.3148 | Dmon_Loss -0.0628 | Val_Loss 1.3268 | Search Time(s) 0.6395 | Infer Time(s) 0.2573 | Time(s) 0.8968 
2023-12-01 16:54:02,039:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 2;	26122: 3;	26123: 3;	26124: 3;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 16:54:02,040:INFO::Validation loss decreased (1.331658 --> 1.326793).  Saving model ...
2023-12-01 16:54:02,043:INFO::Epoch: 21
tensor([[0.5813, 0.5788, 0.5809, 0.5791],
        [0.5801, 0.5800, 0.5787, 0.5815],
        [0.5840, 0.5827, 0.5810, 0.5834],
        [0.5843, 0.5825, 0.5817, 0.5834]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:02,044:INFO::its now!!!!!!!!5
2023-12-01 16:54:02,277:INFO::its now!!!!!!!!0
2023-12-01 16:54:02,278:INFO::its now!!!!!!!!3
2023-12-01 16:54:02,309:INFO::its now!!!!!!!!5
2023-12-01 16:54:02,552:INFO::its now!!!!!!!!
2023-12-01 16:54:02,553:INFO::its now!!!!!!!! on 
2023-12-01 16:54:02,591:INFO::its now!!!!!!!!5
2023-12-01 16:54:02,818:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:02,819:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 1.2822 | Train_Classification_Loss 1.3136 | Dmon_Loss -0.0628 | Val_Loss 1.3266 | Search Time(s) 0.5497 | Infer Time(s) 0.2274 | Time(s) 0.7770 
2023-12-01 16:54:02,889:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:02,890:INFO::Validation loss decreased (1.326793 --> 1.326634).  Saving model ...
2023-12-01 16:54:02,894:INFO::Epoch: 22
tensor([[0.5842, 0.5858, 0.5876, 0.5855],
        [0.5868, 0.5860, 0.5856, 0.5842],
        [0.5866, 0.5886, 0.5879, 0.5906],
        [0.5870, 0.5884, 0.5887, 0.5906]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:02,895:INFO::its now!!!!!!!!5
2023-12-01 16:54:03,179:INFO::its now!!!!!!!!0
2023-12-01 16:54:03,180:INFO::its now!!!!!!!!3
2023-12-01 16:54:03,213:INFO::its now!!!!!!!!5
2023-12-01 16:54:03,459:INFO::its now!!!!!!!!
2023-12-01 16:54:03,459:INFO::its now!!!!!!!! on 
2023-12-01 16:54:03,513:INFO::its now!!!!!!!!5
2023-12-01 16:54:03,751:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:03,753:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 1.2743 | Train_Classification_Loss 1.3057 | Dmon_Loss -0.0629 | Val_Loss 1.3183 | Search Time(s) 0.6048 | Infer Time(s) 0.2553 | Time(s) 0.8602 
2023-12-01 16:54:03,821:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:03,823:INFO::Validation loss decreased (1.326634 --> 1.318263).  Saving model ...
2023-12-01 16:54:03,826:INFO::Epoch: 23
tensor([[0.5882, 0.5921, 0.5911, 0.5917],
        [0.5902, 0.5920, 0.5917, 0.5886],
        [0.5907, 0.5944, 0.5940, 0.5942],
        [0.5911, 0.5943, 0.5947, 0.5943]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:03,826:INFO::its now!!!!!!!!5
2023-12-01 16:54:04,093:INFO::its now!!!!!!!!0
2023-12-01 16:54:04,095:INFO::its now!!!!!!!!3
2023-12-01 16:54:04,139:INFO::its now!!!!!!!!5
2023-12-01 16:54:04,401:INFO::its now!!!!!!!!
2023-12-01 16:54:04,401:INFO::its now!!!!!!!! on 
2023-12-01 16:54:04,460:INFO::its now!!!!!!!!5
2023-12-01 16:54:04,716:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 1.2778 | Train_Classification_Loss 1.3092 | Dmon_Loss -0.0629 | Val_Loss 1.3188 | Search Time(s) 0.6359 | Infer Time(s) 0.2573 | Time(s) 0.8932 
2023-12-01 16:54:04,791:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 1;	26108: 0;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:04,792:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:04,796:INFO::Epoch: 24
tensor([[0.5930, 0.5953, 0.5958, 0.5981],
        [0.5946, 0.5950, 0.5977, 0.5940],
        [0.5958, 0.5974, 0.5997, 0.5991],
        [0.5963, 0.6002, 0.5979, 0.5991]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:04,797:INFO::its now!!!!!!!!5
2023-12-01 16:54:05,053:INFO::its now!!!!!!!!0
2023-12-01 16:54:05,054:INFO::its now!!!!!!!!3
2023-12-01 16:54:05,102:INFO::its now!!!!!!!!5
2023-12-01 16:54:05,353:INFO::its now!!!!!!!!
2023-12-01 16:54:05,354:INFO::its now!!!!!!!! on 
2023-12-01 16:54:05,391:INFO::its now!!!!!!!!5
2023-12-01 16:54:05,625:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:05,627:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 1.2686 | Train_Classification_Loss 1.3000 | Dmon_Loss -0.0629 | Val_Loss 1.3165 | Search Time(s) 0.5965 | Infer Time(s) 0.2364 | Time(s) 0.8329 
2023-12-01 16:54:05,692:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 2;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 1;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:05,693:INFO::Validation loss decreased (1.318263 --> 1.316479).  Saving model ...
2023-12-01 16:54:05,695:INFO::Epoch: 25
tensor([[0.5993, 0.6012, 0.6024, 0.6013],
        [0.6007, 0.6011, 0.6007, 0.6012],
        [0.6026, 0.6034, 0.6027, 0.6058],
        [0.6031, 0.6032, 0.6035, 0.6059]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:05,696:INFO::its now!!!!!!!!5
2023-12-01 16:54:05,936:INFO::its now!!!!!!!!0
2023-12-01 16:54:05,936:INFO::its now!!!!!!!!3
2023-12-01 16:54:05,967:INFO::its now!!!!!!!!5
2023-12-01 16:54:06,222:INFO::its now!!!!!!!!
2023-12-01 16:54:06,222:INFO::its now!!!!!!!! on 
2023-12-01 16:54:06,275:INFO::its now!!!!!!!!5
2023-12-01 16:54:06,522:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:06,524:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 1.2648 | Train_Classification_Loss 1.2963 | Dmon_Loss -0.0630 | Val_Loss 1.3090 | Search Time(s) 0.5690 | Infer Time(s) 0.2599 | Time(s) 0.8289 
2023-12-01 16:54:06,596:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 2;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:06,598:INFO::Validation loss decreased (1.316479 --> 1.309026).  Saving model ...
2023-12-01 16:54:06,601:INFO::Epoch: 26
tensor([[0.6074, 0.6094, 0.6057, 0.6089],
        [0.6086, 0.6096, 0.6077, 0.6049],
        [0.6113, 0.6118, 0.6094, 0.6093],
        [0.6118, 0.6105, 0.6113, 0.6093]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:06,602:INFO::its now!!!!!!!!5
2023-12-01 16:54:06,846:INFO::its now!!!!!!!!0
2023-12-01 16:54:06,847:INFO::its now!!!!!!!!3
2023-12-01 16:54:06,894:INFO::its now!!!!!!!!5
2023-12-01 16:54:07,135:INFO::its now!!!!!!!!
2023-12-01 16:54:07,135:INFO::its now!!!!!!!! on 
2023-12-01 16:54:07,180:INFO::its now!!!!!!!!5
2023-12-01 16:54:07,431:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:07,433:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 1.2594 | Train_Classification_Loss 1.2909 | Dmon_Loss -0.0630 | Val_Loss 1.3029 | Search Time(s) 0.5810 | Infer Time(s) 0.2519 | Time(s) 0.8329 
2023-12-01 16:54:07,499:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:07,500:INFO::Validation loss decreased (1.309026 --> 1.302863).  Saving model ...
2023-12-01 16:54:07,503:INFO::Epoch: 27
tensor([[0.6148, 0.6136, 0.6114, 0.6167],
        [0.6159, 0.6139, 0.6149, 0.6109],
        [0.6192, 0.6160, 0.6163, 0.6150],
        [0.6163, 0.6179, 0.6187, 0.6151]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:07,504:INFO::its now!!!!!!!!5
2023-12-01 16:54:07,760:INFO::its now!!!!!!!!0
2023-12-01 16:54:07,760:INFO::its now!!!!!!!!3
2023-12-01 16:54:07,792:INFO::its now!!!!!!!!5
2023-12-01 16:54:08,041:INFO::its now!!!!!!!!
2023-12-01 16:54:08,042:INFO::its now!!!!!!!! on 
2023-12-01 16:54:08,098:INFO::its now!!!!!!!!5
2023-12-01 16:54:08,338:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 1.2581 | Train_Classification_Loss 1.2896 | Dmon_Loss -0.0630 | Val_Loss 1.3048 | Search Time(s) 0.5814 | Infer Time(s) 0.2564 | Time(s) 0.8379 
2023-12-01 16:54:08,412:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:08,414:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:08,417:INFO::Epoch: 28
tensor([[0.6221, 0.6196, 0.6182, 0.6206],
        [0.6196, 0.6202, 0.6223, 0.6182],
        [0.6233, 0.6223, 0.6234, 0.6220],
        [0.6225, 0.6255, 0.6225, 0.6221]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:08,418:INFO::its now!!!!!!!!5
2023-12-01 16:54:08,657:INFO::its now!!!!!!!!0
2023-12-01 16:54:08,658:INFO::its now!!!!!!!!3
2023-12-01 16:54:08,705:INFO::its now!!!!!!!!5
2023-12-01 16:54:08,918:INFO::its now!!!!!!!!
2023-12-01 16:54:08,919:INFO::its now!!!!!!!! on 
2023-12-01 16:54:08,976:INFO::its now!!!!!!!!5
2023-12-01 16:54:09,197:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:09,200:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 1.2536 | Train_Classification_Loss 1.2851 | Dmon_Loss -0.0630 | Val_Loss 1.3013 | Search Time(s) 0.5605 | Infer Time(s) 0.2220 | Time(s) 0.7825 
2023-12-01 16:54:09,273:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:09,274:INFO::Validation loss decreased (1.302863 --> 1.301265).  Saving model ...
2023-12-01 16:54:09,277:INFO::Epoch: 29
tensor([[0.6258, 0.6253, 0.6244, 0.6256],
        [0.6240, 0.6261, 0.6261, 0.6247],
        [0.6280, 0.6281, 0.6270, 0.6283],
        [0.6283, 0.6295, 0.6270, 0.6284]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:09,278:INFO::its now!!!!!!!!5
2023-12-01 16:54:09,509:INFO::its now!!!!!!!!0
2023-12-01 16:54:09,509:INFO::its now!!!!!!!!3
2023-12-01 16:54:09,558:INFO::its now!!!!!!!!5
2023-12-01 16:54:09,809:INFO::its now!!!!!!!!
2023-12-01 16:54:09,810:INFO::its now!!!!!!!! on 
2023-12-01 16:54:09,866:INFO::its now!!!!!!!!5
2023-12-01 16:54:10,077:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:10,079:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 1.2458 | Train_Classification_Loss 1.2773 | Dmon_Loss -0.0630 | Val_Loss 1.2980 | Search Time(s) 0.5910 | Infer Time(s) 0.2114 | Time(s) 0.8024 
2023-12-01 16:54:10,161:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:10,162:INFO::Validation loss decreased (1.301265 --> 1.297956).  Saving model ...
2023-12-01 16:54:10,166:INFO::Epoch: 30
tensor([[0.6277, 0.6307, 0.6302, 0.6310],
        [0.6287, 0.6291, 0.6306, 0.6308],
        [0.6330, 0.6337, 0.6314, 0.6315],
        [0.6339, 0.6315, 0.6318, 0.6343]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:10,167:INFO::its now!!!!!!!!5
2023-12-01 16:54:10,429:INFO::its now!!!!!!!!0
2023-12-01 16:54:10,429:INFO::its now!!!!!!!!3
2023-12-01 16:54:10,474:INFO::its now!!!!!!!!5
2023-12-01 16:54:10,726:INFO::its now!!!!!!!!
2023-12-01 16:54:10,726:INFO::its now!!!!!!!! on 
2023-12-01 16:54:10,782:INFO::its now!!!!!!!!5
2023-12-01 16:54:11,016:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:11,019:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 1.2350 | Train_Classification_Loss 1.2667 | Dmon_Loss -0.0633 | Val_Loss 1.2873 | Search Time(s) 0.6090 | Infer Time(s) 0.2443 | Time(s) 0.8533 
2023-12-01 16:54:11,106:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:11,107:INFO::Validation loss decreased (1.297956 --> 1.287332).  Saving model ...
2023-12-01 16:54:11,110:INFO::Epoch: 31
tensor([[0.6319, 0.6369, 0.6366, 0.6337],
        [0.6342, 0.6343, 0.6363, 0.6340],
        [0.6390, 0.6366, 0.6369, 0.6368],
        [0.6401, 0.6361, 0.6375, 0.6373]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:11,111:INFO::its now!!!!!!!!5
2023-12-01 16:54:11,376:INFO::its now!!!!!!!!0
2023-12-01 16:54:11,377:INFO::its now!!!!!!!!3
2023-12-01 16:54:11,425:INFO::its now!!!!!!!!5
2023-12-01 16:54:11,663:INFO::its now!!!!!!!!
2023-12-01 16:54:11,663:INFO::its now!!!!!!!! on 
2023-12-01 16:54:11,719:INFO::its now!!!!!!!!5
2023-12-01 16:54:11,955:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:11,957:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 1.2321 | Train_Classification_Loss 1.2637 | Dmon_Loss -0.0632 | Val_Loss 1.2800 | Search Time(s) 0.6110 | Infer Time(s) 0.2374 | Time(s) 0.8483 
2023-12-01 16:54:12,024:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:12,025:INFO::Validation loss decreased (1.287332 --> 1.280037).  Saving model ...
2023-12-01 16:54:12,028:INFO::Epoch: 32
tensor([[0.6371, 0.6400, 0.6432, 0.6388],
        [0.6401, 0.6403, 0.6391, 0.6391],
        [0.6420, 0.6415, 0.6428, 0.6429],
        [0.6434, 0.6419, 0.6435, 0.6424]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:12,029:INFO::its now!!!!!!!!5
2023-12-01 16:54:12,294:INFO::its now!!!!!!!!0
2023-12-01 16:54:12,295:INFO::its now!!!!!!!!3
2023-12-01 16:54:12,344:INFO::its now!!!!!!!!5
2023-12-01 16:54:12,615:INFO::its now!!!!!!!!
2023-12-01 16:54:12,615:INFO::its now!!!!!!!! on 
2023-12-01 16:54:12,652:INFO::its now!!!!!!!!5
2023-12-01 16:54:12,901:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:12,903:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 1.2243 | Train_Classification_Loss 1.2560 | Dmon_Loss -0.0634 | Val_Loss 1.2773 | Search Time(s) 0.6224 | Infer Time(s) 0.2533 | Time(s) 0.8757 
2023-12-01 16:54:12,985:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:12,986:INFO::Validation loss decreased (1.280037 --> 1.277329).  Saving model ...
2023-12-01 16:54:12,988:INFO::Epoch: 33
tensor([[0.6427, 0.6448, 0.6465, 0.6448],
        [0.6460, 0.6433, 0.6438, 0.6452],
        [0.6468, 0.6472, 0.6487, 0.6460],
        [0.6483, 0.6480, 0.6467, 0.6483]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:12,989:INFO::its now!!!!!!!!5
2023-12-01 16:54:13,244:INFO::its now!!!!!!!!0
2023-12-01 16:54:13,245:INFO::its now!!!!!!!!3
2023-12-01 16:54:13,292:INFO::its now!!!!!!!!5
2023-12-01 16:54:13,541:INFO::its now!!!!!!!!
2023-12-01 16:54:13,541:INFO::its now!!!!!!!! on 
2023-12-01 16:54:13,580:INFO::its now!!!!!!!!5
2023-12-01 16:54:13,844:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 1.2232 | Train_Classification_Loss 1.2548 | Dmon_Loss -0.0632 | Val_Loss 1.2805 | Search Time(s) 0.5915 | Infer Time(s) 0.2673 | Time(s) 0.8588 
2023-12-01 16:54:13,920:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:13,922:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:13,925:INFO::Epoch: 34
tensor([[0.6456, 0.6508, 0.6519, 0.6517],
        [0.6489, 0.6486, 0.6497, 0.6521],
        [0.6528, 0.6501, 0.6551, 0.6513],
        [0.6544, 0.6547, 0.6485, 0.6549]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:13,926:INFO::its now!!!!!!!!5
2023-12-01 16:54:14,142:INFO::its now!!!!!!!!0
2023-12-01 16:54:14,143:INFO::its now!!!!!!!!3
2023-12-01 16:54:14,173:INFO::its now!!!!!!!!5
2023-12-01 16:54:14,422:INFO::its now!!!!!!!!
2023-12-01 16:54:14,422:INFO::its now!!!!!!!! on 
2023-12-01 16:54:14,481:INFO::its now!!!!!!!!5
2023-12-01 16:54:14,732:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:14,734:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 1.2213 | Train_Classification_Loss 1.2530 | Dmon_Loss -0.0634 | Val_Loss 1.2747 | Search Time(s) 0.5565 | Infer Time(s) 0.2533 | Time(s) 0.8098 
2023-12-01 16:54:14,807:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:14,808:INFO::Validation loss decreased (1.277329 --> 1.274699).  Saving model ...
2023-12-01 16:54:14,812:INFO::Epoch: 35
tensor([[0.6501, 0.6570, 0.6546, 0.6587],
        [0.6535, 0.6546, 0.6559, 0.6555],
        [0.6590, 0.6550, 0.6584, 0.6574],
        [0.6606, 0.6613, 0.6527, 0.6584]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:14,813:INFO::its now!!!!!!!!5
2023-12-01 16:54:15,056:INFO::its now!!!!!!!!0
2023-12-01 16:54:15,056:INFO::its now!!!!!!!!3
2023-12-01 16:54:15,110:INFO::its now!!!!!!!!5
2023-12-01 16:54:15,359:INFO::its now!!!!!!!!
2023-12-01 16:54:15,359:INFO::its now!!!!!!!! on 
2023-12-01 16:54:15,419:INFO::its now!!!!!!!!5
2023-12-01 16:54:15,651:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:15,653:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 1.2024 | Train_Classification_Loss 1.2341 | Dmon_Loss -0.0635 | Val_Loss 1.2608 | Search Time(s) 0.6094 | Infer Time(s) 0.2334 | Time(s) 0.8427 
2023-12-01 16:54:15,734:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:15,736:INFO::Validation loss decreased (1.274699 --> 1.260799).  Saving model ...
2023-12-01 16:54:15,741:INFO::Epoch: 36
tensor([[0.6567, 0.6645, 0.6606, 0.6622],
        [0.6601, 0.6623, 0.6590, 0.6621],
        [0.6622, 0.6621, 0.6643, 0.6651],
        [0.6682, 0.6648, 0.6592, 0.6649]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:15,744:INFO::its now!!!!!!!!5
2023-12-01 16:54:15,979:INFO::its now!!!!!!!!0
2023-12-01 16:54:15,980:INFO::its now!!!!!!!!3
2023-12-01 16:54:16,028:INFO::its now!!!!!!!!5
2023-12-01 16:54:16,307:INFO::its now!!!!!!!!
2023-12-01 16:54:16,307:INFO::its now!!!!!!!! on 
2023-12-01 16:54:16,350:INFO::its now!!!!!!!!5
2023-12-01 16:54:16,615:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 1.2049 | Train_Classification_Loss 1.2366 | Dmon_Loss -0.0634 | Val_Loss 1.2660 | Search Time(s) 0.6114 | Infer Time(s) 0.2663 | Time(s) 0.8777 
2023-12-01 16:54:16,695:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:16,696:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:16,700:INFO::Epoch: 37
tensor([[0.6653, 0.6683, 0.6694, 0.6702],
        [0.6687, 0.6661, 0.6665, 0.6713],
        [0.6697, 0.6714, 0.6727, 0.6689],
        [0.6723, 0.6724, 0.6679, 0.6739]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:16,701:INFO::its now!!!!!!!!5
2023-12-01 16:54:16,984:INFO::its now!!!!!!!!0
2023-12-01 16:54:16,985:INFO::its now!!!!!!!!3
2023-12-01 16:54:17,019:INFO::its now!!!!!!!!5
2023-12-01 16:54:17,297:INFO::its now!!!!!!!!
2023-12-01 16:54:17,297:INFO::its now!!!!!!!! on 
2023-12-01 16:54:17,357:INFO::its now!!!!!!!!5
2023-12-01 16:54:17,576:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:17,578:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 1.2012 | Train_Classification_Loss 1.2330 | Dmon_Loss -0.0636 | Val_Loss 1.2596 | Search Time(s) 0.6483 | Infer Time(s) 0.2324 | Time(s) 0.8806 
2023-12-01 16:54:17,647:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:17,648:INFO::Validation loss decreased (1.260799 --> 1.259592).  Saving model ...
2023-12-01 16:54:17,651:INFO::Epoch: 38
tensor([[0.6727, 0.6737, 0.6771, 0.6742],
        [0.6761, 0.6717, 0.6735, 0.6760],
        [0.6768, 0.6794, 0.6770, 0.6745],
        [0.6779, 0.6796, 0.6755, 0.6785]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:17,652:INFO::its now!!!!!!!!5
2023-12-01 16:54:17,901:INFO::its now!!!!!!!!0
2023-12-01 16:54:17,902:INFO::its now!!!!!!!!3
2023-12-01 16:54:17,950:INFO::its now!!!!!!!!5
2023-12-01 16:54:18,212:INFO::its now!!!!!!!!
2023-12-01 16:54:18,212:INFO::its now!!!!!!!! on 
2023-12-01 16:54:18,252:INFO::its now!!!!!!!!5
2023-12-01 16:54:18,486:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:18,488:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 1.1921 | Train_Classification_Loss 1.2238 | Dmon_Loss -0.0635 | Val_Loss 1.2557 | Search Time(s) 0.6014 | Infer Time(s) 0.2354 | Time(s) 0.8368 
2023-12-01 16:54:18,548:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:18,550:INFO::Validation loss decreased (1.259592 --> 1.255659).  Saving model ...
2023-12-01 16:54:18,552:INFO::Epoch: 39
tensor([[0.6814, 0.6818, 0.6810, 0.6820],
        [0.6799, 0.6800, 0.6823, 0.6839],
        [0.6856, 0.6834, 0.6842, 0.6830],
        [0.6861, 0.6833, 0.6844, 0.6863]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:18,553:INFO::its now!!!!!!!!5
2023-12-01 16:54:18,799:INFO::its now!!!!!!!!0
2023-12-01 16:54:18,800:INFO::its now!!!!!!!!3
2023-12-01 16:54:18,834:INFO::its now!!!!!!!!5
2023-12-01 16:54:19,095:INFO::its now!!!!!!!!
2023-12-01 16:54:19,095:INFO::its now!!!!!!!! on 
2023-12-01 16:54:19,152:INFO::its now!!!!!!!!5
2023-12-01 16:54:19,382:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:19,386:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 1.1709 | Train_Classification_Loss 1.2028 | Dmon_Loss -0.0639 | Val_Loss 1.2359 | Search Time(s) 0.5884 | Infer Time(s) 0.2443 | Time(s) 0.8328 
2023-12-01 16:54:19,458:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:19,460:INFO::Validation loss decreased (1.255659 --> 1.235858).  Saving model ...
2023-12-01 16:54:19,463:INFO::Epoch: 40
tensor([[0.6910, 0.6916, 0.6890, 0.6859],
        [0.6874, 0.6901, 0.6923, 0.6879],
        [0.6900, 0.6915, 0.6933, 0.6931],
        [0.6959, 0.6913, 0.6942, 0.6903]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:19,464:INFO::its now!!!!!!!!5
2023-12-01 16:54:19,705:INFO::its now!!!!!!!!0
2023-12-01 16:54:19,705:INFO::its now!!!!!!!!3
2023-12-01 16:54:19,756:INFO::its now!!!!!!!!5
2023-12-01 16:54:20,004:INFO::its now!!!!!!!!
2023-12-01 16:54:20,004:INFO::its now!!!!!!!! on 
2023-12-01 16:54:20,066:INFO::its now!!!!!!!!5
2023-12-01 16:54:20,312:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:20,314:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 1.1672 | Train_Classification_Loss 1.1991 | Dmon_Loss -0.0638 | Val_Loss 1.2292 | Search Time(s) 0.6044 | Infer Time(s) 0.2473 | Time(s) 0.8517 
2023-12-01 16:54:20,384:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:20,385:INFO::Validation loss decreased (1.235858 --> 1.229152).  Saving model ...
2023-12-01 16:54:20,391:INFO::Epoch: 41
tensor([[0.6995, 0.6966, 0.6969, 0.6923],
        [0.6950, 0.6991, 0.6973, 0.6942],
        [0.6964, 0.6995, 0.6980, 0.7021],
        [0.7013, 0.6994, 0.7028, 0.6966]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:20,393:INFO::its now!!!!!!!!5
2023-12-01 16:54:20,637:INFO::its now!!!!!!!!0
2023-12-01 16:54:20,638:INFO::its now!!!!!!!!3
2023-12-01 16:54:20,689:INFO::its now!!!!!!!!5
2023-12-01 16:54:20,944:INFO::its now!!!!!!!!
2023-12-01 16:54:20,944:INFO::its now!!!!!!!! on 
2023-12-01 16:54:20,999:INFO::its now!!!!!!!!5
2023-12-01 16:54:21,268:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:21,269:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 1.1629 | Train_Classification_Loss 1.1948 | Dmon_Loss -0.0638 | Val_Loss 1.2228 | Search Time(s) 0.6134 | Infer Time(s) 0.2703 | Time(s) 0.8836 
2023-12-01 16:54:21,331:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:21,332:INFO::Validation loss decreased (1.229152 --> 1.222837).  Saving model ...
2023-12-01 16:54:21,335:INFO::Epoch: 42
tensor([[0.7037, 0.7022, 0.7040, 0.6989],
        [0.7017, 0.7037, 0.7028, 0.7006],
        [0.7027, 0.7066, 0.7032, 0.7067],
        [0.7070, 0.7065, 0.7074, 0.7029]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:21,336:INFO::its now!!!!!!!!5
2023-12-01 16:54:21,559:INFO::its now!!!!!!!!0
2023-12-01 16:54:21,559:INFO::its now!!!!!!!!3
2023-12-01 16:54:21,608:INFO::its now!!!!!!!!5
2023-12-01 16:54:21,874:INFO::its now!!!!!!!!
2023-12-01 16:54:21,874:INFO::its now!!!!!!!! on 
2023-12-01 16:54:21,931:INFO::its now!!!!!!!!5
2023-12-01 16:54:22,155:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 1.1684 | Train_Classification_Loss 1.2003 | Dmon_Loss -0.0639 | Val_Loss 1.2311 | Search Time(s) 0.5844 | Infer Time(s) 0.2384 | Time(s) 0.8228 
2023-12-01 16:54:22,212:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:22,214:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:22,217:INFO::Epoch: 43
tensor([[0.7095, 0.7089, 0.7075, 0.7064],
        [0.7087, 0.7060, 0.7094, 0.7079],
        [0.7098, 0.7140, 0.7095, 0.7090],
        [0.7139, 0.7139, 0.7100, 0.7101]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:22,218:INFO::its now!!!!!!!!5
2023-12-01 16:54:22,492:INFO::its now!!!!!!!!0
2023-12-01 16:54:22,493:INFO::its now!!!!!!!!3
2023-12-01 16:54:22,544:INFO::its now!!!!!!!!5
2023-12-01 16:54:22,796:INFO::its now!!!!!!!!
2023-12-01 16:54:22,796:INFO::its now!!!!!!!! on 
2023-12-01 16:54:22,853:INFO::its now!!!!!!!!5
2023-12-01 16:54:23,102:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:23,104:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 1.1417 | Train_Classification_Loss 1.1738 | Dmon_Loss -0.0643 | Val_Loss 1.2086 | Search Time(s) 0.6253 | Infer Time(s) 0.2623 | Time(s) 0.8876 
2023-12-01 16:54:23,184:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:23,186:INFO::Validation loss decreased (1.222837 --> 1.208573).  Saving model ...
2023-12-01 16:54:23,189:INFO::Epoch: 44
tensor([[0.7124, 0.7167, 0.7140, 0.7149],
        [0.7165, 0.7119, 0.7128, 0.7163],
        [0.7180, 0.7178, 0.7170, 0.7149],
        [0.7218, 0.7178, 0.7157, 0.7184]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:23,190:INFO::its now!!!!!!!!5
2023-12-01 16:54:23,447:INFO::its now!!!!!!!!0
2023-12-01 16:54:23,448:INFO::its now!!!!!!!!3
2023-12-01 16:54:23,495:INFO::its now!!!!!!!!5
2023-12-01 16:54:23,749:INFO::its now!!!!!!!!
2023-12-01 16:54:23,749:INFO::its now!!!!!!!! on 
2023-12-01 16:54:23,792:INFO::its now!!!!!!!!5
2023-12-01 16:54:24,047:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:24,049:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 1.1292 | Train_Classification_Loss 1.1613 | Dmon_Loss -0.0643 | Val_Loss 1.2009 | Search Time(s) 0.6044 | Infer Time(s) 0.2563 | Time(s) 0.8607 
2023-12-01 16:54:24,133:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:24,134:INFO::Validation loss decreased (1.208573 --> 1.200863).  Saving model ...
2023-12-01 16:54:24,137:INFO::Epoch: 45
tensor([[0.7161, 0.7207, 0.7195, 0.7217],
        [0.7204, 0.7172, 0.7168, 0.7229],
        [0.7221, 0.7220, 0.7230, 0.7203],
        [0.7262, 0.7221, 0.7208, 0.7249]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:24,138:INFO::its now!!!!!!!!5
2023-12-01 16:54:24,366:INFO::its now!!!!!!!!0
2023-12-01 16:54:24,367:INFO::its now!!!!!!!!3
2023-12-01 16:54:24,400:INFO::its now!!!!!!!!5
2023-12-01 16:54:24,659:INFO::its now!!!!!!!!
2023-12-01 16:54:24,659:INFO::its now!!!!!!!! on 
2023-12-01 16:54:24,717:INFO::its now!!!!!!!!5
2023-12-01 16:54:24,966:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 1.1375 | Train_Classification_Loss 1.1695 | Dmon_Loss -0.0640 | Val_Loss 1.2152 | Search Time(s) 0.5814 | Infer Time(s) 0.2493 | Time(s) 0.8308 
2023-12-01 16:54:25,034:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:25,036:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:25,039:INFO::Epoch: 46
tensor([[0.7234, 0.7284, 0.7281, 0.7251],
        [0.7279, 0.7258, 0.7245, 0.7262],
        [0.7300, 0.7300, 0.7260, 0.7288],
        [0.7288, 0.7302, 0.7288, 0.7340]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:25,040:INFO::its now!!!!!!!!5
2023-12-01 16:54:25,283:INFO::its now!!!!!!!!0
2023-12-01 16:54:25,284:INFO::its now!!!!!!!!3
2023-12-01 16:54:25,335:INFO::its now!!!!!!!!5
2023-12-01 16:54:25,624:INFO::its now!!!!!!!!
2023-12-01 16:54:25,624:INFO::its now!!!!!!!! on 
2023-12-01 16:54:25,686:INFO::its now!!!!!!!!5
2023-12-01 16:54:25,958:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 1.1304 | Train_Classification_Loss 1.1625 | Dmon_Loss -0.0641 | Val_Loss 1.2090 | Search Time(s) 0.6483 | Infer Time(s) 0.2733 | Time(s) 0.9215 
2023-12-01 16:54:26,027:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:26,029:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:54:26,032:INFO::Epoch: 47
tensor([[0.7307, 0.7324, 0.7362, 0.7310],
        [0.7317, 0.7339, 0.7322, 0.7320],
        [0.7377, 0.7341, 0.7313, 0.7370],
        [0.7342, 0.7381, 0.7365, 0.7386]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:26,033:INFO::its now!!!!!!!!5
2023-12-01 16:54:26,284:INFO::its now!!!!!!!!0
2023-12-01 16:54:26,285:INFO::its now!!!!!!!!3
2023-12-01 16:54:26,333:INFO::its now!!!!!!!!5
2023-12-01 16:54:26,589:INFO::its now!!!!!!!!
2023-12-01 16:54:26,590:INFO::its now!!!!!!!! on 
2023-12-01 16:54:26,647:INFO::its now!!!!!!!!5
2023-12-01 16:54:26,909:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:26,911:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 1.1278 | Train_Classification_Loss 1.1600 | Dmon_Loss -0.0644 | Val_Loss 1.1995 | Search Time(s) 0.6183 | Infer Time(s) 0.2623 | Time(s) 0.8806 
2023-12-01 16:54:26,977:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:26,978:INFO::Validation loss decreased (1.200863 --> 1.199499).  Saving model ...
2023-12-01 16:54:26,981:INFO::Epoch: 48
tensor([[0.7384, 0.7387, 0.7402, 0.7387],
        [0.7377, 0.7380, 0.7403, 0.7396],
        [0.7416, 0.7406, 0.7382, 0.7453],
        [0.7413, 0.7463, 0.7444, 0.7410]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:26,982:INFO::its now!!!!!!!!5
2023-12-01 16:54:27,228:INFO::its now!!!!!!!!0
2023-12-01 16:54:27,229:INFO::its now!!!!!!!!3
2023-12-01 16:54:27,280:INFO::its now!!!!!!!!5
2023-12-01 16:54:27,551:INFO::its now!!!!!!!!
2023-12-01 16:54:27,552:INFO::its now!!!!!!!! on 
2023-12-01 16:54:27,594:INFO::its now!!!!!!!!5
2023-12-01 16:54:27,837:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:27,839:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 1.0929 | Train_Classification_Loss 1.1252 | Dmon_Loss -0.0646 | Val_Loss 1.1705 | Search Time(s) 0.6144 | Infer Time(s) 0.2433 | Time(s) 0.8577 
2023-12-01 16:54:27,900:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:27,901:INFO::Validation loss decreased (1.199499 --> 1.170521).  Saving model ...
2023-12-01 16:54:27,903:INFO::Epoch: 49
tensor([[0.7467, 0.7466, 0.7423, 0.7477],
        [0.7453, 0.7450, 0.7443, 0.7484],
        [0.7485, 0.7487, 0.7464, 0.7496],
        [0.7498, 0.7506, 0.7528, 0.7473]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:27,904:INFO::its now!!!!!!!!5
2023-12-01 16:54:28,135:INFO::its now!!!!!!!!0
2023-12-01 16:54:28,136:INFO::its now!!!!!!!!3
2023-12-01 16:54:28,167:INFO::its now!!!!!!!!5
2023-12-01 16:54:28,429:INFO::its now!!!!!!!!
2023-12-01 16:54:28,429:INFO::its now!!!!!!!! on 
2023-12-01 16:54:28,484:INFO::its now!!!!!!!!5
2023-12-01 16:54:28,689:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:28,693:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 1.0842 | Train_Classification_Loss 1.1167 | Dmon_Loss -0.0650 | Val_Loss 1.1603 | Search Time(s) 0.5695 | Infer Time(s) 0.2184 | Time(s) 0.7879 
2023-12-01 16:54:28,760:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:28,761:INFO::Validation loss decreased (1.170521 --> 1.160298).  Saving model ...
2023-12-01 16:54:28,765:INFO::Epoch: 50
tensor([[0.7558, 0.7557, 0.7489, 0.7522],
        [0.7542, 0.7538, 0.7517, 0.7528],
        [0.7572, 0.7580, 0.7556, 0.7517],
        [0.7594, 0.7583, 0.7575, 0.7559]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:28,766:INFO::its now!!!!!!!!5
2023-12-01 16:54:29,031:INFO::its now!!!!!!!!0
2023-12-01 16:54:29,032:INFO::its now!!!!!!!!3
2023-12-01 16:54:29,081:INFO::its now!!!!!!!!5
2023-12-01 16:54:29,341:INFO::its now!!!!!!!!
2023-12-01 16:54:29,364:INFO::its now!!!!!!!! on 
2023-12-01 16:54:29,430:INFO::its now!!!!!!!!5
2023-12-01 16:54:29,681:INFO::Epoch 00050 | lr 0.00050 | Train_Loss 1.0999 | Train_Classification_Loss 1.1322 | Dmon_Loss -0.0647 | Val_Loss 1.1784 | Search Time(s) 0.6662 | Infer Time(s) 0.2513 | Time(s) 0.9175 
2023-12-01 16:54:29,744:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 0;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:29,745:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:29,747:INFO::Epoch: 51
tensor([[0.7604, 0.7652, 0.7574, 0.7601],
        [0.7586, 0.7633, 0.7605, 0.7605],
        [0.7666, 0.7627, 0.7650, 0.7582],
        [0.7648, 0.7672, 0.7648, 0.7653]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:29,748:INFO::its now!!!!!!!!5
2023-12-01 16:54:29,998:INFO::its now!!!!!!!!0
2023-12-01 16:54:29,998:INFO::its now!!!!!!!!3
2023-12-01 16:54:30,047:INFO::its now!!!!!!!!5
2023-12-01 16:54:30,285:INFO::its now!!!!!!!!
2023-12-01 16:54:30,286:INFO::its now!!!!!!!! on 
2023-12-01 16:54:30,347:INFO::its now!!!!!!!!5
2023-12-01 16:54:30,580:INFO::Epoch 00051 | lr 0.00050 | Train_Loss 1.0850 | Train_Classification_Loss 1.1173 | Dmon_Loss -0.0646 | Val_Loss 1.1750 | Search Time(s) 0.6014 | Infer Time(s) 0.2334 | Time(s) 0.8348 
2023-12-01 16:54:30,639:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:30,640:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:54:30,643:INFO::Epoch: 52
tensor([[0.7659, 0.7700, 0.7650, 0.7675],
        [0.7641, 0.7681, 0.7681, 0.7679],
        [0.7713, 0.7685, 0.7729, 0.7650],
        [0.7709, 0.7718, 0.7717, 0.7734]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:30,644:INFO::its now!!!!!!!!5
2023-12-01 16:54:30,862:INFO::its now!!!!!!!!0
2023-12-01 16:54:30,864:INFO::its now!!!!!!!!3
2023-12-01 16:54:30,917:INFO::its now!!!!!!!!5
2023-12-01 16:54:31,182:INFO::its now!!!!!!!!
2023-12-01 16:54:31,182:INFO::its now!!!!!!!! on 
2023-12-01 16:54:31,230:INFO::its now!!!!!!!!5
2023-12-01 16:54:31,467:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:31,469:INFO::Epoch 00052 | lr 0.00050 | Train_Loss 1.0522 | Train_Classification_Loss 1.0847 | Dmon_Loss -0.0651 | Val_Loss 1.1366 | Search Time(s) 0.5874 | Infer Time(s) 0.2384 | Time(s) 0.8258 
2023-12-01 16:54:31,532:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:31,534:INFO::Validation loss decreased (1.160298 --> 1.136560).  Saving model ...
2023-12-01 16:54:31,536:INFO::Epoch: 53
tensor([[0.7742, 0.7724, 0.7747, 0.7775],
        [0.7725, 0.7763, 0.7719, 0.7777],
        [0.7795, 0.7773, 0.7769, 0.7744],
        [0.7799, 0.7801, 0.7807, 0.7775]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:31,537:INFO::its now!!!!!!!!5
2023-12-01 16:54:31,781:INFO::its now!!!!!!!!0
2023-12-01 16:54:31,782:INFO::its now!!!!!!!!3
2023-12-01 16:54:31,814:INFO::its now!!!!!!!!5
2023-12-01 16:54:32,055:INFO::its now!!!!!!!!
2023-12-01 16:54:32,056:INFO::its now!!!!!!!! on 
2023-12-01 16:54:32,111:INFO::its now!!!!!!!!5
2023-12-01 16:54:32,338:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:32,339:INFO::Epoch 00053 | lr 0.00050 | Train_Loss 1.0333 | Train_Classification_Loss 1.0662 | Dmon_Loss -0.0658 | Val_Loss 1.1237 | Search Time(s) 0.5685 | Infer Time(s) 0.2354 | Time(s) 0.8038 
2023-12-01 16:54:32,411:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:32,413:INFO::Validation loss decreased (1.136560 --> 1.123737).  Saving model ...
2023-12-01 16:54:32,416:INFO::Epoch: 54
tensor([[0.7841, 0.7799, 0.7854, 0.7825],
        [0.7825, 0.7864, 0.7801, 0.7826],
        [0.7836, 0.7877, 0.7850, 0.7852],
        [0.7905, 0.7902, 0.7857, 0.7859]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:32,417:INFO::its now!!!!!!!!5
2023-12-01 16:54:32,674:INFO::its now!!!!!!!!0
2023-12-01 16:54:32,675:INFO::its now!!!!!!!!3
2023-12-01 16:54:32,722:INFO::its now!!!!!!!!5
2023-12-01 16:54:32,934:INFO::its now!!!!!!!!
2023-12-01 16:54:32,935:INFO::its now!!!!!!!! on 
2023-12-01 16:54:32,994:INFO::its now!!!!!!!!5
2023-12-01 16:54:33,250:INFO::Epoch 00054 | lr 0.00050 | Train_Loss 1.0684 | Train_Classification_Loss 1.1009 | Dmon_Loss -0.0651 | Val_Loss 1.1479 | Search Time(s) 0.5804 | Infer Time(s) 0.2573 | Time(s) 0.8378 
2023-12-01 16:54:33,319:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:33,320:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:33,325:INFO::Epoch: 55
tensor([[0.7933, 0.7883, 0.7908, 0.7900],
        [0.7918, 0.7915, 0.7888, 0.7901],
        [0.7905, 0.7930, 0.7935, 0.7951],
        [0.7964, 0.7998, 0.7928, 0.7948]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:33,327:INFO::its now!!!!!!!!5
2023-12-01 16:54:33,606:INFO::its now!!!!!!!!0
2023-12-01 16:54:33,607:INFO::its now!!!!!!!!3
2023-12-01 16:54:33,656:INFO::its now!!!!!!!!5
2023-12-01 16:54:33,916:INFO::its now!!!!!!!!
2023-12-01 16:54:33,916:INFO::its now!!!!!!!! on 
2023-12-01 16:54:33,976:INFO::its now!!!!!!!!5
2023-12-01 16:54:34,246:INFO::Epoch 00055 | lr 0.00050 | Train_Loss 1.0543 | Train_Classification_Loss 1.0871 | Dmon_Loss -0.0655 | Val_Loss 1.1400 | Search Time(s) 0.6542 | Infer Time(s) 0.2709 | Time(s) 0.9251 
2023-12-01 16:54:34,322:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:34,323:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:54:34,327:INFO::Epoch: 56
tensor([[0.7980, 0.7962, 0.7974, 0.7979],
        [0.7965, 0.7979, 0.7969, 0.7979],
        [0.7978, 0.7995, 0.8015, 0.8002],
        [0.8033, 0.8048, 0.8001, 0.8031]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:34,328:INFO::its now!!!!!!!!5
2023-12-01 16:54:34,572:INFO::its now!!!!!!!!0
2023-12-01 16:54:34,573:INFO::its now!!!!!!!!3
2023-12-01 16:54:34,622:INFO::its now!!!!!!!!5
2023-12-01 16:54:34,896:INFO::its now!!!!!!!!
2023-12-01 16:54:34,896:INFO::its now!!!!!!!! on 
2023-12-01 16:54:34,948:INFO::its now!!!!!!!!5
2023-12-01 16:54:35,181:INFO::Epoch 00056 | lr 0.00050 | Train_Loss 1.0408 | Train_Classification_Loss 1.0734 | Dmon_Loss -0.0653 | Val_Loss 1.1377 | Search Time(s) 0.6223 | Infer Time(s) 0.2344 | Time(s) 0.8567 
2023-12-01 16:54:35,252:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:35,253:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:54:35,256:INFO::Epoch: 57
tensor([[0.8004, 0.8039, 0.8044, 0.8058],
        [0.8024, 0.8047, 0.8047, 0.8018],
        [0.8051, 0.8065, 0.8055, 0.8064],
        [0.8105, 0.8074, 0.8074, 0.8110]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:35,257:INFO::its now!!!!!!!!5
2023-12-01 16:54:35,498:INFO::its now!!!!!!!!0
2023-12-01 16:54:35,498:INFO::its now!!!!!!!!3
2023-12-01 16:54:35,545:INFO::its now!!!!!!!!5
2023-12-01 16:54:35,782:INFO::its now!!!!!!!!
2023-12-01 16:54:35,783:INFO::its now!!!!!!!! on 
2023-12-01 16:54:35,840:INFO::its now!!!!!!!!5
2023-12-01 16:54:36,070:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:36,073:INFO::Epoch 00057 | lr 0.00050 | Train_Loss 0.9863 | Train_Classification_Loss 1.0196 | Dmon_Loss -0.0666 | Val_Loss 1.0857 | Search Time(s) 0.5874 | Infer Time(s) 0.2304 | Time(s) 0.8178 
2023-12-01 16:54:36,136:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:36,138:INFO::Validation loss decreased (1.123737 --> 1.085678).  Saving model ...
2023-12-01 16:54:36,140:INFO::Epoch: 58
tensor([[0.8016, 0.8119, 0.8121, 0.8142],
        [0.8095, 0.8082, 0.8127, 0.8084],
        [0.8131, 0.8142, 0.8117, 0.8096],
        [0.8183, 0.8131, 0.8152, 0.8150]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:36,141:INFO::its now!!!!!!!!5
2023-12-01 16:54:36,384:INFO::its now!!!!!!!!0
2023-12-01 16:54:36,385:INFO::its now!!!!!!!!3
2023-12-01 16:54:36,437:INFO::its now!!!!!!!!5
2023-12-01 16:54:36,674:INFO::its now!!!!!!!!
2023-12-01 16:54:36,674:INFO::its now!!!!!!!! on 
2023-12-01 16:54:36,733:INFO::its now!!!!!!!!5
2023-12-01 16:54:37,031:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:37,032:INFO::Epoch 00058 | lr 0.00050 | Train_Loss 0.9894 | Train_Classification_Loss 1.0224 | Dmon_Loss -0.0662 | Val_Loss 1.0801 | Search Time(s) 0.5941 | Infer Time(s) 0.2972 | Time(s) 0.8913 
2023-12-01 16:54:37,104:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:37,105:INFO::Validation loss decreased (1.085678 --> 1.080130).  Saving model ...
2023-12-01 16:54:37,109:INFO::Epoch: 59
tensor([[0.8022, 0.8210, 0.8211, 0.8240],
        [0.8180, 0.8099, 0.8219, 0.8173],
        [0.8223, 0.8234, 0.8201, 0.8111],
        [0.8231, 0.8212, 0.8242, 0.8225]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:37,110:INFO::its now!!!!!!!!5
2023-12-01 16:54:37,372:INFO::its now!!!!!!!!0
2023-12-01 16:54:37,373:INFO::its now!!!!!!!!3
2023-12-01 16:54:37,424:INFO::its now!!!!!!!!5
2023-12-01 16:54:37,683:INFO::its now!!!!!!!!
2023-12-01 16:54:37,683:INFO::its now!!!!!!!! on 
2023-12-01 16:54:37,725:INFO::its now!!!!!!!!5
2023-12-01 16:54:37,935:INFO::Epoch 00059 | lr 0.00050 | Train_Loss 1.0086 | Train_Classification_Loss 1.0415 | Dmon_Loss -0.0657 | Val_Loss 1.1125 | Search Time(s) 0.6179 | Infer Time(s) 0.2114 | Time(s) 0.8293 
2023-12-01 16:54:37,997:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:37,999:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:38,002:INFO::Epoch: 60
tensor([[0.8068, 0.8297, 0.8298, 0.8289],
        [0.8263, 0.8108, 0.8306, 0.8261],
        [0.8311, 0.8280, 0.8283, 0.8165],
        [0.8298, 0.8294, 0.8293, 0.8305]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:38,003:INFO::its now!!!!!!!!5
2023-12-01 16:54:38,241:INFO::its now!!!!!!!!0
2023-12-01 16:54:38,242:INFO::its now!!!!!!!!3
2023-12-01 16:54:38,277:INFO::its now!!!!!!!!5
2023-12-01 16:54:38,549:INFO::its now!!!!!!!!
2023-12-01 16:54:38,549:INFO::its now!!!!!!!! on 
2023-12-01 16:54:38,607:INFO::its now!!!!!!!!5
2023-12-01 16:54:38,844:INFO::Epoch 00060 | lr 0.00050 | Train_Loss 1.0016 | Train_Classification_Loss 1.0350 | Dmon_Loss -0.0667 | Val_Loss 1.0976 | Search Time(s) 0.5945 | Infer Time(s) 0.2503 | Time(s) 0.8448 
2023-12-01 16:54:38,900:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:38,902:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:54:38,905:INFO::Epoch: 61
tensor([[0.8127, 0.8374, 0.8342, 0.8351],
        [0.8338, 0.8150, 0.8350, 0.8342],
        [0.8355, 0.8338, 0.8358, 0.8228],
        [0.8367, 0.8370, 0.8353, 0.8346]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:38,906:INFO::its now!!!!!!!!5
2023-12-01 16:54:39,147:INFO::its now!!!!!!!!0
2023-12-01 16:54:39,148:INFO::its now!!!!!!!!3
2023-12-01 16:54:39,200:INFO::its now!!!!!!!!5
2023-12-01 16:54:39,464:INFO::its now!!!!!!!!
2023-12-01 16:54:39,464:INFO::its now!!!!!!!! on 
2023-12-01 16:54:39,526:INFO::its now!!!!!!!!5
2023-12-01 16:54:39,776:INFO::Epoch 00061 | lr 0.00050 | Train_Loss 0.9875 | Train_Classification_Loss 1.0209 | Dmon_Loss -0.0668 | Val_Loss 1.0887 | Search Time(s) 0.6236 | Infer Time(s) 0.2503 | Time(s) 0.8739 
2023-12-01 16:54:39,854:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:39,855:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:54:39,858:INFO::Epoch: 62
tensor([[0.8197, 0.8413, 0.8404, 0.8424],
        [0.8413, 0.8214, 0.8412, 0.8382],
        [0.8378, 0.8408, 0.8435, 0.8302],
        [0.8444, 0.8448, 0.8423, 0.8368]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:39,858:INFO::its now!!!!!!!!5
2023-12-01 16:54:40,118:INFO::its now!!!!!!!!0
2023-12-01 16:54:40,118:INFO::its now!!!!!!!!3
2023-12-01 16:54:40,173:INFO::its now!!!!!!!!5
2023-12-01 16:54:40,452:INFO::its now!!!!!!!!
2023-12-01 16:54:40,452:INFO::its now!!!!!!!! on 
2023-12-01 16:54:40,511:INFO::its now!!!!!!!!5
2023-12-01 16:54:40,747:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:40,750:INFO::Epoch 00062 | lr 0.00050 | Train_Loss 0.9239 | Train_Classification_Loss 0.9581 | Dmon_Loss -0.0683 | Val_Loss 1.0337 | Search Time(s) 0.6395 | Infer Time(s) 0.2513 | Time(s) 0.8908 
2023-12-01 16:54:40,820:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 0;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:40,822:INFO::Validation loss decreased (1.080130 --> 1.033690).  Saving model ...
2023-12-01 16:54:40,824:INFO::Epoch: 63
tensor([[0.8276, 0.8476, 0.8479, 0.8462],
        [0.8452, 0.8292, 0.8486, 0.8449],
        [0.8434, 0.8487, 0.8474, 0.8385],
        [0.8526, 0.8490, 0.8501, 0.8424]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:40,825:INFO::its now!!!!!!!!5
2023-12-01 16:54:41,065:INFO::its now!!!!!!!!0
2023-12-01 16:54:41,065:INFO::its now!!!!!!!!3
2023-12-01 16:54:41,114:INFO::its now!!!!!!!!5
2023-12-01 16:54:41,340:INFO::its now!!!!!!!!
2023-12-01 16:54:41,340:INFO::its now!!!!!!!! on 
2023-12-01 16:54:41,397:INFO::its now!!!!!!!!5
2023-12-01 16:54:41,650:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:41,653:INFO::Epoch 00063 | lr 0.00050 | Train_Loss 0.9178 | Train_Classification_Loss 0.9516 | Dmon_Loss -0.0675 | Val_Loss 1.0290 | Search Time(s) 0.5742 | Infer Time(s) 0.2523 | Time(s) 0.8265 
2023-12-01 16:54:41,724:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:41,725:INFO::Validation loss decreased (1.033690 --> 1.029042).  Saving model ...
2023-12-01 16:54:41,727:INFO::Epoch: 64
tensor([[0.8360, 0.8551, 0.8516, 0.8528],
        [0.8514, 0.8377, 0.8524, 0.8529],
        [0.8507, 0.8527, 0.8537, 0.8472],
        [0.8575, 0.8555, 0.8583, 0.8499]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:41,728:INFO::its now!!!!!!!!5
2023-12-01 16:54:41,994:INFO::its now!!!!!!!!0
2023-12-01 16:54:41,994:INFO::its now!!!!!!!!3
2023-12-01 16:54:42,044:INFO::its now!!!!!!!!5
2023-12-01 16:54:42,296:INFO::its now!!!!!!!!
2023-12-01 16:54:42,296:INFO::its now!!!!!!!! on 
2023-12-01 16:54:42,352:INFO::its now!!!!!!!!5
2023-12-01 16:54:42,562:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:42,563:INFO::Epoch 00064 | lr 0.00050 | Train_Loss 0.8979 | Train_Classification_Loss 0.9323 | Dmon_Loss -0.0688 | Val_Loss 1.0122 | Search Time(s) 0.6254 | Infer Time(s) 0.2114 | Time(s) 0.8369 
2023-12-01 16:54:42,621:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:42,623:INFO::Validation loss decreased (1.029042 --> 1.012232).  Saving model ...
2023-12-01 16:54:42,627:INFO::Epoch: 65
tensor([[0.8451, 0.8589, 0.8586, 0.8615],
        [0.8594, 0.8472, 0.8594, 0.8569],
        [0.8594, 0.8598, 0.8569, 0.8567],
        [0.8652, 0.8638, 0.8631, 0.8588]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:42,628:INFO::its now!!!!!!!!5
2023-12-01 16:54:42,854:INFO::its now!!!!!!!!0
2023-12-01 16:54:42,855:INFO::its now!!!!!!!!3
2023-12-01 16:54:42,905:INFO::its now!!!!!!!!5
2023-12-01 16:54:43,150:INFO::its now!!!!!!!!
2023-12-01 16:54:43,150:INFO::its now!!!!!!!! on 
2023-12-01 16:54:43,206:INFO::its now!!!!!!!!5
2023-12-01 16:54:43,454:INFO::Epoch 00065 | lr 0.00050 | Train_Loss 0.9423 | Train_Classification_Loss 0.9762 | Dmon_Loss -0.0677 | Val_Loss 1.0504 | Search Time(s) 0.5673 | Infer Time(s) 0.2613 | Time(s) 0.8286 
2023-12-01 16:54:43,528:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:43,529:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:43,532:INFO::Epoch: 66
tensor([[0.8536, 0.8648, 0.8660, 0.8659],
        [0.8634, 0.8559, 0.8667, 0.8631],
        [0.8677, 0.8635, 0.8624, 0.8654],
        [0.8699, 0.8719, 0.8694, 0.8672]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:43,533:INFO::its now!!!!!!!!5
2023-12-01 16:54:43,790:INFO::its now!!!!!!!!0
2023-12-01 16:54:43,790:INFO::its now!!!!!!!!3
2023-12-01 16:54:43,838:INFO::its now!!!!!!!!5
2023-12-01 16:54:44,080:INFO::its now!!!!!!!!
2023-12-01 16:54:44,080:INFO::its now!!!!!!!! on 
2023-12-01 16:54:44,137:INFO::its now!!!!!!!!5
2023-12-01 16:54:44,374:INFO::Epoch 00066 | lr 0.00050 | Train_Loss 0.9369 | Train_Classification_Loss 0.9708 | Dmon_Loss -0.0679 | Val_Loss 1.0429 | Search Time(s) 0.6044 | Infer Time(s) 0.2404 | Time(s) 0.8447 
2023-12-01 16:54:44,439:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:44,440:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:54:44,443:INFO::Epoch: 67
tensor([[0.8608, 0.8708, 0.8698, 0.8713],
        [0.8684, 0.8634, 0.8704, 0.8695],
        [0.8719, 0.8684, 0.8683, 0.8729],
        [0.8754, 0.8761, 0.8757, 0.8745]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:44,444:INFO::its now!!!!!!!!5
2023-12-01 16:54:44,633:INFO::its now!!!!!!!!0
2023-12-01 16:54:44,633:INFO::its now!!!!!!!!3
2023-12-01 16:54:44,683:INFO::its now!!!!!!!!5
2023-12-01 16:54:44,960:INFO::its now!!!!!!!!
2023-12-01 16:54:44,960:INFO::its now!!!!!!!! on 
2023-12-01 16:54:45,018:INFO::its now!!!!!!!!5
2023-12-01 16:54:45,270:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:45,272:INFO::Epoch 00067 | lr 0.00050 | Train_Loss 0.8695 | Train_Classification_Loss 0.9038 | Dmon_Loss -0.0687 | Val_Loss 0.9837 | Search Time(s) 0.5745 | Infer Time(s) 0.2543 | Time(s) 0.8288 
2023-12-01 16:54:45,337:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:45,338:INFO::Validation loss decreased (1.012232 --> 0.983665).  Saving model ...
2023-12-01 16:54:45,342:INFO::Epoch: 68
tensor([[0.8680, 0.8774, 0.8752, 0.8741],
        [0.8744, 0.8709, 0.8723, 0.8765],
        [0.8776, 0.8746, 0.8749, 0.8767],
        [0.8819, 0.8785, 0.8823, 0.8818]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:45,342:INFO::its now!!!!!!!!5
2023-12-01 16:54:45,590:INFO::its now!!!!!!!!0
2023-12-01 16:54:45,591:INFO::its now!!!!!!!!3
2023-12-01 16:54:45,642:INFO::its now!!!!!!!!5
2023-12-01 16:54:45,896:INFO::its now!!!!!!!!
2023-12-01 16:54:45,896:INFO::its now!!!!!!!! on 
2023-12-01 16:54:45,937:INFO::its now!!!!!!!!5
2023-12-01 16:54:46,189:INFO::Epoch 00068 | lr 0.00050 | Train_Loss 0.9054 | Train_Classification_Loss 0.9394 | Dmon_Loss -0.0681 | Val_Loss 1.0341 | Search Time(s) 0.5974 | Infer Time(s) 0.2533 | Time(s) 0.8507 
2023-12-01 16:54:46,255:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 0;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:46,256:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:46,260:INFO::Epoch: 69
tensor([[0.8747, 0.8807, 0.8812, 0.8790],
        [0.8806, 0.8778, 0.8765, 0.8800],
        [0.8804, 0.8810, 0.8814, 0.8819],
        [0.8885, 0.8829, 0.8864, 0.8887]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:46,260:INFO::its now!!!!!!!!5
2023-12-01 16:54:46,510:INFO::its now!!!!!!!!0
2023-12-01 16:54:46,512:INFO::its now!!!!!!!!3
2023-12-01 16:54:46,546:INFO::its now!!!!!!!!5
2023-12-01 16:54:46,807:INFO::its now!!!!!!!!
2023-12-01 16:54:46,807:INFO::its now!!!!!!!! on 
2023-12-01 16:54:46,869:INFO::its now!!!!!!!!5
2023-12-01 16:54:47,120:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:47,121:INFO::Epoch 00069 | lr 0.00050 | Train_Loss 0.8258 | Train_Classification_Loss 0.8617 | Dmon_Loss -0.0717 | Val_Loss 0.9548 | Search Time(s) 0.6094 | Infer Time(s) 0.2523 | Time(s) 0.8617 
2023-12-01 16:54:47,189:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 0;	35: 3;	36: 3;	37: 0;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:47,191:INFO::Validation loss decreased (0.983665 --> 0.954834).  Saving model ...
2023-12-01 16:54:47,195:INFO::Epoch: 70
tensor([[0.8822, 0.8867, 0.8842, 0.8859],
        [0.8836, 0.8856, 0.8829, 0.8863],
        [0.8862, 0.8885, 0.8888, 0.8845],
        [0.8961, 0.8894, 0.8927, 0.8923]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:47,196:INFO::its now!!!!!!!!5
2023-12-01 16:54:47,446:INFO::its now!!!!!!!!0
2023-12-01 16:54:47,446:INFO::its now!!!!!!!!3
2023-12-01 16:54:47,498:INFO::its now!!!!!!!!5
2023-12-01 16:54:47,747:INFO::its now!!!!!!!!
2023-12-01 16:54:47,747:INFO::its now!!!!!!!! on 
2023-12-01 16:54:47,803:INFO::its now!!!!!!!!5
2023-12-01 16:54:48,030:INFO::Epoch 00070 | lr 0.00050 | Train_Loss 0.8252 | Train_Classification_Loss 0.8608 | Dmon_Loss -0.0711 | Val_Loss 0.9559 | Search Time(s) 0.6094 | Infer Time(s) 0.2284 | Time(s) 0.8378 
2023-12-01 16:54:48,101:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:48,102:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:48,105:INFO::Epoch: 71
tensor([[0.8902, 0.8897, 0.8902, 0.8941],
        [0.8895, 0.8939, 0.8905, 0.8894],
        [0.8935, 0.8966, 0.8926, 0.8904],
        [0.9008, 0.8971, 0.9002, 0.8986]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:48,106:INFO::its now!!!!!!!!5
2023-12-01 16:54:48,350:INFO::its now!!!!!!!!0
2023-12-01 16:54:48,351:INFO::its now!!!!!!!!3
2023-12-01 16:54:48,400:INFO::its now!!!!!!!!5
2023-12-01 16:54:48,637:INFO::its now!!!!!!!!
2023-12-01 16:54:48,638:INFO::its now!!!!!!!! on 
2023-12-01 16:54:48,696:INFO::its now!!!!!!!!5
2023-12-01 16:54:48,957:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:48,959:INFO::Epoch 00071 | lr 0.00050 | Train_Loss 0.8131 | Train_Classification_Loss 0.8482 | Dmon_Loss -0.0703 | Val_Loss 0.9420 | Search Time(s) 0.5930 | Infer Time(s) 0.2623 | Time(s) 0.8553 
2023-12-01 16:54:49,028:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:49,029:INFO::Validation loss decreased (0.954834 --> 0.942035).  Saving model ...
2023-12-01 16:54:49,032:INFO::Epoch: 72
tensor([[0.8979, 0.8950, 0.8970, 0.8982],
        [0.8961, 0.8981, 0.8980, 0.8950],
        [0.9009, 0.9007, 0.8982, 0.8972],
        [0.9042, 0.9046, 0.9077, 0.9055]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:49,034:INFO::its now!!!!!!!!5
2023-12-01 16:54:49,277:INFO::its now!!!!!!!!0
2023-12-01 16:54:49,278:INFO::its now!!!!!!!!3
2023-12-01 16:54:49,329:INFO::its now!!!!!!!!5
2023-12-01 16:54:49,572:INFO::its now!!!!!!!!
2023-12-01 16:54:49,572:INFO::its now!!!!!!!! on 
2023-12-01 16:54:49,631:INFO::its now!!!!!!!!5
2023-12-01 16:54:49,874:INFO::Epoch 00072 | lr 0.00050 | Train_Loss 0.8538 | Train_Classification_Loss 0.8884 | Dmon_Loss -0.0693 | Val_Loss 0.9994 | Search Time(s) 0.5993 | Infer Time(s) 0.2443 | Time(s) 0.8437 
2023-12-01 16:54:49,936:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:49,937:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:49,941:INFO::Epoch: 73
tensor([[0.9049, 0.9011, 0.9037, 0.9002],
        [0.9027, 0.9002, 0.9051, 0.9014],
        [0.9046, 0.9062, 0.9044, 0.9040],
        [0.9094, 0.9117, 0.9122, 0.9123]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:49,943:INFO::its now!!!!!!!!5
2023-12-01 16:54:50,176:INFO::its now!!!!!!!!0
2023-12-01 16:54:50,178:INFO::its now!!!!!!!!3
2023-12-01 16:54:50,230:INFO::its now!!!!!!!!5
2023-12-01 16:54:50,492:INFO::its now!!!!!!!!
2023-12-01 16:54:50,492:INFO::its now!!!!!!!! on 
2023-12-01 16:54:50,550:INFO::its now!!!!!!!!5
2023-12-01 16:54:50,759:INFO::Epoch 00073 | lr 0.00050 | Train_Loss 0.8566 | Train_Classification_Loss 0.8920 | Dmon_Loss -0.0707 | Val_Loss 0.9748 | Search Time(s) 0.6106 | Infer Time(s) 0.2104 | Time(s) 0.8210 
2023-12-01 16:54:50,818:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:50,819:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:54:50,822:INFO::Epoch: 74
tensor([[0.9084, 0.9084, 0.9113, 0.9059],
        [0.9101, 0.9056, 0.9086, 0.9091],
        [0.9107, 0.9089, 0.9117, 0.9118],
        [0.9165, 0.9194, 0.9187, 0.9158]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:50,824:INFO::its now!!!!!!!!5
2023-12-01 16:54:51,050:INFO::its now!!!!!!!!0
2023-12-01 16:54:51,051:INFO::its now!!!!!!!!3
2023-12-01 16:54:51,100:INFO::its now!!!!!!!!5
2023-12-01 16:54:51,360:INFO::its now!!!!!!!!
2023-12-01 16:54:51,360:INFO::its now!!!!!!!! on 
2023-12-01 16:54:51,403:INFO::its now!!!!!!!!5
2023-12-01 16:54:51,683:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:51,684:INFO::Epoch 00074 | lr 0.00050 | Train_Loss 0.7631 | Train_Classification_Loss 0.7991 | Dmon_Loss -0.0719 | Val_Loss 0.9023 | Search Time(s) 0.5816 | Infer Time(s) 0.2803 | Time(s) 0.8618 
2023-12-01 16:54:51,767:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 0;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:51,768:INFO::Validation loss decreased (0.942035 --> 0.902323).  Saving model ...
2023-12-01 16:54:51,772:INFO::Epoch: 75
tensor([[0.9103, 0.9149, 0.9179, 0.9117],
        [0.9165, 0.9112, 0.9104, 0.9159],
        [0.9166, 0.9103, 0.9182, 0.9185],
        [0.9229, 0.9236, 0.9248, 0.9205]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:51,772:INFO::its now!!!!!!!!5
2023-12-01 16:54:52,016:INFO::its now!!!!!!!!0
2023-12-01 16:54:52,017:INFO::its now!!!!!!!!3
2023-12-01 16:54:52,048:INFO::its now!!!!!!!!5
2023-12-01 16:54:52,297:INFO::its now!!!!!!!!
2023-12-01 16:54:52,297:INFO::its now!!!!!!!! on 
2023-12-01 16:54:52,356:INFO::its now!!!!!!!!5
2023-12-01 16:54:52,597:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:52,598:INFO::Epoch 00075 | lr 0.00050 | Train_Loss 0.7548 | Train_Classification_Loss 0.7923 | Dmon_Loss -0.0749 | Val_Loss 0.8884 | Search Time(s) 0.5875 | Infer Time(s) 0.2404 | Time(s) 0.8279 
2023-12-01 16:54:52,674:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:52,676:INFO::Validation loss decreased (0.902323 --> 0.888364).  Saving model ...
2023-12-01 16:54:52,679:INFO::Epoch: 76
tensor([[0.9150, 0.9220, 0.9213, 0.9187],
        [0.9198, 0.9179, 0.9152, 0.9233],
        [0.9234, 0.9149, 0.9253, 0.9219],
        [0.9301, 0.9294, 0.9287, 0.9267]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:52,680:INFO::its now!!!!!!!!5
2023-12-01 16:54:52,912:INFO::its now!!!!!!!!0
2023-12-01 16:54:52,913:INFO::its now!!!!!!!!3
2023-12-01 16:54:52,964:INFO::its now!!!!!!!!5
2023-12-01 16:54:53,204:INFO::its now!!!!!!!!
2023-12-01 16:54:53,205:INFO::its now!!!!!!!! on 
2023-12-01 16:54:53,265:INFO::its now!!!!!!!!5
2023-12-01 16:54:53,513:INFO::Epoch 00076 | lr 0.00050 | Train_Loss 0.8012 | Train_Classification_Loss 0.8373 | Dmon_Loss -0.0722 | Val_Loss 0.9351 | Search Time(s) 0.5879 | Infer Time(s) 0.2483 | Time(s) 0.8363 
2023-12-01 16:54:53,584:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:53,585:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:53,589:INFO::Epoch: 77
tensor([[0.9218, 0.9256, 0.9275, 0.9269],
        [0.9258, 0.9257, 0.9221, 0.9270],
        [0.9312, 0.9219, 0.9288, 0.9282],
        [0.9345, 0.9368, 0.9352, 0.9343]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:53,591:INFO::its now!!!!!!!!5
2023-12-01 16:54:53,841:INFO::its now!!!!!!!!0
2023-12-01 16:54:53,842:INFO::its now!!!!!!!!3
2023-12-01 16:54:53,892:INFO::its now!!!!!!!!5
2023-12-01 16:54:54,136:INFO::its now!!!!!!!!
2023-12-01 16:54:54,136:INFO::its now!!!!!!!! on 
2023-12-01 16:54:54,196:INFO::its now!!!!!!!!5
2023-12-01 16:54:54,434:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:54,436:INFO::Epoch 00077 | lr 0.00050 | Train_Loss 0.7300 | Train_Classification_Loss 0.7668 | Dmon_Loss -0.0735 | Val_Loss 0.8722 | Search Time(s) 0.6084 | Infer Time(s) 0.2394 | Time(s) 0.8477 
2023-12-01 16:54:54,508:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:54,510:INFO::Validation loss decreased (0.888364 --> 0.872166).  Saving model ...
2023-12-01 16:54:54,513:INFO::Epoch: 78
tensor([[0.9286, 0.9310, 0.9307, 0.9346],
        [0.9322, 0.9331, 0.9290, 0.9289],
        [0.9352, 0.9289, 0.9341, 0.9349],
        [0.9404, 0.9407, 0.9419, 0.9417]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:54,514:INFO::its now!!!!!!!!5
2023-12-01 16:54:54,741:INFO::its now!!!!!!!!0
2023-12-01 16:54:54,742:INFO::its now!!!!!!!!3
2023-12-01 16:54:54,794:INFO::its now!!!!!!!!5
2023-12-01 16:54:55,025:INFO::its now!!!!!!!!
2023-12-01 16:54:55,025:INFO::its now!!!!!!!! on 
2023-12-01 16:54:55,066:INFO::its now!!!!!!!!5
2023-12-01 16:54:55,317:INFO::Epoch 00078 | lr 0.00050 | Train_Loss 0.7912 | Train_Classification_Loss 0.8269 | Dmon_Loss -0.0713 | Val_Loss 0.9453 | Search Time(s) 0.5546 | Infer Time(s) 0.2525 | Time(s) 0.8071 
2023-12-01 16:54:55,377:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:55,379:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:55,381:INFO::Epoch: 79
tensor([[0.9364, 0.9382, 0.9369, 0.9385],
        [0.9398, 0.9369, 0.9370, 0.9348],
        [0.9372, 0.9370, 0.9413, 0.9429],
        [0.9481, 0.9473, 0.9460, 0.9499]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:55,382:INFO::its now!!!!!!!!5
2023-12-01 16:54:55,643:INFO::its now!!!!!!!!0
2023-12-01 16:54:55,644:INFO::its now!!!!!!!!3
2023-12-01 16:54:55,674:INFO::its now!!!!!!!!5
2023-12-01 16:54:55,895:INFO::its now!!!!!!!!
2023-12-01 16:54:55,895:INFO::its now!!!!!!!! on 
2023-12-01 16:54:55,951:INFO::its now!!!!!!!!5
2023-12-01 16:54:56,198:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:56,200:INFO::Epoch 00079 | lr 0.00050 | Train_Loss 0.6800 | Train_Classification_Loss 0.7200 | Dmon_Loss -0.0799 | Val_Loss 0.8371 | Search Time(s) 0.5565 | Infer Time(s) 0.2629 | Time(s) 0.8194 
2023-12-01 16:54:56,270:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 0;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:56,272:INFO::Validation loss decreased (0.872166 --> 0.837132).  Saving model ...
2023-12-01 16:54:56,274:INFO::Epoch: 80
tensor([[0.9444, 0.9461, 0.9442, 0.9405],
        [0.9437, 0.9430, 0.9452, 0.9421],
        [0.9424, 0.9453, 0.9490, 0.9469],
        [0.9562, 0.9546, 0.9523, 0.9541]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:56,275:INFO::its now!!!!!!!!5
2023-12-01 16:54:56,512:INFO::its now!!!!!!!!0
2023-12-01 16:54:56,513:INFO::its now!!!!!!!!3
2023-12-01 16:54:56,560:INFO::its now!!!!!!!!5
2023-12-01 16:54:56,798:INFO::its now!!!!!!!!
2023-12-01 16:54:56,798:INFO::its now!!!!!!!! on 
2023-12-01 16:54:56,854:INFO::its now!!!!!!!!5
2023-12-01 16:54:57,119:INFO::Epoch 00080 | lr 0.00050 | Train_Loss 0.7364 | Train_Classification_Loss 0.7745 | Dmon_Loss -0.0761 | Val_Loss 0.8824 | Search Time(s) 0.5671 | Infer Time(s) 0.2798 | Time(s) 0.8469 
2023-12-01 16:54:57,191:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 0;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:57,192:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:57,197:INFO::Epoch: 81
tensor([[0.9514, 0.9501, 0.9510, 0.9449],
        [0.9487, 0.9493, 0.9493, 0.9491],
        [0.9482, 0.9526, 0.9529, 0.9521],
        [0.9612, 0.9614, 0.9587, 0.9595]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:57,198:INFO::its now!!!!!!!!5
2023-12-01 16:54:57,457:INFO::its now!!!!!!!!0
2023-12-01 16:54:57,458:INFO::its now!!!!!!!!3
2023-12-01 16:54:57,505:INFO::its now!!!!!!!!5
2023-12-01 16:54:57,764:INFO::its now!!!!!!!!
2023-12-01 16:54:57,765:INFO::its now!!!!!!!! on 
2023-12-01 16:54:57,822:INFO::its now!!!!!!!!5
2023-12-01 16:54:58,068:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:58,071:INFO::Epoch 00081 | lr 0.00050 | Train_Loss 0.6636 | Train_Classification_Loss 0.7029 | Dmon_Loss -0.0784 | Val_Loss 0.8227 | Search Time(s) 0.6279 | Infer Time(s) 0.2473 | Time(s) 0.8752 
2023-12-01 16:54:58,146:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 0;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:58,147:INFO::Validation loss decreased (0.837132 --> 0.822734).  Saving model ...
2023-12-01 16:54:58,149:INFO::Epoch: 82
tensor([[0.9552, 0.9559, 0.9581, 0.9511],
        [0.9548, 0.9562, 0.9514, 0.9565],
        [0.9549, 0.9600, 0.9549, 0.9585],
        [0.9675, 0.9651, 0.9655, 0.9659]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:58,150:INFO::its now!!!!!!!!5
2023-12-01 16:54:58,413:INFO::its now!!!!!!!!0
2023-12-01 16:54:58,414:INFO::its now!!!!!!!!3
2023-12-01 16:54:58,465:INFO::its now!!!!!!!!5
2023-12-01 16:54:58,689:INFO::its now!!!!!!!!
2023-12-01 16:54:58,689:INFO::its now!!!!!!!! on 
2023-12-01 16:54:58,742:INFO::its now!!!!!!!!5
2023-12-01 16:54:58,964:INFO::Epoch 00082 | lr 0.00050 | Train_Loss 0.7488 | Train_Classification_Loss 0.7856 | Dmon_Loss -0.0736 | Val_Loss 0.9047 | Search Time(s) 0.5940 | Infer Time(s) 0.2224 | Time(s) 0.8164 
2023-12-01 16:54:59,019:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:54:59,020:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:54:59,022:INFO::Epoch: 83
tensor([[0.9610, 0.9627, 0.9618, 0.9583],
        [0.9618, 0.9636, 0.9564, 0.9603],
        [0.9622, 0.9638, 0.9599, 0.9657],
        [0.9717, 0.9708, 0.9729, 0.9731]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:59,023:INFO::its now!!!!!!!!5
2023-12-01 16:54:59,280:INFO::its now!!!!!!!!0
2023-12-01 16:54:59,282:INFO::its now!!!!!!!!3
2023-12-01 16:54:59,332:INFO::its now!!!!!!!!5
2023-12-01 16:54:59,558:INFO::its now!!!!!!!!
2023-12-01 16:54:59,558:INFO::its now!!!!!!!! on 
2023-12-01 16:54:59,601:INFO::its now!!!!!!!!5
2023-12-01 16:54:59,850:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:54:59,851:INFO::Epoch 00083 | lr 0.00050 | Train_Loss 0.6320 | Train_Classification_Loss 0.6716 | Dmon_Loss -0.0794 | Val_Loss 0.7960 | Search Time(s) 0.5800 | Infer Time(s) 0.2503 | Time(s) 0.8303 
2023-12-01 16:54:59,920:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 0;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 2;	26102: 1;	26103: 1;	26104: 3;	26105: 0;	26106: 1;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:54:59,921:INFO::Validation loss decreased (0.822734 --> 0.795983).  Saving model ...
2023-12-01 16:54:59,923:INFO::Epoch: 84
tensor([[0.9672, 0.9662, 0.9670, 0.9656],
        [0.9685, 0.9673, 0.9623, 0.9657],
        [0.9692, 0.9690, 0.9658, 0.9694],
        [0.9774, 0.9771, 0.9799, 0.9768]], device='cuda:0', requires_grad=True)
2023-12-01 16:54:59,923:INFO::its now!!!!!!!!5
2023-12-01 16:55:00,159:INFO::its now!!!!!!!!0
2023-12-01 16:55:00,161:INFO::its now!!!!!!!!3
2023-12-01 16:55:00,191:INFO::its now!!!!!!!!5
2023-12-01 16:55:00,462:INFO::its now!!!!!!!!
2023-12-01 16:55:00,462:INFO::its now!!!!!!!! on 
2023-12-01 16:55:00,516:INFO::its now!!!!!!!!5
2023-12-01 16:55:00,777:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:00,779:INFO::Epoch 00084 | lr 0.00050 | Train_Loss 0.6254 | Train_Classification_Loss 0.6656 | Dmon_Loss -0.0804 | Val_Loss 0.7867 | Search Time(s) 0.5796 | Infer Time(s) 0.2763 | Time(s) 0.8559 
2023-12-01 16:55:00,840:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 0;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:00,841:INFO::Validation loss decreased (0.795983 --> 0.786703).  Saving model ...
2023-12-01 16:55:00,842:INFO::Epoch: 85
tensor([[0.9706, 0.9716, 0.9734, 0.9731],
        [0.9719, 0.9729, 0.9690, 0.9724],
        [0.9764, 0.9754, 0.9725, 0.9712],
        [0.9841, 0.9838, 0.9843, 0.9824]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:00,843:INFO::its now!!!!!!!!5
2023-12-01 16:55:01,095:INFO::its now!!!!!!!!0
2023-12-01 16:55:01,096:INFO::its now!!!!!!!!3
2023-12-01 16:55:01,144:INFO::its now!!!!!!!!5
2023-12-01 16:55:01,362:INFO::its now!!!!!!!!
2023-12-01 16:55:01,363:INFO::its now!!!!!!!! on 
2023-12-01 16:55:01,420:INFO::its now!!!!!!!!5
2023-12-01 16:55:01,650:INFO::Epoch 00085 | lr 0.00050 | Train_Loss 0.6346 | Train_Classification_Loss 0.6748 | Dmon_Loss -0.0803 | Val_Loss 0.8016 | Search Time(s) 0.5787 | Infer Time(s) 0.2304 | Time(s) 0.8091 
2023-12-01 16:55:01,723:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:01,725:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:55:01,729:INFO::Epoch: 86
tensor([[0.9759, 0.9781, 0.9768, 0.9807],
        [0.9773, 0.9757, 0.9760, 0.9795],
        [0.9800, 0.9823, 0.9795, 0.9759],
        [0.9912, 0.9908, 0.9874, 0.9889]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:01,730:INFO::its now!!!!!!!!5
2023-12-01 16:55:01,955:INFO::its now!!!!!!!!0
2023-12-01 16:55:01,956:INFO::its now!!!!!!!!3
2023-12-01 16:55:02,003:INFO::its now!!!!!!!!5
2023-12-01 16:55:02,263:INFO::its now!!!!!!!!
2023-12-01 16:55:02,263:INFO::its now!!!!!!!! on 
2023-12-01 16:55:02,317:INFO::its now!!!!!!!!5
2023-12-01 16:55:02,551:INFO::Epoch 00086 | lr 0.00050 | Train_Loss 0.6906 | Train_Classification_Loss 0.7302 | Dmon_Loss -0.0793 | Val_Loss 0.8479 | Search Time(s) 0.5756 | Infer Time(s) 0.2503 | Time(s) 0.8260 
2023-12-01 16:55:02,618:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:02,619:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:55:02,623:INFO::Epoch: 87
tensor([[0.9818, 0.9846, 0.9819, 0.9845],
        [0.9832, 0.9805, 0.9828, 0.9831],
        [0.9852, 0.9858, 0.9863, 0.9816],
        [0.9959, 0.9975, 0.9922, 0.9955]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:02,624:INFO::its now!!!!!!!!5
2023-12-01 16:55:02,875:INFO::its now!!!!!!!!0
2023-12-01 16:55:02,876:INFO::its now!!!!!!!!3
2023-12-01 16:55:02,922:INFO::its now!!!!!!!!5
2023-12-01 16:55:03,181:INFO::its now!!!!!!!!
2023-12-01 16:55:03,182:INFO::its now!!!!!!!! on 
2023-12-01 16:55:03,222:INFO::its now!!!!!!!!5
2023-12-01 16:55:03,462:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:03,464:INFO::Epoch 00087 | lr 0.00050 | Train_Loss 0.5860 | Train_Classification_Loss 0.6292 | Dmon_Loss -0.0864 | Val_Loss 0.7639 | Search Time(s) 0.6010 | Infer Time(s) 0.2419 | Time(s) 0.8429 
2023-12-01 16:55:03,543:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:03,544:INFO::Validation loss decreased (0.786703 --> 0.763864).  Saving model ...
2023-12-01 16:55:03,547:INFO::Epoch: 88
tensor([[0.9884, 0.9879, 0.9883, 0.9904],
        [0.9861, 0.9868, 0.9899, 0.9889],
        [0.9916, 0.9914, 0.9897, 0.9884],
        [1.0000, 1.0000, 0.9985, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:03,548:INFO::its now!!!!!!!!5
2023-12-01 16:55:03,807:INFO::its now!!!!!!!!0
2023-12-01 16:55:03,808:INFO::its now!!!!!!!!3
2023-12-01 16:55:03,840:INFO::its now!!!!!!!!5
2023-12-01 16:55:04,075:INFO::its now!!!!!!!!
2023-12-01 16:55:04,075:INFO::its now!!!!!!!! on 
2023-12-01 16:55:04,131:INFO::its now!!!!!!!!5
2023-12-01 16:55:04,389:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:04,391:INFO::Epoch 00088 | lr 0.00050 | Train_Loss 0.5523 | Train_Classification_Loss 0.5981 | Dmon_Loss -0.0916 | Val_Loss 0.7335 | Search Time(s) 0.5850 | Infer Time(s) 0.2599 | Time(s) 0.8448 
2023-12-01 16:55:04,451:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 0;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:04,452:INFO::Validation loss decreased (0.763864 --> 0.733544).  Saving model ...
2023-12-01 16:55:04,456:INFO::Epoch: 89
tensor([[0.9951, 0.9932, 0.9949, 0.9934],
        [0.9911, 0.9934, 0.9935, 0.9955],
        [0.9948, 0.9977, 0.9949, 0.9954],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:04,457:INFO::its now!!!!!!!!5
2023-12-01 16:55:04,708:INFO::its now!!!!!!!!0
2023-12-01 16:55:04,708:INFO::its now!!!!!!!!3
2023-12-01 16:55:04,757:INFO::its now!!!!!!!!5
2023-12-01 16:55:05,002:INFO::its now!!!!!!!!
2023-12-01 16:55:05,002:INFO::its now!!!!!!!! on 
2023-12-01 16:55:05,058:INFO::its now!!!!!!!!5
2023-12-01 16:55:05,279:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:05,281:INFO::Epoch 00089 | lr 0.00050 | Train_Loss 0.5353 | Train_Classification_Loss 0.5809 | Dmon_Loss -0.0912 | Val_Loss 0.7241 | Search Time(s) 0.5894 | Infer Time(s) 0.2379 | Time(s) 0.8273 
2023-12-01 16:55:05,347:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:05,349:INFO::Validation loss decreased (0.733544 --> 0.724053).  Saving model ...
2023-12-01 16:55:05,352:INFO::Epoch: 90
tensor([[0.9990, 0.9999, 1.0000, 0.9993],
        [0.9976, 1.0000, 0.9995, 0.9988],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:05,353:INFO::its now!!!!!!!!5
2023-12-01 16:55:05,599:INFO::its now!!!!!!!!0
2023-12-01 16:55:05,600:INFO::its now!!!!!!!!3
2023-12-01 16:55:05,647:INFO::its now!!!!!!!!5
2023-12-01 16:55:05,891:INFO::its now!!!!!!!!
2023-12-01 16:55:05,891:INFO::its now!!!!!!!! on 
2023-12-01 16:55:05,929:INFO::its now!!!!!!!!5
2023-12-01 16:55:06,149:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:06,150:INFO::Epoch 00090 | lr 0.00050 | Train_Loss 0.5238 | Train_Classification_Loss 0.5713 | Dmon_Loss -0.0951 | Val_Loss 0.7065 | Search Time(s) 0.5775 | Infer Time(s) 0.2210 | Time(s) 0.7984 
2023-12-01 16:55:06,214:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 3;	26119: 1;	26120: 3;	26121: 0;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:06,215:INFO::Validation loss decreased (0.724053 --> 0.706535).  Saving model ...
2023-12-01 16:55:06,220:INFO::Epoch: 91
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:06,220:INFO::its now!!!!!!!!5
2023-12-01 16:55:06,446:INFO::its now!!!!!!!!0
2023-12-01 16:55:06,447:INFO::its now!!!!!!!!3
2023-12-01 16:55:06,474:INFO::its now!!!!!!!!5
2023-12-01 16:55:06,706:INFO::its now!!!!!!!!
2023-12-01 16:55:06,707:INFO::its now!!!!!!!! on 
2023-12-01 16:55:06,742:INFO::its now!!!!!!!!5
2023-12-01 16:55:06,972:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:06,974:INFO::Epoch 00091 | lr 0.00050 | Train_Loss 0.5005 | Train_Classification_Loss 0.5489 | Dmon_Loss -0.0967 | Val_Loss 0.6945 | Search Time(s) 0.5230 | Infer Time(s) 0.2344 | Time(s) 0.7573 
2023-12-01 16:55:07,036:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 3;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:07,038:INFO::Validation loss decreased (0.706535 --> 0.694459).  Saving model ...
2023-12-01 16:55:07,043:INFO::Epoch: 92
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:07,044:INFO::its now!!!!!!!!5
2023-12-01 16:55:07,296:INFO::its now!!!!!!!!0
2023-12-01 16:55:07,297:INFO::its now!!!!!!!!3
2023-12-01 16:55:07,324:INFO::its now!!!!!!!!5
2023-12-01 16:55:07,589:INFO::its now!!!!!!!!
2023-12-01 16:55:07,589:INFO::its now!!!!!!!! on 
2023-12-01 16:55:07,625:INFO::its now!!!!!!!!5
2023-12-01 16:55:07,853:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:07,854:INFO::Epoch 00092 | lr 0.00050 | Train_Loss 0.4938 | Train_Classification_Loss 0.5432 | Dmon_Loss -0.0989 | Val_Loss 0.6824 | Search Time(s) 0.5826 | Infer Time(s) 0.2314 | Time(s) 0.8140 
2023-12-01 16:55:07,923:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 3;	26119: 1;	26120: 1;	26121: 0;	26122: 3;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:07,925:INFO::Validation loss decreased (0.694459 --> 0.682401).  Saving model ...
2023-12-01 16:55:07,930:INFO::Epoch: 93
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:07,931:INFO::its now!!!!!!!!5
2023-12-01 16:55:08,172:INFO::its now!!!!!!!!0
2023-12-01 16:55:08,173:INFO::its now!!!!!!!!3
2023-12-01 16:55:08,200:INFO::its now!!!!!!!!5
2023-12-01 16:55:08,478:INFO::its now!!!!!!!!
2023-12-01 16:55:08,479:INFO::its now!!!!!!!! on 
2023-12-01 16:55:08,515:INFO::its now!!!!!!!!5
2023-12-01 16:55:08,755:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:08,756:INFO::Epoch 00093 | lr 0.00050 | Train_Loss 0.4776 | Train_Classification_Loss 0.5283 | Dmon_Loss -0.1014 | Val_Loss 0.6704 | Search Time(s) 0.5895 | Infer Time(s) 0.2414 | Time(s) 0.8309 
2023-12-01 16:55:08,816:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 2;	14: 3;	15: 0;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 3;	26119: 1;	26120: 3;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:08,818:INFO::Validation loss decreased (0.682401 --> 0.670426).  Saving model ...
2023-12-01 16:55:08,825:INFO::Epoch: 94
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:08,826:INFO::its now!!!!!!!!5
2023-12-01 16:55:09,071:INFO::its now!!!!!!!!0
2023-12-01 16:55:09,072:INFO::its now!!!!!!!!3
2023-12-01 16:55:09,098:INFO::its now!!!!!!!!5
2023-12-01 16:55:09,330:INFO::its now!!!!!!!!
2023-12-01 16:55:09,330:INFO::its now!!!!!!!! on 
2023-12-01 16:55:09,365:INFO::its now!!!!!!!!5
2023-12-01 16:55:09,610:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:09,612:INFO::Epoch 00094 | lr 0.00050 | Train_Loss 0.4668 | Train_Classification_Loss 0.5187 | Dmon_Loss -0.1038 | Val_Loss 0.6586 | Search Time(s) 0.5447 | Infer Time(s) 0.2473 | Time(s) 0.7920 
2023-12-01 16:55:09,660:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 1;	26119: 2;	26120: 3;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:09,661:INFO::Validation loss decreased (0.670426 --> 0.658625).  Saving model ...
2023-12-01 16:55:09,665:INFO::Epoch: 95
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:09,666:INFO::its now!!!!!!!!5
2023-12-01 16:55:09,933:INFO::its now!!!!!!!!0
2023-12-01 16:55:09,934:INFO::its now!!!!!!!!3
2023-12-01 16:55:09,963:INFO::its now!!!!!!!!5
2023-12-01 16:55:10,218:INFO::its now!!!!!!!!
2023-12-01 16:55:10,218:INFO::its now!!!!!!!! on 
2023-12-01 16:55:10,254:INFO::its now!!!!!!!!5
2023-12-01 16:55:10,465:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:10,467:INFO::Epoch 00095 | lr 0.00050 | Train_Loss 0.4518 | Train_Classification_Loss 0.5046 | Dmon_Loss -0.1056 | Val_Loss 0.6470 | Search Time(s) 0.5901 | Infer Time(s) 0.2130 | Time(s) 0.8032 
2023-12-01 16:55:10,533:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 2;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 3;	26119: 1;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:10,534:INFO::Validation loss decreased (0.658625 --> 0.647007).  Saving model ...
2023-12-01 16:55:10,537:INFO::Epoch: 96
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:10,539:INFO::its now!!!!!!!!5
2023-12-01 16:55:10,775:INFO::its now!!!!!!!!0
2023-12-01 16:55:10,776:INFO::its now!!!!!!!!3
2023-12-01 16:55:10,804:INFO::its now!!!!!!!!5
2023-12-01 16:55:11,052:INFO::its now!!!!!!!!
2023-12-01 16:55:11,052:INFO::its now!!!!!!!! on 
2023-12-01 16:55:11,089:INFO::its now!!!!!!!!5
2023-12-01 16:55:11,334:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:11,336:INFO::Epoch 00096 | lr 0.00050 | Train_Loss 0.4375 | Train_Classification_Loss 0.4911 | Dmon_Loss -0.1072 | Val_Loss 0.6356 | Search Time(s) 0.5535 | Infer Time(s) 0.2456 | Time(s) 0.7991 
2023-12-01 16:55:11,405:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 3;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:11,407:INFO::Validation loss decreased (0.647007 --> 0.635558).  Saving model ...
2023-12-01 16:55:11,412:INFO::Epoch: 97
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:11,413:INFO::its now!!!!!!!!5
2023-12-01 16:55:11,655:INFO::its now!!!!!!!!0
2023-12-01 16:55:11,656:INFO::its now!!!!!!!!3
2023-12-01 16:55:11,684:INFO::its now!!!!!!!!5
2023-12-01 16:55:11,949:INFO::its now!!!!!!!!
2023-12-01 16:55:11,949:INFO::its now!!!!!!!! on 
2023-12-01 16:55:11,984:INFO::its now!!!!!!!!5
2023-12-01 16:55:12,229:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:12,230:INFO::Epoch 00097 | lr 0.00050 | Train_Loss 0.4219 | Train_Classification_Loss 0.4772 | Dmon_Loss -0.1104 | Val_Loss 0.6243 | Search Time(s) 0.5735 | Infer Time(s) 0.2489 | Time(s) 0.8224 
2023-12-01 16:55:12,299:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:12,300:INFO::Validation loss decreased (0.635558 --> 0.624290).  Saving model ...
2023-12-01 16:55:12,304:INFO::Epoch: 98
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:12,305:INFO::its now!!!!!!!!5
2023-12-01 16:55:12,551:INFO::its now!!!!!!!!0
2023-12-01 16:55:12,552:INFO::its now!!!!!!!!3
2023-12-01 16:55:12,580:INFO::its now!!!!!!!!5
2023-12-01 16:55:12,812:INFO::its now!!!!!!!!
2023-12-01 16:55:12,812:INFO::its now!!!!!!!! on 
2023-12-01 16:55:12,848:INFO::its now!!!!!!!!5
2023-12-01 16:55:13,077:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:13,078:INFO::Epoch 00098 | lr 0.00050 | Train_Loss 0.4104 | Train_Classification_Loss 0.4672 | Dmon_Loss -0.1136 | Val_Loss 0.6132 | Search Time(s) 0.5455 | Infer Time(s) 0.2304 | Time(s) 0.7759 
2023-12-01 16:55:13,147:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:13,149:INFO::Validation loss decreased (0.624290 --> 0.613195).  Saving model ...
2023-12-01 16:55:13,153:INFO::Epoch: 99
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:13,154:INFO::its now!!!!!!!!5
2023-12-01 16:55:13,408:INFO::its now!!!!!!!!0
2023-12-01 16:55:13,410:INFO::its now!!!!!!!!3
2023-12-01 16:55:13,440:INFO::its now!!!!!!!!5
2023-12-01 16:55:13,684:INFO::its now!!!!!!!!
2023-12-01 16:55:13,684:INFO::its now!!!!!!!! on 
2023-12-01 16:55:13,719:INFO::its now!!!!!!!!5
2023-12-01 16:55:13,972:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:13,973:INFO::Epoch 00099 | lr 0.00050 | Train_Loss 0.3968 | Train_Classification_Loss 0.4534 | Dmon_Loss -0.1132 | Val_Loss 0.6022 | Search Time(s) 0.5651 | Infer Time(s) 0.2583 | Time(s) 0.8234 
2023-12-01 16:55:14,048:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 0;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:14,049:INFO::Validation loss decreased (0.613195 --> 0.602241).  Saving model ...
2023-12-01 16:55:14,054:INFO::Epoch: 100
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:14,055:INFO::its now!!!!!!!!5
2023-12-01 16:55:14,315:INFO::its now!!!!!!!!0
2023-12-01 16:55:14,316:INFO::its now!!!!!!!!3
2023-12-01 16:55:14,343:INFO::its now!!!!!!!!5
2023-12-01 16:55:14,570:INFO::its now!!!!!!!!
2023-12-01 16:55:14,570:INFO::its now!!!!!!!! on 
2023-12-01 16:55:14,606:INFO::its now!!!!!!!!5
2023-12-01 16:55:14,827:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:14,829:INFO::Epoch 00100 | lr 0.00050 | Train_Loss 0.3832 | Train_Classification_Loss 0.4427 | Dmon_Loss -0.1191 | Val_Loss 0.5915 | Search Time(s) 0.5536 | Infer Time(s) 0.2234 | Time(s) 0.7770 
2023-12-01 16:55:14,909:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:14,910:INFO::Validation loss decreased (0.602241 --> 0.591547).  Saving model ...
2023-12-01 16:55:14,915:INFO::Epoch: 101
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:14,917:INFO::its now!!!!!!!!5
2023-12-01 16:55:15,156:INFO::its now!!!!!!!!0
2023-12-01 16:55:15,157:INFO::its now!!!!!!!!3
2023-12-01 16:55:15,184:INFO::its now!!!!!!!!5
2023-12-01 16:55:15,437:INFO::its now!!!!!!!!
2023-12-01 16:55:15,437:INFO::its now!!!!!!!! on 
2023-12-01 16:55:15,474:INFO::its now!!!!!!!!5
2023-12-01 16:55:15,691:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:15,692:INFO::Epoch 00101 | lr 0.00050 | Train_Loss 0.3614 | Train_Classification_Loss 0.4224 | Dmon_Loss -0.1219 | Val_Loss 0.5811 | Search Time(s) 0.5606 | Infer Time(s) 0.2194 | Time(s) 0.7800 
2023-12-01 16:55:15,754:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 3;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:15,756:INFO::Validation loss decreased (0.591547 --> 0.581082).  Saving model ...
2023-12-01 16:55:15,761:INFO::Epoch: 102
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:15,762:INFO::its now!!!!!!!!5
2023-12-01 16:55:15,999:INFO::its now!!!!!!!!0
2023-12-01 16:55:16,000:INFO::its now!!!!!!!!3
2023-12-01 16:55:16,028:INFO::its now!!!!!!!!5
2023-12-01 16:55:16,274:INFO::its now!!!!!!!!
2023-12-01 16:55:16,275:INFO::its now!!!!!!!! on 
2023-12-01 16:55:16,311:INFO::its now!!!!!!!!5
2023-12-01 16:55:16,565:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:16,567:INFO::Epoch 00102 | lr 0.00050 | Train_Loss 0.3444 | Train_Classification_Loss 0.4064 | Dmon_Loss -0.1240 | Val_Loss 0.5708 | Search Time(s) 0.5517 | Infer Time(s) 0.2573 | Time(s) 0.8090 
2023-12-01 16:55:16,642:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 0;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:16,644:INFO::Validation loss decreased (0.581082 --> 0.570837).  Saving model ...
2023-12-01 16:55:16,647:INFO::Epoch: 103
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:16,648:INFO::its now!!!!!!!!5
2023-12-01 16:55:16,891:INFO::its now!!!!!!!!0
2023-12-01 16:55:16,892:INFO::its now!!!!!!!!3
2023-12-01 16:55:16,919:INFO::its now!!!!!!!!5
2023-12-01 16:55:17,149:INFO::its now!!!!!!!!
2023-12-01 16:55:17,149:INFO::its now!!!!!!!! on 
2023-12-01 16:55:17,185:INFO::its now!!!!!!!!5
2023-12-01 16:55:17,395:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:17,396:INFO::Epoch 00103 | lr 0.00050 | Train_Loss 0.3273 | Train_Classification_Loss 0.3904 | Dmon_Loss -0.1261 | Val_Loss 0.5609 | Search Time(s) 0.5371 | Infer Time(s) 0.2140 | Time(s) 0.7511 
2023-12-01 16:55:17,462:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:17,463:INFO::Validation loss decreased (0.570837 --> 0.560851).  Saving model ...
2023-12-01 16:55:17,467:INFO::Epoch: 104
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:17,468:INFO::its now!!!!!!!!5
2023-12-01 16:55:17,704:INFO::its now!!!!!!!!0
2023-12-01 16:55:17,705:INFO::its now!!!!!!!!3
2023-12-01 16:55:17,733:INFO::its now!!!!!!!!5
2023-12-01 16:55:17,980:INFO::its now!!!!!!!!
2023-12-01 16:55:17,980:INFO::its now!!!!!!!! on 
2023-12-01 16:55:18,015:INFO::its now!!!!!!!!5
2023-12-01 16:55:18,252:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:18,254:INFO::Epoch 00104 | lr 0.00050 | Train_Loss 0.3245 | Train_Classification_Loss 0.3888 | Dmon_Loss -0.1284 | Val_Loss 0.5512 | Search Time(s) 0.5515 | Infer Time(s) 0.2379 | Time(s) 0.7894 
2023-12-01 16:55:18,333:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 2;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:18,335:INFO::Validation loss decreased (0.560851 --> 0.551182).  Saving model ...
2023-12-01 16:55:18,340:INFO::Epoch: 105
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:18,341:INFO::its now!!!!!!!!5
2023-12-01 16:55:18,546:INFO::its now!!!!!!!!0
2023-12-01 16:55:18,547:INFO::its now!!!!!!!!3
2023-12-01 16:55:18,575:INFO::its now!!!!!!!!5
2023-12-01 16:55:18,817:INFO::its now!!!!!!!!
2023-12-01 16:55:18,817:INFO::its now!!!!!!!! on 
2023-12-01 16:55:18,851:INFO::its now!!!!!!!!5
2023-12-01 16:55:19,093:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:19,096:INFO::Epoch 00105 | lr 0.00050 | Train_Loss 0.3239 | Train_Classification_Loss 0.3891 | Dmon_Loss -0.1304 | Val_Loss 0.5418 | Search Time(s) 0.5116 | Infer Time(s) 0.2463 | Time(s) 0.7580 
2023-12-01 16:55:19,173:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 2;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 2;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:19,175:INFO::Validation loss decreased (0.551182 --> 0.541772).  Saving model ...
2023-12-01 16:55:19,180:INFO::Epoch: 106
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:19,181:INFO::its now!!!!!!!!5
2023-12-01 16:55:19,423:INFO::its now!!!!!!!!0
2023-12-01 16:55:19,424:INFO::its now!!!!!!!!3
2023-12-01 16:55:19,452:INFO::its now!!!!!!!!5
2023-12-01 16:55:19,715:INFO::its now!!!!!!!!
2023-12-01 16:55:19,716:INFO::its now!!!!!!!! on 
2023-12-01 16:55:19,750:INFO::its now!!!!!!!!5
2023-12-01 16:55:19,992:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:19,994:INFO::Epoch 00106 | lr 0.00050 | Train_Loss 0.2969 | Train_Classification_Loss 0.3641 | Dmon_Loss -0.1344 | Val_Loss 0.5326 | Search Time(s) 0.5730 | Infer Time(s) 0.2443 | Time(s) 0.8174 
2023-12-01 16:55:20,069:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 2;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:20,071:INFO::Validation loss decreased (0.541772 --> 0.532615).  Saving model ...
2023-12-01 16:55:20,075:INFO::Epoch: 107
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:20,076:INFO::its now!!!!!!!!5
2023-12-01 16:55:20,316:INFO::its now!!!!!!!!0
2023-12-01 16:55:20,317:INFO::its now!!!!!!!!3
2023-12-01 16:55:20,344:INFO::its now!!!!!!!!5
2023-12-01 16:55:20,587:INFO::its now!!!!!!!!
2023-12-01 16:55:20,588:INFO::its now!!!!!!!! on 
2023-12-01 16:55:20,623:INFO::its now!!!!!!!!5
2023-12-01 16:55:20,858:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:20,860:INFO::Epoch 00107 | lr 0.00050 | Train_Loss 0.2803 | Train_Classification_Loss 0.3498 | Dmon_Loss -0.1390 | Val_Loss 0.5238 | Search Time(s) 0.5487 | Infer Time(s) 0.2384 | Time(s) 0.7871 
2023-12-01 16:55:20,916:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:20,917:INFO::Validation loss decreased (0.532615 --> 0.523774).  Saving model ...
2023-12-01 16:55:20,921:INFO::Epoch: 108
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:20,922:INFO::its now!!!!!!!!5
2023-12-01 16:55:21,214:INFO::its now!!!!!!!!0
2023-12-01 16:55:21,214:INFO::its now!!!!!!!!3
2023-12-01 16:55:21,241:INFO::its now!!!!!!!!5
2023-12-01 16:55:21,496:INFO::its now!!!!!!!!
2023-12-01 16:55:21,496:INFO::its now!!!!!!!! on 
2023-12-01 16:55:21,531:INFO::its now!!!!!!!!5
2023-12-01 16:55:21,751:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:21,752:INFO::Epoch 00108 | lr 0.00050 | Train_Loss 0.2770 | Train_Classification_Loss 0.3475 | Dmon_Loss -0.1411 | Val_Loss 0.5153 | Search Time(s) 0.6106 | Infer Time(s) 0.2234 | Time(s) 0.8340 
2023-12-01 16:55:21,821:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 2;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:21,823:INFO::Validation loss decreased (0.523774 --> 0.515284).  Saving model ...
2023-12-01 16:55:21,832:INFO::Epoch: 109
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:21,834:INFO::its now!!!!!!!!5
2023-12-01 16:55:22,086:INFO::its now!!!!!!!!0
2023-12-01 16:55:22,087:INFO::its now!!!!!!!!3
2023-12-01 16:55:22,113:INFO::its now!!!!!!!!5
2023-12-01 16:55:22,364:INFO::its now!!!!!!!!
2023-12-01 16:55:22,364:INFO::its now!!!!!!!! on 
2023-12-01 16:55:22,400:INFO::its now!!!!!!!!5
2023-12-01 16:55:22,636:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:22,637:INFO::Epoch 00109 | lr 0.00050 | Train_Loss 0.2680 | Train_Classification_Loss 0.3388 | Dmon_Loss -0.1416 | Val_Loss 0.5071 | Search Time(s) 0.5717 | Infer Time(s) 0.2394 | Time(s) 0.8111 
2023-12-01 16:55:22,711:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:22,713:INFO::Validation loss decreased (0.515284 --> 0.507093).  Saving model ...
2023-12-01 16:55:22,718:INFO::Epoch: 110
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:22,719:INFO::its now!!!!!!!!5
2023-12-01 16:55:22,980:INFO::its now!!!!!!!!0
2023-12-01 16:55:22,981:INFO::its now!!!!!!!!3
2023-12-01 16:55:23,009:INFO::its now!!!!!!!!5
2023-12-01 16:55:23,251:INFO::its now!!!!!!!!
2023-12-01 16:55:23,251:INFO::its now!!!!!!!! on 
2023-12-01 16:55:23,286:INFO::its now!!!!!!!!5
2023-12-01 16:55:23,523:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:23,525:INFO::Epoch 00110 | lr 0.00050 | Train_Loss 0.2456 | Train_Classification_Loss 0.3188 | Dmon_Loss -0.1465 | Val_Loss 0.4991 | Search Time(s) 0.5681 | Infer Time(s) 0.2419 | Time(s) 0.8100 
2023-12-01 16:55:23,592:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:23,594:INFO::Validation loss decreased (0.507093 --> 0.499140).  Saving model ...
2023-12-01 16:55:23,598:INFO::Epoch: 111
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:23,599:INFO::its now!!!!!!!!5
2023-12-01 16:55:23,841:INFO::its now!!!!!!!!0
2023-12-01 16:55:23,842:INFO::its now!!!!!!!!3
2023-12-01 16:55:23,870:INFO::its now!!!!!!!!5
2023-12-01 16:55:24,111:INFO::its now!!!!!!!!
2023-12-01 16:55:24,111:INFO::its now!!!!!!!! on 
2023-12-01 16:55:24,146:INFO::its now!!!!!!!!5
2023-12-01 16:55:24,376:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:24,378:INFO::Epoch 00111 | lr 0.00050 | Train_Loss 0.2320 | Train_Classification_Loss 0.3059 | Dmon_Loss -0.1479 | Val_Loss 0.4915 | Search Time(s) 0.5481 | Infer Time(s) 0.2340 | Time(s) 0.7821 
2023-12-01 16:55:24,456:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 2;	26104: 3;	26105: 1;	26106: 2;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:24,458:INFO::Validation loss decreased (0.499140 --> 0.491466).  Saving model ...
2023-12-01 16:55:24,469:INFO::Epoch: 112
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:24,470:INFO::its now!!!!!!!!5
2023-12-01 16:55:24,729:INFO::its now!!!!!!!!0
2023-12-01 16:55:24,729:INFO::its now!!!!!!!!3
2023-12-01 16:55:24,755:INFO::its now!!!!!!!!5
2023-12-01 16:55:25,016:INFO::its now!!!!!!!!
2023-12-01 16:55:25,016:INFO::its now!!!!!!!! on 
2023-12-01 16:55:25,053:INFO::its now!!!!!!!!5
2023-12-01 16:55:25,313:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:25,316:INFO::Epoch 00112 | lr 0.00050 | Train_Loss 0.2338 | Train_Classification_Loss 0.3097 | Dmon_Loss -0.1518 | Val_Loss 0.4840 | Search Time(s) 0.5924 | Infer Time(s) 0.2615 | Time(s) 0.8539 
2023-12-01 16:55:25,391:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:25,392:INFO::Validation loss decreased (0.491466 --> 0.484049).  Saving model ...
2023-12-01 16:55:25,397:INFO::Epoch: 113
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:25,398:INFO::its now!!!!!!!!5
2023-12-01 16:55:25,633:INFO::its now!!!!!!!!0
2023-12-01 16:55:25,633:INFO::its now!!!!!!!!3
2023-12-01 16:55:25,661:INFO::its now!!!!!!!!5
2023-12-01 16:55:25,925:INFO::its now!!!!!!!!
2023-12-01 16:55:25,925:INFO::its now!!!!!!!! on 
2023-12-01 16:55:25,961:INFO::its now!!!!!!!!5
2023-12-01 16:55:26,188:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:26,190:INFO::Epoch 00113 | lr 0.00050 | Train_Loss 0.2226 | Train_Classification_Loss 0.2995 | Dmon_Loss -0.1536 | Val_Loss 0.4769 | Search Time(s) 0.5645 | Infer Time(s) 0.2310 | Time(s) 0.7955 
2023-12-01 16:55:26,264:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:26,265:INFO::Validation loss decreased (0.484049 --> 0.476894).  Saving model ...
2023-12-01 16:55:26,272:INFO::Epoch: 114
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:26,273:INFO::its now!!!!!!!!5
2023-12-01 16:55:26,505:INFO::its now!!!!!!!!0
2023-12-01 16:55:26,506:INFO::its now!!!!!!!!3
2023-12-01 16:55:26,532:INFO::its now!!!!!!!!5
2023-12-01 16:55:26,767:INFO::its now!!!!!!!!
2023-12-01 16:55:26,767:INFO::its now!!!!!!!! on 
2023-12-01 16:55:26,804:INFO::its now!!!!!!!!5
2023-12-01 16:55:27,027:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:27,029:INFO::Epoch 00114 | lr 0.00050 | Train_Loss 0.2107 | Train_Classification_Loss 0.2886 | Dmon_Loss -0.1558 | Val_Loss 0.4700 | Search Time(s) 0.5342 | Infer Time(s) 0.2264 | Time(s) 0.7606 
2023-12-01 16:55:27,099:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:27,100:INFO::Validation loss decreased (0.476894 --> 0.470003).  Saving model ...
2023-12-01 16:55:27,106:INFO::Epoch: 115
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:27,107:INFO::its now!!!!!!!!5
2023-12-01 16:55:27,355:INFO::its now!!!!!!!!0
2023-12-01 16:55:27,357:INFO::its now!!!!!!!!3
2023-12-01 16:55:27,386:INFO::its now!!!!!!!!5
2023-12-01 16:55:27,633:INFO::its now!!!!!!!!
2023-12-01 16:55:27,633:INFO::its now!!!!!!!! on 
2023-12-01 16:55:27,668:INFO::its now!!!!!!!!5
2023-12-01 16:55:27,887:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:27,889:INFO::Epoch 00115 | lr 0.00050 | Train_Loss 0.2038 | Train_Classification_Loss 0.2834 | Dmon_Loss -0.1592 | Val_Loss 0.4634 | Search Time(s) 0.5630 | Infer Time(s) 0.2224 | Time(s) 0.7854 
2023-12-01 16:55:27,949:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:27,950:INFO::Validation loss decreased (0.470003 --> 0.463420).  Saving model ...
2023-12-01 16:55:27,956:INFO::Epoch: 116
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:27,957:INFO::its now!!!!!!!!5
2023-12-01 16:55:28,186:INFO::its now!!!!!!!!0
2023-12-01 16:55:28,186:INFO::its now!!!!!!!!3
2023-12-01 16:55:28,214:INFO::its now!!!!!!!!5
2023-12-01 16:55:28,455:INFO::its now!!!!!!!!
2023-12-01 16:55:28,455:INFO::its now!!!!!!!! on 
2023-12-01 16:55:28,491:INFO::its now!!!!!!!!5
2023-12-01 16:55:28,721:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:28,723:INFO::Epoch 00116 | lr 0.00050 | Train_Loss 0.1991 | Train_Classification_Loss 0.2793 | Dmon_Loss -0.1604 | Val_Loss 0.4570 | Search Time(s) 0.5337 | Infer Time(s) 0.2364 | Time(s) 0.7701 
2023-12-01 16:55:28,794:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 2;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:28,795:INFO::Validation loss decreased (0.463420 --> 0.457034).  Saving model ...
2023-12-01 16:55:28,800:INFO::Epoch: 117
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:28,801:INFO::its now!!!!!!!!5
2023-12-01 16:55:29,038:INFO::its now!!!!!!!!0
2023-12-01 16:55:29,039:INFO::its now!!!!!!!!3
2023-12-01 16:55:29,067:INFO::its now!!!!!!!!5
2023-12-01 16:55:29,306:INFO::its now!!!!!!!!
2023-12-01 16:55:29,307:INFO::its now!!!!!!!! on 
2023-12-01 16:55:29,343:INFO::its now!!!!!!!!5
2023-12-01 16:55:29,592:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:29,594:INFO::Epoch 00117 | lr 0.00050 | Train_Loss 0.1877 | Train_Classification_Loss 0.2692 | Dmon_Loss -0.1631 | Val_Loss 0.4509 | Search Time(s) 0.5447 | Infer Time(s) 0.2513 | Time(s) 0.7960 
2023-12-01 16:55:29,664:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:29,665:INFO::Validation loss decreased (0.457034 --> 0.450921).  Saving model ...
2023-12-01 16:55:29,671:INFO::Epoch: 118
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:29,672:INFO::its now!!!!!!!!5
2023-12-01 16:55:29,884:INFO::its now!!!!!!!!0
2023-12-01 16:55:29,884:INFO::its now!!!!!!!!3
2023-12-01 16:55:29,911:INFO::its now!!!!!!!!5
2023-12-01 16:55:30,139:INFO::its now!!!!!!!!
2023-12-01 16:55:30,139:INFO::its now!!!!!!!! on 
2023-12-01 16:55:30,175:INFO::its now!!!!!!!!5
2023-12-01 16:55:30,397:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:30,400:INFO::Epoch 00118 | lr 0.00050 | Train_Loss 0.1817 | Train_Classification_Loss 0.2637 | Dmon_Loss -0.1639 | Val_Loss 0.4450 | Search Time(s) 0.5043 | Infer Time(s) 0.2269 | Time(s) 0.7312 
2023-12-01 16:55:30,463:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 2;	26104: 3;	26105: 0;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 2;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:30,464:INFO::Validation loss decreased (0.450921 --> 0.445049).  Saving model ...
2023-12-01 16:55:30,470:INFO::Epoch: 119
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:30,471:INFO::its now!!!!!!!!5
2023-12-01 16:55:30,740:INFO::its now!!!!!!!!0
2023-12-01 16:55:30,741:INFO::its now!!!!!!!!3
2023-12-01 16:55:30,767:INFO::its now!!!!!!!!5
2023-12-01 16:55:31,011:INFO::its now!!!!!!!!
2023-12-01 16:55:31,011:INFO::its now!!!!!!!! on 
2023-12-01 16:55:31,047:INFO::its now!!!!!!!!5
2023-12-01 16:55:31,306:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:31,307:INFO::Epoch 00119 | lr 0.00050 | Train_Loss 0.1654 | Train_Classification_Loss 0.2490 | Dmon_Loss -0.1671 | Val_Loss 0.4393 | Search Time(s) 0.5794 | Infer Time(s) 0.2615 | Time(s) 0.8409 
2023-12-01 16:55:31,383:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 0;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:31,384:INFO::Validation loss decreased (0.445049 --> 0.439340).  Saving model ...
2023-12-01 16:55:31,387:INFO::Epoch: 120
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:31,388:INFO::its now!!!!!!!!5
2023-12-01 16:55:31,588:INFO::its now!!!!!!!!0
2023-12-01 16:55:31,588:INFO::its now!!!!!!!!3
2023-12-01 16:55:31,615:INFO::its now!!!!!!!!5
2023-12-01 16:55:31,853:INFO::its now!!!!!!!!
2023-12-01 16:55:31,853:INFO::its now!!!!!!!! on 
2023-12-01 16:55:31,887:INFO::its now!!!!!!!!5
2023-12-01 16:55:32,108:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:32,110:INFO::Epoch 00120 | lr 0.00050 | Train_Loss 0.1688 | Train_Classification_Loss 0.2521 | Dmon_Loss -0.1666 | Val_Loss 0.4338 | Search Time(s) 0.5007 | Infer Time(s) 0.2240 | Time(s) 0.7246 
2023-12-01 16:55:32,168:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 2;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:32,170:INFO::Validation loss decreased (0.439340 --> 0.433827).  Saving model ...
2023-12-01 16:55:32,175:INFO::Epoch: 121
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:32,176:INFO::its now!!!!!!!!5
2023-12-01 16:55:32,438:INFO::its now!!!!!!!!0
2023-12-01 16:55:32,439:INFO::its now!!!!!!!!3
2023-12-01 16:55:32,465:INFO::its now!!!!!!!!5
2023-12-01 16:55:32,702:INFO::its now!!!!!!!!
2023-12-01 16:55:32,703:INFO::its now!!!!!!!! on 
2023-12-01 16:55:32,738:INFO::its now!!!!!!!!5
2023-12-01 16:55:32,980:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:32,981:INFO::Epoch 00121 | lr 0.00050 | Train_Loss 0.1583 | Train_Classification_Loss 0.2443 | Dmon_Loss -0.1718 | Val_Loss 0.4285 | Search Time(s) 0.5660 | Infer Time(s) 0.2434 | Time(s) 0.8094 
2023-12-01 16:55:33,039:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:33,042:INFO::Validation loss decreased (0.433827 --> 0.428546).  Saving model ...
2023-12-01 16:55:33,046:INFO::Epoch: 122
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:33,046:INFO::its now!!!!!!!!5
2023-12-01 16:55:33,259:INFO::its now!!!!!!!!0
2023-12-01 16:55:33,260:INFO::its now!!!!!!!!3
2023-12-01 16:55:33,286:INFO::its now!!!!!!!!5
2023-12-01 16:55:33,527:INFO::its now!!!!!!!!
2023-12-01 16:55:33,527:INFO::its now!!!!!!!! on 
2023-12-01 16:55:33,562:INFO::its now!!!!!!!!5
2023-12-01 16:55:33,771:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:33,773:INFO::Epoch 00122 | lr 0.00050 | Train_Loss 0.1430 | Train_Classification_Loss 0.2296 | Dmon_Loss -0.1731 | Val_Loss 0.4235 | Search Time(s) 0.5148 | Infer Time(s) 0.2124 | Time(s) 0.7272 
2023-12-01 16:55:33,834:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 2;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:33,835:INFO::Validation loss decreased (0.428546 --> 0.423490).  Saving model ...
2023-12-01 16:55:33,839:INFO::Epoch: 123
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:33,840:INFO::its now!!!!!!!!5
2023-12-01 16:55:34,079:INFO::its now!!!!!!!!0
2023-12-01 16:55:34,080:INFO::its now!!!!!!!!3
2023-12-01 16:55:34,108:INFO::its now!!!!!!!!5
2023-12-01 16:55:34,354:INFO::its now!!!!!!!!
2023-12-01 16:55:34,354:INFO::its now!!!!!!!! on 
2023-12-01 16:55:34,398:INFO::its now!!!!!!!!5
2023-12-01 16:55:34,654:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:34,656:INFO::Epoch 00123 | lr 0.00050 | Train_Loss 0.1381 | Train_Classification_Loss 0.2253 | Dmon_Loss -0.1744 | Val_Loss 0.4186 | Search Time(s) 0.5602 | Infer Time(s) 0.2583 | Time(s) 0.8185 
2023-12-01 16:55:34,729:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 2;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:34,730:INFO::Validation loss decreased (0.423490 --> 0.418625).  Saving model ...
2023-12-01 16:55:34,734:INFO::Epoch: 124
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:34,735:INFO::its now!!!!!!!!5
2023-12-01 16:55:34,993:INFO::its now!!!!!!!!0
2023-12-01 16:55:34,994:INFO::its now!!!!!!!!3
2023-12-01 16:55:35,021:INFO::its now!!!!!!!!5
2023-12-01 16:55:35,256:INFO::its now!!!!!!!!
2023-12-01 16:55:35,256:INFO::its now!!!!!!!! on 
2023-12-01 16:55:35,292:INFO::its now!!!!!!!!5
2023-12-01 16:55:35,515:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:35,516:INFO::Epoch 00124 | lr 0.00050 | Train_Loss 0.1358 | Train_Classification_Loss 0.2243 | Dmon_Loss -0.1770 | Val_Loss 0.4140 | Search Time(s) 0.5572 | Infer Time(s) 0.2269 | Time(s) 0.7842 
2023-12-01 16:55:35,585:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 1;	26119: 2;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:35,587:INFO::Validation loss decreased (0.418625 --> 0.413968).  Saving model ...
2023-12-01 16:55:35,592:INFO::Epoch: 125
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:35,592:INFO::its now!!!!!!!!5
2023-12-01 16:55:35,818:INFO::its now!!!!!!!!0
2023-12-01 16:55:35,858:INFO::its now!!!!!!!!3
2023-12-01 16:55:35,885:INFO::its now!!!!!!!!5
2023-12-01 16:55:36,114:INFO::its now!!!!!!!!
2023-12-01 16:55:36,115:INFO::its now!!!!!!!! on 
2023-12-01 16:55:36,151:INFO::its now!!!!!!!!5
2023-12-01 16:55:36,411:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:36,414:INFO::Epoch 00125 | lr 0.00050 | Train_Loss 0.1332 | Train_Classification_Loss 0.2220 | Dmon_Loss -0.1775 | Val_Loss 0.4096 | Search Time(s) 0.5591 | Infer Time(s) 0.2648 | Time(s) 0.8239 
2023-12-01 16:55:36,482:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 2;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:36,483:INFO::Validation loss decreased (0.413968 --> 0.409555).  Saving model ...
2023-12-01 16:55:36,488:INFO::Epoch: 126
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:36,489:INFO::its now!!!!!!!!5
2023-12-01 16:55:36,741:INFO::its now!!!!!!!!0
2023-12-01 16:55:36,742:INFO::its now!!!!!!!!3
2023-12-01 16:55:36,769:INFO::its now!!!!!!!!5
2023-12-01 16:55:37,020:INFO::its now!!!!!!!!
2023-12-01 16:55:37,021:INFO::its now!!!!!!!! on 
2023-12-01 16:55:37,056:INFO::its now!!!!!!!!5
2023-12-01 16:55:37,307:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:37,336:INFO::Epoch 00126 | lr 0.00050 | Train_Loss 0.1222 | Train_Classification_Loss 0.2122 | Dmon_Loss -0.1800 | Val_Loss 0.4053 | Search Time(s) 0.5705 | Infer Time(s) 0.2525 | Time(s) 0.8229 
2023-12-01 16:55:37,408:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:37,426:INFO::Validation loss decreased (0.409555 --> 0.405327).  Saving model ...
2023-12-01 16:55:37,430:INFO::Epoch: 127
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:37,430:INFO::its now!!!!!!!!5
2023-12-01 16:55:37,656:INFO::its now!!!!!!!!0
2023-12-01 16:55:37,657:INFO::its now!!!!!!!!3
2023-12-01 16:55:37,685:INFO::its now!!!!!!!!5
2023-12-01 16:55:37,913:INFO::its now!!!!!!!!
2023-12-01 16:55:37,913:INFO::its now!!!!!!!! on 
2023-12-01 16:55:37,950:INFO::its now!!!!!!!!5
2023-12-01 16:55:38,176:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:38,178:INFO::Epoch 00127 | lr 0.00050 | Train_Loss 0.1118 | Train_Classification_Loss 0.2031 | Dmon_Loss -0.1827 | Val_Loss 0.4013 | Search Time(s) 0.5206 | Infer Time(s) 0.2279 | Time(s) 0.7486 
2023-12-01 16:55:38,254:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 2;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 2;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:38,255:INFO::Validation loss decreased (0.405327 --> 0.401319).  Saving model ...
2023-12-01 16:55:38,260:INFO::Epoch: 128
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:38,261:INFO::its now!!!!!!!!5
2023-12-01 16:55:38,498:INFO::its now!!!!!!!!0
2023-12-01 16:55:38,499:INFO::its now!!!!!!!!3
2023-12-01 16:55:38,527:INFO::its now!!!!!!!!5
2023-12-01 16:55:38,777:INFO::its now!!!!!!!!
2023-12-01 16:55:38,784:INFO::its now!!!!!!!! on 
2023-12-01 16:55:38,819:INFO::its now!!!!!!!!5
2023-12-01 16:55:39,043:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:39,045:INFO::Epoch 00128 | lr 0.00050 | Train_Loss 0.1144 | Train_Classification_Loss 0.2054 | Dmon_Loss -0.1819 | Val_Loss 0.3975 | Search Time(s) 0.5601 | Infer Time(s) 0.2274 | Time(s) 0.7875 
2023-12-01 16:55:39,116:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:39,118:INFO::Validation loss decreased (0.401319 --> 0.397461).  Saving model ...
2023-12-01 16:55:39,123:INFO::Epoch: 129
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:39,124:INFO::its now!!!!!!!!5
2023-12-01 16:55:39,355:INFO::its now!!!!!!!!0
2023-12-01 16:55:39,355:INFO::its now!!!!!!!!3
2023-12-01 16:55:39,411:INFO::its now!!!!!!!!5
2023-12-01 16:55:39,641:INFO::its now!!!!!!!!
2023-12-01 16:55:39,641:INFO::its now!!!!!!!! on 
2023-12-01 16:55:39,677:INFO::its now!!!!!!!!5
2023-12-01 16:55:39,882:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:39,884:INFO::Epoch 00129 | lr 0.00050 | Train_Loss 0.1075 | Train_Classification_Loss 0.1988 | Dmon_Loss -0.1827 | Val_Loss 0.3938 | Search Time(s) 0.5561 | Infer Time(s) 0.2074 | Time(s) 0.7635 
2023-12-01 16:55:39,954:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 2;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:39,955:INFO::Validation loss decreased (0.397461 --> 0.393816).  Saving model ...
2023-12-01 16:55:39,960:INFO::Epoch: 130
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:39,961:INFO::its now!!!!!!!!5
2023-12-01 16:55:40,196:INFO::its now!!!!!!!!0
2023-12-01 16:55:40,197:INFO::its now!!!!!!!!3
2023-12-01 16:55:40,224:INFO::its now!!!!!!!!5
2023-12-01 16:55:40,487:INFO::its now!!!!!!!!
2023-12-01 16:55:40,488:INFO::its now!!!!!!!! on 
2023-12-01 16:55:40,524:INFO::its now!!!!!!!!5
2023-12-01 16:55:40,769:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:40,771:INFO::Epoch 00130 | lr 0.00050 | Train_Loss 0.0991 | Train_Classification_Loss 0.1918 | Dmon_Loss -0.1853 | Val_Loss 0.3902 | Search Time(s) 0.5657 | Infer Time(s) 0.2483 | Time(s) 0.8140 
2023-12-01 16:55:40,842:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:40,844:INFO::Validation loss decreased (0.393816 --> 0.390236).  Saving model ...
2023-12-01 16:55:40,848:INFO::Epoch: 131
tensor([[1.0000, 1.0000, 1.0000, 0.9998],
        [1.0000, 0.9998, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9998, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:40,849:INFO::its now!!!!!!!!5
2023-12-01 16:55:41,125:INFO::its now!!!!!!!!0
2023-12-01 16:55:41,125:INFO::its now!!!!!!!!3
2023-12-01 16:55:41,152:INFO::its now!!!!!!!!5
2023-12-01 16:55:41,409:INFO::its now!!!!!!!!
2023-12-01 16:55:41,409:INFO::its now!!!!!!!! on 
2023-12-01 16:55:41,447:INFO::its now!!!!!!!!5
2023-12-01 16:55:41,670:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:41,678:INFO::Epoch 00131 | lr 0.00050 | Train_Loss 0.0937 | Train_Classification_Loss 0.1870 | Dmon_Loss -0.1866 | Val_Loss 0.3868 | Search Time(s) 0.6016 | Infer Time(s) 0.2244 | Time(s) 0.8260 
2023-12-01 16:55:41,751:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 2;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:41,752:INFO::Validation loss decreased (0.390236 --> 0.386782).  Saving model ...
2023-12-01 16:55:41,756:INFO::Epoch: 132
tensor([[1.0000, 1.0000, 1.0000, 0.9997],
        [1.0000, 0.9997, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9997, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:41,757:INFO::its now!!!!!!!!5
2023-12-01 16:55:42,008:INFO::its now!!!!!!!!0
2023-12-01 16:55:42,009:INFO::its now!!!!!!!!3
2023-12-01 16:55:42,036:INFO::its now!!!!!!!!5
2023-12-01 16:55:42,307:INFO::its now!!!!!!!!
2023-12-01 16:55:42,307:INFO::its now!!!!!!!! on 
2023-12-01 16:55:42,343:INFO::its now!!!!!!!!5
2023-12-01 16:55:42,602:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:42,604:INFO::Epoch 00132 | lr 0.00050 | Train_Loss 0.0938 | Train_Classification_Loss 0.1881 | Dmon_Loss -0.1887 | Val_Loss 0.3835 | Search Time(s) 0.5875 | Infer Time(s) 0.2613 | Time(s) 0.8488 
2023-12-01 16:55:42,673:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:42,675:INFO::Validation loss decreased (0.386782 --> 0.383501).  Saving model ...
2023-12-01 16:55:42,678:INFO::Epoch: 133
tensor([[1.0000, 1.0000, 1.0000, 0.9996],
        [1.0000, 0.9996, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9996, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:42,680:INFO::its now!!!!!!!!5
2023-12-01 16:55:42,924:INFO::its now!!!!!!!!0
2023-12-01 16:55:42,925:INFO::its now!!!!!!!!3
2023-12-01 16:55:42,955:INFO::its now!!!!!!!!5
2023-12-01 16:55:43,204:INFO::its now!!!!!!!!
2023-12-01 16:55:43,204:INFO::its now!!!!!!!! on 
2023-12-01 16:55:43,242:INFO::its now!!!!!!!!5
2023-12-01 16:55:43,493:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:43,495:INFO::Epoch 00133 | lr 0.00050 | Train_Loss 0.0887 | Train_Classification_Loss 0.1836 | Dmon_Loss -0.1899 | Val_Loss 0.3804 | Search Time(s) 0.5621 | Infer Time(s) 0.2559 | Time(s) 0.8179 
2023-12-01 16:55:43,577:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 2;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:43,578:INFO::Validation loss decreased (0.383501 --> 0.380379).  Saving model ...
2023-12-01 16:55:43,584:INFO::Epoch: 134
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:43,585:INFO::its now!!!!!!!!5
2023-12-01 16:55:43,833:INFO::its now!!!!!!!!0
2023-12-01 16:55:43,833:INFO::its now!!!!!!!!3
2023-12-01 16:55:43,862:INFO::its now!!!!!!!!5
2023-12-01 16:55:44,104:INFO::its now!!!!!!!!
2023-12-01 16:55:44,104:INFO::its now!!!!!!!! on 
2023-12-01 16:55:44,141:INFO::its now!!!!!!!!5
2023-12-01 16:55:44,354:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:44,356:INFO::Epoch 00134 | lr 0.00050 | Train_Loss 0.0769 | Train_Classification_Loss 0.1727 | Dmon_Loss -0.1917 | Val_Loss 0.3774 | Search Time(s) 0.5581 | Infer Time(s) 0.2180 | Time(s) 0.7761 
2023-12-01 16:55:44,419:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:44,447:INFO::Validation loss decreased (0.380379 --> 0.377423).  Saving model ...
2023-12-01 16:55:44,451:INFO::Epoch: 135
tensor([[1.0000, 0.9997, 0.9997, 0.9996],
        [1.0000, 0.9996, 0.9997, 0.9996],
        [1.0000, 0.9997, 0.9996, 0.9997],
        [1.0000, 0.9997, 0.9997, 0.9997]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:44,452:INFO::its now!!!!!!!!5
2023-12-01 16:55:44,709:INFO::its now!!!!!!!!0
2023-12-01 16:55:44,710:INFO::its now!!!!!!!!3
2023-12-01 16:55:44,737:INFO::its now!!!!!!!!5
2023-12-01 16:55:44,938:INFO::its now!!!!!!!!
2023-12-01 16:55:44,938:INFO::its now!!!!!!!! on 
2023-12-01 16:55:44,977:INFO::its now!!!!!!!!5
2023-12-01 16:55:45,186:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:45,188:INFO::Epoch 00135 | lr 0.00050 | Train_Loss 0.0686 | Train_Classification_Loss 0.1646 | Dmon_Loss -0.1919 | Val_Loss 0.3746 | Search Time(s) 0.5216 | Infer Time(s) 0.2160 | Time(s) 0.7376 
2023-12-01 16:55:45,242:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:45,243:INFO::Validation loss decreased (0.377423 --> 0.374607).  Saving model ...
2023-12-01 16:55:45,246:INFO::Epoch: 136
tensor([[1.0000, 0.9992, 0.9992, 0.9990],
        [1.0000, 0.9990, 0.9992, 0.9992],
        [1.0000, 0.9992, 0.9991, 0.9992],
        [1.0000, 0.9992, 0.9992, 0.9992]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:45,246:INFO::its now!!!!!!!!5
2023-12-01 16:55:45,467:INFO::its now!!!!!!!!0
2023-12-01 16:55:45,468:INFO::its now!!!!!!!!3
2023-12-01 16:55:45,498:INFO::its now!!!!!!!!5
2023-12-01 16:55:45,723:INFO::its now!!!!!!!!
2023-12-01 16:55:45,723:INFO::its now!!!!!!!! on 
2023-12-01 16:55:45,761:INFO::its now!!!!!!!!5
2023-12-01 16:55:45,992:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:45,994:INFO::Epoch 00136 | lr 0.00050 | Train_Loss 0.0744 | Train_Classification_Loss 0.1705 | Dmon_Loss -0.1922 | Val_Loss 0.3719 | Search Time(s) 0.5142 | Infer Time(s) 0.2344 | Time(s) 0.7485 
2023-12-01 16:55:46,042:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:46,043:INFO::Validation loss decreased (0.374607 --> 0.371943).  Saving model ...
2023-12-01 16:55:46,046:INFO::Epoch: 137
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:46,047:INFO::its now!!!!!!!!5
2023-12-01 16:55:46,270:INFO::its now!!!!!!!!0
2023-12-01 16:55:46,271:INFO::its now!!!!!!!!3
2023-12-01 16:55:46,300:INFO::its now!!!!!!!!5
2023-12-01 16:55:46,525:INFO::its now!!!!!!!!
2023-12-01 16:55:46,525:INFO::its now!!!!!!!! on 
2023-12-01 16:55:46,562:INFO::its now!!!!!!!!5
2023-12-01 16:55:46,786:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:46,788:INFO::Epoch 00137 | lr 0.00050 | Train_Loss 0.0578 | Train_Classification_Loss 0.1550 | Dmon_Loss -0.1944 | Val_Loss 0.3694 | Search Time(s) 0.5128 | Infer Time(s) 0.2304 | Time(s) 0.7432 
2023-12-01 16:55:46,857:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:46,858:INFO::Validation loss decreased (0.371943 --> 0.369434).  Saving model ...
2023-12-01 16:55:46,864:INFO::Epoch: 138
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:46,866:INFO::its now!!!!!!!!5
2023-12-01 16:55:47,107:INFO::its now!!!!!!!!0
2023-12-01 16:55:47,108:INFO::its now!!!!!!!!3
2023-12-01 16:55:47,140:INFO::its now!!!!!!!!5
2023-12-01 16:55:47,366:INFO::its now!!!!!!!!
2023-12-01 16:55:47,367:INFO::its now!!!!!!!! on 
2023-12-01 16:55:47,410:INFO::its now!!!!!!!!5
2023-12-01 16:55:47,645:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:47,646:INFO::Epoch 00138 | lr 0.00050 | Train_Loss 0.0623 | Train_Classification_Loss 0.1599 | Dmon_Loss -0.1950 | Val_Loss 0.3670 | Search Time(s) 0.5448 | Infer Time(s) 0.2414 | Time(s) 0.7862 
2023-12-01 16:55:47,712:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:47,712:INFO::Validation loss decreased (0.369434 --> 0.367048).  Saving model ...
2023-12-01 16:55:47,716:INFO::Epoch: 139
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:47,717:INFO::its now!!!!!!!!5
2023-12-01 16:55:47,884:INFO::its now!!!!!!!!0
2023-12-01 16:55:47,885:INFO::its now!!!!!!!!3
2023-12-01 16:55:47,915:INFO::its now!!!!!!!!5
2023-12-01 16:55:48,104:INFO::its now!!!!!!!!
2023-12-01 16:55:48,105:INFO::its now!!!!!!!! on 
2023-12-01 16:55:48,143:INFO::its now!!!!!!!!5
2023-12-01 16:55:48,308:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:48,309:INFO::Epoch 00139 | lr 0.00050 | Train_Loss 0.0576 | Train_Classification_Loss 0.1556 | Dmon_Loss -0.1960 | Val_Loss 0.3647 | Search Time(s) 0.4244 | Infer Time(s) 0.1701 | Time(s) 0.5945 
2023-12-01 16:55:48,351:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:48,352:INFO::Validation loss decreased (0.367048 --> 0.364719).  Saving model ...
2023-12-01 16:55:48,355:INFO::Epoch: 140
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:48,356:INFO::its now!!!!!!!!5
2023-12-01 16:55:48,535:INFO::its now!!!!!!!!0
2023-12-01 16:55:48,536:INFO::its now!!!!!!!!3
2023-12-01 16:55:48,564:INFO::its now!!!!!!!!5
2023-12-01 16:55:48,753:INFO::its now!!!!!!!!
2023-12-01 16:55:48,753:INFO::its now!!!!!!!! on 
2023-12-01 16:55:48,787:INFO::its now!!!!!!!!5
2023-12-01 16:55:48,954:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:48,956:INFO::Epoch 00140 | lr 0.00050 | Train_Loss 0.0556 | Train_Classification_Loss 0.1542 | Dmon_Loss -0.1972 | Val_Loss 0.3625 | Search Time(s) 0.4289 | Infer Time(s) 0.1735 | Time(s) 0.6024 
2023-12-01 16:55:49,017:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:49,018:INFO::Validation loss decreased (0.364719 --> 0.362497).  Saving model ...
2023-12-01 16:55:49,024:INFO::Epoch: 141
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:49,024:INFO::its now!!!!!!!!5
2023-12-01 16:55:49,211:INFO::its now!!!!!!!!0
2023-12-01 16:55:49,211:INFO::its now!!!!!!!!3
2023-12-01 16:55:49,239:INFO::its now!!!!!!!!5
2023-12-01 16:55:49,411:INFO::its now!!!!!!!!
2023-12-01 16:55:49,411:INFO::its now!!!!!!!! on 
2023-12-01 16:55:49,452:INFO::its now!!!!!!!!5
2023-12-01 16:55:49,604:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:49,606:INFO::Epoch 00141 | lr 0.00050 | Train_Loss 0.0476 | Train_Classification_Loss 0.1465 | Dmon_Loss -0.1978 | Val_Loss 0.3603 | Search Time(s) 0.4309 | Infer Time(s) 0.1556 | Time(s) 0.5865 
2023-12-01 16:55:49,651:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:49,652:INFO::Validation loss decreased (0.362497 --> 0.360318).  Saving model ...
2023-12-01 16:55:49,655:INFO::Epoch: 142
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:49,656:INFO::its now!!!!!!!!5
2023-12-01 16:55:49,810:INFO::its now!!!!!!!!0
2023-12-01 16:55:49,810:INFO::its now!!!!!!!!3
2023-12-01 16:55:49,837:INFO::its now!!!!!!!!5
2023-12-01 16:55:49,999:INFO::its now!!!!!!!!
2023-12-01 16:55:50,000:INFO::its now!!!!!!!! on 
2023-12-01 16:55:50,034:INFO::its now!!!!!!!!5
2023-12-01 16:55:50,202:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:50,203:INFO::Epoch 00142 | lr 0.00050 | Train_Loss 0.0456 | Train_Classification_Loss 0.1451 | Dmon_Loss -0.1991 | Val_Loss 0.3581 | Search Time(s) 0.3770 | Infer Time(s) 0.1731 | Time(s) 0.5501 
2023-12-01 16:55:50,241:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:50,242:INFO::Validation loss decreased (0.360318 --> 0.358115).  Saving model ...
2023-12-01 16:55:50,245:INFO::Epoch: 143
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:50,246:INFO::its now!!!!!!!!5
2023-12-01 16:55:50,415:INFO::its now!!!!!!!!0
2023-12-01 16:55:50,416:INFO::its now!!!!!!!!3
2023-12-01 16:55:50,445:INFO::its now!!!!!!!!5
2023-12-01 16:55:50,604:INFO::its now!!!!!!!!
2023-12-01 16:55:50,604:INFO::its now!!!!!!!! on 
2023-12-01 16:55:50,639:INFO::its now!!!!!!!!5
2023-12-01 16:55:50,800:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:50,802:INFO::Epoch 00143 | lr 0.00050 | Train_Loss 0.0388 | Train_Classification_Loss 0.1387 | Dmon_Loss -0.1999 | Val_Loss 0.3559 | Search Time(s) 0.3905 | Infer Time(s) 0.1676 | Time(s) 0.5581 
2023-12-01 16:55:50,864:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:50,865:INFO::Validation loss decreased (0.358115 --> 0.355922).  Saving model ...
2023-12-01 16:55:50,868:INFO::Epoch: 144
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:50,869:INFO::its now!!!!!!!!5
2023-12-01 16:55:51,022:INFO::its now!!!!!!!!0
2023-12-01 16:55:51,022:INFO::its now!!!!!!!!3
2023-12-01 16:55:51,047:INFO::its now!!!!!!!!5
2023-12-01 16:55:51,246:INFO::its now!!!!!!!!
2023-12-01 16:55:51,246:INFO::its now!!!!!!!! on 
2023-12-01 16:55:51,278:INFO::its now!!!!!!!!5
2023-12-01 16:55:51,488:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:51,491:INFO::Epoch 00144 | lr 0.00050 | Train_Loss 0.0428 | Train_Classification_Loss 0.1426 | Dmon_Loss -0.1994 | Val_Loss 0.3538 | Search Time(s) 0.4075 | Infer Time(s) 0.2150 | Time(s) 0.6225 
2023-12-01 16:55:51,536:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:51,538:INFO::Validation loss decreased (0.355922 --> 0.353788).  Saving model ...
2023-12-01 16:55:51,542:INFO::Epoch: 145
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:51,543:INFO::its now!!!!!!!!5
2023-12-01 16:55:51,687:INFO::its now!!!!!!!!0
2023-12-01 16:55:51,688:INFO::its now!!!!!!!!3
2023-12-01 16:55:51,712:INFO::its now!!!!!!!!5
2023-12-01 16:55:51,872:INFO::its now!!!!!!!!
2023-12-01 16:55:51,873:INFO::its now!!!!!!!! on 
2023-12-01 16:55:51,904:INFO::its now!!!!!!!!5
2023-12-01 16:55:52,058:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:52,059:INFO::Epoch 00145 | lr 0.00050 | Train_Loss 0.0389 | Train_Classification_Loss 0.1398 | Dmon_Loss -0.2019 | Val_Loss 0.3517 | Search Time(s) 0.3610 | Infer Time(s) 0.1586 | Time(s) 0.5196 
2023-12-01 16:55:52,099:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:52,100:INFO::Validation loss decreased (0.353788 --> 0.351748).  Saving model ...
2023-12-01 16:55:52,103:INFO::Epoch: 146
tensor([[1.0000, 0.9998, 0.9998, 0.9998],
        [1.0000, 0.9998, 0.9998, 0.9998],
        [1.0000, 0.9998, 0.9998, 0.9998],
        [1.0000, 0.9998, 0.9998, 0.9998]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:52,103:INFO::its now!!!!!!!!5
2023-12-01 16:55:52,292:INFO::its now!!!!!!!!0
2023-12-01 16:55:52,293:INFO::its now!!!!!!!!3
2023-12-01 16:55:52,317:INFO::its now!!!!!!!!5
2023-12-01 16:55:52,484:INFO::its now!!!!!!!!
2023-12-01 16:55:52,484:INFO::its now!!!!!!!! on 
2023-12-01 16:55:52,518:INFO::its now!!!!!!!!5
2023-12-01 16:55:52,672:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:52,674:INFO::Epoch 00146 | lr 0.00050 | Train_Loss 0.0317 | Train_Classification_Loss 0.1335 | Dmon_Loss -0.2035 | Val_Loss 0.3498 | Search Time(s) 0.4120 | Infer Time(s) 0.1586 | Time(s) 0.5706 
2023-12-01 16:55:52,712:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:52,712:INFO::Validation loss decreased (0.351748 --> 0.349832).  Saving model ...
2023-12-01 16:55:52,715:INFO::Epoch: 147
tensor([[1.0000, 0.9998, 0.9998, 0.9998],
        [1.0000, 0.9998, 0.9998, 0.9998],
        [1.0000, 0.9998, 0.9998, 0.9998],
        [1.0000, 0.9998, 0.9998, 0.9998]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:52,716:INFO::its now!!!!!!!!5
2023-12-01 16:55:52,913:INFO::its now!!!!!!!!0
2023-12-01 16:55:52,914:INFO::its now!!!!!!!!3
2023-12-01 16:55:52,940:INFO::its now!!!!!!!!5
2023-12-01 16:55:53,152:INFO::its now!!!!!!!!
2023-12-01 16:55:53,152:INFO::its now!!!!!!!! on 
2023-12-01 16:55:53,184:INFO::its now!!!!!!!!5
2023-12-01 16:55:53,375:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:53,377:INFO::Epoch 00147 | lr 0.00050 | Train_Loss 0.0338 | Train_Classification_Loss 0.1354 | Dmon_Loss -0.2032 | Val_Loss 0.3480 | Search Time(s) 0.4643 | Infer Time(s) 0.1970 | Time(s) 0.6613 
2023-12-01 16:55:53,434:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:53,435:INFO::Validation loss decreased (0.349832 --> 0.347989).  Saving model ...
2023-12-01 16:55:53,437:INFO::Epoch: 148
tensor([[1.0000, 0.9997, 0.9997, 0.9997],
        [1.0000, 0.9997, 0.9997, 0.9997],
        [1.0000, 0.9997, 0.9997, 0.9997],
        [1.0000, 0.9997, 0.9997, 0.9997]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:53,438:INFO::its now!!!!!!!!5
2023-12-01 16:55:53,591:INFO::its now!!!!!!!!0
2023-12-01 16:55:53,591:INFO::its now!!!!!!!!3
2023-12-01 16:55:53,618:INFO::its now!!!!!!!!5
2023-12-01 16:55:53,779:INFO::its now!!!!!!!!
2023-12-01 16:55:53,779:INFO::its now!!!!!!!! on 
2023-12-01 16:55:53,830:INFO::its now!!!!!!!!5
2023-12-01 16:55:53,991:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:53,993:INFO::Epoch 00148 | lr 0.00050 | Train_Loss 0.0266 | Train_Classification_Loss 0.1289 | Dmon_Loss -0.2046 | Val_Loss 0.3463 | Search Time(s) 0.3760 | Infer Time(s) 0.1805 | Time(s) 0.5565 
2023-12-01 16:55:54,050:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:54,051:INFO::Validation loss decreased (0.347989 --> 0.346337).  Saving model ...
2023-12-01 16:55:54,054:INFO::Epoch: 149
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:54,055:INFO::its now!!!!!!!!5
2023-12-01 16:55:54,214:INFO::its now!!!!!!!!0
2023-12-01 16:55:54,215:INFO::its now!!!!!!!!3
2023-12-01 16:55:54,258:INFO::its now!!!!!!!!5
2023-12-01 16:55:54,436:INFO::its now!!!!!!!!
2023-12-01 16:55:54,436:INFO::its now!!!!!!!! on 
2023-12-01 16:55:54,469:INFO::its now!!!!!!!!5
2023-12-01 16:55:54,672:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:54,673:INFO::Epoch 00149 | lr 0.00050 | Train_Loss 0.0157 | Train_Classification_Loss 0.1190 | Dmon_Loss -0.2066 | Val_Loss 0.3447 | Search Time(s) 0.4120 | Infer Time(s) 0.2079 | Time(s) 0.6199 
2023-12-01 16:55:54,722:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:54,723:INFO::Validation loss decreased (0.346337 --> 0.344741).  Saving model ...
2023-12-01 16:55:54,729:INFO::Epoch: 150
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:54,730:INFO::its now!!!!!!!!5
2023-12-01 16:55:54,882:INFO::its now!!!!!!!!0
2023-12-01 16:55:54,883:INFO::its now!!!!!!!!3
2023-12-01 16:55:54,907:INFO::its now!!!!!!!!5
2023-12-01 16:55:55,091:INFO::its now!!!!!!!!
2023-12-01 16:55:55,091:INFO::its now!!!!!!!! on 
2023-12-01 16:55:55,123:INFO::its now!!!!!!!!5
2023-12-01 16:55:55,273:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:55,274:INFO::Epoch 00150 | lr 0.00050 | Train_Loss 0.0216 | Train_Classification_Loss 0.1251 | Dmon_Loss -0.2069 | Val_Loss 0.3432 | Search Time(s) 0.3935 | Infer Time(s) 0.1556 | Time(s) 0.5491 
2023-12-01 16:55:55,332:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:55,334:INFO::Validation loss decreased (0.344741 --> 0.343195).  Saving model ...
2023-12-01 16:55:55,338:INFO::Epoch: 151
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:55,339:INFO::its now!!!!!!!!5
2023-12-01 16:55:55,529:INFO::its now!!!!!!!!0
2023-12-01 16:55:55,529:INFO::its now!!!!!!!!3
2023-12-01 16:55:55,554:INFO::its now!!!!!!!!5
2023-12-01 16:55:55,713:INFO::its now!!!!!!!!
2023-12-01 16:55:55,713:INFO::its now!!!!!!!! on 
2023-12-01 16:55:55,746:INFO::its now!!!!!!!!5
2023-12-01 16:55:55,921:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:55,924:INFO::Epoch 00151 | lr 0.00050 | Train_Loss 0.0187 | Train_Classification_Loss 0.1226 | Dmon_Loss -0.2077 | Val_Loss 0.3418 | Search Time(s) 0.4069 | Infer Time(s) 0.1795 | Time(s) 0.5864 
2023-12-01 16:55:55,983:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:55,984:INFO::Validation loss decreased (0.343195 --> 0.341800).  Saving model ...
2023-12-01 16:55:55,990:INFO::Epoch: 152
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:55,991:INFO::its now!!!!!!!!5
2023-12-01 16:55:56,193:INFO::its now!!!!!!!!0
2023-12-01 16:55:56,193:INFO::its now!!!!!!!!3
2023-12-01 16:55:56,235:INFO::its now!!!!!!!!5
2023-12-01 16:55:56,386:INFO::its now!!!!!!!!
2023-12-01 16:55:56,386:INFO::its now!!!!!!!! on 
2023-12-01 16:55:56,422:INFO::its now!!!!!!!!5
2023-12-01 16:55:56,602:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:56,604:INFO::Epoch 00152 | lr 0.00050 | Train_Loss 0.0069 | Train_Classification_Loss 0.1111 | Dmon_Loss -0.2083 | Val_Loss 0.3405 | Search Time(s) 0.4311 | Infer Time(s) 0.1865 | Time(s) 0.6176 
2023-12-01 16:55:56,649:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:56,650:INFO::Validation loss decreased (0.341800 --> 0.340515).  Saving model ...
2023-12-01 16:55:56,653:INFO::Epoch: 153
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:56,653:INFO::its now!!!!!!!!5
2023-12-01 16:55:56,815:INFO::its now!!!!!!!!0
2023-12-01 16:55:56,815:INFO::its now!!!!!!!!3
2023-12-01 16:55:56,840:INFO::its now!!!!!!!!5
2023-12-01 16:55:57,026:INFO::its now!!!!!!!!
2023-12-01 16:55:57,026:INFO::its now!!!!!!!! on 
2023-12-01 16:55:57,059:INFO::its now!!!!!!!!5
2023-12-01 16:55:57,219:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:57,221:INFO::Epoch 00153 | lr 0.00050 | Train_Loss 0.0056 | Train_Classification_Loss 0.1095 | Dmon_Loss -0.2080 | Val_Loss 0.3392 | Search Time(s) 0.4039 | Infer Time(s) 0.1651 | Time(s) 0.5690 
2023-12-01 16:55:57,275:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:57,276:INFO::Validation loss decreased (0.340515 --> 0.339215).  Saving model ...
2023-12-01 16:55:57,279:INFO::Epoch: 154
tensor([[1.0000, 0.9994, 1.0000, 1.0000],
        [1.0000, 0.9993, 1.0000, 1.0000],
        [1.0000, 0.9992, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9995, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:57,280:INFO::its now!!!!!!!!5
2023-12-01 16:55:57,441:INFO::its now!!!!!!!!0
2023-12-01 16:55:57,441:INFO::its now!!!!!!!!3
2023-12-01 16:55:57,466:INFO::its now!!!!!!!!5
2023-12-01 16:55:57,662:INFO::its now!!!!!!!!
2023-12-01 16:55:57,663:INFO::its now!!!!!!!! on 
2023-12-01 16:55:57,695:INFO::its now!!!!!!!!5
2023-12-01 16:55:57,870:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:57,871:INFO::Epoch 00154 | lr 0.00050 | Train_Loss 0.0147 | Train_Classification_Loss 0.1191 | Dmon_Loss -0.2087 | Val_Loss 0.3380 | Search Time(s) 0.4145 | Infer Time(s) 0.1795 | Time(s) 0.5940 
2023-12-01 16:55:57,927:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:57,929:INFO::Validation loss decreased (0.339215 --> 0.338016).  Saving model ...
2023-12-01 16:55:57,933:INFO::Epoch: 155
tensor([[1.0000, 0.9975, 0.9985, 0.9985],
        [1.0000, 0.9973, 0.9986, 0.9985],
        [1.0000, 0.9971, 0.9986, 0.9985],
        [1.0000, 0.9986, 0.9977, 0.9986]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:57,933:INFO::its now!!!!!!!!5
2023-12-01 16:55:58,121:INFO::its now!!!!!!!!0
2023-12-01 16:55:58,122:INFO::its now!!!!!!!!3
2023-12-01 16:55:58,146:INFO::its now!!!!!!!!5
2023-12-01 16:55:58,342:INFO::its now!!!!!!!!
2023-12-01 16:55:58,343:INFO::its now!!!!!!!! on 
2023-12-01 16:55:58,377:INFO::its now!!!!!!!!5
2023-12-01 16:55:58,594:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:58,596:INFO::Epoch 00155 | lr 0.00050 | Train_Loss 0.0083 | Train_Classification_Loss 0.1134 | Dmon_Loss -0.2103 | Val_Loss 0.3368 | Search Time(s) 0.4454 | Infer Time(s) 0.2204 | Time(s) 0.6658 
2023-12-01 16:55:58,680:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:58,681:INFO::Validation loss decreased (0.338016 --> 0.336838).  Saving model ...
2023-12-01 16:55:58,683:INFO::Epoch: 156
tensor([[1.0000, 0.9968, 0.9981, 0.9981],
        [1.0000, 0.9966, 0.9982, 0.9981],
        [1.0000, 0.9964, 0.9981, 0.9981],
        [1.0000, 0.9982, 0.9970, 0.9982]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:58,684:INFO::its now!!!!!!!!5
2023-12-01 16:55:58,845:INFO::its now!!!!!!!!0
2023-12-01 16:55:58,845:INFO::its now!!!!!!!!3
2023-12-01 16:55:58,871:INFO::its now!!!!!!!!5
2023-12-01 16:55:59,052:INFO::its now!!!!!!!!
2023-12-01 16:55:59,052:INFO::its now!!!!!!!! on 
2023-12-01 16:55:59,087:INFO::its now!!!!!!!!5
2023-12-01 16:55:59,256:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:59,258:INFO::Epoch 00156 | lr 0.00050 | Train_Loss 0.0020 | Train_Classification_Loss 0.1077 | Dmon_Loss -0.2113 | Val_Loss 0.3358 | Search Time(s) 0.3999 | Infer Time(s) 0.1751 | Time(s) 0.5750 
2023-12-01 16:55:59,302:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:55:59,303:INFO::Validation loss decreased (0.336838 --> 0.335785).  Saving model ...
2023-12-01 16:55:59,305:INFO::Epoch: 157
tensor([[1.0000, 0.9962, 0.9976, 0.9976],
        [1.0000, 0.9960, 0.9977, 0.9976],
        [1.0000, 0.9958, 0.9977, 0.9976],
        [1.0000, 0.9977, 0.9965, 0.9977]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:59,306:INFO::its now!!!!!!!!5
2023-12-01 16:55:59,494:INFO::its now!!!!!!!!0
2023-12-01 16:55:59,495:INFO::its now!!!!!!!!3
2023-12-01 16:55:59,520:INFO::its now!!!!!!!!5
2023-12-01 16:55:59,689:INFO::its now!!!!!!!!
2023-12-01 16:55:59,689:INFO::its now!!!!!!!! on 
2023-12-01 16:55:59,722:INFO::its now!!!!!!!!5
2023-12-01 16:55:59,900:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:55:59,901:INFO::Epoch 00157 | lr 0.00050 | Train_Loss -0.0010 | Train_Classification_Loss 0.1053 | Dmon_Loss -0.2126 | Val_Loss 0.3348 | Search Time(s) 0.4149 | Infer Time(s) 0.1825 | Time(s) 0.5974 
2023-12-01 16:55:59,947:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:55:59,948:INFO::Validation loss decreased (0.335785 --> 0.334759).  Saving model ...
2023-12-01 16:55:59,950:INFO::Epoch: 158
tensor([[1.0000, 0.9955, 0.9970, 0.9969],
        [1.0000, 0.9953, 0.9971, 0.9969],
        [1.0000, 0.9951, 0.9971, 0.9970],
        [1.0000, 0.9971, 0.9958, 0.9971]], device='cuda:0', requires_grad=True)
2023-12-01 16:55:59,951:INFO::its now!!!!!!!!5
2023-12-01 16:56:00,124:INFO::its now!!!!!!!!0
2023-12-01 16:56:00,125:INFO::its now!!!!!!!!3
2023-12-01 16:56:00,149:INFO::its now!!!!!!!!5
2023-12-01 16:56:00,327:INFO::its now!!!!!!!!
2023-12-01 16:56:00,327:INFO::its now!!!!!!!! on 
2023-12-01 16:56:00,359:INFO::its now!!!!!!!!5
2023-12-01 16:56:00,521:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:00,522:INFO::Epoch 00158 | lr 0.00050 | Train_Loss 0.0017 | Train_Classification_Loss 0.1083 | Dmon_Loss -0.2132 | Val_Loss 0.3338 | Search Time(s) 0.4071 | Infer Time(s) 0.1656 | Time(s) 0.5726 
2023-12-01 16:56:00,567:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:00,568:INFO::Validation loss decreased (0.334759 --> 0.333786).  Saving model ...
2023-12-01 16:56:00,570:INFO::Epoch: 159
tensor([[1.0000, 0.9954, 0.9970, 0.9969],
        [1.0000, 0.9952, 0.9970, 0.9969],
        [1.0000, 0.9950, 0.9970, 0.9970],
        [1.0000, 0.9970, 0.9957, 0.9970]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:00,571:INFO::its now!!!!!!!!5
2023-12-01 16:56:00,721:INFO::its now!!!!!!!!0
2023-12-01 16:56:00,722:INFO::its now!!!!!!!!3
2023-12-01 16:56:00,748:INFO::its now!!!!!!!!5
2023-12-01 16:56:00,911:INFO::its now!!!!!!!!
2023-12-01 16:56:00,912:INFO::its now!!!!!!!! on 
2023-12-01 16:56:00,945:INFO::its now!!!!!!!!5
2023-12-01 16:56:01,132:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:01,134:INFO::Epoch 00159 | lr 0.00050 | Train_Loss -0.0087 | Train_Classification_Loss 0.0984 | Dmon_Loss -0.2143 | Val_Loss 0.3329 | Search Time(s) 0.3720 | Infer Time(s) 0.1910 | Time(s) 0.5631 
2023-12-01 16:56:01,185:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:01,186:INFO::Validation loss decreased (0.333786 --> 0.332904).  Saving model ...
2023-12-01 16:56:01,189:INFO::Epoch: 160
tensor([[1.0000, 0.9952, 0.9968, 0.9967],
        [1.0000, 0.9950, 0.9968, 0.9967],
        [1.0000, 0.9948, 0.9968, 0.9968],
        [1.0000, 0.9968, 0.9955, 0.9968]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:01,190:INFO::its now!!!!!!!!5
2023-12-01 16:56:01,333:INFO::its now!!!!!!!!0
2023-12-01 16:56:01,334:INFO::its now!!!!!!!!3
2023-12-01 16:56:01,359:INFO::its now!!!!!!!!5
2023-12-01 16:56:01,547:INFO::its now!!!!!!!!
2023-12-01 16:56:01,547:INFO::its now!!!!!!!! on 
2023-12-01 16:56:01,581:INFO::its now!!!!!!!!5
2023-12-01 16:56:01,731:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:01,732:INFO::Epoch 00160 | lr 0.00050 | Train_Loss -0.0023 | Train_Classification_Loss 0.1048 | Dmon_Loss -0.2143 | Val_Loss 0.3322 | Search Time(s) 0.3896 | Infer Time(s) 0.1556 | Time(s) 0.5452 
2023-12-01 16:56:01,803:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:01,804:INFO::Validation loss decreased (0.332904 --> 0.332158).  Saving model ...
2023-12-01 16:56:01,808:INFO::Epoch: 161
tensor([[1.0000, 0.9955, 0.9971, 0.9970],
        [1.0000, 0.9953, 0.9971, 0.9970],
        [1.0000, 0.9951, 0.9971, 0.9971],
        [1.0000, 0.9971, 0.9958, 0.9971]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:01,809:INFO::its now!!!!!!!!5
2023-12-01 16:56:01,983:INFO::its now!!!!!!!!0
2023-12-01 16:56:01,984:INFO::its now!!!!!!!!3
2023-12-01 16:56:02,008:INFO::its now!!!!!!!!5
2023-12-01 16:56:02,214:INFO::its now!!!!!!!!
2023-12-01 16:56:02,214:INFO::its now!!!!!!!! on 
2023-12-01 16:56:02,247:INFO::its now!!!!!!!!5
2023-12-01 16:56:02,398:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:02,408:INFO::Epoch 00161 | lr 0.00050 | Train_Loss -0.0063 | Train_Classification_Loss 0.1016 | Dmon_Loss -0.2158 | Val_Loss 0.3314 | Search Time(s) 0.4344 | Infer Time(s) 0.1581 | Time(s) 0.5925 
2023-12-01 16:56:02,475:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:56:02,476:INFO::Validation loss decreased (0.332158 --> 0.331352).  Saving model ...
2023-12-01 16:56:02,479:INFO::Epoch: 162
tensor([[1.0000, 0.9959, 0.9975, 0.9974],
        [1.0000, 0.9957, 0.9975, 0.9974],
        [1.0000, 0.9955, 0.9975, 0.9974],
        [1.0000, 0.9975, 0.9962, 0.9975]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:02,479:INFO::its now!!!!!!!!5
2023-12-01 16:56:02,642:INFO::its now!!!!!!!!0
2023-12-01 16:56:02,643:INFO::its now!!!!!!!!3
2023-12-01 16:56:02,667:INFO::its now!!!!!!!!5
2023-12-01 16:56:02,829:INFO::its now!!!!!!!!
2023-12-01 16:56:02,830:INFO::its now!!!!!!!! on 
2023-12-01 16:56:02,862:INFO::its now!!!!!!!!5
2023-12-01 16:56:03,031:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:03,033:INFO::Epoch 00162 | lr 0.00050 | Train_Loss -0.0097 | Train_Classification_Loss 0.0991 | Dmon_Loss -0.2176 | Val_Loss 0.3305 | Search Time(s) 0.3800 | Infer Time(s) 0.1745 | Time(s) 0.5545 
2023-12-01 16:56:03,093:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:56:03,094:INFO::Validation loss decreased (0.331352 --> 0.330491).  Saving model ...
2023-12-01 16:56:03,097:INFO::Epoch: 163
tensor([[1.0000, 0.9965, 0.9981, 0.9980],
        [1.0000, 0.9963, 0.9981, 0.9980],
        [1.0000, 0.9961, 0.9981, 0.9981],
        [1.0000, 0.9981, 0.9968, 0.9981]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:03,097:INFO::its now!!!!!!!!5
2023-12-01 16:56:03,255:INFO::its now!!!!!!!!0
2023-12-01 16:56:03,256:INFO::its now!!!!!!!!3
2023-12-01 16:56:03,281:INFO::its now!!!!!!!!5
2023-12-01 16:56:03,447:INFO::its now!!!!!!!!
2023-12-01 16:56:03,447:INFO::its now!!!!!!!! on 
2023-12-01 16:56:03,480:INFO::its now!!!!!!!!5
2023-12-01 16:56:03,634:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:03,636:INFO::Epoch 00163 | lr 0.00050 | Train_Loss -0.0121 | Train_Classification_Loss 0.0965 | Dmon_Loss -0.2173 | Val_Loss 0.3295 | Search Time(s) 0.3792 | Infer Time(s) 0.1596 | Time(s) 0.5388 
2023-12-01 16:56:03,688:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:03,689:INFO::Validation loss decreased (0.330491 --> 0.329545).  Saving model ...
2023-12-01 16:56:03,692:INFO::Epoch: 164
tensor([[1.0000, 0.9961, 0.9976, 0.9976],
        [1.0000, 0.9959, 0.9977, 0.9976],
        [1.0000, 0.9957, 0.9977, 0.9976],
        [1.0000, 0.9977, 0.9963, 0.9977]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:03,693:INFO::its now!!!!!!!!5
2023-12-01 16:56:03,885:INFO::its now!!!!!!!!0
2023-12-01 16:56:03,886:INFO::its now!!!!!!!!3
2023-12-01 16:56:03,911:INFO::its now!!!!!!!!5
2023-12-01 16:56:04,130:INFO::its now!!!!!!!!
2023-12-01 16:56:04,130:INFO::its now!!!!!!!! on 
2023-12-01 16:56:04,163:INFO::its now!!!!!!!!5
2023-12-01 16:56:04,339:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:04,341:INFO::Epoch 00164 | lr 0.00050 | Train_Loss -0.0148 | Train_Classification_Loss 0.0945 | Dmon_Loss -0.2186 | Val_Loss 0.3286 | Search Time(s) 0.4703 | Infer Time(s) 0.1801 | Time(s) 0.6504 
2023-12-01 16:56:04,395:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:04,396:INFO::Validation loss decreased (0.329545 --> 0.328587).  Saving model ...
2023-12-01 16:56:04,400:INFO::Epoch: 165
tensor([[1.0000, 0.9957, 0.9973, 0.9972],
        [1.0000, 0.9955, 0.9973, 0.9972],
        [1.0000, 0.9953, 0.9973, 0.9973],
        [1.0000, 0.9973, 0.9960, 0.9973]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:04,401:INFO::its now!!!!!!!!5
2023-12-01 16:56:04,559:INFO::its now!!!!!!!!0
2023-12-01 16:56:04,560:INFO::its now!!!!!!!!3
2023-12-01 16:56:04,585:INFO::its now!!!!!!!!5
2023-12-01 16:56:04,770:INFO::its now!!!!!!!!
2023-12-01 16:56:04,770:INFO::its now!!!!!!!! on 
2023-12-01 16:56:04,804:INFO::its now!!!!!!!!5
2023-12-01 16:56:04,968:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:04,969:INFO::Epoch 00165 | lr 0.00050 | Train_Loss -0.0219 | Train_Classification_Loss 0.0878 | Dmon_Loss -0.2194 | Val_Loss 0.3277 | Search Time(s) 0.3989 | Infer Time(s) 0.1725 | Time(s) 0.5715 
2023-12-01 16:56:05,024:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:05,026:INFO::Validation loss decreased (0.328587 --> 0.327659).  Saving model ...
2023-12-01 16:56:05,028:INFO::Epoch: 166
tensor([[1.0000, 0.9934, 0.9949, 0.9947],
        [1.0000, 0.9931, 0.9950, 0.9947],
        [1.0000, 0.9929, 0.9949, 0.9949],
        [1.0000, 0.9950, 0.9936, 0.9950]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:05,029:INFO::its now!!!!!!!!5
2023-12-01 16:56:05,199:INFO::its now!!!!!!!!0
2023-12-01 16:56:05,200:INFO::its now!!!!!!!!3
2023-12-01 16:56:05,242:INFO::its now!!!!!!!!5
2023-12-01 16:56:05,402:INFO::its now!!!!!!!!
2023-12-01 16:56:05,403:INFO::its now!!!!!!!! on 
2023-12-01 16:56:05,435:INFO::its now!!!!!!!!5
2023-12-01 16:56:05,595:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:05,596:INFO::Epoch 00166 | lr 0.00050 | Train_Loss -0.0200 | Train_Classification_Loss 0.0898 | Dmon_Loss -0.2196 | Val_Loss 0.3268 | Search Time(s) 0.4021 | Infer Time(s) 0.1666 | Time(s) 0.5687 
2023-12-01 16:56:05,652:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:05,653:INFO::Validation loss decreased (0.327659 --> 0.326782).  Saving model ...
2023-12-01 16:56:05,656:INFO::Epoch: 167
tensor([[1.0000, 0.9924, 0.9966, 0.9965],
        [1.0000, 0.9948, 0.9939, 0.9965],
        [1.0000, 0.9946, 0.9938, 0.9966],
        [1.0000, 0.9941, 0.9953, 0.9967]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:05,657:INFO::its now!!!!!!!!5
2023-12-01 16:56:05,832:INFO::its now!!!!!!!!0
2023-12-01 16:56:05,833:INFO::its now!!!!!!!!3
2023-12-01 16:56:05,859:INFO::its now!!!!!!!!5
2023-12-01 16:56:06,014:INFO::its now!!!!!!!!
2023-12-01 16:56:06,014:INFO::its now!!!!!!!! on 
2023-12-01 16:56:06,048:INFO::its now!!!!!!!!5
2023-12-01 16:56:06,230:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:06,231:INFO::Epoch 00167 | lr 0.00050 | Train_Loss -0.0227 | Train_Classification_Loss 0.0870 | Dmon_Loss -0.2194 | Val_Loss 0.3260 | Search Time(s) 0.3900 | Infer Time(s) 0.1871 | Time(s) 0.5771 
2023-12-01 16:56:06,274:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:06,274:INFO::Validation loss decreased (0.326782 --> 0.325951).  Saving model ...
2023-12-01 16:56:06,277:INFO::Epoch: 168
tensor([[1.0000, 0.9923, 0.9979, 0.9978],
        [1.0000, 0.9961, 0.9938, 0.9978],
        [1.0000, 0.9959, 0.9936, 0.9979],
        [1.0000, 0.9941, 0.9966, 0.9979]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:06,278:INFO::its now!!!!!!!!5
2023-12-01 16:56:06,430:INFO::its now!!!!!!!!0
2023-12-01 16:56:06,430:INFO::its now!!!!!!!!3
2023-12-01 16:56:06,456:INFO::its now!!!!!!!!5
2023-12-01 16:56:06,650:INFO::its now!!!!!!!!
2023-12-01 16:56:06,650:INFO::its now!!!!!!!! on 
2023-12-01 16:56:06,682:INFO::its now!!!!!!!!5
2023-12-01 16:56:06,845:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:06,847:INFO::Epoch 00168 | lr 0.00050 | Train_Loss -0.0235 | Train_Classification_Loss 0.0870 | Dmon_Loss -0.2210 | Val_Loss 0.3252 | Search Time(s) 0.4036 | Infer Time(s) 0.1666 | Time(s) 0.5701 
2023-12-01 16:56:06,888:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:06,889:INFO::Validation loss decreased (0.325951 --> 0.325188).  Saving model ...
2023-12-01 16:56:06,892:INFO::Epoch: 169
tensor([[1.0000, 0.9910, 0.9973, 0.9972],
        [1.0000, 0.9955, 0.9924, 0.9972],
        [1.0000, 0.9953, 0.9922, 0.9973],
        [1.0000, 0.9928, 0.9960, 0.9973]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:06,892:INFO::its now!!!!!!!!5
2023-12-01 16:56:07,069:INFO::its now!!!!!!!!0
2023-12-01 16:56:07,070:INFO::its now!!!!!!!!3
2023-12-01 16:56:07,095:INFO::its now!!!!!!!!5
2023-12-01 16:56:07,267:INFO::its now!!!!!!!!
2023-12-01 16:56:07,267:INFO::its now!!!!!!!! on 
2023-12-01 16:56:07,301:INFO::its now!!!!!!!!5
2023-12-01 16:56:07,470:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:07,471:INFO::Epoch 00169 | lr 0.00050 | Train_Loss -0.0249 | Train_Classification_Loss 0.0856 | Dmon_Loss -0.2210 | Val_Loss 0.3245 | Search Time(s) 0.4081 | Infer Time(s) 0.1725 | Time(s) 0.5806 
2023-12-01 16:56:07,526:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:07,527:INFO::Validation loss decreased (0.325188 --> 0.324500).  Saving model ...
2023-12-01 16:56:07,530:INFO::Epoch: 170
tensor([[1.0000, 0.9907, 0.9973, 0.9972],
        [1.0000, 0.9955, 0.9921, 0.9972],
        [1.0000, 0.9953, 0.9919, 0.9973],
        [1.0000, 0.9925, 0.9960, 0.9973]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:07,531:INFO::its now!!!!!!!!5
2023-12-01 16:56:07,702:INFO::its now!!!!!!!!0
2023-12-01 16:56:07,702:INFO::its now!!!!!!!!3
2023-12-01 16:56:07,727:INFO::its now!!!!!!!!5
2023-12-01 16:56:07,919:INFO::its now!!!!!!!!
2023-12-01 16:56:07,920:INFO::its now!!!!!!!! on 
2023-12-01 16:56:07,952:INFO::its now!!!!!!!!5
2023-12-01 16:56:08,111:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:08,112:INFO::Epoch 00170 | lr 0.00050 | Train_Loss -0.0281 | Train_Classification_Loss 0.0828 | Dmon_Loss -0.2218 | Val_Loss 0.3238 | Search Time(s) 0.4209 | Infer Time(s) 0.1631 | Time(s) 0.5840 
2023-12-01 16:56:08,160:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:08,161:INFO::Validation loss decreased (0.324500 --> 0.323814).  Saving model ...
2023-12-01 16:56:08,164:INFO::Epoch: 171
tensor([[1.0000, 0.9912, 0.9979, 0.9979],
        [1.0000, 0.9962, 0.9926, 0.9979],
        [1.0000, 0.9960, 0.9923, 0.9979],
        [1.0000, 0.9930, 0.9966, 0.9980]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:08,165:INFO::its now!!!!!!!!5
2023-12-01 16:56:08,337:INFO::its now!!!!!!!!0
2023-12-01 16:56:08,338:INFO::its now!!!!!!!!3
2023-12-01 16:56:08,362:INFO::its now!!!!!!!!5
2023-12-01 16:56:08,526:INFO::its now!!!!!!!!
2023-12-01 16:56:08,526:INFO::its now!!!!!!!! on 
2023-12-01 16:56:08,559:INFO::its now!!!!!!!!5
2023-12-01 16:56:08,765:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:08,767:INFO::Epoch 00171 | lr 0.00050 | Train_Loss -0.0299 | Train_Classification_Loss 0.0814 | Dmon_Loss -0.2225 | Val_Loss 0.3232 | Search Time(s) 0.3915 | Infer Time(s) 0.2115 | Time(s) 0.6030 
2023-12-01 16:56:08,812:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:08,813:INFO::Validation loss decreased (0.323814 --> 0.323247).  Saving model ...
2023-12-01 16:56:08,815:INFO::Epoch: 172
tensor([[1.0000, 0.9910, 0.9979, 0.9978],
        [1.0000, 0.9961, 0.9924, 0.9978],
        [1.0000, 0.9959, 0.9922, 0.9979],
        [1.0000, 0.9928, 0.9966, 0.9979]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:08,816:INFO::its now!!!!!!!!5
2023-12-01 16:56:08,985:INFO::its now!!!!!!!!0
2023-12-01 16:56:08,986:INFO::its now!!!!!!!!3
2023-12-01 16:56:09,011:INFO::its now!!!!!!!!5
2023-12-01 16:56:09,201:INFO::its now!!!!!!!!
2023-12-01 16:56:09,201:INFO::its now!!!!!!!! on 
2023-12-01 16:56:09,234:INFO::its now!!!!!!!!5
2023-12-01 16:56:09,428:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:09,430:INFO::Epoch 00172 | lr 0.00050 | Train_Loss -0.0275 | Train_Classification_Loss 0.0840 | Dmon_Loss -0.2231 | Val_Loss 0.3228 | Search Time(s) 0.4155 | Infer Time(s) 0.2001 | Time(s) 0.6155 
2023-12-01 16:56:09,494:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:09,495:INFO::Validation loss decreased (0.323247 --> 0.322763).  Saving model ...
2023-12-01 16:56:09,498:INFO::Epoch: 173
tensor([[1.0000, 0.9898, 0.9967, 0.9965],
        [1.0000, 0.9949, 0.9912, 0.9966],
        [1.0000, 0.9947, 0.9909, 0.9967],
        [1.0000, 0.9916, 0.9954, 0.9967]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:09,499:INFO::its now!!!!!!!!5
2023-12-01 16:56:09,677:INFO::its now!!!!!!!!0
2023-12-01 16:56:09,678:INFO::its now!!!!!!!!3
2023-12-01 16:56:09,705:INFO::its now!!!!!!!!5
2023-12-01 16:56:09,868:INFO::its now!!!!!!!!
2023-12-01 16:56:09,868:INFO::its now!!!!!!!! on 
2023-12-01 16:56:09,901:INFO::its now!!!!!!!!5
2023-12-01 16:56:10,064:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:10,065:INFO::Epoch 00173 | lr 0.00050 | Train_Loss -0.0327 | Train_Classification_Loss 0.0789 | Dmon_Loss -0.2231 | Val_Loss 0.3222 | Search Time(s) 0.4039 | Infer Time(s) 0.1645 | Time(s) 0.5685 
2023-12-01 16:56:10,116:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:10,116:INFO::Validation loss decreased (0.322763 --> 0.322215).  Saving model ...
2023-12-01 16:56:10,119:INFO::Epoch: 174
tensor([[1.0000, 0.9896, 0.9964, 0.9964],
        [1.0000, 0.9947, 0.9910, 0.9959],
        [1.0000, 0.9945, 0.9903, 0.9965],
        [1.0000, 0.9914, 0.9952, 0.9962]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:10,119:INFO::its now!!!!!!!!5
2023-12-01 16:56:10,286:INFO::its now!!!!!!!!0
2023-12-01 16:56:10,287:INFO::its now!!!!!!!!3
2023-12-01 16:56:10,312:INFO::its now!!!!!!!!5
2023-12-01 16:56:10,463:INFO::its now!!!!!!!!
2023-12-01 16:56:10,463:INFO::its now!!!!!!!! on 
2023-12-01 16:56:10,496:INFO::its now!!!!!!!!5
2023-12-01 16:56:10,649:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:10,650:INFO::Epoch 00174 | lr 0.00050 | Train_Loss -0.0315 | Train_Classification_Loss 0.0812 | Dmon_Loss -0.2254 | Val_Loss 0.3219 | Search Time(s) 0.3736 | Infer Time(s) 0.1586 | Time(s) 0.5321 
2023-12-01 16:56:10,705:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:10,706:INFO::Validation loss decreased (0.322215 --> 0.321893).  Saving model ...
2023-12-01 16:56:10,709:INFO::Epoch: 175
tensor([[1.0000, 0.9888, 0.9955, 0.9956],
        [1.0000, 0.9940, 0.9902, 0.9948],
        [1.0000, 0.9937, 0.9893, 0.9957],
        [1.0000, 0.9906, 0.9945, 0.9952]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:10,710:INFO::its now!!!!!!!!5
2023-12-01 16:56:10,861:INFO::its now!!!!!!!!0
2023-12-01 16:56:10,861:INFO::its now!!!!!!!!3
2023-12-01 16:56:10,886:INFO::its now!!!!!!!!5
2023-12-01 16:56:11,112:INFO::its now!!!!!!!!
2023-12-01 16:56:11,112:INFO::its now!!!!!!!! on 
2023-12-01 16:56:11,145:INFO::its now!!!!!!!!5
2023-12-01 16:56:11,305:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:11,306:INFO::Epoch 00175 | lr 0.00050 | Train_Loss -0.0345 | Train_Classification_Loss 0.0779 | Dmon_Loss -0.2249 | Val_Loss 0.3216 | Search Time(s) 0.4348 | Infer Time(s) 0.1641 | Time(s) 0.5989 
2023-12-01 16:56:11,348:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:11,350:INFO::Validation loss decreased (0.321893 --> 0.321584).  Saving model ...
2023-12-01 16:56:11,353:INFO::Epoch: 176
tensor([[1.0000, 0.9882, 0.9948, 0.9949],
        [1.0000, 0.9933, 0.9896, 0.9940],
        [1.0000, 0.9931, 0.9885, 0.9951],
        [1.0000, 0.9900, 0.9938, 0.9945]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:11,355:INFO::its now!!!!!!!!5
2023-12-01 16:56:11,527:INFO::its now!!!!!!!!0
2023-12-01 16:56:11,528:INFO::its now!!!!!!!!3
2023-12-01 16:56:11,552:INFO::its now!!!!!!!!5
2023-12-01 16:56:11,706:INFO::its now!!!!!!!!
2023-12-01 16:56:11,707:INFO::its now!!!!!!!! on 
2023-12-01 16:56:11,740:INFO::its now!!!!!!!!5
2023-12-01 16:56:11,895:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:11,896:INFO::Epoch 00176 | lr 0.00050 | Train_Loss -0.0345 | Train_Classification_Loss 0.0781 | Dmon_Loss -0.2252 | Val_Loss 0.3213 | Search Time(s) 0.3850 | Infer Time(s) 0.1606 | Time(s) 0.5456 
2023-12-01 16:56:11,939:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:11,940:INFO::Validation loss decreased (0.321584 --> 0.321292).  Saving model ...
2023-12-01 16:56:11,942:INFO::Epoch: 177
tensor([[1.0000, 0.9886, 0.9952, 0.9954],
        [1.0000, 0.9937, 0.9900, 0.9944],
        [1.0000, 0.9935, 0.9889, 0.9955],
        [1.0000, 0.9904, 0.9943, 0.9949]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:11,942:INFO::its now!!!!!!!!5
2023-12-01 16:56:12,121:INFO::its now!!!!!!!!0
2023-12-01 16:56:12,121:INFO::its now!!!!!!!!3
2023-12-01 16:56:12,146:INFO::its now!!!!!!!!5
2023-12-01 16:56:12,324:INFO::its now!!!!!!!!
2023-12-01 16:56:12,325:INFO::its now!!!!!!!! on 
2023-12-01 16:56:12,357:INFO::its now!!!!!!!!5
2023-12-01 16:56:12,524:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:12,526:INFO::Epoch 00177 | lr 0.00050 | Train_Loss -0.0356 | Train_Classification_Loss 0.0776 | Dmon_Loss -0.2264 | Val_Loss 0.3209 | Search Time(s) 0.4110 | Infer Time(s) 0.1725 | Time(s) 0.5836 
2023-12-01 16:56:12,579:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:12,580:INFO::Validation loss decreased (0.321292 --> 0.320887).  Saving model ...
2023-12-01 16:56:12,582:INFO::Epoch: 178
tensor([[1.0000, 0.9876, 0.9943, 0.9944],
        [1.0000, 0.9928, 0.9891, 0.9934],
        [1.0000, 0.9925, 0.9879, 0.9946],
        [1.0000, 0.9895, 0.9933, 0.9939]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:12,583:INFO::its now!!!!!!!!5
2023-12-01 16:56:12,747:INFO::its now!!!!!!!!0
2023-12-01 16:56:12,747:INFO::its now!!!!!!!!3
2023-12-01 16:56:12,772:INFO::its now!!!!!!!!5
2023-12-01 16:56:12,951:INFO::its now!!!!!!!!
2023-12-01 16:56:12,951:INFO::its now!!!!!!!! on 
2023-12-01 16:56:12,984:INFO::its now!!!!!!!!5
2023-12-01 16:56:13,169:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:13,170:INFO::Epoch 00178 | lr 0.00050 | Train_Loss -0.0349 | Train_Classification_Loss 0.0781 | Dmon_Loss -0.2260 | Val_Loss 0.3205 | Search Time(s) 0.3979 | Infer Time(s) 0.1911 | Time(s) 0.5890 
2023-12-01 16:56:13,220:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 3;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:13,221:INFO::Validation loss decreased (0.320887 --> 0.320451).  Saving model ...
2023-12-01 16:56:13,224:INFO::Epoch: 179
tensor([[1.0000, 0.9871, 0.9937, 0.9939],
        [1.0000, 0.9922, 0.9886, 0.9928],
        [1.0000, 0.9920, 0.9873, 0.9941],
        [1.0000, 0.9890, 0.9928, 0.9934]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:13,225:INFO::its now!!!!!!!!5
2023-12-01 16:56:13,384:INFO::its now!!!!!!!!0
2023-12-01 16:56:13,384:INFO::its now!!!!!!!!3
2023-12-01 16:56:13,414:INFO::its now!!!!!!!!5
2023-12-01 16:56:13,613:INFO::its now!!!!!!!!
2023-12-01 16:56:13,613:INFO::its now!!!!!!!! on 
2023-12-01 16:56:13,646:INFO::its now!!!!!!!!5
2023-12-01 16:56:13,791:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:13,793:INFO::Epoch 00179 | lr 0.00050 | Train_Loss -0.0420 | Train_Classification_Loss 0.0715 | Dmon_Loss -0.2269 | Val_Loss 0.3200 | Search Time(s) 0.4185 | Infer Time(s) 0.1506 | Time(s) 0.5691 
2023-12-01 16:56:13,834:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:13,835:INFO::Validation loss decreased (0.320451 --> 0.320029).  Saving model ...
2023-12-01 16:56:13,838:INFO::Epoch: 180
tensor([[1.0000, 0.9903, 0.9937, 0.9971],
        [1.0000, 0.9955, 0.9917, 0.9961],
        [1.0000, 0.9952, 0.9905, 0.9938],
        [1.0000, 0.9921, 0.9959, 0.9932]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:13,839:INFO::its now!!!!!!!!5
2023-12-01 16:56:14,027:INFO::its now!!!!!!!!0
2023-12-01 16:56:14,027:INFO::its now!!!!!!!!3
2023-12-01 16:56:14,052:INFO::its now!!!!!!!!5
2023-12-01 16:56:14,230:INFO::its now!!!!!!!!
2023-12-01 16:56:14,230:INFO::its now!!!!!!!! on 
2023-12-01 16:56:14,262:INFO::its now!!!!!!!!5
2023-12-01 16:56:14,416:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:14,417:INFO::Epoch 00180 | lr 0.00050 | Train_Loss -0.0398 | Train_Classification_Loss 0.0742 | Dmon_Loss -0.2280 | Val_Loss 0.3196 | Search Time(s) 0.4209 | Infer Time(s) 0.1596 | Time(s) 0.5804 
2023-12-01 16:56:14,460:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:14,461:INFO::Validation loss decreased (0.320029 --> 0.319612).  Saving model ...
2023-12-01 16:56:14,464:INFO::Epoch: 181
tensor([[1.0000, 0.9912, 0.9929, 0.9981],
        [1.0000, 0.9964, 0.9926, 0.9970],
        [1.0000, 0.9962, 0.9914, 0.9930],
        [1.0000, 0.9930, 0.9968, 0.9924]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:14,465:INFO::its now!!!!!!!!5
2023-12-01 16:56:14,650:INFO::its now!!!!!!!!0
2023-12-01 16:56:14,650:INFO::its now!!!!!!!!3
2023-12-01 16:56:14,675:INFO::its now!!!!!!!!5
2023-12-01 16:56:14,825:INFO::its now!!!!!!!!
2023-12-01 16:56:14,825:INFO::its now!!!!!!!! on 
2023-12-01 16:56:14,858:INFO::its now!!!!!!!!5
2023-12-01 16:56:15,069:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:15,071:INFO::Epoch 00181 | lr 0.00050 | Train_Loss -0.0459 | Train_Classification_Loss 0.0684 | Dmon_Loss -0.2286 | Val_Loss 0.3191 | Search Time(s) 0.3920 | Infer Time(s) 0.2164 | Time(s) 0.6084 
2023-12-01 16:56:15,127:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:15,129:INFO::Validation loss decreased (0.319612 --> 0.319145).  Saving model ...
2023-12-01 16:56:15,131:INFO::Epoch: 182
tensor([[1.0000, 0.9913, 0.9922, 0.9982],
        [1.0000, 0.9965, 0.9927, 0.9971],
        [1.0000, 0.9963, 0.9915, 0.9922],
        [1.0000, 0.9931, 0.9969, 0.9917]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:15,132:INFO::its now!!!!!!!!5
2023-12-01 16:56:15,304:INFO::its now!!!!!!!!0
2023-12-01 16:56:15,305:INFO::its now!!!!!!!!3
2023-12-01 16:56:15,330:INFO::its now!!!!!!!!5
2023-12-01 16:56:15,509:INFO::its now!!!!!!!!
2023-12-01 16:56:15,509:INFO::its now!!!!!!!! on 
2023-12-01 16:56:15,542:INFO::its now!!!!!!!!5
2023-12-01 16:56:15,703:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:15,705:INFO::Epoch 00182 | lr 0.00050 | Train_Loss -0.0448 | Train_Classification_Loss 0.0697 | Dmon_Loss -0.2289 | Val_Loss 0.3187 | Search Time(s) 0.4069 | Infer Time(s) 0.1666 | Time(s) 0.5735 
2023-12-01 16:56:15,757:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:15,758:INFO::Validation loss decreased (0.319145 --> 0.318688).  Saving model ...
2023-12-01 16:56:15,760:INFO::Epoch: 183
tensor([[1.0000, 0.9912, 0.9917, 0.9981],
        [1.0000, 0.9964, 0.9926, 0.9970],
        [1.0000, 0.9962, 0.9914, 0.9917],
        [1.0000, 0.9930, 0.9969, 0.9912]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:15,760:INFO::its now!!!!!!!!5
2023-12-01 16:56:15,929:INFO::its now!!!!!!!!0
2023-12-01 16:56:15,930:INFO::its now!!!!!!!!3
2023-12-01 16:56:15,979:INFO::its now!!!!!!!!5
2023-12-01 16:56:16,130:INFO::its now!!!!!!!!
2023-12-01 16:56:16,131:INFO::its now!!!!!!!! on 
2023-12-01 16:56:16,164:INFO::its now!!!!!!!!5
2023-12-01 16:56:16,346:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:16,348:INFO::Epoch 00183 | lr 0.00050 | Train_Loss -0.0460 | Train_Classification_Loss 0.0686 | Dmon_Loss -0.2292 | Val_Loss 0.3183 | Search Time(s) 0.3989 | Infer Time(s) 0.1885 | Time(s) 0.5874 
2023-12-01 16:56:16,399:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 1;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:16,400:INFO::Validation loss decreased (0.318688 --> 0.318309).  Saving model ...
2023-12-01 16:56:16,405:INFO::Epoch: 184
tensor([[1.0000, 0.9914, 0.9942, 1.0000],
        [1.0000, 0.9991, 0.9927, 0.9998],
        [1.0000, 0.9989, 0.9941, 0.9942],
        [1.0000, 0.9957, 0.9995, 0.9910]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:16,406:INFO::its now!!!!!!!!5
2023-12-01 16:56:16,569:INFO::its now!!!!!!!!0
2023-12-01 16:56:16,570:INFO::its now!!!!!!!!3
2023-12-01 16:56:16,595:INFO::its now!!!!!!!!5
2023-12-01 16:56:16,793:INFO::its now!!!!!!!!
2023-12-01 16:56:16,793:INFO::its now!!!!!!!! on 
2023-12-01 16:56:16,825:INFO::its now!!!!!!!!5
2023-12-01 16:56:16,992:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:16,994:INFO::Epoch 00184 | lr 0.00050 | Train_Loss -0.0492 | Train_Classification_Loss 0.0662 | Dmon_Loss -0.2308 | Val_Loss 0.3180 | Search Time(s) 0.4189 | Infer Time(s) 0.1735 | Time(s) 0.5924 
2023-12-01 16:56:17,039:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:17,040:INFO::Validation loss decreased (0.318309 --> 0.318044).  Saving model ...
2023-12-01 16:56:17,043:INFO::Epoch: 185
tensor([[1.0000, 0.9909, 0.9949, 1.0000],
        [1.0000, 0.9999, 0.9922, 1.0000],
        [1.0000, 0.9997, 0.9949, 0.9949],
        [1.0000, 0.9965, 1.0000, 0.9904]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:17,043:INFO::its now!!!!!!!!5
2023-12-01 16:56:17,202:INFO::its now!!!!!!!!0
2023-12-01 16:56:17,203:INFO::its now!!!!!!!!3
2023-12-01 16:56:17,227:INFO::its now!!!!!!!!5
2023-12-01 16:56:17,438:INFO::its now!!!!!!!!
2023-12-01 16:56:17,439:INFO::its now!!!!!!!! on 
2023-12-01 16:56:17,471:INFO::its now!!!!!!!!5
2023-12-01 16:56:17,663:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:17,664:INFO::Epoch 00185 | lr 0.00050 | Train_Loss -0.0489 | Train_Classification_Loss 0.0665 | Dmon_Loss -0.2309 | Val_Loss 0.3179 | Search Time(s) 0.4229 | Infer Time(s) 0.1995 | Time(s) 0.6223 
2023-12-01 16:56:17,713:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:17,714:INFO::Validation loss decreased (0.318044 --> 0.317924).  Saving model ...
2023-12-01 16:56:17,717:INFO::Epoch: 186
tensor([[1.0000, 0.9886, 0.9932, 0.9983],
        [1.0000, 0.9982, 0.9898, 0.9983],
        [1.0000, 0.9980, 0.9932, 0.9931],
        [1.0000, 0.9948, 0.9983, 0.9880]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:17,718:INFO::its now!!!!!!!!5
2023-12-01 16:56:17,893:INFO::its now!!!!!!!!0
2023-12-01 16:56:17,894:INFO::its now!!!!!!!!3
2023-12-01 16:56:17,920:INFO::its now!!!!!!!!5
2023-12-01 16:56:18,112:INFO::its now!!!!!!!!
2023-12-01 16:56:18,113:INFO::its now!!!!!!!! on 
2023-12-01 16:56:18,146:INFO::its now!!!!!!!!5
2023-12-01 16:56:18,294:INFO::Epoch 00186 | lr 0.00050 | Train_Loss -0.0507 | Train_Classification_Loss 0.0645 | Dmon_Loss -0.2304 | Val_Loss 0.3179 | Search Time(s) 0.4254 | Infer Time(s) 0.1541 | Time(s) 0.5796 
2023-12-01 16:56:18,335:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:18,336:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:56:18,338:INFO::Epoch: 187
tensor([[1.0000, 0.9895, 0.9944, 0.9995],
        [1.0000, 0.9995, 0.9907, 0.9995],
        [1.0000, 0.9992, 0.9945, 0.9943],
        [1.0000, 0.9960, 0.9995, 0.9889]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:18,339:INFO::its now!!!!!!!!5
2023-12-01 16:56:18,528:INFO::its now!!!!!!!!0
2023-12-01 16:56:18,529:INFO::its now!!!!!!!!3
2023-12-01 16:56:18,553:INFO::its now!!!!!!!!5
2023-12-01 16:56:18,709:INFO::its now!!!!!!!!
2023-12-01 16:56:18,709:INFO::its now!!!!!!!! on 
2023-12-01 16:56:18,742:INFO::its now!!!!!!!!5
2023-12-01 16:56:18,903:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:18,905:INFO::Epoch 00187 | lr 0.00050 | Train_Loss -0.0538 | Train_Classification_Loss 0.0617 | Dmon_Loss -0.2310 | Val_Loss 0.3178 | Search Time(s) 0.3999 | Infer Time(s) 0.1666 | Time(s) 0.5665 
2023-12-01 16:56:18,978:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 0;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:18,979:INFO::Validation loss decreased (0.317924 --> 0.317812).  Saving model ...
2023-12-01 16:56:18,982:INFO::Epoch: 188
tensor([[1.0000, 0.9909, 0.9960, 1.0000],
        [1.0000, 1.0000, 0.9921, 1.0000],
        [1.0000, 1.0000, 0.9960, 0.9959],
        [1.0000, 0.9976, 1.0000, 0.9903]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:18,983:INFO::its now!!!!!!!!5
2023-12-01 16:56:19,138:INFO::its now!!!!!!!!0
2023-12-01 16:56:19,138:INFO::its now!!!!!!!!3
2023-12-01 16:56:19,163:INFO::its now!!!!!!!!5
2023-12-01 16:56:19,313:INFO::its now!!!!!!!!
2023-12-01 16:56:19,313:INFO::its now!!!!!!!! on 
2023-12-01 16:56:19,347:INFO::its now!!!!!!!!5
2023-12-01 16:56:19,523:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:19,525:INFO::Epoch 00188 | lr 0.00050 | Train_Loss -0.0507 | Train_Classification_Loss 0.0647 | Dmon_Loss -0.2308 | Val_Loss 0.3177 | Search Time(s) 0.3642 | Infer Time(s) 0.1795 | Time(s) 0.5437 
2023-12-01 16:56:19,564:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:19,565:INFO::Validation loss decreased (0.317812 --> 0.317706).  Saving model ...
2023-12-01 16:56:19,568:INFO::Epoch: 189
tensor([[1.0000, 0.9926, 0.9977, 1.0000],
        [1.0000, 1.0000, 0.9938, 1.0000],
        [1.0000, 1.0000, 0.9978, 0.9977],
        [1.0000, 0.9993, 1.0000, 0.9919]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:19,568:INFO::its now!!!!!!!!5
2023-12-01 16:56:19,711:INFO::its now!!!!!!!!0
2023-12-01 16:56:19,711:INFO::its now!!!!!!!!3
2023-12-01 16:56:19,754:INFO::its now!!!!!!!!5
2023-12-01 16:56:19,922:INFO::its now!!!!!!!!
2023-12-01 16:56:19,922:INFO::its now!!!!!!!! on 
2023-12-01 16:56:19,956:INFO::its now!!!!!!!!5
2023-12-01 16:56:20,144:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:20,146:INFO::Epoch 00189 | lr 0.00050 | Train_Loss -0.0518 | Train_Classification_Loss 0.0642 | Dmon_Loss -0.2320 | Val_Loss 0.3177 | Search Time(s) 0.3840 | Infer Time(s) 0.1950 | Time(s) 0.5790 
2023-12-01 16:56:20,191:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:20,192:INFO::Validation loss decreased (0.317706 --> 0.317672).  Saving model ...
2023-12-01 16:56:20,194:INFO::Epoch: 190
tensor([[1.0000, 0.9937, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9966, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9928]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:20,195:INFO::its now!!!!!!!!5
2023-12-01 16:56:20,399:INFO::its now!!!!!!!!0
2023-12-01 16:56:20,400:INFO::its now!!!!!!!!3
2023-12-01 16:56:20,430:INFO::its now!!!!!!!!5
2023-12-01 16:56:20,616:INFO::its now!!!!!!!!
2023-12-01 16:56:20,616:INFO::its now!!!!!!!! on 
2023-12-01 16:56:20,649:INFO::its now!!!!!!!!5
2023-12-01 16:56:20,834:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:20,836:INFO::Epoch 00190 | lr 0.00050 | Train_Loss -0.0539 | Train_Classification_Loss 0.0628 | Dmon_Loss -0.2335 | Val_Loss 0.3176 | Search Time(s) 0.4523 | Infer Time(s) 0.1885 | Time(s) 0.6408 
2023-12-01 16:56:20,891:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:20,892:INFO::Validation loss decreased (0.317672 --> 0.317593).  Saving model ...
2023-12-01 16:56:20,895:INFO::Epoch: 191
tensor([[1.0000, 0.9955, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9993, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9945]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:20,895:INFO::its now!!!!!!!!5
2023-12-01 16:56:21,084:INFO::its now!!!!!!!!0
2023-12-01 16:56:21,085:INFO::its now!!!!!!!!3
2023-12-01 16:56:21,110:INFO::its now!!!!!!!!5
2023-12-01 16:56:21,293:INFO::its now!!!!!!!!
2023-12-01 16:56:21,293:INFO::its now!!!!!!!! on 
2023-12-01 16:56:21,326:INFO::its now!!!!!!!!5
2023-12-01 16:56:21,498:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:21,500:INFO::Epoch 00191 | lr 0.00050 | Train_Loss -0.0597 | Train_Classification_Loss 0.0569 | Dmon_Loss -0.2333 | Val_Loss 0.3174 | Search Time(s) 0.4290 | Infer Time(s) 0.1765 | Time(s) 0.6055 
2023-12-01 16:56:21,541:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:21,541:INFO::Validation loss decreased (0.317593 --> 0.317380).  Saving model ...
2023-12-01 16:56:21,543:INFO::Epoch: 192
tensor([[1.0000, 0.9959, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9949]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:21,544:INFO::its now!!!!!!!!5
2023-12-01 16:56:21,685:INFO::its now!!!!!!!!0
2023-12-01 16:56:21,686:INFO::its now!!!!!!!!3
2023-12-01 16:56:21,712:INFO::its now!!!!!!!!5
2023-12-01 16:56:21,898:INFO::its now!!!!!!!!
2023-12-01 16:56:21,898:INFO::its now!!!!!!!! on 
2023-12-01 16:56:21,931:INFO::its now!!!!!!!!5
2023-12-01 16:56:22,105:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:22,107:INFO::Epoch 00192 | lr 0.00050 | Train_Loss -0.0569 | Train_Classification_Loss 0.0595 | Dmon_Loss -0.2328 | Val_Loss 0.3171 | Search Time(s) 0.3860 | Infer Time(s) 0.1771 | Time(s) 0.5631 
2023-12-01 16:56:22,160:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:22,161:INFO::Validation loss decreased (0.317380 --> 0.317101).  Saving model ...
2023-12-01 16:56:22,164:INFO::Epoch: 193
tensor([[1.0000, 0.9962, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9951]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:22,165:INFO::its now!!!!!!!!5
2023-12-01 16:56:22,324:INFO::its now!!!!!!!!0
2023-12-01 16:56:22,324:INFO::its now!!!!!!!!3
2023-12-01 16:56:22,349:INFO::its now!!!!!!!!5
2023-12-01 16:56:22,543:INFO::its now!!!!!!!!
2023-12-01 16:56:22,544:INFO::its now!!!!!!!! on 
2023-12-01 16:56:22,576:INFO::its now!!!!!!!!5
2023-12-01 16:56:22,734:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:22,735:INFO::Epoch 00193 | lr 0.00050 | Train_Loss -0.0576 | Train_Classification_Loss 0.0597 | Dmon_Loss -0.2346 | Val_Loss 0.3168 | Search Time(s) 0.4085 | Infer Time(s) 0.1646 | Time(s) 0.5731 
2023-12-01 16:56:22,797:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:22,798:INFO::Validation loss decreased (0.317101 --> 0.316843).  Saving model ...
2023-12-01 16:56:22,801:INFO::Epoch: 194
tensor([[1.0000, 0.9963, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9952]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:22,801:INFO::its now!!!!!!!!5
2023-12-01 16:56:22,988:INFO::its now!!!!!!!!0
2023-12-01 16:56:22,989:INFO::its now!!!!!!!!3
2023-12-01 16:56:23,013:INFO::its now!!!!!!!!5
2023-12-01 16:56:23,197:INFO::its now!!!!!!!!
2023-12-01 16:56:23,197:INFO::its now!!!!!!!! on 
2023-12-01 16:56:23,230:INFO::its now!!!!!!!!5
2023-12-01 16:56:23,410:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:23,412:INFO::Epoch 00194 | lr 0.00050 | Train_Loss -0.0559 | Train_Classification_Loss 0.0612 | Dmon_Loss -0.2342 | Val_Loss 0.3165 | Search Time(s) 0.4264 | Infer Time(s) 0.1845 | Time(s) 0.6109 
2023-12-01 16:56:23,455:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 1;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 1;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:23,456:INFO::Validation loss decreased (0.316843 --> 0.316523).  Saving model ...
2023-12-01 16:56:23,459:INFO::Epoch: 195
tensor([[1.0000, 0.9953, 0.9990, 0.9990],
        [1.0000, 0.9991, 0.9991, 0.9990],
        [1.0000, 0.9990, 0.9991, 0.9990],
        [1.0000, 0.9991, 0.9990, 0.9942]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:23,460:INFO::its now!!!!!!!!5
2023-12-01 16:56:23,618:INFO::its now!!!!!!!!0
2023-12-01 16:56:23,619:INFO::its now!!!!!!!!3
2023-12-01 16:56:23,645:INFO::its now!!!!!!!!5
2023-12-01 16:56:23,808:INFO::its now!!!!!!!!
2023-12-01 16:56:23,808:INFO::its now!!!!!!!! on 
2023-12-01 16:56:23,843:INFO::its now!!!!!!!!5
2023-12-01 16:56:24,021:INFO::Epoch 00195 | lr 0.00050 | Train_Loss 0.0476 | Train_Classification_Loss 0.1467 | Dmon_Loss -0.1982 | Val_Loss 0.4063 | Search Time(s) 0.3860 | Infer Time(s) 0.1785 | Time(s) 0.5645 
2023-12-01 16:56:24,069:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 3;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 0;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 3;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:24,070:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:56:24,073:INFO::Epoch: 196
tensor([[0.9982, 0.9929, 0.9987, 0.9967],
        [0.9979, 0.9967, 0.9968, 0.9984],
        [0.9979, 0.9966, 0.9968, 0.9985],
        [0.9983, 0.9968, 0.9987, 0.9919]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:24,073:INFO::its now!!!!!!!!5
2023-12-01 16:56:24,201:INFO::its now!!!!!!!!0
2023-12-01 16:56:24,201:INFO::its now!!!!!!!!3
2023-12-01 16:56:24,227:INFO::its now!!!!!!!!5
2023-12-01 16:56:24,412:INFO::its now!!!!!!!!
2023-12-01 16:56:24,412:INFO::its now!!!!!!!! on 
2023-12-01 16:56:24,452:INFO::its now!!!!!!!!5
2023-12-01 16:56:24,616:INFO::Epoch 00196 | lr 0.00050 | Train_Loss 0.0490 | Train_Classification_Loss 0.1511 | Dmon_Loss -0.2041 | Val_Loss 0.3979 | Search Time(s) 0.3771 | Infer Time(s) 0.1685 | Time(s) 0.5457 
2023-12-01 16:56:24,682:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 0;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 3;	28: 1;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:24,684:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:56:24,687:INFO::Epoch: 197
tensor([[0.9966, 0.9911, 0.9987, 0.9948],
        [0.9962, 0.9949, 0.9950, 0.9981],
        [0.9961, 0.9948, 0.9950, 0.9982],
        [0.9967, 0.9950, 0.9988, 0.9901]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:24,688:INFO::its now!!!!!!!!5
2023-12-01 16:56:24,864:INFO::its now!!!!!!!!0
2023-12-01 16:56:24,865:INFO::its now!!!!!!!!3
2023-12-01 16:56:24,890:INFO::its now!!!!!!!!5
2023-12-01 16:56:25,059:INFO::its now!!!!!!!!
2023-12-01 16:56:25,059:INFO::its now!!!!!!!! on 
2023-12-01 16:56:25,094:INFO::its now!!!!!!!!5
2023-12-01 16:56:25,274:INFO::Epoch 00197 | lr 0.00050 | Train_Loss 0.0401 | Train_Classification_Loss 0.1420 | Dmon_Loss -0.2037 | Val_Loss 0.4008 | Search Time(s) 0.4059 | Infer Time(s) 0.1831 | Time(s) 0.5890 
2023-12-01 16:56:25,324:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 0;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 0;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:25,326:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:56:25,328:INFO::Epoch: 198
tensor([[0.9962, 0.9905, 0.9989, 0.9942],
        [0.9957, 0.9943, 0.9944, 0.9980],
        [0.9956, 0.9942, 0.9944, 0.9981],
        [0.9962, 0.9945, 0.9992, 0.9895]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:25,329:INFO::its now!!!!!!!!5
2023-12-01 16:56:25,509:INFO::its now!!!!!!!!0
2023-12-01 16:56:25,510:INFO::its now!!!!!!!!3
2023-12-01 16:56:25,537:INFO::its now!!!!!!!!5
2023-12-01 16:56:25,725:INFO::its now!!!!!!!!
2023-12-01 16:56:25,725:INFO::its now!!!!!!!! on 
2023-12-01 16:56:25,763:INFO::its now!!!!!!!!5
2023-12-01 16:56:25,919:INFO::Epoch 00198 | lr 0.00050 | Train_Loss 0.0375 | Train_Classification_Loss 0.1396 | Dmon_Loss -0.2042 | Val_Loss 0.3946 | Search Time(s) 0.4348 | Infer Time(s) 0.1586 | Time(s) 0.5934 
2023-12-01 16:56:25,978:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 0;	29: 3;	30: 0;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:25,979:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 16:56:25,982:INFO::Epoch: 199
tensor([[0.9975, 0.9916, 0.9992, 0.9953],
        [0.9970, 0.9954, 0.9955, 0.9979],
        [0.9969, 0.9953, 0.9955, 0.9980],
        [0.9977, 0.9955, 0.9997, 0.9905]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:25,982:INFO::its now!!!!!!!!5
2023-12-01 16:56:26,167:INFO::its now!!!!!!!!0
2023-12-01 16:56:26,168:INFO::its now!!!!!!!!3
2023-12-01 16:56:26,196:INFO::its now!!!!!!!!5
2023-12-01 16:56:26,370:INFO::its now!!!!!!!!
2023-12-01 16:56:26,370:INFO::its now!!!!!!!! on 
2023-12-01 16:56:26,404:INFO::its now!!!!!!!!5
2023-12-01 16:56:26,581:INFO::Epoch 00199 | lr 0.00050 | Train_Loss 0.0292 | Train_Classification_Loss 0.1320 | Dmon_Loss -0.2055 | Val_Loss 0.3973 | Search Time(s) 0.4210 | Infer Time(s) 0.1805 | Time(s) 0.6015 
2023-12-01 16:56:26,634:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 0;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:26,635:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 16:56:26,638:INFO::Epoch: 200
tensor([[0.9970, 0.9911, 0.9997, 0.9948],
        [0.9964, 0.9949, 0.9949, 0.9978],
        [0.9963, 0.9948, 0.9949, 0.9980],
        [0.9971, 0.9950, 1.0000, 0.9900]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:26,639:INFO::its now!!!!!!!!5
2023-12-01 16:56:26,811:INFO::its now!!!!!!!!0
2023-12-01 16:56:26,811:INFO::its now!!!!!!!!3
2023-12-01 16:56:26,837:INFO::its now!!!!!!!!5
2023-12-01 16:56:27,011:INFO::its now!!!!!!!!
2023-12-01 16:56:27,011:INFO::its now!!!!!!!! on 
2023-12-01 16:56:27,047:INFO::its now!!!!!!!!5
2023-12-01 16:56:27,218:INFO::Epoch 00200 | lr 0.00050 | Train_Loss -0.0351 | Train_Classification_Loss 0.0730 | Dmon_Loss -0.2162 | Val_Loss 0.3519 | Search Time(s) 0.4039 | Infer Time(s) 0.1791 | Time(s) 0.5830 
2023-12-01 16:56:27,270:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 3;	39: 1;	40: 3;	41: 0;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:27,271:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 16:56:27,273:INFO::Epoch: 201
tensor([[0.9999, 0.9937, 1.0000, 0.9975],
        [0.9994, 0.9975, 0.9976, 0.9977],
        [0.9994, 0.9974, 0.9975, 0.9980],
        [1.0000, 0.9976, 1.0000, 0.9926]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:27,273:INFO::its now!!!!!!!!5
2023-12-01 16:56:27,438:INFO::its now!!!!!!!!0
2023-12-01 16:56:27,439:INFO::its now!!!!!!!!3
2023-12-01 16:56:27,466:INFO::its now!!!!!!!!5
2023-12-01 16:56:27,656:INFO::its now!!!!!!!!
2023-12-01 16:56:27,656:INFO::its now!!!!!!!! on 
2023-12-01 16:56:27,688:INFO::its now!!!!!!!!5
2023-12-01 16:56:27,834:INFO::Epoch 00201 | lr 0.00050 | Train_Loss -0.0664 | Train_Classification_Loss 0.0522 | Dmon_Loss -0.2370 | Val_Loss 0.3204 | Search Time(s) 0.4105 | Infer Time(s) 0.1526 | Time(s) 0.5631 
2023-12-01 16:56:27,884:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 3;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:27,885:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 16:56:27,888:INFO::Epoch: 202
tensor([[1.0000, 0.9957, 1.0000, 0.9995],
        [1.0000, 0.9995, 0.9995, 0.9984],
        [1.0000, 0.9994, 0.9995, 0.9986],
        [1.0000, 0.9995, 1.0000, 0.9946]], device='cuda:0', requires_grad=True)
2023-12-01 16:56:27,888:INFO::its now!!!!!!!!5
2023-12-01 16:56:28,061:INFO::its now!!!!!!!!0
2023-12-01 16:56:28,062:INFO::its now!!!!!!!!3
2023-12-01 16:56:28,087:INFO::its now!!!!!!!!5
2023-12-01 16:56:28,248:INFO::its now!!!!!!!!
2023-12-01 16:56:28,248:INFO::its now!!!!!!!! on 
2023-12-01 16:56:28,280:INFO::its now!!!!!!!!5
2023-12-01 16:56:28,444:INFO::Epoch 00202 | lr 0.00050 | Train_Loss -0.0614 | Train_Classification_Loss 0.0575 | Dmon_Loss -0.2377 | Val_Loss 0.3199 | Search Time(s) 0.3905 | Infer Time(s) 0.1681 | Time(s) 0.5587 
2023-12-01 16:56:28,498:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 0;	16: 3;	17: 0;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 1;	26: 3;	27: 1;	28: 1;	29: 3;	30: 1;	31: 3;	32: 3;	33: 0;	34: 0;	35: 0;	36: 1;	37: 1;	38: 0;	39: 3;	40: 0;	41: 0;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 1;	26103: 1;	26104: 3;	26105: 1;	26106: 1;	26107: 1;	26108: 3;	26109: 0;	26110: 3;	26111: 3;	26112: 3;	26113: 0;	26114: 0;	26115: 1;	26116: 3;	26117: 3;	26118: 1;	26119: 1;	26120: 1;	26121: 0;	26122: 1;	26123: 3;	26124: 0;	26125: 0;	26126: 3;	26127: 3;	
2023-12-01 16:56:28,499:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 16:56:28,500:INFO::Eearly stopping!
2023-12-01 16:56:28,927:INFO::############### Search Stage Ends! ###############
2023-12-01 16:56:28,948:INFO::=============== Retrain Stage Starts:
2023-12-01 16:56:28,949:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:28,957:INFO::node_assign_Counter:
Counter({-1: 14328, 3: 5638, 0: 4149, 1: 2013})
2023-12-01 16:56:28,957:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:56:29,451:INFO::============= repeat round: 2; seed: 1233
2023-12-01 16:56:29,638:INFO::arch_weights:
[[1.         0.99528474 0.9990038  0.9990413 ]
 [1.         0.99906087 0.9990742  0.9989752 ]
 [1.         0.99899876 0.99907094 0.99898463]
 [1.         0.9990858  0.99901575 0.9942061 ]]
2023-12-01 16:56:29,639:INFO::arch_weights_softmax:
[[0.25041682 0.24923883 0.2501675  0.25017685]
 [0.25018066 0.24994579 0.24994916 0.24992439]
 [0.25018415 0.2499338  0.24995182 0.24993025]
 [0.2504806  0.2502517  0.2502342  0.24903351]]
2023-12-01 16:56:29,640:INFO::genotype choice:
['gcn', 'gcn', 'gcn', 'gcn']
2023-12-01 16:56:30,078:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.3862 | Val_Loss 1.3845 | Time(s) 0.3920
2023-12-01 16:56:30,563:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3846 | Val_Loss 1.3811 | Time(s) 0.3118
2023-12-01 16:56:30,571:INFO::Validation loss decreased (inf --> 1.381119).  Saving model ...
2023-12-01 16:56:30,740:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3796 | Val_Loss 1.3778 | Time(s) 0.1685
2023-12-01 16:56:30,750:INFO::Validation loss decreased (1.381119 --> 1.377798).  Saving model ...
2023-12-01 16:56:30,914:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.3751 | Val_Loss 1.3746 | Time(s) 0.1636
2023-12-01 16:56:30,923:INFO::Validation loss decreased (1.377798 --> 1.374574).  Saving model ...
2023-12-01 16:56:31,086:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.3707 | Val_Loss 1.3714 | Time(s) 0.1626
2023-12-01 16:56:31,095:INFO::Validation loss decreased (1.374574 --> 1.371410).  Saving model ...
2023-12-01 16:56:31,265:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.3692 | Val_Loss 1.3683 | Time(s) 0.1702
2023-12-01 16:56:31,275:INFO::Validation loss decreased (1.371410 --> 1.368286).  Saving model ...
2023-12-01 16:56:31,453:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.3640 | Val_Loss 1.3652 | Time(s) 0.1781
2023-12-01 16:56:31,465:INFO::Validation loss decreased (1.368286 --> 1.365219).  Saving model ...
2023-12-01 16:56:31,633:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.3617 | Val_Loss 1.3622 | Time(s) 0.1665
2023-12-01 16:56:31,641:INFO::Validation loss decreased (1.365219 --> 1.362191).  Saving model ...
2023-12-01 16:56:31,799:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.3567 | Val_Loss 1.3592 | Time(s) 0.1586
2023-12-01 16:56:31,808:INFO::Validation loss decreased (1.362191 --> 1.359206).  Saving model ...
2023-12-01 16:56:31,980:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.3550 | Val_Loss 1.3562 | Time(s) 0.1716
2023-12-01 16:56:31,989:INFO::Validation loss decreased (1.359206 --> 1.356225).  Saving model ...
2023-12-01 16:56:32,145:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.3497 | Val_Loss 1.3532 | Time(s) 0.1562
2023-12-01 16:56:32,153:INFO::Validation loss decreased (1.356225 --> 1.353226).  Saving model ...
2023-12-01 16:56:32,306:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.3469 | Val_Loss 1.3502 | Time(s) 0.1536
2023-12-01 16:56:32,315:INFO::Validation loss decreased (1.353226 --> 1.350213).  Saving model ...
2023-12-01 16:56:32,501:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 1.3407 | Val_Loss 1.3472 | Time(s) 0.1845
2023-12-01 16:56:32,510:INFO::Validation loss decreased (1.350213 --> 1.347179).  Saving model ...
2023-12-01 16:56:32,665:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 1.3388 | Val_Loss 1.3441 | Time(s) 0.1546
2023-12-01 16:56:32,673:INFO::Validation loss decreased (1.347179 --> 1.344104).  Saving model ...
2023-12-01 16:56:32,834:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 1.3353 | Val_Loss 1.3410 | Time(s) 0.1606
2023-12-01 16:56:32,842:INFO::Validation loss decreased (1.344104 --> 1.340957).  Saving model ...
2023-12-01 16:56:32,997:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 1.3328 | Val_Loss 1.3377 | Time(s) 0.1526
2023-12-01 16:56:33,004:INFO::Validation loss decreased (1.340957 --> 1.337744).  Saving model ...
2023-12-01 16:56:33,187:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 1.3267 | Val_Loss 1.3344 | Time(s) 0.1821
2023-12-01 16:56:33,196:INFO::Validation loss decreased (1.337744 --> 1.334440).  Saving model ...
2023-12-01 16:56:33,370:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 1.3225 | Val_Loss 1.3310 | Time(s) 0.1742
2023-12-01 16:56:33,382:INFO::Validation loss decreased (1.334440 --> 1.331039).  Saving model ...
2023-12-01 16:56:33,556:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 1.3165 | Val_Loss 1.3275 | Time(s) 0.1745
2023-12-01 16:56:33,567:INFO::Validation loss decreased (1.331039 --> 1.327526).  Saving model ...
2023-12-01 16:56:33,741:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 1.3162 | Val_Loss 1.3239 | Time(s) 0.1735
2023-12-01 16:56:33,750:INFO::Validation loss decreased (1.327526 --> 1.323874).  Saving model ...
2023-12-01 16:56:33,928:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 1.3097 | Val_Loss 1.3201 | Time(s) 0.1785
2023-12-01 16:56:33,938:INFO::Validation loss decreased (1.323874 --> 1.320081).  Saving model ...
2023-12-01 16:56:34,100:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 1.3042 | Val_Loss 1.3161 | Time(s) 0.1617
2023-12-01 16:56:34,109:INFO::Validation loss decreased (1.320081 --> 1.316148).  Saving model ...
2023-12-01 16:56:34,266:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 1.3008 | Val_Loss 1.3120 | Time(s) 0.1556
2023-12-01 16:56:34,273:INFO::Validation loss decreased (1.316148 --> 1.312041).  Saving model ...
2023-12-01 16:56:34,438:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 1.2956 | Val_Loss 1.3078 | Time(s) 0.1631
2023-12-01 16:56:34,445:INFO::Validation loss decreased (1.312041 --> 1.307752).  Saving model ...
2023-12-01 16:56:34,604:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 1.2896 | Val_Loss 1.3033 | Time(s) 0.1576
2023-12-01 16:56:34,612:INFO::Validation loss decreased (1.307752 --> 1.303258).  Saving model ...
2023-12-01 16:56:34,769:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 1.2862 | Val_Loss 1.2986 | Time(s) 0.1566
2023-12-01 16:56:34,777:INFO::Validation loss decreased (1.303258 --> 1.298559).  Saving model ...
2023-12-01 16:56:34,948:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 1.2783 | Val_Loss 1.2936 | Time(s) 0.1705
2023-12-01 16:56:34,957:INFO::Validation loss decreased (1.298559 --> 1.293632).  Saving model ...
2023-12-01 16:56:35,114:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 1.2716 | Val_Loss 1.2885 | Time(s) 0.1572
2023-12-01 16:56:35,122:INFO::Validation loss decreased (1.293632 --> 1.288477).  Saving model ...
2023-12-01 16:56:35,288:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 1.2653 | Val_Loss 1.2831 | Time(s) 0.1657
2023-12-01 16:56:35,295:INFO::Validation loss decreased (1.288477 --> 1.283088).  Saving model ...
2023-12-01 16:56:35,468:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 1.2623 | Val_Loss 1.2775 | Time(s) 0.1715
2023-12-01 16:56:35,477:INFO::Validation loss decreased (1.283088 --> 1.277457).  Saving model ...
2023-12-01 16:56:35,632:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 1.2535 | Val_Loss 1.2716 | Time(s) 0.1556
2023-12-01 16:56:35,641:INFO::Validation loss decreased (1.277457 --> 1.271593).  Saving model ...
2023-12-01 16:56:35,798:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 1.2464 | Val_Loss 1.2655 | Time(s) 0.1566
2023-12-01 16:56:35,806:INFO::Validation loss decreased (1.271593 --> 1.265482).  Saving model ...
2023-12-01 16:56:35,959:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 1.2361 | Val_Loss 1.2591 | Time(s) 0.1536
2023-12-01 16:56:35,967:INFO::Validation loss decreased (1.265482 --> 1.259124).  Saving model ...
2023-12-01 16:56:36,125:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 1.2318 | Val_Loss 1.2525 | Time(s) 0.1579
2023-12-01 16:56:36,133:INFO::Validation loss decreased (1.259124 --> 1.252524).  Saving model ...
2023-12-01 16:56:36,287:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 1.2240 | Val_Loss 1.2457 | Time(s) 0.1542
2023-12-01 16:56:36,299:INFO::Validation loss decreased (1.252524 --> 1.245668).  Saving model ...
2023-12-01 16:56:36,487:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 1.2165 | Val_Loss 1.2386 | Time(s) 0.1875
2023-12-01 16:56:36,495:INFO::Validation loss decreased (1.245668 --> 1.238557).  Saving model ...
2023-12-01 16:56:36,672:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 1.2036 | Val_Loss 1.2312 | Time(s) 0.1775
2023-12-01 16:56:36,681:INFO::Validation loss decreased (1.238557 --> 1.231204).  Saving model ...
2023-12-01 16:56:36,851:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 1.1938 | Val_Loss 1.2236 | Time(s) 0.1686
2023-12-01 16:56:36,858:INFO::Validation loss decreased (1.231204 --> 1.223593).  Saving model ...
2023-12-01 16:56:37,018:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 1.1883 | Val_Loss 1.2157 | Time(s) 0.1586
2023-12-01 16:56:37,026:INFO::Validation loss decreased (1.223593 --> 1.215748).  Saving model ...
2023-12-01 16:56:37,185:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 1.1759 | Val_Loss 1.2076 | Time(s) 0.1592
2023-12-01 16:56:37,193:INFO::Validation loss decreased (1.215748 --> 1.207646).  Saving model ...
2023-12-01 16:56:37,367:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 1.1682 | Val_Loss 1.1993 | Time(s) 0.1734
2023-12-01 16:56:37,375:INFO::Validation loss decreased (1.207646 --> 1.199296).  Saving model ...
2023-12-01 16:56:37,538:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 1.1558 | Val_Loss 1.1907 | Time(s) 0.1626
2023-12-01 16:56:37,546:INFO::Validation loss decreased (1.199296 --> 1.190700).  Saving model ...
2023-12-01 16:56:37,716:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 1.1479 | Val_Loss 1.1819 | Time(s) 0.1695
2023-12-01 16:56:37,724:INFO::Validation loss decreased (1.190700 --> 1.181889).  Saving model ...
2023-12-01 16:56:37,882:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 1.1350 | Val_Loss 1.1728 | Time(s) 0.1586
2023-12-01 16:56:37,889:INFO::Validation loss decreased (1.181889 --> 1.172819).  Saving model ...
2023-12-01 16:56:38,047:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 1.1240 | Val_Loss 1.1635 | Time(s) 0.1566
2023-12-01 16:56:38,055:INFO::Validation loss decreased (1.172819 --> 1.163501).  Saving model ...
2023-12-01 16:56:38,215:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 1.1136 | Val_Loss 1.1539 | Time(s) 0.1601
2023-12-01 16:56:38,223:INFO::Validation loss decreased (1.163501 --> 1.153932).  Saving model ...
2023-12-01 16:56:38,383:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 1.1025 | Val_Loss 1.1441 | Time(s) 0.1593
2023-12-01 16:56:38,393:INFO::Validation loss decreased (1.153932 --> 1.144109).  Saving model ...
2023-12-01 16:56:38,556:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 1.0915 | Val_Loss 1.1340 | Time(s) 0.1630
2023-12-01 16:56:38,564:INFO::Validation loss decreased (1.144109 --> 1.134039).  Saving model ...
2023-12-01 16:56:38,721:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 1.0749 | Val_Loss 1.1237 | Time(s) 0.1566
2023-12-01 16:56:38,730:INFO::Validation loss decreased (1.134039 --> 1.123724).  Saving model ...
2023-12-01 16:56:38,888:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 1.0634 | Val_Loss 1.1132 | Time(s) 0.1576
2023-12-01 16:56:38,897:INFO::Validation loss decreased (1.123724 --> 1.113158).  Saving model ...
2023-12-01 16:56:39,059:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 1.0471 | Val_Loss 1.1023 | Time(s) 0.1616
2023-12-01 16:56:39,068:INFO::Validation loss decreased (1.113158 --> 1.102333).  Saving model ...
2023-12-01 16:56:39,225:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 1.0388 | Val_Loss 1.0913 | Time(s) 0.1572
2023-12-01 16:56:39,234:INFO::Validation loss decreased (1.102333 --> 1.091273).  Saving model ...
2023-12-01 16:56:39,396:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 1.0219 | Val_Loss 1.0800 | Time(s) 0.1622
2023-12-01 16:56:39,404:INFO::Validation loss decreased (1.091273 --> 1.079971).  Saving model ...
2023-12-01 16:56:39,563:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 1.0144 | Val_Loss 1.0685 | Time(s) 0.1576
2023-12-01 16:56:39,608:INFO::Validation loss decreased (1.079971 --> 1.068461).  Saving model ...
2023-12-01 16:56:39,766:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.9977 | Val_Loss 1.0568 | Time(s) 0.1586
2023-12-01 16:56:39,774:INFO::Validation loss decreased (1.068461 --> 1.056754).  Saving model ...
2023-12-01 16:56:39,948:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.9820 | Val_Loss 1.0449 | Time(s) 0.1736
2023-12-01 16:56:39,957:INFO::Validation loss decreased (1.056754 --> 1.044855).  Saving model ...
2023-12-01 16:56:40,110:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.9649 | Val_Loss 1.0328 | Time(s) 0.1532
2023-12-01 16:56:40,122:INFO::Validation loss decreased (1.044855 --> 1.032753).  Saving model ...
2023-12-01 16:56:40,277:INFO::Epoch 00057 | lr 0.00050 |Train_Loss 0.9527 | Val_Loss 1.0205 | Time(s) 0.1546
2023-12-01 16:56:40,289:INFO::Validation loss decreased (1.032753 --> 1.020460).  Saving model ...
2023-12-01 16:56:40,459:INFO::Epoch 00058 | lr 0.00050 |Train_Loss 0.9357 | Val_Loss 1.0080 | Time(s) 0.1702
2023-12-01 16:56:40,468:INFO::Validation loss decreased (1.020460 --> 1.008004).  Saving model ...
2023-12-01 16:56:40,627:INFO::Epoch 00059 | lr 0.00050 |Train_Loss 0.9219 | Val_Loss 0.9954 | Time(s) 0.1596
2023-12-01 16:56:40,635:INFO::Validation loss decreased (1.008004 --> 0.995385).  Saving model ...
2023-12-01 16:56:40,798:INFO::Epoch 00060 | lr 0.00050 |Train_Loss 0.9122 | Val_Loss 0.9826 | Time(s) 0.1626
2023-12-01 16:56:40,807:INFO::Validation loss decreased (0.995385 --> 0.982629).  Saving model ...
2023-12-01 16:56:40,959:INFO::Epoch 00061 | lr 0.00050 |Train_Loss 0.8879 | Val_Loss 0.9697 | Time(s) 0.1526
2023-12-01 16:56:40,967:INFO::Validation loss decreased (0.982629 --> 0.969749).  Saving model ...
2023-12-01 16:56:41,147:INFO::Epoch 00062 | lr 0.00050 |Train_Loss 0.8752 | Val_Loss 0.9568 | Time(s) 0.1782
2023-12-01 16:56:41,155:INFO::Validation loss decreased (0.969749 --> 0.956776).  Saving model ...
2023-12-01 16:56:41,312:INFO::Epoch 00063 | lr 0.00050 |Train_Loss 0.8646 | Val_Loss 0.9438 | Time(s) 0.1572
2023-12-01 16:56:41,320:INFO::Validation loss decreased (0.956776 --> 0.943756).  Saving model ...
2023-12-01 16:56:41,492:INFO::Epoch 00064 | lr 0.00050 |Train_Loss 0.8451 | Val_Loss 0.9307 | Time(s) 0.1715
2023-12-01 16:56:41,501:INFO::Validation loss decreased (0.943756 --> 0.930667).  Saving model ...
2023-12-01 16:56:41,656:INFO::Epoch 00065 | lr 0.00050 |Train_Loss 0.8328 | Val_Loss 0.9175 | Time(s) 0.1536
2023-12-01 16:56:41,663:INFO::Validation loss decreased (0.930667 --> 0.917547).  Saving model ...
2023-12-01 16:56:41,815:INFO::Epoch 00066 | lr 0.00050 |Train_Loss 0.8182 | Val_Loss 0.9044 | Time(s) 0.1516
2023-12-01 16:56:41,823:INFO::Validation loss decreased (0.917547 --> 0.904409).  Saving model ...
2023-12-01 16:56:41,978:INFO::Epoch 00067 | lr 0.00050 |Train_Loss 0.7968 | Val_Loss 0.8913 | Time(s) 0.1546
2023-12-01 16:56:41,987:INFO::Validation loss decreased (0.904409 --> 0.891291).  Saving model ...
2023-12-01 16:56:42,174:INFO::Epoch 00068 | lr 0.00050 |Train_Loss 0.7804 | Val_Loss 0.8782 | Time(s) 0.1862
2023-12-01 16:56:42,182:INFO::Validation loss decreased (0.891291 --> 0.878187).  Saving model ...
2023-12-01 16:56:42,353:INFO::Epoch 00069 | lr 0.00050 |Train_Loss 0.7670 | Val_Loss 0.8651 | Time(s) 0.1712
2023-12-01 16:56:42,361:INFO::Validation loss decreased (0.878187 --> 0.865132).  Saving model ...
2023-12-01 16:56:42,532:INFO::Epoch 00070 | lr 0.00050 |Train_Loss 0.7557 | Val_Loss 0.8521 | Time(s) 0.1705
2023-12-01 16:56:42,540:INFO::Validation loss decreased (0.865132 --> 0.852138).  Saving model ...
2023-12-01 16:56:42,696:INFO::Epoch 00071 | lr 0.00050 |Train_Loss 0.7359 | Val_Loss 0.8392 | Time(s) 0.1556
2023-12-01 16:56:42,704:INFO::Validation loss decreased (0.852138 --> 0.839193).  Saving model ...
2023-12-01 16:56:42,862:INFO::Epoch 00072 | lr 0.00050 |Train_Loss 0.7196 | Val_Loss 0.8263 | Time(s) 0.1566
2023-12-01 16:56:42,869:INFO::Validation loss decreased (0.839193 --> 0.826313).  Saving model ...
2023-12-01 16:56:43,022:INFO::Epoch 00073 | lr 0.00050 |Train_Loss 0.7002 | Val_Loss 0.8135 | Time(s) 0.1516
2023-12-01 16:56:43,029:INFO::Validation loss decreased (0.826313 --> 0.813535).  Saving model ...
2023-12-01 16:56:43,206:INFO::Epoch 00074 | lr 0.00050 |Train_Loss 0.6889 | Val_Loss 0.8009 | Time(s) 0.1752
2023-12-01 16:56:43,213:INFO::Validation loss decreased (0.813535 --> 0.800884).  Saving model ...
2023-12-01 16:56:43,368:INFO::Epoch 00075 | lr 0.00050 |Train_Loss 0.6760 | Val_Loss 0.7883 | Time(s) 0.1552
2023-12-01 16:56:43,383:INFO::Validation loss decreased (0.800884 --> 0.788335).  Saving model ...
2023-12-01 16:56:43,545:INFO::Epoch 00076 | lr 0.00050 |Train_Loss 0.6536 | Val_Loss 0.7759 | Time(s) 0.1615
2023-12-01 16:56:43,554:INFO::Validation loss decreased (0.788335 --> 0.775870).  Saving model ...
2023-12-01 16:56:43,718:INFO::Epoch 00077 | lr 0.00050 |Train_Loss 0.6488 | Val_Loss 0.7635 | Time(s) 0.1636
2023-12-01 16:56:43,726:INFO::Validation loss decreased (0.775870 --> 0.763546).  Saving model ...
2023-12-01 16:56:43,882:INFO::Epoch 00078 | lr 0.00050 |Train_Loss 0.6290 | Val_Loss 0.7514 | Time(s) 0.1556
2023-12-01 16:56:43,890:INFO::Validation loss decreased (0.763546 --> 0.751368).  Saving model ...
2023-12-01 16:56:44,045:INFO::Epoch 00079 | lr 0.00050 |Train_Loss 0.6111 | Val_Loss 0.7393 | Time(s) 0.1546
2023-12-01 16:56:44,054:INFO::Validation loss decreased (0.751368 --> 0.739334).  Saving model ...
2023-12-01 16:56:44,213:INFO::Epoch 00080 | lr 0.00050 |Train_Loss 0.6002 | Val_Loss 0.7274 | Time(s) 0.1583
2023-12-01 16:56:44,221:INFO::Validation loss decreased (0.739334 --> 0.727426).  Saving model ...
2023-12-01 16:56:44,379:INFO::Epoch 00081 | lr 0.00050 |Train_Loss 0.5855 | Val_Loss 0.7157 | Time(s) 0.1582
2023-12-01 16:56:44,387:INFO::Validation loss decreased (0.727426 --> 0.715715).  Saving model ...
2023-12-01 16:56:44,556:INFO::Epoch 00082 | lr 0.00050 |Train_Loss 0.5682 | Val_Loss 0.7042 | Time(s) 0.1685
2023-12-01 16:56:44,564:INFO::Validation loss decreased (0.715715 --> 0.704194).  Saving model ...
2023-12-01 16:56:44,719:INFO::Epoch 00083 | lr 0.00050 |Train_Loss 0.5567 | Val_Loss 0.6929 | Time(s) 0.1546
2023-12-01 16:56:44,727:INFO::Validation loss decreased (0.704194 --> 0.692860).  Saving model ...
2023-12-01 16:56:44,888:INFO::Epoch 00084 | lr 0.00050 |Train_Loss 0.5432 | Val_Loss 0.6818 | Time(s) 0.1616
2023-12-01 16:56:44,897:INFO::Validation loss decreased (0.692860 --> 0.681763).  Saving model ...
2023-12-01 16:56:45,053:INFO::Epoch 00085 | lr 0.00050 |Train_Loss 0.5335 | Val_Loss 0.6709 | Time(s) 0.1556
2023-12-01 16:56:45,062:INFO::Validation loss decreased (0.681763 --> 0.670891).  Saving model ...
2023-12-01 16:56:45,225:INFO::Epoch 00086 | lr 0.00050 |Train_Loss 0.5122 | Val_Loss 0.6602 | Time(s) 0.1634
2023-12-01 16:56:45,233:INFO::Validation loss decreased (0.670891 --> 0.660246).  Saving model ...
2023-12-01 16:56:45,390:INFO::Epoch 00087 | lr 0.00050 |Train_Loss 0.4963 | Val_Loss 0.6498 | Time(s) 0.1572
2023-12-01 16:56:45,399:INFO::Validation loss decreased (0.660246 --> 0.649810).  Saving model ...
2023-12-01 16:56:45,559:INFO::Epoch 00088 | lr 0.00050 |Train_Loss 0.4802 | Val_Loss 0.6396 | Time(s) 0.1586
2023-12-01 16:56:45,569:INFO::Validation loss decreased (0.649810 --> 0.639632).  Saving model ...
2023-12-01 16:56:45,731:INFO::Epoch 00089 | lr 0.00050 |Train_Loss 0.4759 | Val_Loss 0.6297 | Time(s) 0.1625
2023-12-01 16:56:45,743:INFO::Validation loss decreased (0.639632 --> 0.629678).  Saving model ...
2023-12-01 16:56:45,927:INFO::Epoch 00090 | lr 0.00050 |Train_Loss 0.4674 | Val_Loss 0.6199 | Time(s) 0.1835
2023-12-01 16:56:45,935:INFO::Validation loss decreased (0.629678 --> 0.619907).  Saving model ...
2023-12-01 16:56:46,090:INFO::Epoch 00091 | lr 0.00050 |Train_Loss 0.4569 | Val_Loss 0.6104 | Time(s) 0.1546
2023-12-01 16:56:46,099:INFO::Validation loss decreased (0.619907 --> 0.610383).  Saving model ...
2023-12-01 16:56:46,260:INFO::Epoch 00092 | lr 0.00050 |Train_Loss 0.4365 | Val_Loss 0.6011 | Time(s) 0.1602
2023-12-01 16:56:46,268:INFO::Validation loss decreased (0.610383 --> 0.601062).  Saving model ...
2023-12-01 16:56:46,432:INFO::Epoch 00093 | lr 0.00050 |Train_Loss 0.4250 | Val_Loss 0.5920 | Time(s) 0.1632
2023-12-01 16:56:46,446:INFO::Validation loss decreased (0.601062 --> 0.591983).  Saving model ...
2023-12-01 16:56:46,613:INFO::Epoch 00094 | lr 0.00050 |Train_Loss 0.4213 | Val_Loss 0.5831 | Time(s) 0.1676
2023-12-01 16:56:46,620:INFO::Validation loss decreased (0.591983 --> 0.583071).  Saving model ...
2023-12-01 16:56:46,804:INFO::Epoch 00095 | lr 0.00050 |Train_Loss 0.4010 | Val_Loss 0.5743 | Time(s) 0.1835
2023-12-01 16:56:46,812:INFO::Validation loss decreased (0.583071 --> 0.574342).  Saving model ...
2023-12-01 16:56:46,969:INFO::Epoch 00096 | lr 0.00050 |Train_Loss 0.3892 | Val_Loss 0.5658 | Time(s) 0.1566
2023-12-01 16:56:46,976:INFO::Validation loss decreased (0.574342 --> 0.565816).  Saving model ...
2023-12-01 16:56:47,147:INFO::Epoch 00097 | lr 0.00050 |Train_Loss 0.3959 | Val_Loss 0.5575 | Time(s) 0.1712
2023-12-01 16:56:47,155:INFO::Validation loss decreased (0.565816 --> 0.557526).  Saving model ...
2023-12-01 16:56:47,310:INFO::Epoch 00098 | lr 0.00050 |Train_Loss 0.3714 | Val_Loss 0.5495 | Time(s) 0.1542
2023-12-01 16:56:47,318:INFO::Validation loss decreased (0.557526 --> 0.549461).  Saving model ...
2023-12-01 16:56:47,481:INFO::Epoch 00099 | lr 0.00050 |Train_Loss 0.3701 | Val_Loss 0.5416 | Time(s) 0.1636
2023-12-01 16:56:47,490:INFO::Validation loss decreased (0.549461 --> 0.541561).  Saving model ...
2023-12-01 16:56:47,675:INFO::Epoch 00100 | lr 0.00050 |Train_Loss 0.3493 | Val_Loss 0.5339 | Time(s) 0.1845
2023-12-01 16:56:47,684:INFO::Validation loss decreased (0.541561 --> 0.533893).  Saving model ...
2023-12-01 16:56:47,852:INFO::Epoch 00101 | lr 0.00050 |Train_Loss 0.3527 | Val_Loss 0.5264 | Time(s) 0.1685
2023-12-01 16:56:47,861:INFO::Validation loss decreased (0.533893 --> 0.526433).  Saving model ...
2023-12-01 16:56:48,023:INFO::Epoch 00102 | lr 0.00050 |Train_Loss 0.3316 | Val_Loss 0.5193 | Time(s) 0.1596
2023-12-01 16:56:48,032:INFO::Validation loss decreased (0.526433 --> 0.519301).  Saving model ...
2023-12-01 16:56:48,196:INFO::Epoch 00103 | lr 0.00050 |Train_Loss 0.3273 | Val_Loss 0.5125 | Time(s) 0.1642
2023-12-01 16:56:48,204:INFO::Validation loss decreased (0.519301 --> 0.512462).  Saving model ...
2023-12-01 16:56:48,360:INFO::Epoch 00104 | lr 0.00050 |Train_Loss 0.3266 | Val_Loss 0.5059 | Time(s) 0.1552
2023-12-01 16:56:48,368:INFO::Validation loss decreased (0.512462 --> 0.505856).  Saving model ...
2023-12-01 16:56:48,526:INFO::Epoch 00105 | lr 0.00050 |Train_Loss 0.3064 | Val_Loss 0.4995 | Time(s) 0.1565
2023-12-01 16:56:48,536:INFO::Validation loss decreased (0.505856 --> 0.499501).  Saving model ...
2023-12-01 16:56:48,702:INFO::Epoch 00106 | lr 0.00050 |Train_Loss 0.3080 | Val_Loss 0.4934 | Time(s) 0.1665
2023-12-01 16:56:48,712:INFO::Validation loss decreased (0.499501 --> 0.493434).  Saving model ...
2023-12-01 16:56:48,874:INFO::Epoch 00107 | lr 0.00050 |Train_Loss 0.2981 | Val_Loss 0.4876 | Time(s) 0.1616
2023-12-01 16:56:48,883:INFO::Validation loss decreased (0.493434 --> 0.487634).  Saving model ...
2023-12-01 16:56:49,050:INFO::Epoch 00108 | lr 0.00050 |Train_Loss 0.2822 | Val_Loss 0.4820 | Time(s) 0.1666
2023-12-01 16:56:49,061:INFO::Validation loss decreased (0.487634 --> 0.482049).  Saving model ...
2023-12-01 16:56:49,217:INFO::Epoch 00109 | lr 0.00050 |Train_Loss 0.2809 | Val_Loss 0.4766 | Time(s) 0.1561
2023-12-01 16:56:49,225:INFO::Validation loss decreased (0.482049 --> 0.476642).  Saving model ...
2023-12-01 16:56:49,382:INFO::Epoch 00110 | lr 0.00050 |Train_Loss 0.2718 | Val_Loss 0.4714 | Time(s) 0.1563
2023-12-01 16:56:49,390:INFO::Validation loss decreased (0.476642 --> 0.471426).  Saving model ...
2023-12-01 16:56:49,547:INFO::Epoch 00111 | lr 0.00050 |Train_Loss 0.2695 | Val_Loss 0.4663 | Time(s) 0.1576
2023-12-01 16:56:49,554:INFO::Validation loss decreased (0.471426 --> 0.466330).  Saving model ...
2023-12-01 16:56:49,722:INFO::Epoch 00112 | lr 0.00050 |Train_Loss 0.2611 | Val_Loss 0.4613 | Time(s) 0.1676
2023-12-01 16:56:49,729:INFO::Validation loss decreased (0.466330 --> 0.461331).  Saving model ...
2023-12-01 16:56:49,883:INFO::Epoch 00113 | lr 0.00050 |Train_Loss 0.2552 | Val_Loss 0.4564 | Time(s) 0.1545
2023-12-01 16:56:49,891:INFO::Validation loss decreased (0.461331 --> 0.456446).  Saving model ...
2023-12-01 16:56:50,065:INFO::Epoch 00114 | lr 0.00050 |Train_Loss 0.2522 | Val_Loss 0.4517 | Time(s) 0.1726
2023-12-01 16:56:50,073:INFO::Validation loss decreased (0.456446 --> 0.451707).  Saving model ...
2023-12-01 16:56:50,228:INFO::Epoch 00115 | lr 0.00050 |Train_Loss 0.2383 | Val_Loss 0.4471 | Time(s) 0.1542
2023-12-01 16:56:50,236:INFO::Validation loss decreased (0.451707 --> 0.447095).  Saving model ...
2023-12-01 16:56:50,398:INFO::Epoch 00116 | lr 0.00050 |Train_Loss 0.2377 | Val_Loss 0.4426 | Time(s) 0.1612
2023-12-01 16:56:50,406:INFO::Validation loss decreased (0.447095 --> 0.442581).  Saving model ...
2023-12-01 16:56:50,562:INFO::Epoch 00117 | lr 0.00050 |Train_Loss 0.2272 | Val_Loss 0.4383 | Time(s) 0.1546
2023-12-01 16:56:50,569:INFO::Validation loss decreased (0.442581 --> 0.438281).  Saving model ...
2023-12-01 16:56:50,731:INFO::Epoch 00118 | lr 0.00050 |Train_Loss 0.2262 | Val_Loss 0.4341 | Time(s) 0.1626
2023-12-01 16:56:50,740:INFO::Validation loss decreased (0.438281 --> 0.434125).  Saving model ...
2023-12-01 16:56:50,895:INFO::Epoch 00119 | lr 0.00050 |Train_Loss 0.2253 | Val_Loss 0.4302 | Time(s) 0.1526
2023-12-01 16:56:50,902:INFO::Validation loss decreased (0.434125 --> 0.430175).  Saving model ...
2023-12-01 16:56:51,084:INFO::Epoch 00120 | lr 0.00050 |Train_Loss 0.2076 | Val_Loss 0.4264 | Time(s) 0.1815
2023-12-01 16:56:51,094:INFO::Validation loss decreased (0.430175 --> 0.426405).  Saving model ...
2023-12-01 16:56:51,247:INFO::Epoch 00121 | lr 0.00050 |Train_Loss 0.2132 | Val_Loss 0.4228 | Time(s) 0.1531
2023-12-01 16:56:51,256:INFO::Validation loss decreased (0.426405 --> 0.422751).  Saving model ...
2023-12-01 16:56:51,418:INFO::Epoch 00122 | lr 0.00050 |Train_Loss 0.2038 | Val_Loss 0.4193 | Time(s) 0.1612
2023-12-01 16:56:51,428:INFO::Validation loss decreased (0.422751 --> 0.419321).  Saving model ...
2023-12-01 16:56:51,586:INFO::Epoch 00123 | lr 0.00050 |Train_Loss 0.2028 | Val_Loss 0.4160 | Time(s) 0.1576
2023-12-01 16:56:51,594:INFO::Validation loss decreased (0.419321 --> 0.416026).  Saving model ...
2023-12-01 16:56:51,752:INFO::Epoch 00124 | lr 0.00050 |Train_Loss 0.1872 | Val_Loss 0.4128 | Time(s) 0.1575
2023-12-01 16:56:51,760:INFO::Validation loss decreased (0.416026 --> 0.412788).  Saving model ...
2023-12-01 16:56:51,918:INFO::Epoch 00125 | lr 0.00050 |Train_Loss 0.1874 | Val_Loss 0.4098 | Time(s) 0.1576
2023-12-01 16:56:51,927:INFO::Validation loss decreased (0.412788 --> 0.409768).  Saving model ...
2023-12-01 16:56:52,092:INFO::Epoch 00126 | lr 0.00050 |Train_Loss 0.1875 | Val_Loss 0.4069 | Time(s) 0.1645
2023-12-01 16:56:52,101:INFO::Validation loss decreased (0.409768 --> 0.406865).  Saving model ...
2023-12-01 16:56:52,285:INFO::Epoch 00127 | lr 0.00050 |Train_Loss 0.1782 | Val_Loss 0.4041 | Time(s) 0.1825
2023-12-01 16:56:52,293:INFO::Validation loss decreased (0.406865 --> 0.404067).  Saving model ...
2023-12-01 16:56:52,454:INFO::Epoch 00128 | lr 0.00050 |Train_Loss 0.1785 | Val_Loss 0.4013 | Time(s) 0.1616
2023-12-01 16:56:52,462:INFO::Validation loss decreased (0.404067 --> 0.401255).  Saving model ...
2023-12-01 16:56:52,623:INFO::Epoch 00129 | lr 0.00050 |Train_Loss 0.1721 | Val_Loss 0.3985 | Time(s) 0.1605
2023-12-01 16:56:52,631:INFO::Validation loss decreased (0.401255 --> 0.398521).  Saving model ...
2023-12-01 16:56:52,804:INFO::Epoch 00130 | lr 0.00050 |Train_Loss 0.1643 | Val_Loss 0.3959 | Time(s) 0.1725
2023-12-01 16:56:52,813:INFO::Validation loss decreased (0.398521 --> 0.395874).  Saving model ...
2023-12-01 16:56:52,997:INFO::Epoch 00131 | lr 0.00050 |Train_Loss 0.1638 | Val_Loss 0.3932 | Time(s) 0.1825
2023-12-01 16:56:53,005:INFO::Validation loss decreased (0.395874 --> 0.393186).  Saving model ...
2023-12-01 16:56:53,194:INFO::Epoch 00132 | lr 0.00050 |Train_Loss 0.1671 | Val_Loss 0.3907 | Time(s) 0.1888
2023-12-01 16:56:53,203:INFO::Validation loss decreased (0.393186 --> 0.390695).  Saving model ...
2023-12-01 16:56:53,365:INFO::Epoch 00133 | lr 0.00050 |Train_Loss 0.1621 | Val_Loss 0.3883 | Time(s) 0.1602
2023-12-01 16:56:53,373:INFO::Validation loss decreased (0.390695 --> 0.388325).  Saving model ...
2023-12-01 16:56:53,535:INFO::Epoch 00134 | lr 0.00050 |Train_Loss 0.1527 | Val_Loss 0.3860 | Time(s) 0.1626
2023-12-01 16:56:53,543:INFO::Validation loss decreased (0.388325 --> 0.386027).  Saving model ...
2023-12-01 16:56:53,708:INFO::Epoch 00135 | lr 0.00050 |Train_Loss 0.1528 | Val_Loss 0.3839 | Time(s) 0.1645
2023-12-01 16:56:53,716:INFO::Validation loss decreased (0.386027 --> 0.383854).  Saving model ...
2023-12-01 16:56:53,874:INFO::Epoch 00136 | lr 0.00050 |Train_Loss 0.1476 | Val_Loss 0.3819 | Time(s) 0.1586
2023-12-01 16:56:53,883:INFO::Validation loss decreased (0.383854 --> 0.381867).  Saving model ...
2023-12-01 16:56:54,044:INFO::Epoch 00137 | lr 0.00050 |Train_Loss 0.1483 | Val_Loss 0.3801 | Time(s) 0.1606
2023-12-01 16:56:54,052:INFO::Validation loss decreased (0.381867 --> 0.380077).  Saving model ...
2023-12-01 16:56:54,210:INFO::Epoch 00138 | lr 0.00050 |Train_Loss 0.1424 | Val_Loss 0.3784 | Time(s) 0.1582
2023-12-01 16:56:54,217:INFO::Validation loss decreased (0.380077 --> 0.378417).  Saving model ...
2023-12-01 16:56:54,390:INFO::Epoch 00139 | lr 0.00050 |Train_Loss 0.1434 | Val_Loss 0.3769 | Time(s) 0.1714
2023-12-01 16:56:54,400:INFO::Validation loss decreased (0.378417 --> 0.376854).  Saving model ...
2023-12-01 16:56:54,570:INFO::Epoch 00140 | lr 0.00050 |Train_Loss 0.1317 | Val_Loss 0.3755 | Time(s) 0.1685
2023-12-01 16:56:54,577:INFO::Validation loss decreased (0.376854 --> 0.375461).  Saving model ...
2023-12-01 16:56:54,739:INFO::Epoch 00141 | lr 0.00050 |Train_Loss 0.1359 | Val_Loss 0.3741 | Time(s) 0.1623
2023-12-01 16:56:54,747:INFO::Validation loss decreased (0.375461 --> 0.374107).  Saving model ...
2023-12-01 16:56:54,904:INFO::Epoch 00142 | lr 0.00050 |Train_Loss 0.1313 | Val_Loss 0.3729 | Time(s) 0.1566
2023-12-01 16:56:54,913:INFO::Validation loss decreased (0.374107 --> 0.372886).  Saving model ...
2023-12-01 16:56:55,070:INFO::Epoch 00143 | lr 0.00050 |Train_Loss 0.1252 | Val_Loss 0.3716 | Time(s) 0.1576
2023-12-01 16:56:55,078:INFO::Validation loss decreased (0.372886 --> 0.371640).  Saving model ...
2023-12-01 16:56:55,245:INFO::Epoch 00144 | lr 0.00050 |Train_Loss 0.1253 | Val_Loss 0.3704 | Time(s) 0.1671
2023-12-01 16:56:55,254:INFO::Validation loss decreased (0.371640 --> 0.370442).  Saving model ...
2023-12-01 16:56:55,422:INFO::Epoch 00145 | lr 0.00050 |Train_Loss 0.1223 | Val_Loss 0.3692 | Time(s) 0.1671
2023-12-01 16:56:55,439:INFO::Validation loss decreased (0.370442 --> 0.369233).  Saving model ...
2023-12-01 16:56:55,599:INFO::Epoch 00146 | lr 0.00050 |Train_Loss 0.1190 | Val_Loss 0.3679 | Time(s) 0.1596
2023-12-01 16:56:55,607:INFO::Validation loss decreased (0.369233 --> 0.367936).  Saving model ...
2023-12-01 16:56:55,772:INFO::Epoch 00147 | lr 0.00050 |Train_Loss 0.1132 | Val_Loss 0.3666 | Time(s) 0.1646
2023-12-01 16:56:55,780:INFO::Validation loss decreased (0.367936 --> 0.366591).  Saving model ...
2023-12-01 16:56:55,933:INFO::Epoch 00148 | lr 0.00050 |Train_Loss 0.1139 | Val_Loss 0.3652 | Time(s) 0.1536
2023-12-01 16:56:55,942:INFO::Validation loss decreased (0.366591 --> 0.365211).  Saving model ...
2023-12-01 16:56:56,118:INFO::Epoch 00149 | lr 0.00050 |Train_Loss 0.1140 | Val_Loss 0.3637 | Time(s) 0.1742
2023-12-01 16:56:56,126:INFO::Validation loss decreased (0.365211 --> 0.363681).  Saving model ...
2023-12-01 16:56:56,295:INFO::Epoch 00150 | lr 0.00050 |Train_Loss 0.1085 | Val_Loss 0.3622 | Time(s) 0.1681
2023-12-01 16:56:56,303:INFO::Validation loss decreased (0.363681 --> 0.362176).  Saving model ...
2023-12-01 16:56:56,464:INFO::Epoch 00151 | lr 0.00050 |Train_Loss 0.1064 | Val_Loss 0.3608 | Time(s) 0.1606
2023-12-01 16:56:56,474:INFO::Validation loss decreased (0.362176 --> 0.360792).  Saving model ...
2023-12-01 16:56:56,633:INFO::Epoch 00152 | lr 0.00050 |Train_Loss 0.1048 | Val_Loss 0.3595 | Time(s) 0.1596
2023-12-01 16:56:56,641:INFO::Validation loss decreased (0.360792 --> 0.359502).  Saving model ...
2023-12-01 16:56:56,819:INFO::Epoch 00153 | lr 0.00050 |Train_Loss 0.1038 | Val_Loss 0.3583 | Time(s) 0.1775
2023-12-01 16:56:56,827:INFO::Validation loss decreased (0.359502 --> 0.358252).  Saving model ...
2023-12-01 16:56:56,986:INFO::Epoch 00154 | lr 0.00050 |Train_Loss 0.1014 | Val_Loss 0.3570 | Time(s) 0.1586
2023-12-01 16:56:56,994:INFO::Validation loss decreased (0.358252 --> 0.356974).  Saving model ...
2023-12-01 16:56:57,153:INFO::Epoch 00155 | lr 0.00050 |Train_Loss 0.1052 | Val_Loss 0.3558 | Time(s) 0.1582
2023-12-01 16:56:57,162:INFO::Validation loss decreased (0.356974 --> 0.355782).  Saving model ...
2023-12-01 16:56:57,337:INFO::Epoch 00156 | lr 0.00050 |Train_Loss 0.0993 | Val_Loss 0.3548 | Time(s) 0.1751
2023-12-01 16:56:57,345:INFO::Validation loss decreased (0.355782 --> 0.354773).  Saving model ...
2023-12-01 16:56:57,513:INFO::Epoch 00157 | lr 0.00050 |Train_Loss 0.1064 | Val_Loss 0.3539 | Time(s) 0.1685
2023-12-01 16:56:57,521:INFO::Validation loss decreased (0.354773 --> 0.353901).  Saving model ...
2023-12-01 16:56:57,698:INFO::Epoch 00158 | lr 0.00050 |Train_Loss 0.1019 | Val_Loss 0.3532 | Time(s) 0.1766
2023-12-01 16:56:57,707:INFO::Validation loss decreased (0.353901 --> 0.353161).  Saving model ...
2023-12-01 16:56:57,871:INFO::Epoch 00159 | lr 0.00050 |Train_Loss 0.0950 | Val_Loss 0.3525 | Time(s) 0.1646
2023-12-01 16:56:57,879:INFO::Validation loss decreased (0.353161 --> 0.352478).  Saving model ...
2023-12-01 16:56:58,051:INFO::Epoch 00160 | lr 0.00050 |Train_Loss 0.0906 | Val_Loss 0.3518 | Time(s) 0.1706
2023-12-01 16:56:58,061:INFO::Validation loss decreased (0.352478 --> 0.351824).  Saving model ...
2023-12-01 16:56:58,227:INFO::Epoch 00161 | lr 0.00050 |Train_Loss 0.0893 | Val_Loss 0.3513 | Time(s) 0.1661
2023-12-01 16:56:58,237:INFO::Validation loss decreased (0.351824 --> 0.351279).  Saving model ...
2023-12-01 16:56:58,414:INFO::Epoch 00162 | lr 0.00050 |Train_Loss 0.0910 | Val_Loss 0.3508 | Time(s) 0.1751
2023-12-01 16:56:58,424:INFO::Validation loss decreased (0.351279 --> 0.350831).  Saving model ...
2023-12-01 16:56:58,593:INFO::Epoch 00163 | lr 0.00050 |Train_Loss 0.0898 | Val_Loss 0.3504 | Time(s) 0.1695
2023-12-01 16:56:58,601:INFO::Validation loss decreased (0.350831 --> 0.350361).  Saving model ...
2023-12-01 16:56:58,765:INFO::Epoch 00164 | lr 0.00050 |Train_Loss 0.0883 | Val_Loss 0.3500 | Time(s) 0.1636
2023-12-01 16:56:58,772:INFO::Validation loss decreased (0.350361 --> 0.349980).  Saving model ...
2023-12-01 16:56:58,926:INFO::Epoch 00165 | lr 0.00050 |Train_Loss 0.0857 | Val_Loss 0.3496 | Time(s) 0.1536
2023-12-01 16:56:58,934:INFO::Validation loss decreased (0.349980 --> 0.349570).  Saving model ...
2023-12-01 16:56:59,096:INFO::Epoch 00166 | lr 0.00050 |Train_Loss 0.0882 | Val_Loss 0.3492 | Time(s) 0.1626
2023-12-01 16:56:59,105:INFO::Validation loss decreased (0.349570 --> 0.349231).  Saving model ...
2023-12-01 16:56:59,267:INFO::Epoch 00167 | lr 0.00050 |Train_Loss 0.0788 | Val_Loss 0.3489 | Time(s) 0.1616
2023-12-01 16:56:59,275:INFO::Validation loss decreased (0.349231 --> 0.348902).  Saving model ...
2023-12-01 16:56:59,448:INFO::Epoch 00168 | lr 0.00050 |Train_Loss 0.0839 | Val_Loss 0.3486 | Time(s) 0.1732
2023-12-01 16:56:59,458:INFO::Validation loss decreased (0.348902 --> 0.348551).  Saving model ...
2023-12-01 16:56:59,619:INFO::Epoch 00169 | lr 0.00050 |Train_Loss 0.0822 | Val_Loss 0.3482 | Time(s) 0.1606
2023-12-01 16:56:59,627:INFO::Validation loss decreased (0.348551 --> 0.348158).  Saving model ...
2023-12-01 16:56:59,794:INFO::Epoch 00170 | lr 0.00050 |Train_Loss 0.0770 | Val_Loss 0.3477 | Time(s) 0.1666
2023-12-01 16:56:59,801:INFO::Validation loss decreased (0.348158 --> 0.347697).  Saving model ...
2023-12-01 16:56:59,956:INFO::Epoch 00171 | lr 0.00050 |Train_Loss 0.0768 | Val_Loss 0.3473 | Time(s) 0.1536
2023-12-01 16:56:59,964:INFO::Validation loss decreased (0.347697 --> 0.347267).  Saving model ...
2023-12-01 16:57:00,127:INFO::Epoch 00172 | lr 0.00050 |Train_Loss 0.0758 | Val_Loss 0.3469 | Time(s) 0.1633
2023-12-01 16:57:00,135:INFO::Validation loss decreased (0.347267 --> 0.346861).  Saving model ...
2023-12-01 16:57:00,296:INFO::Epoch 00173 | lr 0.00050 |Train_Loss 0.0753 | Val_Loss 0.3465 | Time(s) 0.1611
2023-12-01 16:57:00,305:INFO::Validation loss decreased (0.346861 --> 0.346474).  Saving model ...
2023-12-01 16:57:00,480:INFO::Epoch 00174 | lr 0.00050 |Train_Loss 0.0740 | Val_Loss 0.3462 | Time(s) 0.1745
2023-12-01 16:57:00,492:INFO::Validation loss decreased (0.346474 --> 0.346152).  Saving model ...
2023-12-01 16:57:00,651:INFO::Epoch 00175 | lr 0.00050 |Train_Loss 0.0705 | Val_Loss 0.3459 | Time(s) 0.1596
2023-12-01 16:57:00,659:INFO::Validation loss decreased (0.346152 --> 0.345880).  Saving model ...
2023-12-01 16:57:00,821:INFO::Epoch 00176 | lr 0.00050 |Train_Loss 0.0711 | Val_Loss 0.3458 | Time(s) 0.1616
2023-12-01 16:57:00,831:INFO::Validation loss decreased (0.345880 --> 0.345806).  Saving model ...
2023-12-01 16:57:00,985:INFO::Epoch 00177 | lr 0.00050 |Train_Loss 0.0722 | Val_Loss 0.3457 | Time(s) 0.1526
2023-12-01 16:57:00,993:INFO::Validation loss decreased (0.345806 --> 0.345705).  Saving model ...
2023-12-01 16:57:01,164:INFO::Epoch 00178 | lr 0.00050 |Train_Loss 0.0672 | Val_Loss 0.3456 | Time(s) 0.1702
2023-12-01 16:57:01,172:INFO::Validation loss decreased (0.345705 --> 0.345638).  Saving model ...
2023-12-01 16:57:01,329:INFO::Epoch 00179 | lr 0.00050 |Train_Loss 0.0704 | Val_Loss 0.3456 | Time(s) 0.1571
2023-12-01 16:57:01,337:INFO::Validation loss decreased (0.345638 --> 0.345611).  Saving model ...
2023-12-01 16:57:01,513:INFO::Epoch 00180 | lr 0.00050 |Train_Loss 0.0696 | Val_Loss 0.3455 | Time(s) 0.1755
2023-12-01 16:57:01,521:INFO::Validation loss decreased (0.345611 --> 0.345482).  Saving model ...
2023-12-01 16:57:01,679:INFO::Epoch 00181 | lr 0.00050 |Train_Loss 0.0636 | Val_Loss 0.3454 | Time(s) 0.1576
2023-12-01 16:57:01,687:INFO::Validation loss decreased (0.345482 --> 0.345351).  Saving model ...
2023-12-01 16:57:01,848:INFO::Epoch 00182 | lr 0.00050 |Train_Loss 0.0629 | Val_Loss 0.3451 | Time(s) 0.1616
2023-12-01 16:57:01,857:INFO::Validation loss decreased (0.345351 --> 0.345105).  Saving model ...
2023-12-01 16:57:02,018:INFO::Epoch 00183 | lr 0.00050 |Train_Loss 0.0644 | Val_Loss 0.3449 | Time(s) 0.1606
2023-12-01 16:57:02,026:INFO::Validation loss decreased (0.345105 --> 0.344856).  Saving model ...
2023-12-01 16:57:02,186:INFO::Epoch 00184 | lr 0.00050 |Train_Loss 0.0580 | Val_Loss 0.3445 | Time(s) 0.1592
2023-12-01 16:57:02,204:INFO::Validation loss decreased (0.344856 --> 0.344520).  Saving model ...
2023-12-01 16:57:02,376:INFO::Epoch 00185 | lr 0.00050 |Train_Loss 0.0658 | Val_Loss 0.3443 | Time(s) 0.1712
2023-12-01 16:57:02,385:INFO::Validation loss decreased (0.344520 --> 0.344280).  Saving model ...
2023-12-01 16:57:02,551:INFO::Epoch 00186 | lr 0.00050 |Train_Loss 0.0625 | Val_Loss 0.3440 | Time(s) 0.1656
2023-12-01 16:57:02,559:INFO::Validation loss decreased (0.344280 --> 0.343988).  Saving model ...
2023-12-01 16:57:02,721:INFO::Epoch 00187 | lr 0.00050 |Train_Loss 0.0631 | Val_Loss 0.3437 | Time(s) 0.1625
2023-12-01 16:57:02,729:INFO::Validation loss decreased (0.343988 --> 0.343669).  Saving model ...
2023-12-01 16:57:02,899:INFO::Epoch 00188 | lr 0.00050 |Train_Loss 0.0595 | Val_Loss 0.3433 | Time(s) 0.1695
2023-12-01 16:57:02,907:INFO::Validation loss decreased (0.343669 --> 0.343319).  Saving model ...
2023-12-01 16:57:03,071:INFO::Epoch 00189 | lr 0.00050 |Train_Loss 0.0534 | Val_Loss 0.3429 | Time(s) 0.1646
2023-12-01 16:57:03,078:INFO::Validation loss decreased (0.343319 --> 0.342861).  Saving model ...
2023-12-01 16:57:03,235:INFO::Epoch 00190 | lr 0.00050 |Train_Loss 0.0601 | Val_Loss 0.3425 | Time(s) 0.1562
2023-12-01 16:57:03,244:INFO::Validation loss decreased (0.342861 --> 0.342502).  Saving model ...
2023-12-01 16:57:03,414:INFO::Epoch 00191 | lr 0.00050 |Train_Loss 0.0554 | Val_Loss 0.3422 | Time(s) 0.1702
2023-12-01 16:57:03,423:INFO::Validation loss decreased (0.342502 --> 0.342210).  Saving model ...
2023-12-01 16:57:03,593:INFO::Epoch 00192 | lr 0.00050 |Train_Loss 0.0600 | Val_Loss 0.3420 | Time(s) 0.1701
2023-12-01 16:57:03,603:INFO::Validation loss decreased (0.342210 --> 0.341972).  Saving model ...
2023-12-01 16:57:03,792:INFO::Epoch 00193 | lr 0.00050 |Train_Loss 0.0556 | Val_Loss 0.3419 | Time(s) 0.1879
2023-12-01 16:57:03,800:INFO::Validation loss decreased (0.341972 --> 0.341869).  Saving model ...
2023-12-01 16:57:03,975:INFO::Epoch 00194 | lr 0.00050 |Train_Loss 0.0558 | Val_Loss 0.3418 | Time(s) 0.1725
2023-12-01 16:57:03,983:INFO::Validation loss decreased (0.341869 --> 0.341797).  Saving model ...
2023-12-01 16:57:04,142:INFO::Epoch 00195 | lr 0.00050 |Train_Loss 0.0547 | Val_Loss 0.3417 | Time(s) 0.1596
2023-12-01 16:57:04,151:INFO::Validation loss decreased (0.341797 --> 0.341710).  Saving model ...
2023-12-01 16:57:04,305:INFO::Epoch 00196 | lr 0.00050 |Train_Loss 0.0551 | Val_Loss 0.3417 | Time(s) 0.1536
2023-12-01 16:57:04,313:INFO::Validation loss decreased (0.341710 --> 0.341671).  Saving model ...
2023-12-01 16:57:04,478:INFO::Epoch 00197 | lr 0.00050 |Train_Loss 0.0516 | Val_Loss 0.3415 | Time(s) 0.1636
2023-12-01 16:57:04,485:INFO::Validation loss decreased (0.341671 --> 0.341530).  Saving model ...
2023-12-01 16:57:04,640:INFO::Epoch 00198 | lr 0.00050 |Train_Loss 0.0522 | Val_Loss 0.3414 | Time(s) 0.1546
2023-12-01 16:57:04,648:INFO::Validation loss decreased (0.341530 --> 0.341409).  Saving model ...
2023-12-01 16:57:04,805:INFO::Epoch 00199 | lr 0.00050 |Train_Loss 0.0507 | Val_Loss 0.3415 | Time(s) 0.1556
2023-12-01 16:57:04,806:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:57:04,969:INFO::Epoch 00200 | lr 0.00050 |Train_Loss 0.0494 | Val_Loss 0.3415 | Time(s) 0.1626
2023-12-01 16:57:04,970:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:57:05,143:INFO::Epoch 00201 | lr 0.00050 |Train_Loss 0.0507 | Val_Loss 0.3413 | Time(s) 0.1715
2023-12-01 16:57:05,152:INFO::Validation loss decreased (0.341409 --> 0.341276).  Saving model ...
2023-12-01 16:57:05,323:INFO::Epoch 00202 | lr 0.00050 |Train_Loss 0.0534 | Val_Loss 0.3411 | Time(s) 0.1705
2023-12-01 16:57:05,331:INFO::Validation loss decreased (0.341276 --> 0.341052).  Saving model ...
2023-12-01 16:57:05,498:INFO::Epoch 00203 | lr 0.00050 |Train_Loss 0.0493 | Val_Loss 0.3409 | Time(s) 0.1656
2023-12-01 16:57:05,507:INFO::Validation loss decreased (0.341052 --> 0.340917).  Saving model ...
2023-12-01 16:57:05,661:INFO::Epoch 00204 | lr 0.00050 |Train_Loss 0.0502 | Val_Loss 0.3409 | Time(s) 0.1546
2023-12-01 16:57:05,662:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:57:05,819:INFO::Epoch 00205 | lr 0.00050 |Train_Loss 0.0500 | Val_Loss 0.3410 | Time(s) 0.1566
2023-12-01 16:57:05,820:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:57:05,977:INFO::Epoch 00206 | lr 0.00050 |Train_Loss 0.0491 | Val_Loss 0.3411 | Time(s) 0.1566
2023-12-01 16:57:05,977:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:57:06,136:INFO::Epoch 00207 | lr 0.00050 |Train_Loss 0.0469 | Val_Loss 0.3412 | Time(s) 0.1586
2023-12-01 16:57:06,137:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 16:57:06,307:INFO::Epoch 00208 | lr 0.00050 |Train_Loss 0.0487 | Val_Loss 0.3414 | Time(s) 0.1695
2023-12-01 16:57:06,308:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 16:57:06,473:INFO::Epoch 00209 | lr 0.00050 |Train_Loss 0.0447 | Val_Loss 0.3416 | Time(s) 0.1656
2023-12-01 16:57:06,474:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 16:57:06,640:INFO::Epoch 00210 | lr 0.00050 |Train_Loss 0.0455 | Val_Loss 0.3419 | Time(s) 0.1656
2023-12-01 16:57:06,641:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 16:57:06,803:INFO::Epoch 00211 | lr 0.00050 |Train_Loss 0.0461 | Val_Loss 0.3421 | Time(s) 0.1626
2023-12-01 16:57:06,804:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 16:57:06,804:INFO::Eearly stopping!
2023-12-01 16:57:06,804:INFO::
testing...
2023-12-01 16:57:06,875:INFO::submit dir: submit/submit_gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:07,040:INFO::{'micro-f1': 0.8908450704225352, 'macro-f1': 0.8834490070607068}
2023-12-01 16:57:07,164:INFO::############### Retrain Stage Ends! #################
2023-12-01 16:57:07,235:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gcn', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-16-46-32', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=1024, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=3, last_hidden_dim=64, logger=<Logger log_output (INFO)>)
2023-12-01 16:57:24,007:INFO::node_type_num: 4
2023-12-01 16:57:24,724:INFO::=============== Prepare basic data stage finish, use 17.489269733428955 time.
2023-12-01 16:57:24,880:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:32,140:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:32,214:INFO::its now!!!!!!!!5
2023-12-01 16:57:32,605:INFO::its now!!!!!!!!0
2023-12-01 16:57:32,606:INFO::its now!!!!!!!!3
2023-12-01 16:57:32,665:INFO::its now!!!!!!!!5
2023-12-01 16:57:32,923:INFO::its now!!!!!!!!
2023-12-01 16:57:32,923:INFO::its now!!!!!!!! on 
2023-12-01 16:57:33,018:INFO::its now!!!!!!!!5
2023-12-01 16:57:33,161:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:33,165:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.3602 | Train_Classification_Loss 1.3905 | Dmon_Loss -0.0607 | Val_Loss 1.3888 | Search Time(s) 0.9786 | Infer Time(s) 0.1581 | Time(s) 1.1367 
2023-12-01 16:57:33,228:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 0;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 0;	26114: 0;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 3;	26121: 0;	26122: 0;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:57:33,231:INFO::Epoch: 1
tensor([[0.4950, 0.5050, 0.5050, 0.5050],
        [0.5050, 0.5050, 0.5050, 0.5050],
        [0.4950, 0.5050, 0.5050, 0.5050],
        [0.5050, 0.5050, 0.5050, 0.5050]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:33,231:INFO::its now!!!!!!!!5
2023-12-01 16:57:33,379:INFO::its now!!!!!!!!0
2023-12-01 16:57:33,380:INFO::its now!!!!!!!!3
2023-12-01 16:57:33,426:INFO::its now!!!!!!!!5
2023-12-01 16:57:33,597:INFO::its now!!!!!!!!
2023-12-01 16:57:33,598:INFO::its now!!!!!!!! on 
2023-12-01 16:57:33,648:INFO::its now!!!!!!!!5
2023-12-01 16:57:33,810:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:33,812:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3548 | Train_Classification_Loss 1.3853 | Dmon_Loss -0.0610 | Val_Loss 1.3855 | Search Time(s) 0.3995 | Infer Time(s) 0.1815 | Time(s) 0.5810 
2023-12-01 16:57:33,850:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 0;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 0;	26109: 0;	26110: 3;	26111: 3;	26112: 0;	26113: 3;	26114: 0;	26115: 0;	26116: 0;	26117: 0;	26118: 0;	26119: 0;	26120: 0;	26121: 0;	26122: 3;	26123: 0;	26124: 0;	26125: 0;	26126: 0;	26127: 3;	
2023-12-01 16:57:33,851:INFO::Validation loss decreased (inf --> 1.385467).  Saving model ...
2023-12-01 16:57:33,854:INFO::Epoch: 2
tensor([[0.4903, 0.5081, 0.5053, 0.5053],
        [0.5003, 0.5073, 0.5053, 0.5053],
        [0.4902, 0.5074, 0.5053, 0.5053],
        [0.5003, 0.5078, 0.5053, 0.5053]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:33,854:INFO::its now!!!!!!!!5
2023-12-01 16:57:34,030:INFO::its now!!!!!!!!0
2023-12-01 16:57:34,031:INFO::its now!!!!!!!!3
2023-12-01 16:57:34,077:INFO::its now!!!!!!!!5
2023-12-01 16:57:34,253:INFO::its now!!!!!!!!
2023-12-01 16:57:34,253:INFO::its now!!!!!!!! on 
2023-12-01 16:57:34,289:INFO::its now!!!!!!!!5
2023-12-01 16:57:34,457:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:34,458:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3547 | Train_Classification_Loss 1.3861 | Dmon_Loss -0.0628 | Val_Loss 1.3846 | Search Time(s) 0.4324 | Infer Time(s) 0.1741 | Time(s) 0.6065 
2023-12-01 16:57:34,515:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 3;	5: 3;	6: 1;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:34,517:INFO::Validation loss decreased (1.385467 --> 1.384645).  Saving model ...
2023-12-01 16:57:34,519:INFO::Epoch: 3
tensor([[0.4949, 0.5100, 0.5101, 0.5101],
        [0.5049, 0.5085, 0.5101, 0.5101],
        [0.4948, 0.5086, 0.5101, 0.5101],
        [0.5049, 0.5098, 0.5101, 0.5101]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:34,520:INFO::its now!!!!!!!!5
2023-12-01 16:57:34,678:INFO::its now!!!!!!!!0
2023-12-01 16:57:34,679:INFO::its now!!!!!!!!3
2023-12-01 16:57:34,708:INFO::its now!!!!!!!!5
2023-12-01 16:57:34,889:INFO::its now!!!!!!!!
2023-12-01 16:57:34,889:INFO::its now!!!!!!!! on 
2023-12-01 16:57:34,974:INFO::its now!!!!!!!!5
2023-12-01 16:57:35,123:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:35,125:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3504 | Train_Classification_Loss 1.3819 | Dmon_Loss -0.0630 | Val_Loss 1.3811 | Search Time(s) 0.4558 | Infer Time(s) 0.1503 | Time(s) 0.6061 
2023-12-01 16:57:35,178:INFO::cluster info:
0: 1;	1: 1;	2: 3;	3: 1;	4: 3;	5: 3;	6: 1;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 1;	13: 3;	14: 1;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 1;	23: 3;	24: 3;	25: 3;	26: 1;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 3;	26110: 1;	26111: 1;	26112: 1;	26113: 3;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:35,179:INFO::Validation loss decreased (1.384645 --> 1.381088).  Saving model ...
2023-12-01 16:57:35,181:INFO::Epoch: 4
tensor([[0.5003, 0.5154, 0.5127, 0.5155],
        [0.5103, 0.5137, 0.5127, 0.5155],
        [0.5002, 0.5139, 0.5127, 0.5155],
        [0.5103, 0.5153, 0.5128, 0.5155]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:35,182:INFO::its now!!!!!!!!5
2023-12-01 16:57:35,352:INFO::its now!!!!!!!!0
2023-12-01 16:57:35,353:INFO::its now!!!!!!!!3
2023-12-01 16:57:35,376:INFO::its now!!!!!!!!5
2023-12-01 16:57:35,565:INFO::its now!!!!!!!!
2023-12-01 16:57:35,565:INFO::its now!!!!!!!! on 
2023-12-01 16:57:35,596:INFO::its now!!!!!!!!5
2023-12-01 16:57:35,743:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:35,744:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3452 | Train_Classification_Loss 1.3768 | Dmon_Loss -0.0630 | Val_Loss 1.3780 | Search Time(s) 0.4115 | Infer Time(s) 0.1516 | Time(s) 0.5631 
2023-12-01 16:57:35,802:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 1;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 1;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 1;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 1;	40: 3;	41: 3;	42: 1;	43: 3;	44
26098: 3;	26099: 1;	26100: 3;	26101: 3;	26102: 1;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 3;	26113: 3;	26114: 1;	26115: 1;	26116: 1;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 3;	26127: 1;	
2023-12-01 16:57:35,803:INFO::Validation loss decreased (1.381088 --> 1.377992).  Saving model ...
2023-12-01 16:57:35,806:INFO::Epoch: 5
tensor([[0.5033, 0.5183, 0.5141, 0.5185],
        [0.5133, 0.5166, 0.5141, 0.5185],
        [0.5032, 0.5168, 0.5141, 0.5185],
        [0.5133, 0.5182, 0.5143, 0.5185]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:35,807:INFO::its now!!!!!!!!5
2023-12-01 16:57:35,977:INFO::its now!!!!!!!!0
2023-12-01 16:57:35,978:INFO::its now!!!!!!!!3
2023-12-01 16:57:36,003:INFO::its now!!!!!!!!5
2023-12-01 16:57:36,219:INFO::its now!!!!!!!!
2023-12-01 16:57:36,219:INFO::its now!!!!!!!! on 
2023-12-01 16:57:36,269:INFO::its now!!!!!!!!5
2023-12-01 16:57:36,444:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:36,453:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3378 | Train_Classification_Loss 1.3688 | Dmon_Loss -0.0621 | Val_Loss 1.3738 | Search Time(s) 0.4503 | Infer Time(s) 0.1911 | Time(s) 0.6414 
2023-12-01 16:57:36,508:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 1;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:36,509:INFO::Validation loss decreased (1.377992 --> 1.373762).  Saving model ...
2023-12-01 16:57:36,511:INFO::Epoch: 6
tensor([[0.5080, 0.5237, 0.5187, 0.5201],
        [0.5180, 0.5220, 0.5187, 0.5200],
        [0.5079, 0.5221, 0.5187, 0.5201],
        [0.5180, 0.5236, 0.5189, 0.5201]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:36,511:INFO::its now!!!!!!!!5
2023-12-01 16:57:36,680:INFO::its now!!!!!!!!0
2023-12-01 16:57:36,681:INFO::its now!!!!!!!!3
2023-12-01 16:57:36,727:INFO::its now!!!!!!!!5
2023-12-01 16:57:36,896:INFO::its now!!!!!!!!
2023-12-01 16:57:36,896:INFO::its now!!!!!!!! on 
2023-12-01 16:57:36,950:INFO::its now!!!!!!!!5
2023-12-01 16:57:37,123:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:37,125:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.3335 | Train_Classification_Loss 1.3647 | Dmon_Loss -0.0623 | Val_Loss 1.3711 | Search Time(s) 0.4249 | Infer Time(s) 0.1891 | Time(s) 0.6139 
2023-12-01 16:57:37,175:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:37,176:INFO::Validation loss decreased (1.373762 --> 1.371074).  Saving model ...
2023-12-01 16:57:37,179:INFO::Epoch: 7
tensor([[0.5110, 0.5266, 0.5217, 0.5214],
        [0.5210, 0.5249, 0.5217, 0.5213],
        [0.5109, 0.5250, 0.5217, 0.5214],
        [0.5210, 0.5267, 0.5219, 0.5215]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:37,180:INFO::its now!!!!!!!!5
2023-12-01 16:57:37,360:INFO::its now!!!!!!!!0
2023-12-01 16:57:37,361:INFO::its now!!!!!!!!3
2023-12-01 16:57:37,409:INFO::its now!!!!!!!!5
2023-12-01 16:57:37,560:INFO::its now!!!!!!!!
2023-12-01 16:57:37,560:INFO::its now!!!!!!!! on 
2023-12-01 16:57:37,600:INFO::its now!!!!!!!!5
2023-12-01 16:57:37,769:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:37,770:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.3320 | Train_Classification_Loss 1.3637 | Dmon_Loss -0.0633 | Val_Loss 1.3696 | Search Time(s) 0.4115 | Infer Time(s) 0.1805 | Time(s) 0.5920 
2023-12-01 16:57:37,829:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:37,831:INFO::Validation loss decreased (1.371074 --> 1.369609).  Saving model ...
2023-12-01 16:57:37,833:INFO::Epoch: 8
tensor([[0.5172, 0.5281, 0.5282, 0.5274],
        [0.5272, 0.5264, 0.5282, 0.5272],
        [0.5171, 0.5266, 0.5282, 0.5274],
        [0.5272, 0.5282, 0.5284, 0.5275]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:37,834:INFO::its now!!!!!!!!5
2023-12-01 16:57:38,014:INFO::its now!!!!!!!!0
2023-12-01 16:57:38,015:INFO::its now!!!!!!!!3
2023-12-01 16:57:38,044:INFO::its now!!!!!!!!5
2023-12-01 16:57:38,221:INFO::its now!!!!!!!!
2023-12-01 16:57:38,222:INFO::its now!!!!!!!! on 
2023-12-01 16:57:38,280:INFO::its now!!!!!!!!5
2023-12-01 16:57:38,439:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:38,441:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.3279 | Train_Classification_Loss 1.3592 | Dmon_Loss -0.0627 | Val_Loss 1.3658 | Search Time(s) 0.4454 | Infer Time(s) 0.1631 | Time(s) 0.6085 
2023-12-01 16:57:38,483:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:38,484:INFO::Validation loss decreased (1.369609 --> 1.365761).  Saving model ...
2023-12-01 16:57:38,487:INFO::Epoch: 9
tensor([[0.5234, 0.5337, 0.5316, 0.5336],
        [0.5335, 0.5319, 0.5316, 0.5335],
        [0.5233, 0.5321, 0.5317, 0.5336],
        [0.5335, 0.5338, 0.5319, 0.5337]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:38,487:INFO::its now!!!!!!!!5
2023-12-01 16:57:38,630:INFO::its now!!!!!!!!0
2023-12-01 16:57:38,630:INFO::its now!!!!!!!!3
2023-12-01 16:57:38,673:INFO::its now!!!!!!!!5
2023-12-01 16:57:38,860:INFO::its now!!!!!!!!
2023-12-01 16:57:38,860:INFO::its now!!!!!!!! on 
2023-12-01 16:57:38,914:INFO::its now!!!!!!!!5
2023-12-01 16:57:39,060:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:39,061:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.3245 | Train_Classification_Loss 1.3561 | Dmon_Loss -0.0633 | Val_Loss 1.3638 | Search Time(s) 0.4259 | Infer Time(s) 0.1486 | Time(s) 0.5745 
2023-12-01 16:57:39,103:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 1;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 1;	28: 3;	29: 1;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 1;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 1;	26111: 1;	26112: 1;	26113: 3;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 1;	26121: 3;	26122: 1;	26123: 1;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:39,104:INFO::Validation loss decreased (1.365761 --> 1.363844).  Saving model ...
2023-12-01 16:57:39,107:INFO::Epoch: 10
tensor([[0.5286, 0.5366, 0.5358, 0.5389],
        [0.5387, 0.5375, 0.5356, 0.5368],
        [0.5285, 0.5377, 0.5358, 0.5369],
        [0.5387, 0.5369, 0.5360, 0.5390]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:39,108:INFO::its now!!!!!!!!5
2023-12-01 16:57:39,274:INFO::its now!!!!!!!!0
2023-12-01 16:57:39,275:INFO::its now!!!!!!!!3
2023-12-01 16:57:39,317:INFO::its now!!!!!!!!5
2023-12-01 16:57:39,496:INFO::its now!!!!!!!!
2023-12-01 16:57:39,496:INFO::its now!!!!!!!! on 
2023-12-01 16:57:39,548:INFO::its now!!!!!!!!5
2023-12-01 16:57:39,701:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:39,703:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.3221 | Train_Classification_Loss 1.3535 | Dmon_Loss -0.0629 | Val_Loss 1.3616 | Search Time(s) 0.4394 | Infer Time(s) 0.1566 | Time(s) 0.5960 
2023-12-01 16:57:39,753:INFO::cluster info:
0: 3;	1: 1;	2: 3;	3: 1;	4: 3;	5: 1;	6: 3;	7: 1;	8: 3;	9: 3;	10: 1;	11: 3;	12: 1;	13: 1;	14: 1;	15: 3;	16: 1;	17: 3;	18: 3;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 3;	25: 3;	26: 1;	27: 3;	28: 1;	29: 1;	30: 1;	31: 3;	32: 1;	33: 3;	34: 1;	35: 3;	36: 1;	37: 3;	38: 1;	39: 3;	40: 3;	41: 3;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 1;	
2023-12-01 16:57:39,755:INFO::Validation loss decreased (1.363844 --> 1.361582).  Saving model ...
2023-12-01 16:57:39,759:INFO::Epoch: 11
tensor([[0.5358, 0.5439, 0.5429, 0.5417],
        [0.5414, 0.5456, 0.5427, 0.5434],
        [0.5357, 0.5407, 0.5429, 0.5435],
        [0.5458, 0.5442, 0.5432, 0.5419]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:39,760:INFO::its now!!!!!!!!5
2023-12-01 16:57:39,927:INFO::its now!!!!!!!!0
2023-12-01 16:57:39,928:INFO::its now!!!!!!!!3
2023-12-01 16:57:39,971:INFO::its now!!!!!!!!5
2023-12-01 16:57:40,147:INFO::its now!!!!!!!!
2023-12-01 16:57:40,147:INFO::its now!!!!!!!! on 
2023-12-01 16:57:40,197:INFO::its now!!!!!!!!5
2023-12-01 16:57:40,367:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:40,369:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.3159 | Train_Classification_Loss 1.3474 | Dmon_Loss -0.0631 | Val_Loss 1.3581 | Search Time(s) 0.4235 | Infer Time(s) 0.1880 | Time(s) 0.6115 
2023-12-01 16:57:40,417:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:40,418:INFO::Validation loss decreased (1.361582 --> 1.358136).  Saving model ...
2023-12-01 16:57:40,422:INFO::Epoch: 12
tensor([[0.5406, 0.5477, 0.5478, 0.5446],
        [0.5443, 0.5499, 0.5476, 0.5480],
        [0.5405, 0.5442, 0.5478, 0.5470],
        [0.5496, 0.5494, 0.5481, 0.5448]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:40,423:INFO::its now!!!!!!!!5
2023-12-01 16:57:40,611:INFO::its now!!!!!!!!0
2023-12-01 16:57:40,612:INFO::its now!!!!!!!!3
2023-12-01 16:57:40,659:INFO::its now!!!!!!!!5
2023-12-01 16:57:40,859:INFO::its now!!!!!!!!
2023-12-01 16:57:40,859:INFO::its now!!!!!!!! on 
2023-12-01 16:57:40,913:INFO::its now!!!!!!!!5
2023-12-01 16:57:41,113:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:41,115:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.3136 | Train_Classification_Loss 1.3452 | Dmon_Loss -0.0634 | Val_Loss 1.3561 | Search Time(s) 0.4777 | Infer Time(s) 0.2170 | Time(s) 0.6947 
2023-12-01 16:57:41,152:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:41,154:INFO::Validation loss decreased (1.358136 --> 1.356078).  Saving model ...
2023-12-01 16:57:41,158:INFO::Epoch: 13
tensor([[0.5444, 0.5512, 0.5504, 0.5477],
        [0.5472, 0.5521, 0.5515, 0.5517],
        [0.5443, 0.5481, 0.5504, 0.5500],
        [0.5516, 0.5536, 0.5520, 0.5479]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:41,158:INFO::its now!!!!!!!!5
2023-12-01 16:57:41,324:INFO::its now!!!!!!!!0
2023-12-01 16:57:41,325:INFO::its now!!!!!!!!3
2023-12-01 16:57:41,371:INFO::its now!!!!!!!!5
2023-12-01 16:57:41,586:INFO::its now!!!!!!!!
2023-12-01 16:57:41,586:INFO::its now!!!!!!!! on 
2023-12-01 16:57:41,642:INFO::its now!!!!!!!!5
2023-12-01 16:57:41,822:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:41,823:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.3089 | Train_Classification_Loss 1.3408 | Dmon_Loss -0.0637 | Val_Loss 1.3537 | Search Time(s) 0.4873 | Infer Time(s) 0.1805 | Time(s) 0.6678 
2023-12-01 16:57:41,881:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:41,882:INFO::Validation loss decreased (1.356078 --> 1.353662).  Saving model ...
2023-12-01 16:57:41,884:INFO::Epoch: 14
tensor([[0.5474, 0.5530, 0.5530, 0.5508],
        [0.5502, 0.5532, 0.5548, 0.5548],
        [0.5473, 0.5521, 0.5517, 0.5529],
        [0.5537, 0.5558, 0.5553, 0.5510]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:41,885:INFO::its now!!!!!!!!5
2023-12-01 16:57:42,038:INFO::its now!!!!!!!!0
2023-12-01 16:57:42,038:INFO::its now!!!!!!!!3
2023-12-01 16:57:42,085:INFO::its now!!!!!!!!5
2023-12-01 16:57:42,241:INFO::its now!!!!!!!!
2023-12-01 16:57:42,241:INFO::its now!!!!!!!! on 
2023-12-01 16:57:42,299:INFO::its now!!!!!!!!5
2023-12-01 16:57:42,453:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:42,455:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.3078 | Train_Classification_Loss 1.3397 | Dmon_Loss -0.0638 | Val_Loss 1.3508 | Search Time(s) 0.4151 | Infer Time(s) 0.1566 | Time(s) 0.5717 
2023-12-01 16:57:42,512:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:42,513:INFO::Validation loss decreased (1.353662 --> 1.350789).  Saving model ...
2023-12-01 16:57:42,515:INFO::Epoch: 15
tensor([[0.5545, 0.5540, 0.5602, 0.5587],
        [0.5579, 0.5602, 0.5565, 0.5621],
        [0.5544, 0.5610, 0.5585, 0.5543],
        [0.5605, 0.5569, 0.5628, 0.5589]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:42,515:INFO::its now!!!!!!!!5
2023-12-01 16:57:42,669:INFO::its now!!!!!!!!0
2023-12-01 16:57:42,670:INFO::its now!!!!!!!!3
2023-12-01 16:57:42,714:INFO::its now!!!!!!!!5
2023-12-01 16:57:42,884:INFO::its now!!!!!!!!
2023-12-01 16:57:42,884:INFO::its now!!!!!!!! on 
2023-12-01 16:57:42,943:INFO::its now!!!!!!!!5
2023-12-01 16:57:43,100:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:43,101:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.3018 | Train_Classification_Loss 1.3332 | Dmon_Loss -0.0627 | Val_Loss 1.3471 | Search Time(s) 0.4268 | Infer Time(s) 0.1601 | Time(s) 0.5870 
2023-12-01 16:57:43,151:INFO::cluster info:
0: 3;	1: 1;	2: 3;	3: 1;	4: 1;	5: 1;	6: 3;	7: 1;	8: 3;	9: 1;	10: 3;	11: 3;	12: 3;	13: 1;	14: 1;	15: 3;	16: 1;	17: 3;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 1;	25: 1;	26: 1;	27: 1;	28: 1;	29: 1;	30: 1;	31: 3;	32: 1;	33: 3;	34: 1;	35: 1;	36: 1;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 1;	43: 3;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 1;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 16:57:43,152:INFO::Validation loss decreased (1.350789 --> 1.347115).  Saving model ...
2023-12-01 16:57:43,154:INFO::Epoch: 16
tensor([[0.5627, 0.5611, 0.5640, 0.5676],
        [0.5667, 0.5687, 0.5634, 0.5658],
        [0.5625, 0.5656, 0.5666, 0.5610],
        [0.5685, 0.5640, 0.5666, 0.5678]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:43,155:INFO::its now!!!!!!!!5
2023-12-01 16:57:43,322:INFO::its now!!!!!!!!0
2023-12-01 16:57:43,323:INFO::its now!!!!!!!!3
2023-12-01 16:57:43,368:INFO::its now!!!!!!!!5
2023-12-01 16:57:43,524:INFO::its now!!!!!!!!
2023-12-01 16:57:43,525:INFO::its now!!!!!!!! on 
2023-12-01 16:57:43,575:INFO::its now!!!!!!!!5
2023-12-01 16:57:43,730:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:43,732:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 1.2976 | Train_Classification_Loss 1.3297 | Dmon_Loss -0.0641 | Val_Loss 1.3463 | Search Time(s) 0.4204 | Infer Time(s) 0.1576 | Time(s) 0.5780 
2023-12-01 16:57:43,771:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:43,772:INFO::Validation loss decreased (1.347115 --> 1.346292).  Saving model ...
2023-12-01 16:57:43,775:INFO::Epoch: 17
tensor([[0.5679, 0.5661, 0.5672, 0.5722],
        [0.5723, 0.5730, 0.5682, 0.5691],
        [0.5678, 0.5696, 0.5709, 0.5657],
        [0.5727, 0.5691, 0.5699, 0.5736]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:43,776:INFO::its now!!!!!!!!5
2023-12-01 16:57:43,965:INFO::its now!!!!!!!!0
2023-12-01 16:57:43,965:INFO::its now!!!!!!!!3
2023-12-01 16:57:44,008:INFO::its now!!!!!!!!5
2023-12-01 16:57:44,161:INFO::its now!!!!!!!!
2023-12-01 16:57:44,161:INFO::its now!!!!!!!! on 
2023-12-01 16:57:44,212:INFO::its now!!!!!!!!5
2023-12-01 16:57:44,385:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:44,387:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 1.2959 | Train_Classification_Loss 1.3274 | Dmon_Loss -0.0630 | Val_Loss 1.3412 | Search Time(s) 0.4394 | Infer Time(s) 0.1741 | Time(s) 0.6135 
2023-12-01 16:57:44,448:INFO::cluster info:
0: 1;	1: 1;	2: 1;	3: 1;	4: 3;	5: 1;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 1;	13: 1;	14: 1;	15: 3;	16: 1;	17: 3;	18: 1;	19: 1;	20: 3;	21: 3;	22: 1;	23: 1;	24: 3;	25: 1;	26: 3;	27: 3;	28: 3;	29: 3;	30: 1;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 1;	37: 3;	38: 3;	39: 1;	40: 1;	41: 1;	42: 1;	43: 1;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 16:57:44,449:INFO::Validation loss decreased (1.346292 --> 1.341207).  Saving model ...
2023-12-01 16:57:44,451:INFO::Epoch: 18
tensor([[0.5735, 0.5725, 0.5724, 0.5745],
        [0.5783, 0.5752, 0.5742, 0.5741],
        [0.5734, 0.5757, 0.5730, 0.5715],
        [0.5777, 0.5754, 0.5750, 0.5765]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:44,452:INFO::its now!!!!!!!!5
2023-12-01 16:57:44,607:INFO::its now!!!!!!!!0
2023-12-01 16:57:44,608:INFO::its now!!!!!!!!3
2023-12-01 16:57:44,652:INFO::its now!!!!!!!!5
2023-12-01 16:57:44,814:INFO::its now!!!!!!!!
2023-12-01 16:57:44,814:INFO::its now!!!!!!!! on 
2023-12-01 16:57:44,865:INFO::its now!!!!!!!!5
2023-12-01 16:57:45,005:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:45,006:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 1.2924 | Train_Classification_Loss 1.3245 | Dmon_Loss -0.0642 | Val_Loss 1.3392 | Search Time(s) 0.3939 | Infer Time(s) 0.1616 | Time(s) 0.5555 
2023-12-01 16:57:45,054:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:45,055:INFO::Validation loss decreased (1.341207 --> 1.339219).  Saving model ...
2023-12-01 16:57:45,058:INFO::Epoch: 19
tensor([[0.5800, 0.5802, 0.5793, 0.5757],
        [0.5815, 0.5806, 0.5815, 0.5808],
        [0.5799, 0.5789, 0.5782, 0.5787],
        [0.5804, 0.5831, 0.5819, 0.5822]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:45,059:INFO::its now!!!!!!!!5
2023-12-01 16:57:45,203:INFO::its now!!!!!!!!0
2023-12-01 16:57:45,204:INFO::its now!!!!!!!!3
2023-12-01 16:57:45,249:INFO::its now!!!!!!!!5
2023-12-01 16:57:45,423:INFO::its now!!!!!!!!
2023-12-01 16:57:45,423:INFO::its now!!!!!!!! on 
2023-12-01 16:57:45,461:INFO::its now!!!!!!!!5
2023-12-01 16:57:45,617:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:45,618:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 1.2851 | Train_Classification_Loss 1.3173 | Dmon_Loss -0.0644 | Val_Loss 1.3365 | Search Time(s) 0.4031 | Infer Time(s) 0.1596 | Time(s) 0.5627 
2023-12-01 16:57:45,669:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:45,670:INFO::Validation loss decreased (1.339219 --> 1.336478).  Saving model ...
2023-12-01 16:57:45,672:INFO::Epoch: 20
tensor([[0.5873, 0.5842, 0.5873, 0.5814],
        [0.5878, 0.5878, 0.5852, 0.5887],
        [0.5832, 0.5862, 0.5852, 0.5869],
        [0.5862, 0.5868, 0.5899, 0.5896]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:45,673:INFO::its now!!!!!!!!5
2023-12-01 16:57:45,836:INFO::its now!!!!!!!!0
2023-12-01 16:57:45,837:INFO::its now!!!!!!!!3
2023-12-01 16:57:45,866:INFO::its now!!!!!!!!5
2023-12-01 16:57:46,033:INFO::its now!!!!!!!!
2023-12-01 16:57:46,033:INFO::its now!!!!!!!! on 
2023-12-01 16:57:46,088:INFO::its now!!!!!!!!5
2023-12-01 16:57:46,246:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:46,248:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 1.2812 | Train_Classification_Loss 1.3131 | Dmon_Loss -0.0639 | Val_Loss 1.3339 | Search Time(s) 0.4139 | Infer Time(s) 0.1624 | Time(s) 0.5763 
2023-12-01 16:57:46,303:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 1;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:46,304:INFO::Validation loss decreased (1.336478 --> 1.333943).  Saving model ...
2023-12-01 16:57:46,307:INFO::Epoch: 21
tensor([[0.5911, 0.5937, 0.5977, 0.5911],
        [0.5975, 0.5979, 0.5944, 0.5928],
        [0.5916, 0.5970, 0.5951, 0.5911],
        [0.5956, 0.5962, 0.5940, 0.5998]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:46,307:INFO::its now!!!!!!!!5
2023-12-01 16:57:46,484:INFO::its now!!!!!!!!0
2023-12-01 16:57:46,485:INFO::its now!!!!!!!!3
2023-12-01 16:57:46,528:INFO::its now!!!!!!!!5
2023-12-01 16:57:46,693:INFO::its now!!!!!!!!
2023-12-01 16:57:46,693:INFO::its now!!!!!!!! on 
2023-12-01 16:57:46,747:INFO::its now!!!!!!!!5
2023-12-01 16:57:46,958:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:46,959:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 1.2790 | Train_Classification_Loss 1.3110 | Dmon_Loss -0.0640 | Val_Loss 1.3307 | Search Time(s) 0.4398 | Infer Time(s) 0.2144 | Time(s) 0.6542 
2023-12-01 16:57:47,028:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 1;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:47,029:INFO::Validation loss decreased (1.333943 --> 1.330689).  Saving model ...
2023-12-01 16:57:47,032:INFO::Epoch: 22
tensor([[0.5953, 0.6007, 0.6031, 0.5981],
        [0.6044, 0.6030, 0.6012, 0.5974],
        [0.5979, 0.6025, 0.6021, 0.5958],
        [0.6023, 0.6031, 0.5987, 0.6050]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:47,033:INFO::its now!!!!!!!!5
2023-12-01 16:57:47,244:INFO::its now!!!!!!!!0
2023-12-01 16:57:47,245:INFO::its now!!!!!!!!3
2023-12-01 16:57:47,289:INFO::its now!!!!!!!!5
2023-12-01 16:57:47,470:INFO::its now!!!!!!!!
2023-12-01 16:57:47,470:INFO::its now!!!!!!!! on 
2023-12-01 16:57:47,520:INFO::its now!!!!!!!!5
2023-12-01 16:57:47,683:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:47,685:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 1.2802 | Train_Classification_Loss 1.3127 | Dmon_Loss -0.0650 | Val_Loss 1.3300 | Search Time(s) 0.4689 | Infer Time(s) 0.1845 | Time(s) 0.6534 
2023-12-01 16:57:47,729:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:47,731:INFO::Validation loss decreased (1.330689 --> 1.329996).  Saving model ...
2023-12-01 16:57:47,733:INFO::Epoch: 23
tensor([[0.6022, 0.6087, 0.6058, 0.6059],
        [0.6080, 0.6099, 0.6091, 0.6049],
        [0.6051, 0.6053, 0.6097, 0.6034],
        [0.6097, 0.6112, 0.6062, 0.6076]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:47,734:INFO::its now!!!!!!!!5
2023-12-01 16:57:47,874:INFO::its now!!!!!!!!0
2023-12-01 16:57:47,875:INFO::its now!!!!!!!!3
2023-12-01 16:57:47,916:INFO::its now!!!!!!!!5
2023-12-01 16:57:48,091:INFO::its now!!!!!!!!
2023-12-01 16:57:48,091:INFO::its now!!!!!!!! on 
2023-12-01 16:57:48,140:INFO::its now!!!!!!!!5
2023-12-01 16:57:48,321:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:48,323:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 1.2760 | Train_Classification_Loss 1.3086 | Dmon_Loss -0.0651 | Val_Loss 1.3268 | Search Time(s) 0.3875 | Infer Time(s) 0.2020 | Time(s) 0.5895 
2023-12-01 16:57:48,381:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:48,382:INFO::Validation loss decreased (1.329996 --> 1.326847).  Saving model ...
2023-12-01 16:57:48,386:INFO::Epoch: 24
tensor([[0.6065, 0.6129, 0.6080, 0.6106],
        [0.6106, 0.6133, 0.6138, 0.6095],
        [0.6095, 0.6076, 0.6135, 0.6081],
        [0.6142, 0.6152, 0.6109, 0.6097]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:48,408:INFO::its now!!!!!!!!5
2023-12-01 16:57:48,572:INFO::its now!!!!!!!!0
2023-12-01 16:57:48,573:INFO::its now!!!!!!!!3
2023-12-01 16:57:48,602:INFO::its now!!!!!!!!5
2023-12-01 16:57:48,775:INFO::its now!!!!!!!!
2023-12-01 16:57:48,775:INFO::its now!!!!!!!! on 
2023-12-01 16:57:48,828:INFO::its now!!!!!!!!5
2023-12-01 16:57:49,008:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:49,010:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 1.2731 | Train_Classification_Loss 1.3058 | Dmon_Loss -0.0654 | Val_Loss 1.3237 | Search Time(s) 0.4269 | Infer Time(s) 0.1975 | Time(s) 0.6243 
2023-12-01 16:57:49,063:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:49,065:INFO::Validation loss decreased (1.326847 --> 1.323661).  Saving model ...
2023-12-01 16:57:49,069:INFO::Epoch: 25
tensor([[0.6106, 0.6169, 0.6091, 0.6148],
        [0.6138, 0.6169, 0.6181, 0.6119],
        [0.6135, 0.6109, 0.6155, 0.6126],
        [0.6182, 0.6191, 0.6154, 0.6108]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:49,070:INFO::its now!!!!!!!!5
2023-12-01 16:57:49,237:INFO::its now!!!!!!!!0
2023-12-01 16:57:49,238:INFO::its now!!!!!!!!3
2023-12-01 16:57:49,282:INFO::its now!!!!!!!!5
2023-12-01 16:57:49,446:INFO::its now!!!!!!!!
2023-12-01 16:57:49,446:INFO::its now!!!!!!!! on 
2023-12-01 16:57:49,501:INFO::its now!!!!!!!!5
2023-12-01 16:57:49,655:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:49,657:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 1.2630 | Train_Classification_Loss 1.2950 | Dmon_Loss -0.0639 | Val_Loss 1.3143 | Search Time(s) 0.4350 | Infer Time(s) 0.1556 | Time(s) 0.5906 
2023-12-01 16:57:49,712:INFO::cluster info:
0: 3;	1: 1;	2: 3;	3: 1;	4: 3;	5: 1;	6: 3;	7: 3;	8: 1;	9: 1;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 1;	17: 3;	18: 1;	19: 1;	20: 3;	21: 1;	22: 1;	23: 1;	24: 1;	25: 1;	26: 3;	27: 3;	28: 3;	29: 1;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 1;	43: 3;	44
26098: 1;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 1;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 3;	26114: 3;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:49,713:INFO::Validation loss decreased (1.323661 --> 1.314261).  Saving model ...
2023-12-01 16:57:49,717:INFO::Epoch: 26
tensor([[0.6161, 0.6189, 0.6131, 0.6201],
        [0.6187, 0.6218, 0.6203, 0.6168],
        [0.6185, 0.6163, 0.6165, 0.6186],
        [0.6232, 0.6210, 0.6214, 0.6148]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:49,718:INFO::its now!!!!!!!!5
2023-12-01 16:57:49,880:INFO::its now!!!!!!!!0
2023-12-01 16:57:49,881:INFO::its now!!!!!!!!3
2023-12-01 16:57:49,929:INFO::its now!!!!!!!!5
2023-12-01 16:57:50,095:INFO::its now!!!!!!!!
2023-12-01 16:57:50,096:INFO::its now!!!!!!!! on 
2023-12-01 16:57:50,153:INFO::its now!!!!!!!!5
2023-12-01 16:57:50,322:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 1.2594 | Train_Classification_Loss 1.2921 | Dmon_Loss -0.0653 | Val_Loss 1.3157 | Search Time(s) 0.4374 | Infer Time(s) 0.1701 | Time(s) 0.6075 
2023-12-01 16:57:50,367:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:50,368:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:57:50,372:INFO::Epoch: 27
tensor([[0.6187, 0.6197, 0.6148, 0.6228],
        [0.6209, 0.6241, 0.6211, 0.6191],
        [0.6208, 0.6187, 0.6168, 0.6217],
        [0.6259, 0.6217, 0.6242, 0.6166]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:50,372:INFO::its now!!!!!!!!5
2023-12-01 16:57:50,523:INFO::its now!!!!!!!!0
2023-12-01 16:57:50,524:INFO::its now!!!!!!!!3
2023-12-01 16:57:50,568:INFO::its now!!!!!!!!5
2023-12-01 16:57:50,729:INFO::its now!!!!!!!!
2023-12-01 16:57:50,729:INFO::its now!!!!!!!! on 
2023-12-01 16:57:50,779:INFO::its now!!!!!!!!5
2023-12-01 16:57:50,919:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:50,921:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 1.2512 | Train_Classification_Loss 1.2838 | Dmon_Loss -0.0652 | Val_Loss 1.3085 | Search Time(s) 0.3930 | Infer Time(s) 0.1586 | Time(s) 0.5515 
2023-12-01 16:57:50,963:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 1;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:50,964:INFO::Validation loss decreased (1.314261 --> 1.308503).  Saving model ...
2023-12-01 16:57:50,966:INFO::Epoch: 28
tensor([[0.6245, 0.6248, 0.6203, 0.6242],
        [0.6265, 0.6253, 0.6261, 0.6251],
        [0.6261, 0.6249, 0.6213, 0.6232],
        [0.6274, 0.6267, 0.6305, 0.6220]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:50,967:INFO::its now!!!!!!!!5
2023-12-01 16:57:51,161:INFO::its now!!!!!!!!0
2023-12-01 16:57:51,162:INFO::its now!!!!!!!!3
2023-12-01 16:57:51,207:INFO::its now!!!!!!!!5
2023-12-01 16:57:51,400:INFO::its now!!!!!!!!
2023-12-01 16:57:51,400:INFO::its now!!!!!!!! on 
2023-12-01 16:57:51,457:INFO::its now!!!!!!!!5
2023-12-01 16:57:51,679:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:51,680:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 1.2481 | Train_Classification_Loss 1.2808 | Dmon_Loss -0.0654 | Val_Loss 1.3041 | Search Time(s) 0.4778 | Infer Time(s) 0.2374 | Time(s) 0.7152 
2023-12-01 16:57:51,735:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 1;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:51,736:INFO::Validation loss decreased (1.308503 --> 1.304093).  Saving model ...
2023-12-01 16:57:51,739:INFO::Epoch: 29
tensor([[0.6301, 0.6274, 0.6257, 0.6275],
        [0.6294, 0.6285, 0.6313, 0.6310],
        [0.6288, 0.6308, 0.6260, 0.6271],
        [0.6307, 0.6319, 0.6337, 0.6273]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:51,740:INFO::its now!!!!!!!!5
2023-12-01 16:57:51,933:INFO::its now!!!!!!!!0
2023-12-01 16:57:51,934:INFO::its now!!!!!!!!3
2023-12-01 16:57:51,979:INFO::its now!!!!!!!!5
2023-12-01 16:57:52,145:INFO::its now!!!!!!!!
2023-12-01 16:57:52,146:INFO::its now!!!!!!!! on 
2023-12-01 16:57:52,201:INFO::its now!!!!!!!!5
2023-12-01 16:57:52,380:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:52,382:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 1.2407 | Train_Classification_Loss 1.2734 | Dmon_Loss -0.0655 | Val_Loss 1.2995 | Search Time(s) 0.4623 | Infer Time(s) 0.1821 | Time(s) 0.6445 
2023-12-01 16:57:52,475:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:52,476:INFO::Validation loss decreased (1.304093 --> 1.299525).  Saving model ...
2023-12-01 16:57:52,481:INFO::Epoch: 30
tensor([[0.6370, 0.6329, 0.6324, 0.6292],
        [0.6349, 0.6301, 0.6379, 0.6383],
        [0.6302, 0.6380, 0.6322, 0.6337],
        [0.6326, 0.6386, 0.6398, 0.6340]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:52,481:INFO::its now!!!!!!!!5
2023-12-01 16:57:52,729:INFO::its now!!!!!!!!0
2023-12-01 16:57:52,729:INFO::its now!!!!!!!!3
2023-12-01 16:57:52,781:INFO::its now!!!!!!!!5
2023-12-01 16:57:52,955:INFO::its now!!!!!!!!
2023-12-01 16:57:52,955:INFO::its now!!!!!!!! on 
2023-12-01 16:57:53,011:INFO::its now!!!!!!!!5
2023-12-01 16:57:53,202:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 1.2397 | Train_Classification_Loss 1.2727 | Dmon_Loss -0.0661 | Val_Loss 1.3007 | Search Time(s) 0.5329 | Infer Time(s) 0.1905 | Time(s) 0.7234 
2023-12-01 16:57:53,254:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:53,255:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:57:53,258:INFO::Epoch: 31
tensor([[0.6405, 0.6409, 0.6409, 0.6355],
        [0.6427, 0.6362, 0.6463, 0.6420],
        [0.6360, 0.6417, 0.6401, 0.6426],
        [0.6388, 0.6471, 0.6431, 0.6424]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:53,259:INFO::its now!!!!!!!!5
2023-12-01 16:57:53,435:INFO::its now!!!!!!!!0
2023-12-01 16:57:53,435:INFO::its now!!!!!!!!3
2023-12-01 16:57:53,479:INFO::its now!!!!!!!!5
2023-12-01 16:57:53,662:INFO::its now!!!!!!!!
2023-12-01 16:57:53,662:INFO::its now!!!!!!!! on 
2023-12-01 16:57:53,714:INFO::its now!!!!!!!!5
2023-12-01 16:57:53,862:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:53,864:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 1.2354 | Train_Classification_Loss 1.2685 | Dmon_Loss -0.0663 | Val_Loss 1.2965 | Search Time(s) 0.4558 | Infer Time(s) 0.1506 | Time(s) 0.6064 
2023-12-01 16:57:53,910:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:53,911:INFO::Validation loss decreased (1.299525 --> 1.296480).  Saving model ...
2023-12-01 16:57:53,915:INFO::Epoch: 32
tensor([[0.6450, 0.6450, 0.6477, 0.6413],
        [0.6492, 0.6419, 0.6505, 0.6468],
        [0.6414, 0.6465, 0.6465, 0.6472],
        [0.6444, 0.6513, 0.6477, 0.6491]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:53,915:INFO::its now!!!!!!!!5
2023-12-01 16:57:54,087:INFO::its now!!!!!!!!0
2023-12-01 16:57:54,088:INFO::its now!!!!!!!!3
2023-12-01 16:57:54,131:INFO::its now!!!!!!!!5
2023-12-01 16:57:54,308:INFO::its now!!!!!!!!
2023-12-01 16:57:54,308:INFO::its now!!!!!!!! on 
2023-12-01 16:57:54,356:INFO::its now!!!!!!!!5
2023-12-01 16:57:54,513:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:54,515:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 1.2320 | Train_Classification_Loss 1.2653 | Dmon_Loss -0.0666 | Val_Loss 1.2917 | Search Time(s) 0.4289 | Infer Time(s) 0.1735 | Time(s) 0.6024 
2023-12-01 16:57:54,571:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:54,573:INFO::Validation loss decreased (1.296480 --> 1.291716).  Saving model ...
2023-12-01 16:57:54,576:INFO::Epoch: 33
tensor([[0.6471, 0.6469, 0.6511, 0.6441],
        [0.6523, 0.6446, 0.6527, 0.6491],
        [0.6440, 0.6488, 0.6497, 0.6495],
        [0.6471, 0.6532, 0.6499, 0.6524]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:54,577:INFO::its now!!!!!!!!5
2023-12-01 16:57:54,765:INFO::its now!!!!!!!!0
2023-12-01 16:57:54,765:INFO::its now!!!!!!!!3
2023-12-01 16:57:54,807:INFO::its now!!!!!!!!5
2023-12-01 16:57:54,981:INFO::its now!!!!!!!!
2023-12-01 16:57:54,981:INFO::its now!!!!!!!! on 
2023-12-01 16:57:55,017:INFO::its now!!!!!!!!5
2023-12-01 16:57:55,150:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:55,151:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 1.2216 | Train_Classification_Loss 1.2542 | Dmon_Loss -0.0650 | Val_Loss 1.2846 | Search Time(s) 0.4418 | Infer Time(s) 0.1352 | Time(s) 0.5771 
2023-12-01 16:57:55,188:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:55,189:INFO::Validation loss decreased (1.291716 --> 1.284621).  Saving model ...
2023-12-01 16:57:55,191:INFO::Epoch: 34
tensor([[0.6523, 0.6518, 0.6529, 0.6494],
        [0.6577, 0.6499, 0.6538, 0.6546],
        [0.6490, 0.6542, 0.6513, 0.6549],
        [0.6523, 0.6540, 0.6554, 0.6578]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:55,192:INFO::its now!!!!!!!!5
2023-12-01 16:57:55,353:INFO::its now!!!!!!!!0
2023-12-01 16:57:55,354:INFO::its now!!!!!!!!3
2023-12-01 16:57:55,381:INFO::its now!!!!!!!!5
2023-12-01 16:57:55,548:INFO::its now!!!!!!!!
2023-12-01 16:57:55,548:INFO::its now!!!!!!!! on 
2023-12-01 16:57:55,605:INFO::its now!!!!!!!!5
2023-12-01 16:57:55,782:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:55,784:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 1.2135 | Train_Classification_Loss 1.2465 | Dmon_Loss -0.0661 | Val_Loss 1.2737 | Search Time(s) 0.4155 | Infer Time(s) 0.1775 | Time(s) 0.5930 
2023-12-01 16:57:55,840:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:55,841:INFO::Validation loss decreased (1.284621 --> 1.273657).  Saving model ...
2023-12-01 16:57:55,843:INFO::Epoch: 35
tensor([[0.6593, 0.6586, 0.6538, 0.6563],
        [0.6604, 0.6567, 0.6587, 0.6620],
        [0.6555, 0.6616, 0.6562, 0.6577],
        [0.6590, 0.6589, 0.6628, 0.6606]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:55,844:INFO::its now!!!!!!!!5
2023-12-01 16:57:56,007:INFO::its now!!!!!!!!0
2023-12-01 16:57:56,008:INFO::its now!!!!!!!!3
2023-12-01 16:57:56,055:INFO::its now!!!!!!!!5
2023-12-01 16:57:56,240:INFO::its now!!!!!!!!
2023-12-01 16:57:56,240:INFO::its now!!!!!!!! on 
2023-12-01 16:57:56,295:INFO::its now!!!!!!!!5
2023-12-01 16:57:56,475:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:56,477:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 1.2027 | Train_Classification_Loss 1.2358 | Dmon_Loss -0.0662 | Val_Loss 1.2677 | Search Time(s) 0.4504 | Infer Time(s) 0.1840 | Time(s) 0.6344 
2023-12-01 16:57:56,535:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:56,536:INFO::Validation loss decreased (1.273657 --> 1.267734).  Saving model ...
2023-12-01 16:57:56,538:INFO::Epoch: 36
tensor([[0.6628, 0.6646, 0.6569, 0.6624],
        [0.6644, 0.6627, 0.6637, 0.6657],
        [0.6612, 0.6653, 0.6611, 0.6620],
        [0.6648, 0.6639, 0.6669, 0.6645]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:56,538:INFO::its now!!!!!!!!5
2023-12-01 16:57:56,701:INFO::its now!!!!!!!!0
2023-12-01 16:57:56,702:INFO::its now!!!!!!!!3
2023-12-01 16:57:56,747:INFO::its now!!!!!!!!5
2023-12-01 16:57:56,918:INFO::its now!!!!!!!!
2023-12-01 16:57:56,918:INFO::its now!!!!!!!! on 
2023-12-01 16:57:56,955:INFO::its now!!!!!!!!5
2023-12-01 16:57:57,138:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:57,140:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 1.1961 | Train_Classification_Loss 1.2290 | Dmon_Loss -0.0657 | Val_Loss 1.2602 | Search Time(s) 0.4169 | Infer Time(s) 0.1851 | Time(s) 0.6020 
2023-12-01 16:57:57,177:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 3;	26114: 3;	26115: 1;	26116: 1;	26117: 1;	26118: 3;	26119: 1;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:57,179:INFO::Validation loss decreased (1.267734 --> 1.260244).  Saving model ...
2023-12-01 16:57:57,182:INFO::Epoch: 37
tensor([[0.6697, 0.6676, 0.6636, 0.6702],
        [0.6713, 0.6704, 0.6712, 0.6676],
        [0.6687, 0.6672, 0.6683, 0.6696],
        [0.6724, 0.6715, 0.6693, 0.6714]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:57,183:INFO::its now!!!!!!!!5
2023-12-01 16:57:57,364:INFO::its now!!!!!!!!0
2023-12-01 16:57:57,366:INFO::its now!!!!!!!!3
2023-12-01 16:57:57,405:INFO::its now!!!!!!!!5
2023-12-01 16:57:57,574:INFO::its now!!!!!!!!
2023-12-01 16:57:57,575:INFO::its now!!!!!!!! on 
2023-12-01 16:57:57,627:INFO::its now!!!!!!!!5
2023-12-01 16:57:57,795:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 1.1972 | Train_Classification_Loss 1.2308 | Dmon_Loss -0.0673 | Val_Loss 1.2644 | Search Time(s) 0.4284 | Infer Time(s) 0.1875 | Time(s) 0.6160 
2023-12-01 16:57:57,832:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:57,832:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:57:57,835:INFO::Epoch: 38
tensor([[0.6755, 0.6714, 0.6692, 0.6742],
        [0.6748, 0.6765, 0.6772, 0.6711],
        [0.6746, 0.6707, 0.6740, 0.6734],
        [0.6767, 0.6775, 0.6730, 0.6771]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:57,835:INFO::its now!!!!!!!!5
2023-12-01 16:57:57,993:INFO::its now!!!!!!!!0
2023-12-01 16:57:57,993:INFO::its now!!!!!!!!3
2023-12-01 16:57:58,038:INFO::its now!!!!!!!!5
2023-12-01 16:57:58,251:INFO::its now!!!!!!!!
2023-12-01 16:57:58,251:INFO::its now!!!!!!!! on 
2023-12-01 16:57:58,305:INFO::its now!!!!!!!!5
2023-12-01 16:57:58,503:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:58,504:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 1.1902 | Train_Classification_Loss 1.2230 | Dmon_Loss -0.0656 | Val_Loss 1.2586 | Search Time(s) 0.4704 | Infer Time(s) 0.2005 | Time(s) 0.6708 
2023-12-01 16:57:58,553:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:58,554:INFO::Validation loss decreased (1.260244 --> 1.258555).  Saving model ...
2023-12-01 16:57:58,556:INFO::Epoch: 39
tensor([[0.6784, 0.6756, 0.6743, 0.6784],
        [0.6787, 0.6816, 0.6802, 0.6753],
        [0.6775, 0.6749, 0.6789, 0.6777],
        [0.6809, 0.6804, 0.6774, 0.6821]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:58,557:INFO::its now!!!!!!!!5
2023-12-01 16:57:58,739:INFO::its now!!!!!!!!0
2023-12-01 16:57:58,740:INFO::its now!!!!!!!!3
2023-12-01 16:57:58,786:INFO::its now!!!!!!!!5
2023-12-01 16:57:58,945:INFO::its now!!!!!!!!
2023-12-01 16:57:58,945:INFO::its now!!!!!!!! on 
2023-12-01 16:57:58,981:INFO::its now!!!!!!!!5
2023-12-01 16:57:59,139:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:57:59,141:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 1.1748 | Train_Classification_Loss 1.2079 | Dmon_Loss -0.0662 | Val_Loss 1.2406 | Search Time(s) 0.4239 | Infer Time(s) 0.1611 | Time(s) 0.5850 
2023-12-01 16:57:59,189:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 1;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 1;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 3;	26110: 1;	26111: 3;	26112: 1;	26113: 3;	26114: 3;	26115: 1;	26116: 1;	26117: 3;	26118: 3;	26119: 1;	26120: 1;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:59,190:INFO::Validation loss decreased (1.258555 --> 1.240599).  Saving model ...
2023-12-01 16:57:59,194:INFO::Epoch: 40
tensor([[0.6799, 0.6826, 0.6816, 0.6851],
        [0.6854, 0.6842, 0.6864, 0.6828],
        [0.6835, 0.6823, 0.6814, 0.6850],
        [0.6876, 0.6867, 0.6850, 0.6846]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:59,195:INFO::its now!!!!!!!!5
2023-12-01 16:57:59,358:INFO::its now!!!!!!!!0
2023-12-01 16:57:59,359:INFO::its now!!!!!!!!3
2023-12-01 16:57:59,386:INFO::its now!!!!!!!!5
2023-12-01 16:57:59,555:INFO::its now!!!!!!!!
2023-12-01 16:57:59,556:INFO::its now!!!!!!!! on 
2023-12-01 16:57:59,604:INFO::its now!!!!!!!!5
2023-12-01 16:57:59,745:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 1.1767 | Train_Classification_Loss 1.2105 | Dmon_Loss -0.0677 | Val_Loss 1.2463 | Search Time(s) 0.3945 | Infer Time(s) 0.1596 | Time(s) 0.5541 
2023-12-01 16:57:59,788:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:57:59,789:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:57:59,792:INFO::Epoch: 41
tensor([[0.6843, 0.6897, 0.6887, 0.6885],
        [0.6921, 0.6891, 0.6896, 0.6903],
        [0.6898, 0.6898, 0.6860, 0.6887],
        [0.6914, 0.6933, 0.6926, 0.6894]], device='cuda:0', requires_grad=True)
2023-12-01 16:57:59,793:INFO::its now!!!!!!!!5
2023-12-01 16:57:59,943:INFO::its now!!!!!!!!0
2023-12-01 16:57:59,944:INFO::its now!!!!!!!!3
2023-12-01 16:57:59,985:INFO::its now!!!!!!!!5
2023-12-01 16:58:00,162:INFO::its now!!!!!!!!
2023-12-01 16:58:00,162:INFO::its now!!!!!!!! on 
2023-12-01 16:58:00,215:INFO::its now!!!!!!!!5
2023-12-01 16:58:00,353:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:00,355:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 1.1568 | Train_Classification_Loss 1.1903 | Dmon_Loss -0.0670 | Val_Loss 1.2276 | Search Time(s) 0.4254 | Infer Time(s) 0.1382 | Time(s) 0.5637 
2023-12-01 16:58:00,411:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:00,412:INFO::Validation loss decreased (1.240599 --> 1.227582).  Saving model ...
2023-12-01 16:58:00,415:INFO::Epoch: 42
tensor([[0.6889, 0.6932, 0.6945, 0.6924],
        [0.6955, 0.6937, 0.6934, 0.6965],
        [0.6929, 0.6959, 0.6905, 0.6930],
        [0.6954, 0.6966, 0.6989, 0.6941]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:00,416:INFO::its now!!!!!!!!5
2023-12-01 16:58:00,566:INFO::its now!!!!!!!!0
2023-12-01 16:58:00,567:INFO::its now!!!!!!!!3
2023-12-01 16:58:00,610:INFO::its now!!!!!!!!5
2023-12-01 16:58:00,776:INFO::its now!!!!!!!!
2023-12-01 16:58:00,776:INFO::its now!!!!!!!! on 
2023-12-01 16:58:00,828:INFO::its now!!!!!!!!5
2023-12-01 16:58:00,986:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 1.1642 | Train_Classification_Loss 1.1982 | Dmon_Loss -0.0680 | Val_Loss 1.2353 | Search Time(s) 0.4139 | Infer Time(s) 0.1596 | Time(s) 0.5735 
2023-12-01 16:58:01,052:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:01,054:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:01,057:INFO::Epoch: 43
tensor([[0.6963, 0.7000, 0.6974, 0.6992],
        [0.7021, 0.7008, 0.7002, 0.6996],
        [0.6991, 0.6990, 0.6975, 0.7004],
        [0.7022, 0.7032, 0.7027, 0.7013]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:01,058:INFO::its now!!!!!!!!5
2023-12-01 16:58:01,244:INFO::its now!!!!!!!!0
2023-12-01 16:58:01,244:INFO::its now!!!!!!!!3
2023-12-01 16:58:01,293:INFO::its now!!!!!!!!5
2023-12-01 16:58:01,452:INFO::its now!!!!!!!!
2023-12-01 16:58:01,452:INFO::its now!!!!!!!! on 
2023-12-01 16:58:01,507:INFO::its now!!!!!!!!5
2023-12-01 16:58:01,646:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:01,648:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 1.1362 | Train_Classification_Loss 1.1695 | Dmon_Loss -0.0668 | Val_Loss 1.2114 | Search Time(s) 0.4490 | Infer Time(s) 0.1426 | Time(s) 0.5917 
2023-12-01 16:58:01,696:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:01,697:INFO::Validation loss decreased (1.227582 --> 1.211386).  Saving model ...
2023-12-01 16:58:01,699:INFO::Epoch: 44
tensor([[0.7011, 0.7034, 0.6999, 0.7037],
        [0.7053, 0.7054, 0.7046, 0.7023],
        [0.7032, 0.7017, 0.7020, 0.7041],
        [0.7066, 0.7064, 0.7058, 0.7059]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:01,701:INFO::its now!!!!!!!!5
2023-12-01 16:58:01,884:INFO::its now!!!!!!!!0
2023-12-01 16:58:01,885:INFO::its now!!!!!!!!3
2023-12-01 16:58:01,932:INFO::its now!!!!!!!!5
2023-12-01 16:58:02,110:INFO::its now!!!!!!!!
2023-12-01 16:58:02,110:INFO::its now!!!!!!!! on 
2023-12-01 16:58:02,167:INFO::its now!!!!!!!!5
2023-12-01 16:58:02,336:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:02,339:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 1.1325 | Train_Classification_Loss 1.1661 | Dmon_Loss -0.0672 | Val_Loss 1.2044 | Search Time(s) 0.4673 | Infer Time(s) 0.1721 | Time(s) 0.6395 
2023-12-01 16:58:02,404:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 1;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 1;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:02,405:INFO::Validation loss decreased (1.211386 --> 1.204382).  Saving model ...
2023-12-01 16:58:02,412:INFO::Epoch: 45
tensor([[0.7056, 0.7072, 0.7033, 0.7059],
        [0.7090, 0.7097, 0.7089, 0.7037],
        [0.7072, 0.7054, 0.7042, 0.7082],
        [0.7107, 0.7081, 0.7096, 0.7103]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:02,414:INFO::its now!!!!!!!!5
2023-12-01 16:58:02,582:INFO::its now!!!!!!!!0
2023-12-01 16:58:02,583:INFO::its now!!!!!!!!3
2023-12-01 16:58:02,626:INFO::its now!!!!!!!!5
2023-12-01 16:58:02,790:INFO::its now!!!!!!!!
2023-12-01 16:58:02,790:INFO::its now!!!!!!!! on 
2023-12-01 16:58:02,826:INFO::its now!!!!!!!!5
2023-12-01 16:58:02,968:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 1.1366 | Train_Classification_Loss 1.1698 | Dmon_Loss -0.0664 | Val_Loss 1.2148 | Search Time(s) 0.4159 | Infer Time(s) 0.1466 | Time(s) 0.5625 
2023-12-01 16:58:03,030:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:03,031:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:03,034:INFO::Epoch: 46
tensor([[0.7141, 0.7092, 0.7112, 0.7130],
        [0.7168, 0.7119, 0.7170, 0.7112],
        [0.7149, 0.7139, 0.7113, 0.7103],
        [0.7135, 0.7150, 0.7183, 0.7185]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:03,035:INFO::its now!!!!!!!!5
2023-12-01 16:58:03,199:INFO::its now!!!!!!!!0
2023-12-01 16:58:03,200:INFO::its now!!!!!!!!3
2023-12-01 16:58:03,227:INFO::its now!!!!!!!!5
2023-12-01 16:58:03,437:INFO::its now!!!!!!!!
2023-12-01 16:58:03,438:INFO::its now!!!!!!!! on 
2023-12-01 16:58:03,493:INFO::its now!!!!!!!!5
2023-12-01 16:58:03,707:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:03,708:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 1.1157 | Train_Classification_Loss 1.1496 | Dmon_Loss -0.0679 | Val_Loss 1.1886 | Search Time(s) 0.4600 | Infer Time(s) 0.2154 | Time(s) 0.6754 
2023-12-01 16:58:03,766:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:03,767:INFO::Validation loss decreased (1.204382 --> 1.188642).  Saving model ...
2023-12-01 16:58:03,770:INFO::Epoch: 47
tensor([[0.7184, 0.7168, 0.7213, 0.7226],
        [0.7266, 0.7195, 0.7211, 0.7216],
        [0.7187, 0.7247, 0.7207, 0.7183],
        [0.7212, 0.7245, 0.7292, 0.7227]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:03,771:INFO::its now!!!!!!!!5
2023-12-01 16:58:03,979:INFO::its now!!!!!!!!0
2023-12-01 16:58:03,980:INFO::its now!!!!!!!!3
2023-12-01 16:58:04,026:INFO::its now!!!!!!!!5
2023-12-01 16:58:04,242:INFO::its now!!!!!!!!
2023-12-01 16:58:04,242:INFO::its now!!!!!!!! on 
2023-12-01 16:58:04,294:INFO::its now!!!!!!!!5
2023-12-01 16:58:04,470:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:04,473:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 1.1052 | Train_Classification_Loss 1.1392 | Dmon_Loss -0.0679 | Val_Loss 1.1798 | Search Time(s) 0.5086 | Infer Time(s) 0.1939 | Time(s) 0.7025 
2023-12-01 16:58:04,511:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:04,512:INFO::Validation loss decreased (1.188642 --> 1.179815).  Saving model ...
2023-12-01 16:58:04,514:INFO::Epoch: 48
tensor([[0.7235, 0.7235, 0.7291, 0.7274],
        [0.7315, 0.7262, 0.7261, 0.7297],
        [0.7235, 0.7301, 0.7281, 0.7254],
        [0.7279, 0.7320, 0.7355, 0.7277]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:04,515:INFO::its now!!!!!!!!5
2023-12-01 16:58:04,689:INFO::its now!!!!!!!!0
2023-12-01 16:58:04,690:INFO::its now!!!!!!!!3
2023-12-01 16:58:04,741:INFO::its now!!!!!!!!5
2023-12-01 16:58:04,908:INFO::its now!!!!!!!!
2023-12-01 16:58:04,908:INFO::its now!!!!!!!! on 
2023-12-01 16:58:04,966:INFO::its now!!!!!!!!5
2023-12-01 16:58:05,120:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 1.1182 | Train_Classification_Loss 1.1526 | Dmon_Loss -0.0689 | Val_Loss 1.1930 | Search Time(s) 0.4508 | Infer Time(s) 0.1576 | Time(s) 0.6084 
2023-12-01 16:58:05,166:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:05,167:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:05,169:INFO::Epoch: 49
tensor([[0.7320, 0.7326, 0.7331, 0.7353],
        [0.7340, 0.7351, 0.7343, 0.7396],
        [0.7313, 0.7329, 0.7371, 0.7348],
        [0.7367, 0.7410, 0.7393, 0.7360]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:05,170:INFO::its now!!!!!!!!5
2023-12-01 16:58:05,338:INFO::its now!!!!!!!!0
2023-12-01 16:58:05,338:INFO::its now!!!!!!!!3
2023-12-01 16:58:05,381:INFO::its now!!!!!!!!5
2023-12-01 16:58:05,561:INFO::its now!!!!!!!!
2023-12-01 16:58:05,562:INFO::its now!!!!!!!! on 
2023-12-01 16:58:05,616:INFO::its now!!!!!!!!5
2023-12-01 16:58:05,770:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 1.1114 | Train_Classification_Loss 1.1459 | Dmon_Loss -0.0689 | Val_Loss 1.1855 | Search Time(s) 0.4458 | Infer Time(s) 0.1576 | Time(s) 0.6034 
2023-12-01 16:58:05,828:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:05,829:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:58:05,832:INFO::Epoch: 50
tensor([[0.7416, 0.7371, 0.7405, 0.7442],
        [0.7406, 0.7447, 0.7384, 0.7498],
        [0.7402, 0.7401, 0.7464, 0.7396],
        [0.7462, 0.7505, 0.7419, 0.7453]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:05,833:INFO::its now!!!!!!!!5
2023-12-01 16:58:06,010:INFO::its now!!!!!!!!0
2023-12-01 16:58:06,011:INFO::its now!!!!!!!!3
2023-12-01 16:58:06,052:INFO::its now!!!!!!!!5
2023-12-01 16:58:06,232:INFO::its now!!!!!!!!
2023-12-01 16:58:06,232:INFO::its now!!!!!!!! on 
2023-12-01 16:58:06,284:INFO::its now!!!!!!!!5
2023-12-01 16:58:06,447:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:06,448:INFO::Epoch 00050 | lr 0.00050 | Train_Loss 1.0996 | Train_Classification_Loss 1.1345 | Dmon_Loss -0.0698 | Val_Loss 1.1777 | Search Time(s) 0.4528 | Infer Time(s) 0.1646 | Time(s) 0.6173 
2023-12-01 16:58:06,501:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:06,502:INFO::Validation loss decreased (1.179815 --> 1.177669).  Saving model ...
2023-12-01 16:58:06,506:INFO::Epoch: 51
tensor([[0.7506, 0.7437, 0.7483, 0.7487],
        [0.7479, 0.7535, 0.7447, 0.7550],
        [0.7486, 0.7480, 0.7512, 0.7464],
        [0.7548, 0.7553, 0.7479, 0.7540]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:06,507:INFO::its now!!!!!!!!5
2023-12-01 16:58:06,652:INFO::its now!!!!!!!!0
2023-12-01 16:58:06,652:INFO::its now!!!!!!!!3
2023-12-01 16:58:06,698:INFO::its now!!!!!!!!5
2023-12-01 16:58:06,883:INFO::its now!!!!!!!!
2023-12-01 16:58:06,883:INFO::its now!!!!!!!! on 
2023-12-01 16:58:06,934:INFO::its now!!!!!!!!5
2023-12-01 16:58:07,094:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:07,095:INFO::Epoch 00051 | lr 0.00050 | Train_Loss 1.0610 | Train_Classification_Loss 1.0953 | Dmon_Loss -0.0686 | Val_Loss 1.1418 | Search Time(s) 0.4149 | Infer Time(s) 0.1765 | Time(s) 0.5914 
2023-12-01 16:58:07,145:INFO::cluster info:
0: 1;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:07,146:INFO::Validation loss decreased (1.177669 --> 1.141799).  Saving model ...
2023-12-01 16:58:07,148:INFO::Epoch: 52
tensor([[0.7551, 0.7495, 0.7546, 0.7533],
        [0.7539, 0.7602, 0.7504, 0.7576],
        [0.7551, 0.7546, 0.7536, 0.7524],
        [0.7615, 0.7577, 0.7537, 0.7608]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:07,149:INFO::its now!!!!!!!!5
2023-12-01 16:58:07,322:INFO::its now!!!!!!!!0
2023-12-01 16:58:07,323:INFO::its now!!!!!!!!3
2023-12-01 16:58:07,369:INFO::its now!!!!!!!!5
2023-12-01 16:58:07,540:INFO::its now!!!!!!!!
2023-12-01 16:58:07,540:INFO::its now!!!!!!!! on 
2023-12-01 16:58:07,597:INFO::its now!!!!!!!!5
2023-12-01 16:58:07,773:INFO::Epoch 00052 | lr 0.00050 | Train_Loss 1.0819 | Train_Classification_Loss 1.1156 | Dmon_Loss -0.0673 | Val_Loss 1.1642 | Search Time(s) 0.4478 | Infer Time(s) 0.1795 | Time(s) 0.6273 
2023-12-01 16:58:07,828:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:07,829:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:07,831:INFO::Epoch: 53
tensor([[0.7574, 0.7583, 0.7635, 0.7612],
        [0.7626, 0.7636, 0.7592, 0.7650],
        [0.7584, 0.7639, 0.7603, 0.7615],
        [0.7657, 0.7646, 0.7630, 0.7698]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:07,832:INFO::its now!!!!!!!!5
2023-12-01 16:58:07,999:INFO::its now!!!!!!!!0
2023-12-01 16:58:07,999:INFO::its now!!!!!!!!3
2023-12-01 16:58:08,042:INFO::its now!!!!!!!!5
2023-12-01 16:58:08,238:INFO::its now!!!!!!!!
2023-12-01 16:58:08,238:INFO::its now!!!!!!!! on 
2023-12-01 16:58:08,273:INFO::its now!!!!!!!!5
2023-12-01 16:58:08,454:INFO::Epoch 00053 | lr 0.00050 | Train_Loss 1.0751 | Train_Classification_Loss 1.1089 | Dmon_Loss -0.0674 | Val_Loss 1.1564 | Search Time(s) 0.4418 | Infer Time(s) 0.1835 | Time(s) 0.6253 
2023-12-01 16:58:08,511:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:08,512:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:58:08,514:INFO::Epoch: 54
tensor([[0.7631, 0.7670, 0.7680, 0.7692],
        [0.7710, 0.7697, 0.7678, 0.7687],
        [0.7643, 0.7686, 0.7677, 0.7705],
        [0.7721, 0.7721, 0.7722, 0.7745]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:08,515:INFO::its now!!!!!!!!5
2023-12-01 16:58:08,692:INFO::its now!!!!!!!!0
2023-12-01 16:58:08,693:INFO::its now!!!!!!!!3
2023-12-01 16:58:08,716:INFO::its now!!!!!!!!5
2023-12-01 16:58:08,873:INFO::its now!!!!!!!!
2023-12-01 16:58:08,873:INFO::its now!!!!!!!! on 
2023-12-01 16:58:08,926:INFO::its now!!!!!!!!5
2023-12-01 16:58:09,141:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:09,143:INFO::Epoch 00054 | lr 0.00050 | Train_Loss 1.0327 | Train_Classification_Loss 1.0675 | Dmon_Loss -0.0695 | Val_Loss 1.1155 | Search Time(s) 0.4129 | Infer Time(s) 0.2164 | Time(s) 0.6293 
2023-12-01 16:58:09,205:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:09,206:INFO::Validation loss decreased (1.141799 --> 1.115497).  Saving model ...
2023-12-01 16:58:09,208:INFO::Epoch: 55
tensor([[0.7694, 0.7747, 0.7736, 0.7733],
        [0.7752, 0.7760, 0.7754, 0.7740],
        [0.7704, 0.7745, 0.7745, 0.7751],
        [0.7786, 0.7790, 0.7804, 0.7768]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:09,208:INFO::its now!!!!!!!!5
2023-12-01 16:58:09,388:INFO::its now!!!!!!!!0
2023-12-01 16:58:09,388:INFO::its now!!!!!!!!3
2023-12-01 16:58:09,439:INFO::its now!!!!!!!!5
2023-12-01 16:58:09,639:INFO::its now!!!!!!!!
2023-12-01 16:58:09,639:INFO::its now!!!!!!!! on 
2023-12-01 16:58:09,691:INFO::its now!!!!!!!!5
2023-12-01 16:58:09,881:INFO::Epoch 00055 | lr 0.00050 | Train_Loss 1.0564 | Train_Classification_Loss 1.0915 | Dmon_Loss -0.0703 | Val_Loss 1.1367 | Search Time(s) 0.4625 | Infer Time(s) 0.2124 | Time(s) 0.6750 
2023-12-01 16:58:09,926:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:09,927:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:09,931:INFO::Epoch: 56
tensor([[0.7781, 0.7786, 0.7816, 0.7805],
        [0.7825, 0.7792, 0.7845, 0.7821],
        [0.7787, 0.7830, 0.7829, 0.7774],
        [0.7870, 0.7875, 0.7855, 0.7834]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:09,932:INFO::its now!!!!!!!!5
2023-12-01 16:58:10,090:INFO::its now!!!!!!!!0
2023-12-01 16:58:10,091:INFO::its now!!!!!!!!3
2023-12-01 16:58:10,131:INFO::its now!!!!!!!!5
2023-12-01 16:58:10,310:INFO::its now!!!!!!!!
2023-12-01 16:58:10,310:INFO::its now!!!!!!!! on 
2023-12-01 16:58:10,345:INFO::its now!!!!!!!!5
2023-12-01 16:58:10,495:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:10,496:INFO::Epoch 00056 | lr 0.00050 | Train_Loss 1.0096 | Train_Classification_Loss 1.0446 | Dmon_Loss -0.0701 | Val_Loss 1.0933 | Search Time(s) 0.4160 | Infer Time(s) 0.1506 | Time(s) 0.5666 
2023-12-01 16:58:10,537:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:10,538:INFO::Validation loss decreased (1.115497 --> 1.093279).  Saving model ...
2023-12-01 16:58:10,541:INFO::Epoch: 57
tensor([[0.7860, 0.7841, 0.7857, 0.7874],
        [0.7896, 0.7844, 0.7891, 0.7898],
        [0.7862, 0.7873, 0.7904, 0.7823],
        [0.7946, 0.7920, 0.7919, 0.7902]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:10,542:INFO::its now!!!!!!!!5
2023-12-01 16:58:10,728:INFO::its now!!!!!!!!0
2023-12-01 16:58:10,729:INFO::its now!!!!!!!!3
2023-12-01 16:58:10,762:INFO::its now!!!!!!!!5
2023-12-01 16:58:10,942:INFO::its now!!!!!!!!
2023-12-01 16:58:10,943:INFO::its now!!!!!!!! on 
2023-12-01 16:58:10,982:INFO::its now!!!!!!!!5
2023-12-01 16:58:11,169:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:11,170:INFO::Epoch 00057 | lr 0.00050 | Train_Loss 1.0020 | Train_Classification_Loss 1.0371 | Dmon_Loss -0.0701 | Val_Loss 1.0851 | Search Time(s) 0.4318 | Infer Time(s) 0.1990 | Time(s) 0.6309 
2023-12-01 16:58:11,214:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:11,215:INFO::Validation loss decreased (1.093279 --> 1.085076).  Saving model ...
2023-12-01 16:58:11,217:INFO::Epoch: 58
tensor([[0.7945, 0.7915, 0.7923, 0.7909],
        [0.7974, 0.7916, 0.7958, 0.7937],
        [0.7943, 0.7941, 0.7942, 0.7896],
        [0.7996, 0.7985, 0.8001, 0.7980]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:11,217:INFO::its now!!!!!!!!5
2023-12-01 16:58:11,386:INFO::its now!!!!!!!!0
2023-12-01 16:58:11,387:INFO::its now!!!!!!!!3
2023-12-01 16:58:11,421:INFO::its now!!!!!!!!5
2023-12-01 16:58:11,610:INFO::its now!!!!!!!!
2023-12-01 16:58:11,610:INFO::its now!!!!!!!! on 
2023-12-01 16:58:11,665:INFO::its now!!!!!!!!5
2023-12-01 16:58:11,857:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:11,859:INFO::Epoch 00058 | lr 0.00050 | Train_Loss 0.9821 | Train_Classification_Loss 1.0176 | Dmon_Loss -0.0709 | Val_Loss 1.0721 | Search Time(s) 0.4304 | Infer Time(s) 0.2114 | Time(s) 0.6419 
2023-12-01 16:58:11,900:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:11,901:INFO::Validation loss decreased (1.085076 --> 1.072103).  Saving model ...
2023-12-01 16:58:11,904:INFO::Epoch: 59
tensor([[0.7988, 0.8006, 0.8008, 0.7979],
        [0.8013, 0.8006, 0.8045, 0.8011],
        [0.7984, 0.8030, 0.8011, 0.7989],
        [0.8073, 0.8068, 0.8052, 0.8071]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:11,904:INFO::its now!!!!!!!!5
2023-12-01 16:58:12,079:INFO::its now!!!!!!!!0
2023-12-01 16:58:12,080:INFO::its now!!!!!!!!3
2023-12-01 16:58:12,128:INFO::its now!!!!!!!!5
2023-12-01 16:58:12,299:INFO::its now!!!!!!!!
2023-12-01 16:58:12,299:INFO::its now!!!!!!!! on 
2023-12-01 16:58:12,356:INFO::its now!!!!!!!!5
2023-12-01 16:58:12,524:INFO::Epoch 00059 | lr 0.00050 | Train_Loss 1.0128 | Train_Classification_Loss 1.0472 | Dmon_Loss -0.0688 | Val_Loss 1.1075 | Search Time(s) 0.4539 | Infer Time(s) 0.1695 | Time(s) 0.6234 
2023-12-01 16:58:12,567:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:12,568:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:12,571:INFO::Epoch: 60
tensor([[0.8078, 0.8116, 0.8051, 0.8076],
        [0.8098, 0.8115, 0.8088, 0.8115],
        [0.8069, 0.8075, 0.8107, 0.8101],
        [0.8124, 0.8171, 0.8150, 0.8179]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:12,572:INFO::its now!!!!!!!!5
2023-12-01 16:58:12,714:INFO::its now!!!!!!!!0
2023-12-01 16:58:12,715:INFO::its now!!!!!!!!3
2023-12-01 16:58:12,758:INFO::its now!!!!!!!!5
2023-12-01 16:58:12,932:INFO::its now!!!!!!!!
2023-12-01 16:58:12,932:INFO::its now!!!!!!!! on 
2023-12-01 16:58:12,984:INFO::its now!!!!!!!!5
2023-12-01 16:58:13,181:INFO::Epoch 00060 | lr 0.00050 | Train_Loss 1.0001 | Train_Classification_Loss 1.0361 | Dmon_Loss -0.0719 | Val_Loss 1.0932 | Search Time(s) 0.4119 | Infer Time(s) 0.2011 | Time(s) 0.6130 
2023-12-01 16:58:13,229:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:13,230:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:58:13,233:INFO::Epoch: 61
tensor([[0.8175, 0.8171, 0.8126, 0.8174],
        [0.8190, 0.8170, 0.8164, 0.8218],
        [0.8162, 0.8154, 0.8156, 0.8210],
        [0.8203, 0.8270, 0.8254, 0.8234]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:13,234:INFO::its now!!!!!!!!5
2023-12-01 16:58:13,390:INFO::its now!!!!!!!!0
2023-12-01 16:58:13,391:INFO::its now!!!!!!!!3
2023-12-01 16:58:13,424:INFO::its now!!!!!!!!5
2023-12-01 16:58:13,615:INFO::its now!!!!!!!!
2023-12-01 16:58:13,615:INFO::its now!!!!!!!! on 
2023-12-01 16:58:13,666:INFO::its now!!!!!!!!5
2023-12-01 16:58:13,831:INFO::Epoch 00061 | lr 0.00050 | Train_Loss 0.9937 | Train_Classification_Loss 1.0298 | Dmon_Loss -0.0720 | Val_Loss 1.0841 | Search Time(s) 0.4324 | Infer Time(s) 0.1676 | Time(s) 0.6000 
2023-12-01 16:58:13,892:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:13,894:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:58:13,897:INFO::Epoch: 62
tensor([[0.8253, 0.8228, 0.8194, 0.8223],
        [0.8236, 0.8227, 0.8232, 0.8299],
        [0.8209, 0.8224, 0.8209, 0.8294],
        [0.8272, 0.8347, 0.8318, 0.8291]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:13,898:INFO::its now!!!!!!!!5
2023-12-01 16:58:14,051:INFO::its now!!!!!!!!0
2023-12-01 16:58:14,052:INFO::its now!!!!!!!!3
2023-12-01 16:58:14,105:INFO::its now!!!!!!!!5
2023-12-01 16:58:14,265:INFO::its now!!!!!!!!
2023-12-01 16:58:14,265:INFO::its now!!!!!!!! on 
2023-12-01 16:58:14,324:INFO::its now!!!!!!!!5
2023-12-01 16:58:14,536:INFO::Epoch 00062 | lr 0.00050 | Train_Loss 0.9782 | Train_Classification_Loss 1.0144 | Dmon_Loss -0.0725 | Val_Loss 1.0748 | Search Time(s) 0.4260 | Infer Time(s) 0.2164 | Time(s) 0.6424 
2023-12-01 16:58:14,591:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:14,593:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 16:58:14,596:INFO::Epoch: 63
tensor([[0.8329, 0.8294, 0.8228, 0.8282],
        [0.8294, 0.8256, 0.8302, 0.8375],
        [0.8267, 0.8297, 0.8269, 0.8336],
        [0.8321, 0.8419, 0.8388, 0.8354]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:14,597:INFO::its now!!!!!!!!5
2023-12-01 16:58:14,796:INFO::its now!!!!!!!!0
2023-12-01 16:58:14,797:INFO::its now!!!!!!!!3
2023-12-01 16:58:14,839:INFO::its now!!!!!!!!5
2023-12-01 16:58:15,023:INFO::its now!!!!!!!!
2023-12-01 16:58:15,023:INFO::its now!!!!!!!! on 
2023-12-01 16:58:15,076:INFO::its now!!!!!!!!5
2023-12-01 16:58:15,264:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:15,265:INFO::Epoch 00063 | lr 0.00050 | Train_Loss 0.9204 | Train_Classification_Loss 0.9564 | Dmon_Loss -0.0720 | Val_Loss 1.0215 | Search Time(s) 0.4797 | Infer Time(s) 0.1911 | Time(s) 0.6708 
2023-12-01 16:58:15,310:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:15,311:INFO::Validation loss decreased (1.072103 --> 1.021500).  Saving model ...
2023-12-01 16:58:15,313:INFO::Epoch: 64
tensor([[0.8366, 0.8366, 0.8285, 0.8349],
        [0.8361, 0.8311, 0.8376, 0.8413],
        [0.8334, 0.8374, 0.8337, 0.8357],
        [0.8385, 0.8458, 0.8465, 0.8424]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:15,313:INFO::its now!!!!!!!!5
2023-12-01 16:58:15,469:INFO::its now!!!!!!!!0
2023-12-01 16:58:15,469:INFO::its now!!!!!!!!3
2023-12-01 16:58:15,519:INFO::its now!!!!!!!!5
2023-12-01 16:58:15,698:INFO::its now!!!!!!!!
2023-12-01 16:58:15,698:INFO::its now!!!!!!!! on 
2023-12-01 16:58:15,751:INFO::its now!!!!!!!!5
2023-12-01 16:58:15,904:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:15,906:INFO::Epoch 00064 | lr 0.00050 | Train_Loss 0.9070 | Train_Classification_Loss 0.9433 | Dmon_Loss -0.0726 | Val_Loss 1.0101 | Search Time(s) 0.4199 | Infer Time(s) 0.1725 | Time(s) 0.5924 
2023-12-01 16:58:15,964:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:15,965:INFO::Validation loss decreased (1.021500 --> 1.010101).  Saving model ...
2023-12-01 16:58:15,968:INFO::Epoch: 65
tensor([[0.8386, 0.8439, 0.8352, 0.8418],
        [0.8431, 0.8377, 0.8451, 0.8432],
        [0.8404, 0.8412, 0.8407, 0.8407],
        [0.8455, 0.8513, 0.8516, 0.8496]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:15,969:INFO::its now!!!!!!!!5
2023-12-01 16:58:16,147:INFO::its now!!!!!!!!0
2023-12-01 16:58:16,148:INFO::its now!!!!!!!!3
2023-12-01 16:58:16,193:INFO::its now!!!!!!!!5
2023-12-01 16:58:16,377:INFO::its now!!!!!!!!
2023-12-01 16:58:16,377:INFO::its now!!!!!!!! on 
2023-12-01 16:58:16,440:INFO::its now!!!!!!!!5
2023-12-01 16:58:16,616:INFO::Epoch 00065 | lr 0.00050 | Train_Loss 0.9477 | Train_Classification_Loss 0.9842 | Dmon_Loss -0.0731 | Val_Loss 1.0461 | Search Time(s) 0.4729 | Infer Time(s) 0.1775 | Time(s) 0.6504 
2023-12-01 16:58:16,679:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:16,680:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:16,682:INFO::Epoch: 66
tensor([[0.8455, 0.8477, 0.8444, 0.8507],
        [0.8521, 0.8468, 0.8489, 0.8501],
        [0.8495, 0.8432, 0.8496, 0.8491],
        [0.8548, 0.8595, 0.8555, 0.8588]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:16,683:INFO::its now!!!!!!!!5
2023-12-01 16:58:16,842:INFO::its now!!!!!!!!0
2023-12-01 16:58:16,843:INFO::its now!!!!!!!!3
2023-12-01 16:58:16,889:INFO::its now!!!!!!!!5
2023-12-01 16:58:17,072:INFO::its now!!!!!!!!
2023-12-01 16:58:17,072:INFO::its now!!!!!!!! on 
2023-12-01 16:58:17,105:INFO::its now!!!!!!!!5
2023-12-01 16:58:17,266:INFO::Epoch 00066 | lr 0.00050 | Train_Loss 0.9362 | Train_Classification_Loss 0.9716 | Dmon_Loss -0.0708 | Val_Loss 1.0472 | Search Time(s) 0.4235 | Infer Time(s) 0.1616 | Time(s) 0.5851 
2023-12-01 16:58:17,308:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:17,309:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:58:17,312:INFO::Epoch: 67
tensor([[0.8535, 0.8541, 0.8535, 0.8552],
        [0.8567, 0.8557, 0.8554, 0.8580],
        [0.8583, 0.8490, 0.8542, 0.8578],
        [0.8638, 0.8638, 0.8624, 0.8677]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:17,314:INFO::its now!!!!!!!!5
2023-12-01 16:58:17,462:INFO::its now!!!!!!!!0
2023-12-01 16:58:17,463:INFO::its now!!!!!!!!3
2023-12-01 16:58:17,490:INFO::its now!!!!!!!!5
2023-12-01 16:58:17,668:INFO::its now!!!!!!!!
2023-12-01 16:58:17,669:INFO::its now!!!!!!!! on 
2023-12-01 16:58:17,724:INFO::its now!!!!!!!!5
2023-12-01 16:58:17,899:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:17,901:INFO::Epoch 00067 | lr 0.00050 | Train_Loss 0.8709 | Train_Classification_Loss 0.9083 | Dmon_Loss -0.0749 | Val_Loss 0.9760 | Search Time(s) 0.4109 | Infer Time(s) 0.1785 | Time(s) 0.5894 
2023-12-01 16:58:17,969:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:17,971:INFO::Validation loss decreased (1.010101 --> 0.975995).  Saving model ...
2023-12-01 16:58:17,974:INFO::Epoch: 68
tensor([[0.8637, 0.8636, 0.8640, 0.8574],
        [0.8650, 0.8663, 0.8649, 0.8620],
        [0.8627, 0.8585, 0.8624, 0.8683],
        [0.8744, 0.8719, 0.8724, 0.8723]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:17,975:INFO::its now!!!!!!!!5
2023-12-01 16:58:18,123:INFO::its now!!!!!!!!0
2023-12-01 16:58:18,124:INFO::its now!!!!!!!!3
2023-12-01 16:58:18,173:INFO::its now!!!!!!!!5
2023-12-01 16:58:18,383:INFO::its now!!!!!!!!
2023-12-01 16:58:18,383:INFO::its now!!!!!!!! on 
2023-12-01 16:58:18,427:INFO::its now!!!!!!!!5
2023-12-01 16:58:18,589:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:18,590:INFO::Epoch 00068 | lr 0.00050 | Train_Loss 0.8516 | Train_Classification_Loss 0.8888 | Dmon_Loss -0.0744 | Val_Loss 0.9629 | Search Time(s) 0.4518 | Infer Time(s) 0.1666 | Time(s) 0.6183 
2023-12-01 16:58:18,633:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 1;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:18,634:INFO::Validation loss decreased (0.975995 --> 0.962882).  Saving model ...
2023-12-01 16:58:18,636:INFO::Epoch: 69
tensor([[0.8735, 0.8732, 0.8694, 0.8634],
        [0.8737, 0.8716, 0.8745, 0.8690],
        [0.8697, 0.8684, 0.8711, 0.8736],
        [0.8811, 0.8805, 0.8825, 0.8794]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:18,637:INFO::its now!!!!!!!!5
2023-12-01 16:58:18,784:INFO::its now!!!!!!!!0
2023-12-01 16:58:18,785:INFO::its now!!!!!!!!3
2023-12-01 16:58:18,814:INFO::its now!!!!!!!!5
2023-12-01 16:58:18,974:INFO::its now!!!!!!!!
2023-12-01 16:58:18,975:INFO::its now!!!!!!!! on 
2023-12-01 16:58:19,031:INFO::its now!!!!!!!!5
2023-12-01 16:58:19,181:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:19,182:INFO::Epoch 00069 | lr 0.00050 | Train_Loss 0.8513 | Train_Classification_Loss 0.8897 | Dmon_Loss -0.0766 | Val_Loss 0.9531 | Search Time(s) 0.3770 | Infer Time(s) 0.1705 | Time(s) 0.5475 
2023-12-01 16:58:19,249:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:19,250:INFO::Validation loss decreased (0.962882 --> 0.953138).  Saving model ...
2023-12-01 16:58:19,253:INFO::Epoch: 70
tensor([[0.8785, 0.8841, 0.8782, 0.8725],
        [0.8840, 0.8804, 0.8794, 0.8788],
        [0.8792, 0.8795, 0.8813, 0.8763],
        [0.8906, 0.8905, 0.8891, 0.8890]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:19,253:INFO::its now!!!!!!!!5
2023-12-01 16:58:19,427:INFO::its now!!!!!!!!0
2023-12-01 16:58:19,428:INFO::its now!!!!!!!!3
2023-12-01 16:58:19,476:INFO::its now!!!!!!!!5
2023-12-01 16:58:19,658:INFO::its now!!!!!!!!
2023-12-01 16:58:19,658:INFO::its now!!!!!!!! on 
2023-12-01 16:58:19,712:INFO::its now!!!!!!!!5
2023-12-01 16:58:19,870:INFO::Epoch 00070 | lr 0.00050 | Train_Loss 0.8941 | Train_Classification_Loss 0.9319 | Dmon_Loss -0.0756 | Val_Loss 0.9984 | Search Time(s) 0.4438 | Infer Time(s) 0.1745 | Time(s) 0.6183 
2023-12-01 16:58:19,916:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:19,917:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:19,920:INFO::Epoch: 71
tensor([[0.8854, 0.8896, 0.8869, 0.8812],
        [0.8891, 0.8891, 0.8863, 0.8880],
        [0.8881, 0.8896, 0.8864, 0.8822],
        [0.8968, 0.8996, 0.8971, 0.8980]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:19,920:INFO::its now!!!!!!!!5
2023-12-01 16:58:20,160:INFO::its now!!!!!!!!0
2023-12-01 16:58:20,160:INFO::its now!!!!!!!!3
2023-12-01 16:58:20,211:INFO::its now!!!!!!!!5
2023-12-01 16:58:20,410:INFO::its now!!!!!!!!
2023-12-01 16:58:20,410:INFO::its now!!!!!!!! on 
2023-12-01 16:58:20,473:INFO::its now!!!!!!!!5
2023-12-01 16:58:20,652:INFO::Epoch 00071 | lr 0.00050 | Train_Loss 0.8889 | Train_Classification_Loss 0.9253 | Dmon_Loss -0.0728 | Val_Loss 1.0021 | Search Time(s) 0.5535 | Infer Time(s) 0.1815 | Time(s) 0.7350 
2023-12-01 16:58:20,699:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:20,701:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:58:20,704:INFO::Epoch: 72
tensor([[0.8943, 0.8923, 0.8966, 0.8908],
        [0.8917, 0.8987, 0.8953, 0.8980],
        [0.8978, 0.8946, 0.8941, 0.8908],
        [0.9052, 0.9044, 0.9068, 0.9077]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:20,706:INFO::its now!!!!!!!!5
2023-12-01 16:58:20,881:INFO::its now!!!!!!!!0
2023-12-01 16:58:20,882:INFO::its now!!!!!!!!3
2023-12-01 16:58:20,930:INFO::its now!!!!!!!!5
2023-12-01 16:58:21,117:INFO::its now!!!!!!!!
2023-12-01 16:58:21,118:INFO::its now!!!!!!!! on 
2023-12-01 16:58:21,156:INFO::its now!!!!!!!!5
2023-12-01 16:58:21,325:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:21,327:INFO::Epoch 00072 | lr 0.00050 | Train_Loss 0.7951 | Train_Classification_Loss 0.8335 | Dmon_Loss -0.0769 | Val_Loss 0.9183 | Search Time(s) 0.4528 | Infer Time(s) 0.1705 | Time(s) 0.6233 
2023-12-01 16:58:21,384:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:21,385:INFO::Validation loss decreased (0.953138 --> 0.918314).  Saving model ...
2023-12-01 16:58:21,389:INFO::Epoch: 73
tensor([[0.9024, 0.8974, 0.9014, 0.8990],
        [0.8966, 0.9036, 0.9034, 0.9065],
        [0.9026, 0.9009, 0.9014, 0.8987],
        [0.9130, 0.9103, 0.9155, 0.9127]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:21,390:INFO::its now!!!!!!!!5
2023-12-01 16:58:21,540:INFO::its now!!!!!!!!0
2023-12-01 16:58:21,540:INFO::its now!!!!!!!!3
2023-12-01 16:58:21,571:INFO::its now!!!!!!!!5
2023-12-01 16:58:21,735:INFO::its now!!!!!!!!
2023-12-01 16:58:21,735:INFO::its now!!!!!!!! on 
2023-12-01 16:58:21,769:INFO::its now!!!!!!!!5
2023-12-01 16:58:21,936:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:21,938:INFO::Epoch 00073 | lr 0.00050 | Train_Loss 0.7860 | Train_Classification_Loss 0.8248 | Dmon_Loss -0.0777 | Val_Loss 0.9059 | Search Time(s) 0.3770 | Infer Time(s) 0.1735 | Time(s) 0.5505 
2023-12-01 16:58:21,989:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:21,990:INFO::Validation loss decreased (0.918314 --> 0.905922).  Saving model ...
2023-12-01 16:58:21,992:INFO::Epoch: 74
tensor([[0.9066, 0.9044, 0.9081, 0.9072],
        [0.9033, 0.9102, 0.9118, 0.9108],
        [0.9051, 0.9085, 0.9091, 0.9071],
        [0.9211, 0.9172, 0.9214, 0.9193]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:21,993:INFO::its now!!!!!!!!5
2023-12-01 16:58:22,162:INFO::its now!!!!!!!!0
2023-12-01 16:58:22,163:INFO::its now!!!!!!!!3
2023-12-01 16:58:22,188:INFO::its now!!!!!!!!5
2023-12-01 16:58:22,363:INFO::its now!!!!!!!!
2023-12-01 16:58:22,363:INFO::its now!!!!!!!! on 
2023-12-01 16:58:22,419:INFO::its now!!!!!!!!5
2023-12-01 16:58:22,596:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:22,598:INFO::Epoch 00074 | lr 0.00050 | Train_Loss 0.7795 | Train_Classification_Loss 0.8191 | Dmon_Loss -0.0792 | Val_Loss 0.9007 | Search Time(s) 0.4249 | Infer Time(s) 0.1805 | Time(s) 0.6054 
2023-12-01 16:58:22,650:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:22,650:INFO::Validation loss decreased (0.905922 --> 0.900700).  Saving model ...
2023-12-01 16:58:22,652:INFO::Epoch: 75
tensor([[0.9113, 0.9105, 0.9115, 0.9138],
        [0.9092, 0.9161, 0.9161, 0.9156],
        [0.9089, 0.9150, 0.9130, 0.9139],
        [0.9277, 0.9232, 0.9258, 0.9252]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:22,653:INFO::its now!!!!!!!!5
2023-12-01 16:58:22,791:INFO::its now!!!!!!!!0
2023-12-01 16:58:22,791:INFO::its now!!!!!!!!3
2023-12-01 16:58:22,840:INFO::its now!!!!!!!!5
2023-12-01 16:58:23,022:INFO::its now!!!!!!!!
2023-12-01 16:58:23,022:INFO::its now!!!!!!!! on 
2023-12-01 16:58:23,062:INFO::its now!!!!!!!!5
2023-12-01 16:58:23,226:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:23,227:INFO::Epoch 00075 | lr 0.00050 | Train_Loss 0.7659 | Train_Classification_Loss 0.8061 | Dmon_Loss -0.0804 | Val_Loss 0.8882 | Search Time(s) 0.4079 | Infer Time(s) 0.1666 | Time(s) 0.5745 
2023-12-01 16:58:23,271:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:23,273:INFO::Validation loss decreased (0.900700 --> 0.888178).  Saving model ...
2023-12-01 16:58:23,287:INFO::Epoch: 76
tensor([[0.9167, 0.9166, 0.9162, 0.9172],
        [0.9150, 0.9191, 0.9212, 0.9210],
        [0.9137, 0.9182, 0.9177, 0.9204],
        [0.9325, 0.9290, 0.9311, 0.9310]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:23,287:INFO::its now!!!!!!!!5
2023-12-01 16:58:23,468:INFO::its now!!!!!!!!0
2023-12-01 16:58:23,469:INFO::its now!!!!!!!!3
2023-12-01 16:58:23,499:INFO::its now!!!!!!!!5
2023-12-01 16:58:23,669:INFO::its now!!!!!!!!
2023-12-01 16:58:23,669:INFO::its now!!!!!!!! on 
2023-12-01 16:58:23,726:INFO::its now!!!!!!!!5
2023-12-01 16:58:23,901:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:23,903:INFO::Epoch 00076 | lr 0.00050 | Train_Loss 0.7508 | Train_Classification_Loss 0.7911 | Dmon_Loss -0.0806 | Val_Loss 0.8744 | Search Time(s) 0.4518 | Infer Time(s) 0.1765 | Time(s) 0.6283 
2023-12-01 16:58:23,972:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:23,973:INFO::Validation loss decreased (0.888178 --> 0.874370).  Saving model ...
2023-12-01 16:58:23,975:INFO::Epoch: 77
tensor([[0.9209, 0.9211, 0.9200, 0.9188],
        [0.9194, 0.9221, 0.9238, 0.9252],
        [0.9175, 0.9214, 0.9215, 0.9236],
        [0.9365, 0.9333, 0.9354, 0.9354]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:23,975:INFO::its now!!!!!!!!5
2023-12-01 16:58:24,158:INFO::its now!!!!!!!!0
2023-12-01 16:58:24,159:INFO::its now!!!!!!!!3
2023-12-01 16:58:24,206:INFO::its now!!!!!!!!5
2023-12-01 16:58:24,369:INFO::its now!!!!!!!!
2023-12-01 16:58:24,369:INFO::its now!!!!!!!! on 
2023-12-01 16:58:24,423:INFO::its now!!!!!!!!5
2023-12-01 16:58:24,604:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:24,605:INFO::Epoch 00077 | lr 0.00050 | Train_Loss 0.7378 | Train_Classification_Loss 0.7787 | Dmon_Loss -0.0818 | Val_Loss 0.8628 | Search Time(s) 0.4498 | Infer Time(s) 0.1815 | Time(s) 0.6313 
2023-12-01 16:58:24,682:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:24,683:INFO::Validation loss decreased (0.874370 --> 0.862756).  Saving model ...
2023-12-01 16:58:24,685:INFO::Epoch: 78
tensor([[0.9233, 0.9234, 0.9222, 0.9200],
        [0.9219, 0.9239, 0.9254, 0.9273],
        [0.9198, 0.9234, 0.9237, 0.9252],
        [0.9402, 0.9358, 0.9379, 0.9379]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:24,686:INFO::its now!!!!!!!!5
2023-12-01 16:58:24,846:INFO::its now!!!!!!!!0
2023-12-01 16:58:24,847:INFO::its now!!!!!!!!3
2023-12-01 16:58:24,893:INFO::its now!!!!!!!!5
2023-12-01 16:58:25,078:INFO::its now!!!!!!!!
2023-12-01 16:58:25,078:INFO::its now!!!!!!!! on 
2023-12-01 16:58:25,114:INFO::its now!!!!!!!!5
2023-12-01 16:58:25,265:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:25,266:INFO::Epoch 00078 | lr 0.00050 | Train_Loss 0.7220 | Train_Classification_Loss 0.7633 | Dmon_Loss -0.0827 | Val_Loss 0.8459 | Search Time(s) 0.4219 | Infer Time(s) 0.1596 | Time(s) 0.5815 
2023-12-01 16:58:25,312:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 1;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:25,313:INFO::Validation loss decreased (0.862756 --> 0.845857).  Saving model ...
2023-12-01 16:58:25,315:INFO::Epoch: 79
tensor([[0.9279, 0.9246, 0.9266, 0.9238],
        [0.9264, 0.9281, 0.9297, 0.9283],
        [0.9242, 0.9278, 0.9280, 0.9260],
        [0.9437, 0.9402, 0.9427, 0.9424]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:25,315:INFO::its now!!!!!!!!5
2023-12-01 16:58:25,542:INFO::its now!!!!!!!!0
2023-12-01 16:58:25,542:INFO::its now!!!!!!!!3
2023-12-01 16:58:25,571:INFO::its now!!!!!!!!5
2023-12-01 16:58:25,794:INFO::its now!!!!!!!!
2023-12-01 16:58:25,795:INFO::its now!!!!!!!! on 
2023-12-01 16:58:25,847:INFO::its now!!!!!!!!5
2023-12-01 16:58:26,013:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:26,014:INFO::Epoch 00079 | lr 0.00050 | Train_Loss 0.7011 | Train_Classification_Loss 0.7420 | Dmon_Loss -0.0818 | Val_Loss 0.8373 | Search Time(s) 0.5156 | Infer Time(s) 0.1845 | Time(s) 0.7001 
2023-12-01 16:58:26,070:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:26,071:INFO::Validation loss decreased (0.845857 --> 0.837322).  Saving model ...
2023-12-01 16:58:26,074:INFO::Epoch: 80
tensor([[0.9304, 0.9277, 0.9313, 0.9281],
        [0.9311, 0.9326, 0.9318, 0.9313],
        [0.9288, 0.9326, 0.9302, 0.9289],
        [0.9471, 0.9447, 0.9478, 0.9470]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:26,075:INFO::its now!!!!!!!!5
2023-12-01 16:58:26,217:INFO::its now!!!!!!!!0
2023-12-01 16:58:26,218:INFO::its now!!!!!!!!3
2023-12-01 16:58:26,262:INFO::its now!!!!!!!!5
2023-12-01 16:58:26,456:INFO::its now!!!!!!!!
2023-12-01 16:58:26,457:INFO::its now!!!!!!!! on 
2023-12-01 16:58:26,509:INFO::its now!!!!!!!!5
2023-12-01 16:58:26,646:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:26,646:INFO::Epoch 00080 | lr 0.00050 | Train_Loss 0.6976 | Train_Classification_Loss 0.7391 | Dmon_Loss -0.0830 | Val_Loss 0.8291 | Search Time(s) 0.4199 | Infer Time(s) 0.1536 | Time(s) 0.5735 
2023-12-01 16:58:26,690:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:26,692:INFO::Validation loss decreased (0.837322 --> 0.829116).  Saving model ...
2023-12-01 16:58:26,697:INFO::Epoch: 81
tensor([[0.9330, 0.9306, 0.9337, 0.9315],
        [0.9347, 0.9349, 0.9342, 0.9341],
        [0.9324, 0.9350, 0.9326, 0.9317],
        [0.9501, 0.9482, 0.9520, 0.9506]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:26,698:INFO::its now!!!!!!!!5
2023-12-01 16:58:26,885:INFO::its now!!!!!!!!0
2023-12-01 16:58:26,886:INFO::its now!!!!!!!!3
2023-12-01 16:58:26,931:INFO::its now!!!!!!!!5
2023-12-01 16:58:27,111:INFO::its now!!!!!!!!
2023-12-01 16:58:27,111:INFO::its now!!!!!!!! on 
2023-12-01 16:58:27,166:INFO::its now!!!!!!!!5
2023-12-01 16:58:27,335:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:27,336:INFO::Epoch 00081 | lr 0.00050 | Train_Loss 0.6739 | Train_Classification_Loss 0.7158 | Dmon_Loss -0.0839 | Val_Loss 0.8133 | Search Time(s) 0.4558 | Infer Time(s) 0.1855 | Time(s) 0.6413 
2023-12-01 16:58:27,394:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:27,394:INFO::Validation loss decreased (0.829116 --> 0.813338).  Saving model ...
2023-12-01 16:58:27,398:INFO::Epoch: 82
tensor([[0.9347, 0.9325, 0.9351, 0.9335],
        [0.9369, 0.9360, 0.9358, 0.9360],
        [0.9346, 0.9362, 0.9341, 0.9336],
        [0.9520, 0.9503, 0.9558, 0.9528]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:27,399:INFO::its now!!!!!!!!5
2023-12-01 16:58:27,550:INFO::its now!!!!!!!!0
2023-12-01 16:58:27,551:INFO::its now!!!!!!!!3
2023-12-01 16:58:27,597:INFO::its now!!!!!!!!5
2023-12-01 16:58:27,781:INFO::its now!!!!!!!!
2023-12-01 16:58:27,782:INFO::its now!!!!!!!! on 
2023-12-01 16:58:27,820:INFO::its now!!!!!!!!5
2023-12-01 16:58:27,982:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:27,983:INFO::Epoch 00082 | lr 0.00050 | Train_Loss 0.6644 | Train_Classification_Loss 0.7069 | Dmon_Loss -0.0850 | Val_Loss 0.8040 | Search Time(s) 0.4249 | Infer Time(s) 0.1626 | Time(s) 0.5874 
2023-12-01 16:58:28,030:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:28,031:INFO::Validation loss decreased (0.813338 --> 0.804031).  Saving model ...
2023-12-01 16:58:28,033:INFO::Epoch: 83
tensor([[0.9373, 0.9352, 0.9359, 0.9363],
        [0.9380, 0.9383, 0.9384, 0.9386],
        [0.9374, 0.9368, 0.9365, 0.9362],
        [0.9547, 0.9530, 0.9594, 0.9555]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:28,034:INFO::its now!!!!!!!!5
2023-12-01 16:58:28,197:INFO::its now!!!!!!!!0
2023-12-01 16:58:28,198:INFO::its now!!!!!!!!3
2023-12-01 16:58:28,230:INFO::its now!!!!!!!!5
2023-12-01 16:58:28,409:INFO::its now!!!!!!!!
2023-12-01 16:58:28,409:INFO::its now!!!!!!!! on 
2023-12-01 16:58:28,451:INFO::its now!!!!!!!!5
2023-12-01 16:58:28,627:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:28,629:INFO::Epoch 00083 | lr 0.00050 | Train_Loss 0.6613 | Train_Classification_Loss 0.7039 | Dmon_Loss -0.0851 | Val_Loss 0.8010 | Search Time(s) 0.4159 | Infer Time(s) 0.1805 | Time(s) 0.5964 
2023-12-01 16:58:28,693:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:28,694:INFO::Validation loss decreased (0.804031 --> 0.800987).  Saving model ...
2023-12-01 16:58:28,696:INFO::Epoch: 84
tensor([[0.9389, 0.9394, 0.9391, 0.9403],
        [0.9414, 0.9422, 0.9425, 0.9400],
        [0.9388, 0.9400, 0.9404, 0.9405],
        [0.9588, 0.9570, 0.9630, 0.9596]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:28,696:INFO::its now!!!!!!!!5
2023-12-01 16:58:28,850:INFO::its now!!!!!!!!0
2023-12-01 16:58:28,851:INFO::its now!!!!!!!!3
2023-12-01 16:58:28,880:INFO::its now!!!!!!!!5
2023-12-01 16:58:29,054:INFO::its now!!!!!!!!
2023-12-01 16:58:29,054:INFO::its now!!!!!!!! on 
2023-12-01 16:58:29,106:INFO::its now!!!!!!!!5
2023-12-01 16:58:29,244:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:29,245:INFO::Epoch 00084 | lr 0.00050 | Train_Loss 0.6350 | Train_Classification_Loss 0.6784 | Dmon_Loss -0.0868 | Val_Loss 0.7828 | Search Time(s) 0.3939 | Infer Time(s) 0.1556 | Time(s) 0.5495 
2023-12-01 16:58:29,301:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:29,302:INFO::Validation loss decreased (0.800987 --> 0.782837).  Saving model ...
2023-12-01 16:58:29,306:INFO::Epoch: 85
tensor([[0.9410, 0.9428, 0.9420, 0.9424],
        [0.9443, 0.9455, 0.9446, 0.9420],
        [0.9408, 0.9430, 0.9436, 0.9426],
        [0.9622, 0.9603, 0.9667, 0.9629]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:29,306:INFO::its now!!!!!!!!5
2023-12-01 16:58:29,489:INFO::its now!!!!!!!!0
2023-12-01 16:58:29,490:INFO::its now!!!!!!!!3
2023-12-01 16:58:29,516:INFO::its now!!!!!!!!5
2023-12-01 16:58:29,667:INFO::its now!!!!!!!!
2023-12-01 16:58:29,668:INFO::its now!!!!!!!! on 
2023-12-01 16:58:29,721:INFO::its now!!!!!!!!5
2023-12-01 16:58:29,914:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:29,916:INFO::Epoch 00085 | lr 0.00050 | Train_Loss 0.6248 | Train_Classification_Loss 0.6685 | Dmon_Loss -0.0874 | Val_Loss 0.7731 | Search Time(s) 0.4009 | Infer Time(s) 0.2104 | Time(s) 0.6114 
2023-12-01 16:58:29,983:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:29,985:INFO::Validation loss decreased (0.782837 --> 0.773114).  Saving model ...
2023-12-01 16:58:29,987:INFO::Epoch: 86
tensor([[0.9422, 0.9463, 0.9452, 0.9451],
        [0.9458, 0.9488, 0.9474, 0.9447],
        [0.9418, 0.9462, 0.9468, 0.9454],
        [0.9656, 0.9635, 0.9704, 0.9663]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:29,988:INFO::its now!!!!!!!!5
2023-12-01 16:58:30,145:INFO::its now!!!!!!!!0
2023-12-01 16:58:30,146:INFO::its now!!!!!!!!3
2023-12-01 16:58:30,191:INFO::its now!!!!!!!!5
2023-12-01 16:58:30,386:INFO::its now!!!!!!!!
2023-12-01 16:58:30,386:INFO::its now!!!!!!!! on 
2023-12-01 16:58:30,442:INFO::its now!!!!!!!!5
2023-12-01 16:58:30,592:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:30,593:INFO::Epoch 00086 | lr 0.00050 | Train_Loss 0.5918 | Train_Classification_Loss 0.6365 | Dmon_Loss -0.0893 | Val_Loss 0.7523 | Search Time(s) 0.4398 | Infer Time(s) 0.1676 | Time(s) 0.6074 
2023-12-01 16:58:30,641:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:30,642:INFO::Validation loss decreased (0.773114 --> 0.752261).  Saving model ...
2023-12-01 16:58:30,645:INFO::Epoch: 87
tensor([[0.9466, 0.9481, 0.9504, 0.9499],
        [0.9501, 0.9505, 0.9525, 0.9498],
        [0.9459, 0.9516, 0.9485, 0.9505],
        [0.9710, 0.9686, 0.9743, 0.9714]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:30,646:INFO::its now!!!!!!!!5
2023-12-01 16:58:30,805:INFO::its now!!!!!!!!0
2023-12-01 16:58:30,805:INFO::its now!!!!!!!!3
2023-12-01 16:58:30,850:INFO::its now!!!!!!!!5
2023-12-01 16:58:31,079:INFO::its now!!!!!!!!
2023-12-01 16:58:31,079:INFO::its now!!!!!!!! on 
2023-12-01 16:58:31,117:INFO::its now!!!!!!!!5
2023-12-01 16:58:31,311:INFO::Epoch 00087 | lr 0.00050 | Train_Loss 0.6019 | Train_Classification_Loss 0.6467 | Dmon_Loss -0.0896 | Val_Loss 0.7537 | Search Time(s) 0.4717 | Infer Time(s) 0.1975 | Time(s) 0.6692 
2023-12-01 16:58:31,366:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:31,367:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:31,370:INFO::Epoch: 88
tensor([[0.9513, 0.9516, 0.9533, 0.9547],
        [0.9547, 0.9538, 0.9551, 0.9548],
        [0.9504, 0.9543, 0.9517, 0.9556],
        [0.9761, 0.9735, 0.9781, 0.9764]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:31,371:INFO::its now!!!!!!!!5
2023-12-01 16:58:31,551:INFO::its now!!!!!!!!0
2023-12-01 16:58:31,552:INFO::its now!!!!!!!!3
2023-12-01 16:58:31,582:INFO::its now!!!!!!!!5
2023-12-01 16:58:31,750:INFO::its now!!!!!!!!
2023-12-01 16:58:31,750:INFO::its now!!!!!!!! on 
2023-12-01 16:58:31,789:INFO::its now!!!!!!!!5
2023-12-01 16:58:31,945:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:31,946:INFO::Epoch 00088 | lr 0.00050 | Train_Loss 0.5751 | Train_Classification_Loss 0.6207 | Dmon_Loss -0.0913 | Val_Loss 0.7380 | Search Time(s) 0.4179 | Infer Time(s) 0.1606 | Time(s) 0.5785 
2023-12-01 16:58:31,984:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 1;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:31,985:INFO::Validation loss decreased (0.752261 --> 0.738009).  Saving model ...
2023-12-01 16:58:31,988:INFO::Epoch: 89
tensor([[0.9549, 0.9546, 0.9560, 0.9572],
        [0.9582, 0.9567, 0.9565, 0.9587],
        [0.9539, 0.9570, 0.9545, 0.9582],
        [0.9799, 0.9771, 0.9821, 0.9801]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:31,989:INFO::its now!!!!!!!!5
2023-12-01 16:58:32,154:INFO::its now!!!!!!!!0
2023-12-01 16:58:32,155:INFO::its now!!!!!!!!3
2023-12-01 16:58:32,183:INFO::its now!!!!!!!!5
2023-12-01 16:58:32,342:INFO::its now!!!!!!!!
2023-12-01 16:58:32,342:INFO::its now!!!!!!!! on 
2023-12-01 16:58:32,380:INFO::its now!!!!!!!!5
2023-12-01 16:58:32,567:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:32,569:INFO::Epoch 00089 | lr 0.00050 | Train_Loss 0.5752 | Train_Classification_Loss 0.6211 | Dmon_Loss -0.0917 | Val_Loss 0.7330 | Search Time(s) 0.3939 | Infer Time(s) 0.1875 | Time(s) 0.5815 
2023-12-01 16:58:32,607:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:32,608:INFO::Validation loss decreased (0.738009 --> 0.732998).  Saving model ...
2023-12-01 16:58:32,611:INFO::Epoch: 90
tensor([[0.9573, 0.9566, 0.9578, 0.9584],
        [0.9605, 0.9587, 0.9577, 0.9606],
        [0.9562, 0.9589, 0.9564, 0.9595],
        [0.9823, 0.9794, 0.9860, 0.9825]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:32,612:INFO::its now!!!!!!!!5
2023-12-01 16:58:32,791:INFO::its now!!!!!!!!0
2023-12-01 16:58:32,792:INFO::its now!!!!!!!!3
2023-12-01 16:58:32,823:INFO::its now!!!!!!!!5
2023-12-01 16:58:32,994:INFO::its now!!!!!!!!
2023-12-01 16:58:32,994:INFO::its now!!!!!!!! on 
2023-12-01 16:58:33,048:INFO::its now!!!!!!!!5
2023-12-01 16:58:33,226:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:33,228:INFO::Epoch 00090 | lr 0.00050 | Train_Loss 0.5432 | Train_Classification_Loss 0.5903 | Dmon_Loss -0.0941 | Val_Loss 0.7070 | Search Time(s) 0.4209 | Infer Time(s) 0.1974 | Time(s) 0.6183 
2023-12-01 16:58:33,287:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 1;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 0;	26099: 3;	26100: 3;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:33,288:INFO::Validation loss decreased (0.732998 --> 0.706966).  Saving model ...
2023-12-01 16:58:33,290:INFO::Epoch: 91
tensor([[0.9594, 0.9587, 0.9597, 0.9591],
        [0.9626, 0.9607, 0.9592, 0.9616],
        [0.9583, 0.9608, 0.9583, 0.9602],
        [0.9845, 0.9814, 0.9902, 0.9846]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:33,291:INFO::its now!!!!!!!!5
2023-12-01 16:58:33,443:INFO::its now!!!!!!!!0
2023-12-01 16:58:33,444:INFO::its now!!!!!!!!3
2023-12-01 16:58:33,490:INFO::its now!!!!!!!!5
2023-12-01 16:58:33,661:INFO::its now!!!!!!!!
2023-12-01 16:58:33,661:INFO::its now!!!!!!!! on 
2023-12-01 16:58:33,716:INFO::its now!!!!!!!!5
2023-12-01 16:58:33,848:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:33,850:INFO::Epoch 00091 | lr 0.00050 | Train_Loss 0.5286 | Train_Classification_Loss 0.5761 | Dmon_Loss -0.0951 | Val_Loss 0.6991 | Search Time(s) 0.4089 | Infer Time(s) 0.1516 | Time(s) 0.5605 
2023-12-01 16:58:33,913:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:58:33,914:INFO::Validation loss decreased (0.706966 --> 0.699095).  Saving model ...
2023-12-01 16:58:33,917:INFO::Epoch: 92
tensor([[0.9611, 0.9603, 0.9610, 0.9600],
        [0.9637, 0.9622, 0.9607, 0.9627],
        [0.9599, 0.9618, 0.9598, 0.9611],
        [0.9861, 0.9831, 0.9940, 0.9862]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:33,918:INFO::its now!!!!!!!!5
2023-12-01 16:58:34,086:INFO::its now!!!!!!!!0
2023-12-01 16:58:34,087:INFO::its now!!!!!!!!3
2023-12-01 16:58:34,135:INFO::its now!!!!!!!!5
2023-12-01 16:58:34,303:INFO::its now!!!!!!!!
2023-12-01 16:58:34,303:INFO::its now!!!!!!!! on 
2023-12-01 16:58:34,339:INFO::its now!!!!!!!!5
2023-12-01 16:58:34,513:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:34,514:INFO::Epoch 00092 | lr 0.00050 | Train_Loss 0.5132 | Train_Classification_Loss 0.5618 | Dmon_Loss -0.0971 | Val_Loss 0.6853 | Search Time(s) 0.4224 | Infer Time(s) 0.1755 | Time(s) 0.5979 
2023-12-01 16:58:34,557:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 1;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 1;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 1;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:58:34,558:INFO::Validation loss decreased (0.699095 --> 0.685264).  Saving model ...
2023-12-01 16:58:34,561:INFO::Epoch: 93
tensor([[0.9625, 0.9632, 0.9637, 0.9624],
        [0.9642, 0.9650, 0.9634, 0.9652],
        [0.9627, 0.9623, 0.9625, 0.9636],
        [0.9890, 0.9857, 0.9977, 0.9890]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:34,561:INFO::its now!!!!!!!!5
2023-12-01 16:58:34,715:INFO::its now!!!!!!!!0
2023-12-01 16:58:34,716:INFO::its now!!!!!!!!3
2023-12-01 16:58:34,743:INFO::its now!!!!!!!!5
2023-12-01 16:58:34,899:INFO::its now!!!!!!!!
2023-12-01 16:58:34,899:INFO::its now!!!!!!!! on 
2023-12-01 16:58:34,955:INFO::its now!!!!!!!!5
2023-12-01 16:58:35,118:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:35,119:INFO::Epoch 00093 | lr 0.00050 | Train_Loss 0.5075 | Train_Classification_Loss 0.5561 | Dmon_Loss -0.0971 | Val_Loss 0.6760 | Search Time(s) 0.3939 | Infer Time(s) 0.1666 | Time(s) 0.5605 
2023-12-01 16:58:35,186:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:58:35,187:INFO::Validation loss decreased (0.685264 --> 0.676048).  Saving model ...
2023-12-01 16:58:35,190:INFO::Epoch: 94
tensor([[0.9638, 0.9652, 0.9654, 0.9641],
        [0.9651, 0.9670, 0.9653, 0.9665],
        [0.9646, 0.9631, 0.9644, 0.9649],
        [0.9909, 0.9876, 1.0000, 0.9909]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:35,191:INFO::its now!!!!!!!!5
2023-12-01 16:58:35,360:INFO::its now!!!!!!!!0
2023-12-01 16:58:35,361:INFO::its now!!!!!!!!3
2023-12-01 16:58:35,409:INFO::its now!!!!!!!!5
2023-12-01 16:58:35,589:INFO::its now!!!!!!!!
2023-12-01 16:58:35,589:INFO::its now!!!!!!!! on 
2023-12-01 16:58:35,645:INFO::its now!!!!!!!!5
2023-12-01 16:58:35,817:INFO::Epoch 00094 | lr 0.00050 | Train_Loss 0.5154 | Train_Classification_Loss 0.5638 | Dmon_Loss -0.0968 | Val_Loss 0.6875 | Search Time(s) 0.4568 | Infer Time(s) 0.1725 | Time(s) 0.6293 
2023-12-01 16:58:35,855:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 0;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:35,856:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:35,859:INFO::Epoch: 95
tensor([[0.9654, 0.9672, 0.9668, 0.9659],
        [0.9664, 0.9680, 0.9673, 0.9681],
        [0.9666, 0.9645, 0.9663, 0.9655],
        [0.9929, 0.9895, 1.0000, 0.9928]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:35,859:INFO::its now!!!!!!!!5
2023-12-01 16:58:36,011:INFO::its now!!!!!!!!0
2023-12-01 16:58:36,012:INFO::its now!!!!!!!!3
2023-12-01 16:58:36,060:INFO::its now!!!!!!!!5
2023-12-01 16:58:36,231:INFO::its now!!!!!!!!
2023-12-01 16:58:36,231:INFO::its now!!!!!!!! on 
2023-12-01 16:58:36,286:INFO::its now!!!!!!!!5
2023-12-01 16:58:36,484:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:36,486:INFO::Epoch 00095 | lr 0.00050 | Train_Loss 0.4718 | Train_Classification_Loss 0.5217 | Dmon_Loss -0.0998 | Val_Loss 0.6587 | Search Time(s) 0.4289 | Infer Time(s) 0.1985 | Time(s) 0.6273 
2023-12-01 16:58:36,553:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 1;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:58:36,554:INFO::Validation loss decreased (0.676048 --> 0.658652).  Saving model ...
2023-12-01 16:58:36,556:INFO::Epoch: 96
tensor([[0.9665, 0.9682, 0.9678, 0.9672],
        [0.9674, 0.9688, 0.9686, 0.9690],
        [0.9675, 0.9656, 0.9675, 0.9662],
        [0.9942, 0.9907, 1.0000, 0.9941]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:36,557:INFO::its now!!!!!!!!5
2023-12-01 16:58:36,750:INFO::its now!!!!!!!!0
2023-12-01 16:58:36,751:INFO::its now!!!!!!!!3
2023-12-01 16:58:36,797:INFO::its now!!!!!!!!5
2023-12-01 16:58:36,967:INFO::its now!!!!!!!!
2023-12-01 16:58:36,968:INFO::its now!!!!!!!! on 
2023-12-01 16:58:37,004:INFO::its now!!!!!!!!5
2023-12-01 16:58:37,180:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:37,181:INFO::Epoch 00096 | lr 0.00050 | Train_Loss 0.4540 | Train_Classification_Loss 0.5047 | Dmon_Loss -0.1015 | Val_Loss 0.6415 | Search Time(s) 0.4428 | Infer Time(s) 0.1835 | Time(s) 0.6263 
2023-12-01 16:58:37,232:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 1;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 3;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:37,233:INFO::Validation loss decreased (0.658652 --> 0.641484).  Saving model ...
2023-12-01 16:58:37,237:INFO::Epoch: 97
tensor([[0.9684, 0.9689, 0.9696, 0.9690],
        [0.9692, 0.9705, 0.9706, 0.9694],
        [0.9693, 0.9675, 0.9682, 0.9679],
        [0.9961, 0.9925, 1.0000, 0.9960]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:37,238:INFO::its now!!!!!!!!5
2023-12-01 16:58:37,419:INFO::its now!!!!!!!!0
2023-12-01 16:58:37,419:INFO::its now!!!!!!!!3
2023-12-01 16:58:37,448:INFO::its now!!!!!!!!5
2023-12-01 16:58:37,649:INFO::its now!!!!!!!!
2023-12-01 16:58:37,650:INFO::its now!!!!!!!! on 
2023-12-01 16:58:37,703:INFO::its now!!!!!!!!5
2023-12-01 16:58:37,839:INFO::Epoch 00097 | lr 0.00050 | Train_Loss 0.4836 | Train_Classification_Loss 0.5338 | Dmon_Loss -0.1004 | Val_Loss 0.6653 | Search Time(s) 0.4677 | Infer Time(s) 0.1386 | Time(s) 0.6064 
2023-12-01 16:58:37,896:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:37,897:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:37,901:INFO::Epoch: 98
tensor([[0.9711, 0.9710, 0.9711, 0.9716],
        [0.9717, 0.9730, 0.9716, 0.9713],
        [0.9701, 0.9702, 0.9701, 0.9704],
        [0.9987, 0.9951, 1.0000, 0.9985]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:37,902:INFO::its now!!!!!!!!5
2023-12-01 16:58:38,041:INFO::its now!!!!!!!!0
2023-12-01 16:58:38,042:INFO::its now!!!!!!!!3
2023-12-01 16:58:38,087:INFO::its now!!!!!!!!5
2023-12-01 16:58:38,286:INFO::its now!!!!!!!!
2023-12-01 16:58:38,286:INFO::its now!!!!!!!! on 
2023-12-01 16:58:38,340:INFO::its now!!!!!!!!5
2023-12-01 16:58:38,531:INFO::Epoch 00098 | lr 0.00050 | Train_Loss 0.4825 | Train_Classification_Loss 0.5345 | Dmon_Loss -0.1040 | Val_Loss 0.6569 | Search Time(s) 0.4398 | Infer Time(s) 0.1945 | Time(s) 0.6343 
2023-12-01 16:58:38,590:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:38,591:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:58:38,593:INFO::Epoch: 99
tensor([[0.9725, 0.9721, 0.9719, 0.9729],
        [0.9731, 0.9743, 0.9721, 0.9723],
        [0.9706, 0.9716, 0.9711, 0.9717],
        [1.0000, 0.9964, 1.0000, 0.9999]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:38,595:INFO::its now!!!!!!!!5
2023-12-01 16:58:38,788:INFO::its now!!!!!!!!0
2023-12-01 16:58:38,788:INFO::its now!!!!!!!!3
2023-12-01 16:58:38,838:INFO::its now!!!!!!!!5
2023-12-01 16:58:39,004:INFO::its now!!!!!!!!
2023-12-01 16:58:39,004:INFO::its now!!!!!!!! on 
2023-12-01 16:58:39,060:INFO::its now!!!!!!!!5
2023-12-01 16:58:39,202:INFO::Epoch 00099 | lr 0.00050 | Train_Loss 0.4800 | Train_Classification_Loss 0.5314 | Dmon_Loss -0.1028 | Val_Loss 0.6620 | Search Time(s) 0.4682 | Infer Time(s) 0.1422 | Time(s) 0.6104 
2023-12-01 16:58:39,251:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:39,252:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:58:39,254:INFO::Epoch: 100
tensor([[0.9779, 0.9773, 0.9728, 0.9780],
        [0.9782, 0.9795, 0.9771, 0.9728],
        [0.9709, 0.9771, 0.9761, 0.9771],
        [1.0000, 0.9974, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:39,255:INFO::its now!!!!!!!!5
2023-12-01 16:58:39,447:INFO::its now!!!!!!!!0
2023-12-01 16:58:39,448:INFO::its now!!!!!!!!3
2023-12-01 16:58:39,494:INFO::its now!!!!!!!!5
2023-12-01 16:58:39,650:INFO::its now!!!!!!!!
2023-12-01 16:58:39,650:INFO::its now!!!!!!!! on 
2023-12-01 16:58:39,705:INFO::its now!!!!!!!!5
2023-12-01 16:58:39,861:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:39,863:INFO::Epoch 00100 | lr 0.00050 | Train_Loss 0.4529 | Train_Classification_Loss 0.5063 | Dmon_Loss -0.1066 | Val_Loss 0.6325 | Search Time(s) 0.4484 | Infer Time(s) 0.1606 | Time(s) 0.6090 
2023-12-01 16:58:39,926:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 1;	8: 3;	9: 1;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:39,927:INFO::Validation loss decreased (0.641484 --> 0.632530).  Saving model ...
2023-12-01 16:58:39,930:INFO::Epoch: 101
tensor([[0.9817, 0.9810, 0.9742, 0.9806],
        [0.9818, 0.9822, 0.9806, 0.9741],
        [0.9720, 0.9798, 0.9796, 0.9808],
        [1.0000, 0.9989, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:39,930:INFO::its now!!!!!!!!5
2023-12-01 16:58:40,100:INFO::its now!!!!!!!!0
2023-12-01 16:58:40,100:INFO::its now!!!!!!!!3
2023-12-01 16:58:40,128:INFO::its now!!!!!!!!5
2023-12-01 16:58:40,318:INFO::its now!!!!!!!!
2023-12-01 16:58:40,318:INFO::its now!!!!!!!! on 
2023-12-01 16:58:40,372:INFO::its now!!!!!!!!5
2023-12-01 16:58:40,540:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:40,542:INFO::Epoch 00101 | lr 0.00050 | Train_Loss 0.4359 | Train_Classification_Loss 0.4906 | Dmon_Loss -0.1094 | Val_Loss 0.6236 | Search Time(s) 0.4290 | Infer Time(s) 0.1835 | Time(s) 0.6125 
2023-12-01 16:58:40,583:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 1;	17: 3;	18: 3;	19: 3;	20: 3;	21: 2;	22: 3;	23: 3;	24: 1;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:40,584:INFO::Validation loss decreased (0.632530 --> 0.623623).  Saving model ...
2023-12-01 16:58:40,587:INFO::Epoch: 102
tensor([[0.9855, 0.9849, 0.9769, 0.9820],
        [0.9855, 0.9854, 0.9823, 0.9768],
        [0.9745, 0.9832, 0.9832, 0.9827],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:40,588:INFO::its now!!!!!!!!5
2023-12-01 16:58:40,753:INFO::its now!!!!!!!!0
2023-12-01 16:58:40,754:INFO::its now!!!!!!!!3
2023-12-01 16:58:40,786:INFO::its now!!!!!!!!5
2023-12-01 16:58:40,953:INFO::its now!!!!!!!!
2023-12-01 16:58:40,953:INFO::its now!!!!!!!! on 
2023-12-01 16:58:41,004:INFO::its now!!!!!!!!5
2023-12-01 16:58:41,197:INFO::Epoch 00102 | lr 0.00050 | Train_Loss 0.4574 | Train_Classification_Loss 0.5105 | Dmon_Loss -0.1062 | Val_Loss 0.6368 | Search Time(s) 0.3989 | Infer Time(s) 0.2130 | Time(s) 0.6119 
2023-12-01 16:58:41,244:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 0;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:41,245:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:41,249:INFO::Epoch: 103
tensor([[0.9880, 0.9950, 0.9864, 0.9906],
        [0.9874, 0.9951, 0.9915, 0.9864],
        [0.9839, 0.9933, 0.9850, 0.9919],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:41,249:INFO::its now!!!!!!!!5
2023-12-01 16:58:41,414:INFO::its now!!!!!!!!0
2023-12-01 16:58:41,415:INFO::its now!!!!!!!!3
2023-12-01 16:58:41,470:INFO::its now!!!!!!!!5
2023-12-01 16:58:41,664:INFO::its now!!!!!!!!
2023-12-01 16:58:41,664:INFO::its now!!!!!!!! on 
2023-12-01 16:58:41,719:INFO::its now!!!!!!!!5
2023-12-01 16:58:41,868:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:41,870:INFO::Epoch 00103 | lr 0.00050 | Train_Loss 0.4257 | Train_Classification_Loss 0.4809 | Dmon_Loss -0.1103 | Val_Loss 0.6170 | Search Time(s) 0.4703 | Infer Time(s) 0.1516 | Time(s) 0.6219 
2023-12-01 16:58:41,940:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 1;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 1;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:41,942:INFO::Validation loss decreased (0.623623 --> 0.617019).  Saving model ...
2023-12-01 16:58:41,946:INFO::Epoch: 104
tensor([[0.9914, 1.0000, 0.9932, 0.9968],
        [0.9904, 0.9999, 0.9980, 0.9932],
        [0.9905, 0.9983, 0.9879, 0.9984],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:41,947:INFO::its now!!!!!!!!5
2023-12-01 16:58:42,158:INFO::its now!!!!!!!!0
2023-12-01 16:58:42,159:INFO::its now!!!!!!!!3
2023-12-01 16:58:42,188:INFO::its now!!!!!!!!5
2023-12-01 16:58:42,368:INFO::its now!!!!!!!!
2023-12-01 16:58:42,368:INFO::its now!!!!!!!! on 
2023-12-01 16:58:42,424:INFO::its now!!!!!!!!5
2023-12-01 16:58:42,584:INFO::Epoch 00104 | lr 0.00050 | Train_Loss 0.4339 | Train_Classification_Loss 0.4887 | Dmon_Loss -0.1095 | Val_Loss 0.6183 | Search Time(s) 0.4779 | Infer Time(s) 0.1646 | Time(s) 0.6424 
2023-12-01 16:58:42,639:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:42,641:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:42,646:INFO::Epoch: 105
tensor([[0.9919, 1.0000, 0.9970, 0.9989],
        [0.9908, 1.0000, 1.0000, 0.9966],
        [0.9928, 0.9997, 0.9893, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:42,647:INFO::its now!!!!!!!!5
2023-12-01 16:58:42,791:INFO::its now!!!!!!!!0
2023-12-01 16:58:42,791:INFO::its now!!!!!!!!3
2023-12-01 16:58:42,839:INFO::its now!!!!!!!!5
2023-12-01 16:58:43,004:INFO::its now!!!!!!!!
2023-12-01 16:58:43,004:INFO::its now!!!!!!!! on 
2023-12-01 16:58:43,059:INFO::its now!!!!!!!!5
2023-12-01 16:58:43,223:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:43,224:INFO::Epoch 00105 | lr 0.00050 | Train_Loss 0.4138 | Train_Classification_Loss 0.4700 | Dmon_Loss -0.1123 | Val_Loss 0.6030 | Search Time(s) 0.4159 | Infer Time(s) 0.1662 | Time(s) 0.5821 
2023-12-01 16:58:43,272:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 1;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:43,273:INFO::Validation loss decreased (0.617019 --> 0.603014).  Saving model ...
2023-12-01 16:58:43,277:INFO::Epoch: 106
tensor([[0.9898, 1.0000, 0.9966, 0.9977],
        [0.9886, 1.0000, 0.9988, 0.9960],
        [0.9917, 0.9981, 0.9878, 1.0000],
        [1.0000, 0.9989, 1.0000, 0.9979]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:43,277:INFO::its now!!!!!!!!5
2023-12-01 16:58:43,449:INFO::its now!!!!!!!!0
2023-12-01 16:58:43,450:INFO::its now!!!!!!!!3
2023-12-01 16:58:43,498:INFO::its now!!!!!!!!5
2023-12-01 16:58:43,673:INFO::its now!!!!!!!!
2023-12-01 16:58:43,673:INFO::its now!!!!!!!! on 
2023-12-01 16:58:43,727:INFO::its now!!!!!!!!5
2023-12-01 16:58:43,893:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:43,895:INFO::Epoch 00106 | lr 0.00050 | Train_Loss 0.4125 | Train_Classification_Loss 0.4684 | Dmon_Loss -0.1118 | Val_Loss 0.6020 | Search Time(s) 0.4523 | Infer Time(s) 0.1672 | Time(s) 0.6196 
2023-12-01 16:58:43,940:INFO::cluster info:
0: 1;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 0;	26099: 3;	26100: 3;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:43,941:INFO::Validation loss decreased (0.603014 --> 0.601982).  Saving model ...
2023-12-01 16:58:43,943:INFO::Epoch: 107
tensor([[0.9857, 1.0000, 0.9936, 0.9945],
        [0.9847, 1.0000, 0.9954, 0.9929],
        [0.9884, 0.9944, 0.9841, 1.0000],
        [1.0000, 0.9957, 0.9973, 0.9940]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:43,943:INFO::its now!!!!!!!!5
2023-12-01 16:58:44,109:INFO::its now!!!!!!!!0
2023-12-01 16:58:44,109:INFO::its now!!!!!!!!3
2023-12-01 16:58:44,157:INFO::its now!!!!!!!!5
2023-12-01 16:58:44,345:INFO::its now!!!!!!!!
2023-12-01 16:58:44,345:INFO::its now!!!!!!!! on 
2023-12-01 16:58:44,401:INFO::its now!!!!!!!!5
2023-12-01 16:58:44,569:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:44,570:INFO::Epoch 00107 | lr 0.00050 | Train_Loss 0.3825 | Train_Classification_Loss 0.4403 | Dmon_Loss -0.1156 | Val_Loss 0.5862 | Search Time(s) 0.4589 | Infer Time(s) 0.1695 | Time(s) 0.6285 
2023-12-01 16:58:44,616:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 1;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:44,617:INFO::Validation loss decreased (0.601982 --> 0.586181).  Saving model ...
2023-12-01 16:58:44,620:INFO::Epoch: 108
tensor([[0.9864, 1.0000, 0.9946, 0.9953],
        [0.9853, 1.0000, 0.9962, 0.9939],
        [0.9892, 0.9952, 0.9849, 1.0000],
        [1.0000, 0.9965, 0.9986, 0.9946]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:44,621:INFO::its now!!!!!!!!5
2023-12-01 16:58:44,785:INFO::its now!!!!!!!!0
2023-12-01 16:58:44,786:INFO::its now!!!!!!!!3
2023-12-01 16:58:44,831:INFO::its now!!!!!!!!5
2023-12-01 16:58:44,997:INFO::its now!!!!!!!!
2023-12-01 16:58:44,997:INFO::its now!!!!!!!! on 
2023-12-01 16:58:45,055:INFO::its now!!!!!!!!5
2023-12-01 16:58:45,244:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:45,246:INFO::Epoch 00108 | lr 0.00050 | Train_Loss 0.3904 | Train_Classification_Loss 0.4478 | Dmon_Loss -0.1148 | Val_Loss 0.5834 | Search Time(s) 0.4348 | Infer Time(s) 0.1920 | Time(s) 0.6269 
2023-12-01 16:58:45,306:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 1;	24: 1;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:58:45,307:INFO::Validation loss decreased (0.586181 --> 0.583426).  Saving model ...
2023-12-01 16:58:45,310:INFO::Epoch: 109
tensor([[0.9872, 0.9986, 0.9936, 0.9941],
        [0.9840, 1.0000, 0.9951, 0.9928],
        [0.9896, 0.9939, 0.9837, 0.9985],
        [1.0000, 0.9954, 0.9976, 0.9933]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:45,310:INFO::its now!!!!!!!!5
2023-12-01 16:58:45,472:INFO::its now!!!!!!!!0
2023-12-01 16:58:45,472:INFO::its now!!!!!!!!3
2023-12-01 16:58:45,519:INFO::its now!!!!!!!!5
2023-12-01 16:58:45,673:INFO::its now!!!!!!!!
2023-12-01 16:58:45,673:INFO::its now!!!!!!!! on 
2023-12-01 16:58:45,727:INFO::its now!!!!!!!!5
2023-12-01 16:58:45,885:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:45,886:INFO::Epoch 00109 | lr 0.00050 | Train_Loss 0.3758 | Train_Classification_Loss 0.4347 | Dmon_Loss -0.1178 | Val_Loss 0.5715 | Search Time(s) 0.4179 | Infer Time(s) 0.1596 | Time(s) 0.5775 
2023-12-01 16:58:45,924:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 1;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 1;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:45,925:INFO::Validation loss decreased (0.583426 --> 0.571473).  Saving model ...
2023-12-01 16:58:45,928:INFO::Epoch: 110
tensor([[0.9885, 0.9981, 0.9939, 0.9944],
        [0.9842, 1.0000, 0.9953, 0.9931],
        [0.9906, 0.9942, 0.9839, 0.9978],
        [1.0000, 0.9957, 0.9979, 0.9935]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:45,928:INFO::its now!!!!!!!!5
2023-12-01 16:58:46,109:INFO::its now!!!!!!!!0
2023-12-01 16:58:46,110:INFO::its now!!!!!!!!3
2023-12-01 16:58:46,157:INFO::its now!!!!!!!!5
2023-12-01 16:58:46,323:INFO::its now!!!!!!!!
2023-12-01 16:58:46,323:INFO::its now!!!!!!!! on 
2023-12-01 16:58:46,380:INFO::its now!!!!!!!!5
2023-12-01 16:58:46,551:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:46,552:INFO::Epoch 00110 | lr 0.00050 | Train_Loss 0.3730 | Train_Classification_Loss 0.4315 | Dmon_Loss -0.1170 | Val_Loss 0.5669 | Search Time(s) 0.4529 | Infer Time(s) 0.1735 | Time(s) 0.6265 
2023-12-01 16:58:46,602:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:58:46,603:INFO::Validation loss decreased (0.571473 --> 0.566944).  Saving model ...
2023-12-01 16:58:46,606:INFO::Epoch: 111
tensor([[0.9901, 0.9980, 0.9949, 0.9953],
        [0.9852, 1.0000, 0.9963, 0.9941],
        [0.9920, 0.9952, 0.9849, 0.9974],
        [1.0000, 0.9966, 0.9990, 0.9945]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:46,606:INFO::its now!!!!!!!!5
2023-12-01 16:58:46,778:INFO::its now!!!!!!!!0
2023-12-01 16:58:46,779:INFO::its now!!!!!!!!3
2023-12-01 16:58:46,824:INFO::its now!!!!!!!!5
2023-12-01 16:58:47,002:INFO::its now!!!!!!!!
2023-12-01 16:58:47,002:INFO::its now!!!!!!!! on 
2023-12-01 16:58:47,052:INFO::its now!!!!!!!!5
2023-12-01 16:58:47,806:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:47,845:INFO::Epoch 00111 | lr 0.00050 | Train_Loss 0.3528 | Train_Classification_Loss 0.4130 | Dmon_Loss -0.1204 | Val_Loss 0.5564 | Search Time(s) 0.4299 | Infer Time(s) 0.7722 | Time(s) 1.2020 
2023-12-01 16:58:47,902:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 1;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:47,903:INFO::Validation loss decreased (0.566944 --> 0.556381).  Saving model ...
2023-12-01 16:58:47,906:INFO::Epoch: 112
tensor([[0.9933, 0.9982, 0.9976, 0.9980],
        [0.9880, 1.0000, 0.9991, 0.9969],
        [0.9950, 0.9980, 0.9877, 0.9972],
        [1.0000, 0.9993, 1.0000, 0.9972]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:47,906:INFO::its now!!!!!!!!5
2023-12-01 16:58:48,090:INFO::its now!!!!!!!!0
2023-12-01 16:58:48,091:INFO::its now!!!!!!!!3
2023-12-01 16:58:48,152:INFO::its now!!!!!!!!5
2023-12-01 16:58:48,347:INFO::its now!!!!!!!!
2023-12-01 16:58:48,347:INFO::its now!!!!!!!! on 
2023-12-01 16:58:48,403:INFO::its now!!!!!!!!5
2023-12-01 16:58:48,573:INFO::Epoch 00112 | lr 0.00050 | Train_Loss 0.3552 | Train_Classification_Loss 0.4134 | Dmon_Loss -0.1164 | Val_Loss 0.5597 | Search Time(s) 0.4968 | Infer Time(s) 0.1735 | Time(s) 0.6704 
2023-12-01 16:58:48,631:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 1;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 16:58:48,632:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:48,635:INFO::Epoch: 113
tensor([[0.9941, 0.9985, 0.9982, 0.9985],
        [0.9885, 1.0000, 0.9997, 0.9975],
        [0.9956, 0.9994, 0.9882, 0.9963],
        [1.0000, 0.9998, 1.0000, 0.9978]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:48,635:INFO::its now!!!!!!!!5
2023-12-01 16:58:48,788:INFO::its now!!!!!!!!0
2023-12-01 16:58:48,789:INFO::its now!!!!!!!!3
2023-12-01 16:58:48,834:INFO::its now!!!!!!!!5
2023-12-01 16:58:49,014:INFO::its now!!!!!!!!
2023-12-01 16:58:49,014:INFO::its now!!!!!!!! on 
2023-12-01 16:58:49,067:INFO::its now!!!!!!!!5
2023-12-01 16:58:49,211:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:49,213:INFO::Epoch 00113 | lr 0.00050 | Train_Loss 0.3313 | Train_Classification_Loss 0.3931 | Dmon_Loss -0.1237 | Val_Loss 0.5378 | Search Time(s) 0.4128 | Infer Time(s) 0.1661 | Time(s) 0.5789 
2023-12-01 16:58:49,251:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 1;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:49,252:INFO::Validation loss decreased (0.556381 --> 0.537772).  Saving model ...
2023-12-01 16:58:49,254:INFO::Epoch: 114
tensor([[0.9965, 1.0000, 1.0000, 0.9989],
        [0.9908, 1.0000, 1.0000, 0.9998],
        [0.9979, 1.0000, 0.9905, 0.9978],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:49,254:INFO::its now!!!!!!!!5
2023-12-01 16:58:49,422:INFO::its now!!!!!!!!0
2023-12-01 16:58:49,423:INFO::its now!!!!!!!!3
2023-12-01 16:58:49,472:INFO::its now!!!!!!!!5
2023-12-01 16:58:49,645:INFO::its now!!!!!!!!
2023-12-01 16:58:49,645:INFO::its now!!!!!!!! on 
2023-12-01 16:58:49,700:INFO::its now!!!!!!!!5
2023-12-01 16:58:49,855:INFO::Epoch 00114 | lr 0.00050 | Train_Loss 0.3291 | Train_Classification_Loss 0.3900 | Dmon_Loss -0.1218 | Val_Loss 0.5388 | Search Time(s) 0.4304 | Infer Time(s) 0.1725 | Time(s) 0.6030 
2023-12-01 16:58:49,916:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 3;	26127: 0;	
2023-12-01 16:58:49,918:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:58:49,921:INFO::Epoch: 115
tensor([[0.9993, 1.0000, 1.0000, 1.0000],
        [0.9935, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9931, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:49,921:INFO::its now!!!!!!!!5
2023-12-01 16:58:50,089:INFO::its now!!!!!!!!0
2023-12-01 16:58:50,090:INFO::its now!!!!!!!!3
2023-12-01 16:58:50,134:INFO::its now!!!!!!!!5
2023-12-01 16:58:50,281:INFO::its now!!!!!!!!
2023-12-01 16:58:50,281:INFO::its now!!!!!!!! on 
2023-12-01 16:58:50,332:INFO::its now!!!!!!!!5
2023-12-01 16:58:50,510:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:50,511:INFO::Epoch 00115 | lr 0.00050 | Train_Loss 0.2970 | Train_Classification_Loss 0.3609 | Dmon_Loss -0.1278 | Val_Loss 0.5128 | Search Time(s) 0.3941 | Infer Time(s) 0.1985 | Time(s) 0.5926 
2023-12-01 16:58:50,557:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:50,558:INFO::Validation loss decreased (0.537772 --> 0.512782).  Saving model ...
2023-12-01 16:58:50,749:INFO::Epoch: 116
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9947, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 0.9943, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:50,750:INFO::its now!!!!!!!!5
2023-12-01 16:58:51,107:INFO::its now!!!!!!!!0
2023-12-01 16:58:51,108:INFO::its now!!!!!!!!3
2023-12-01 16:58:51,152:INFO::its now!!!!!!!!5
2023-12-01 16:58:51,326:INFO::its now!!!!!!!!
2023-12-01 16:58:51,326:INFO::its now!!!!!!!! on 
2023-12-01 16:58:51,379:INFO::its now!!!!!!!!5
2023-12-01 16:58:51,545:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:51,548:INFO::Epoch 00116 | lr 0.00050 | Train_Loss 0.2816 | Train_Classification_Loss 0.3467 | Dmon_Loss -0.1303 | Val_Loss 0.5067 | Search Time(s) 0.8030 | Infer Time(s) 0.1825 | Time(s) 0.9855 
2023-12-01 16:58:51,616:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:51,617:INFO::Validation loss decreased (0.512782 --> 0.506652).  Saving model ...
2023-12-01 16:58:51,619:INFO::Epoch: 117
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9950, 1.0000, 0.9999, 1.0000],
        [1.0000, 0.9997, 0.9946, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:51,620:INFO::its now!!!!!!!!5
2023-12-01 16:58:51,782:INFO::its now!!!!!!!!0
2023-12-01 16:58:51,783:INFO::its now!!!!!!!!3
2023-12-01 16:58:51,827:INFO::its now!!!!!!!!5
2023-12-01 16:58:52,015:INFO::its now!!!!!!!!
2023-12-01 16:58:52,015:INFO::its now!!!!!!!! on 
2023-12-01 16:58:52,067:INFO::its now!!!!!!!!5
2023-12-01 16:58:52,237:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:52,238:INFO::Epoch 00117 | lr 0.00050 | Train_Loss 0.2776 | Train_Classification_Loss 0.3434 | Dmon_Loss -0.1314 | Val_Loss 0.5003 | Search Time(s) 0.4328 | Infer Time(s) 0.1860 | Time(s) 0.6189 
2023-12-01 16:58:52,287:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:52,288:INFO::Validation loss decreased (0.506652 --> 0.500295).  Saving model ...
2023-12-01 16:58:52,292:INFO::Epoch: 118
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9951, 1.0000, 1.0000, 1.0000],
        [1.0000, 0.9996, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9999]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:52,293:INFO::its now!!!!!!!!5
2023-12-01 16:58:52,453:INFO::its now!!!!!!!!0
2023-12-01 16:58:52,453:INFO::its now!!!!!!!!3
2023-12-01 16:58:52,498:INFO::its now!!!!!!!!5
2023-12-01 16:58:52,698:INFO::its now!!!!!!!!
2023-12-01 16:58:52,698:INFO::its now!!!!!!!! on 
2023-12-01 16:58:52,748:INFO::its now!!!!!!!!5
2023-12-01 16:58:52,955:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:52,956:INFO::Epoch 00118 | lr 0.00050 | Train_Loss 0.2734 | Train_Classification_Loss 0.3398 | Dmon_Loss -0.1327 | Val_Loss 0.4929 | Search Time(s) 0.4414 | Infer Time(s) 0.2244 | Time(s) 0.6658 
2023-12-01 16:58:53,014:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 1;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:53,015:INFO::Validation loss decreased (0.500295 --> 0.492941).  Saving model ...
2023-12-01 16:58:53,018:INFO::Epoch: 119
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9976, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:53,018:INFO::its now!!!!!!!!5
2023-12-01 16:58:53,216:INFO::its now!!!!!!!!0
2023-12-01 16:58:53,217:INFO::its now!!!!!!!!3
2023-12-01 16:58:53,261:INFO::its now!!!!!!!!5
2023-12-01 16:58:53,435:INFO::its now!!!!!!!!
2023-12-01 16:58:53,435:INFO::its now!!!!!!!! on 
2023-12-01 16:58:53,486:INFO::its now!!!!!!!!5
2023-12-01 16:58:53,624:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:53,625:INFO::Epoch 00119 | lr 0.00050 | Train_Loss 0.2595 | Train_Classification_Loss 0.3269 | Dmon_Loss -0.1347 | Val_Loss 0.4864 | Search Time(s) 0.4529 | Infer Time(s) 0.1566 | Time(s) 0.6095 
2023-12-01 16:58:53,690:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 1;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:53,691:INFO::Validation loss decreased (0.492941 --> 0.486402).  Saving model ...
2023-12-01 16:58:53,694:INFO::Epoch: 120
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9955, 1.0000, 1.0000, 1.0000],
        [0.9997, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9979]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:53,695:INFO::its now!!!!!!!!5
2023-12-01 16:58:53,870:INFO::its now!!!!!!!!0
2023-12-01 16:58:53,871:INFO::its now!!!!!!!!3
2023-12-01 16:58:53,917:INFO::its now!!!!!!!!5
2023-12-01 16:58:54,449:INFO::its now!!!!!!!!
2023-12-01 16:58:54,449:INFO::its now!!!!!!!! on 
2023-12-01 16:58:54,507:INFO::its now!!!!!!!!5
2023-12-01 16:58:54,671:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:54,673:INFO::Epoch 00120 | lr 0.00050 | Train_Loss 0.2542 | Train_Classification_Loss 0.3215 | Dmon_Loss -0.1346 | Val_Loss 0.4807 | Search Time(s) 0.7980 | Infer Time(s) 0.1813 | Time(s) 0.9793 
2023-12-01 16:58:54,736:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 1;	32: 0;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:54,737:INFO::Validation loss decreased (0.486402 --> 0.480694).  Saving model ...
2023-12-01 16:58:54,742:INFO::Epoch: 121
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9944, 1.0000, 1.0000, 1.0000],
        [0.9995, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9968]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:54,743:INFO::its now!!!!!!!!5
2023-12-01 16:58:54,939:INFO::its now!!!!!!!!0
2023-12-01 16:58:54,940:INFO::its now!!!!!!!!3
2023-12-01 16:58:54,983:INFO::its now!!!!!!!!5
2023-12-01 16:58:55,149:INFO::its now!!!!!!!!
2023-12-01 16:58:55,149:INFO::its now!!!!!!!! on 
2023-12-01 16:58:55,199:INFO::its now!!!!!!!!5
2023-12-01 16:58:55,367:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:55,368:INFO::Epoch 00121 | lr 0.00050 | Train_Loss 0.2425 | Train_Classification_Loss 0.3110 | Dmon_Loss -0.1370 | Val_Loss 0.4744 | Search Time(s) 0.4444 | Infer Time(s) 0.1841 | Time(s) 0.6284 
2023-12-01 16:58:55,424:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 1;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 1;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:55,425:INFO::Validation loss decreased (0.480694 --> 0.474402).  Saving model ...
2023-12-01 16:58:55,427:INFO::Epoch: 122
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9944, 1.0000, 1.0000, 1.0000],
        [0.9999, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9967]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:55,428:INFO::its now!!!!!!!!5
2023-12-01 16:58:55,597:INFO::its now!!!!!!!!0
2023-12-01 16:58:55,598:INFO::its now!!!!!!!!3
2023-12-01 16:58:55,641:INFO::its now!!!!!!!!5
2023-12-01 16:58:55,821:INFO::its now!!!!!!!!
2023-12-01 16:58:55,821:INFO::its now!!!!!!!! on 
2023-12-01 16:58:55,874:INFO::its now!!!!!!!!5
2023-12-01 16:58:56,056:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:56,057:INFO::Epoch 00122 | lr 0.00050 | Train_Loss 0.2389 | Train_Classification_Loss 0.3078 | Dmon_Loss -0.1377 | Val_Loss 0.4691 | Search Time(s) 0.4338 | Infer Time(s) 0.1965 | Time(s) 0.6303 
2023-12-01 16:58:56,111:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:56,112:INFO::Validation loss decreased (0.474402 --> 0.469147).  Saving model ...
2023-12-01 16:58:56,114:INFO::Epoch: 123
tensor([[1.0000, 1.0000, 1.0000, 1.0000],
        [0.9944, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 1.0000],
        [1.0000, 1.0000, 1.0000, 0.9967]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:56,115:INFO::its now!!!!!!!!5
2023-12-01 16:58:56,282:INFO::its now!!!!!!!!0
2023-12-01 16:58:56,282:INFO::its now!!!!!!!!3
2023-12-01 16:58:56,325:INFO::its now!!!!!!!!5
2023-12-01 16:58:56,513:INFO::its now!!!!!!!!
2023-12-01 16:58:56,513:INFO::its now!!!!!!!! on 
2023-12-01 16:58:56,562:INFO::its now!!!!!!!!5
2023-12-01 16:58:56,719:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:56,721:INFO::Epoch 00123 | lr 0.00050 | Train_Loss 0.2331 | Train_Classification_Loss 0.3034 | Dmon_Loss -0.1405 | Val_Loss 0.4636 | Search Time(s) 0.4334 | Infer Time(s) 0.1735 | Time(s) 0.6069 
2023-12-01 16:58:56,787:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 1;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:57,108:INFO::Validation loss decreased (0.469147 --> 0.463623).  Saving model ...
2023-12-01 16:58:57,113:INFO::Epoch: 124
tensor([[1.0000, 0.9985, 0.9986, 0.9985],
        [0.9926, 1.0000, 0.9986, 0.9986],
        [1.0000, 0.9983, 0.9986, 0.9986],
        [1.0000, 0.9986, 0.9986, 0.9950]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:57,114:INFO::its now!!!!!!!!5
2023-12-01 16:58:57,454:INFO::its now!!!!!!!!0
2023-12-01 16:58:57,455:INFO::its now!!!!!!!!3
2023-12-01 16:58:57,501:INFO::its now!!!!!!!!5
2023-12-01 16:58:57,673:INFO::its now!!!!!!!!
2023-12-01 16:58:57,673:INFO::its now!!!!!!!! on 
2023-12-01 16:58:57,726:INFO::its now!!!!!!!!5
2023-12-01 16:58:57,904:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:57,905:INFO::Epoch 00124 | lr 0.00050 | Train_Loss 0.2222 | Train_Classification_Loss 0.2932 | Dmon_Loss -0.1420 | Val_Loss 0.4586 | Search Time(s) 0.6011 | Infer Time(s) 0.1955 | Time(s) 0.7965 
2023-12-01 16:58:57,943:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:57,944:INFO::Validation loss decreased (0.463623 --> 0.458628).  Saving model ...
2023-12-01 16:58:57,947:INFO::Epoch: 125
tensor([[1.0000, 0.9983, 0.9983, 0.9983],
        [0.9923, 1.0000, 0.9983, 0.9983],
        [1.0000, 0.9979, 0.9983, 0.9983],
        [1.0000, 0.9984, 0.9983, 0.9946]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:57,948:INFO::its now!!!!!!!!5
2023-12-01 16:58:58,120:INFO::its now!!!!!!!!0
2023-12-01 16:58:58,120:INFO::its now!!!!!!!!3
2023-12-01 16:58:58,164:INFO::its now!!!!!!!!5
2023-12-01 16:58:58,375:INFO::its now!!!!!!!!
2023-12-01 16:58:58,375:INFO::its now!!!!!!!! on 
2023-12-01 16:58:58,435:INFO::its now!!!!!!!!5
2023-12-01 16:58:58,621:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:58,623:INFO::Epoch 00125 | lr 0.00050 | Train_Loss 0.2050 | Train_Classification_Loss 0.2766 | Dmon_Loss -0.1432 | Val_Loss 0.4529 | Search Time(s) 0.4728 | Infer Time(s) 0.2045 | Time(s) 0.6773 
2023-12-01 16:58:58,681:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:58,682:INFO::Validation loss decreased (0.458628 --> 0.452889).  Saving model ...
2023-12-01 16:58:58,685:INFO::Epoch: 126
tensor([[1.0000, 0.9984, 0.9985, 0.9984],
        [0.9923, 1.0000, 0.9984, 0.9984],
        [1.0000, 0.9980, 0.9984, 0.9984],
        [1.0000, 0.9985, 0.9984, 0.9947]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:58,686:INFO::its now!!!!!!!!5
2023-12-01 16:58:58,852:INFO::its now!!!!!!!!0
2023-12-01 16:58:58,852:INFO::its now!!!!!!!!3
2023-12-01 16:58:58,894:INFO::its now!!!!!!!!5
2023-12-01 16:58:59,077:INFO::its now!!!!!!!!
2023-12-01 16:58:59,077:INFO::its now!!!!!!!! on 
2023-12-01 16:58:59,128:INFO::its now!!!!!!!!5
2023-12-01 16:58:59,285:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:59,286:INFO::Epoch 00126 | lr 0.00050 | Train_Loss 0.1962 | Train_Classification_Loss 0.2689 | Dmon_Loss -0.1455 | Val_Loss 0.4480 | Search Time(s) 0.4320 | Infer Time(s) 0.1705 | Time(s) 0.6025 
2023-12-01 16:58:59,337:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:59,338:INFO::Validation loss decreased (0.452889 --> 0.447982).  Saving model ...
2023-12-01 16:58:59,341:INFO::Epoch: 127
tensor([[1.0000, 0.9961, 0.9963, 0.9961],
        [0.9899, 1.0000, 0.9962, 0.9962],
        [1.0000, 0.9955, 0.9962, 0.9962],
        [1.0000, 0.9964, 0.9962, 0.9923]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:59,342:INFO::its now!!!!!!!!5
2023-12-01 16:58:59,509:INFO::its now!!!!!!!!0
2023-12-01 16:58:59,510:INFO::its now!!!!!!!!3
2023-12-01 16:58:59,552:INFO::its now!!!!!!!!5
2023-12-01 16:58:59,737:INFO::its now!!!!!!!!
2023-12-01 16:58:59,737:INFO::its now!!!!!!!! on 
2023-12-01 16:58:59,789:INFO::its now!!!!!!!!5
2023-12-01 16:58:59,935:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:58:59,937:INFO::Epoch 00127 | lr 0.00050 | Train_Loss 0.2023 | Train_Classification_Loss 0.2751 | Dmon_Loss -0.1456 | Val_Loss 0.4430 | Search Time(s) 0.4319 | Infer Time(s) 0.1645 | Time(s) 0.5964 
2023-12-01 16:58:59,985:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 0;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:58:59,987:INFO::Validation loss decreased (0.447982 --> 0.442950).  Saving model ...
2023-12-01 16:58:59,989:INFO::Epoch: 128
tensor([[1.0000, 0.9928, 0.9930, 0.9927],
        [0.9863, 1.0000, 0.9929, 0.9929],
        [1.0000, 0.9919, 0.9930, 0.9928],
        [1.0000, 0.9933, 0.9929, 0.9887]], device='cuda:0', requires_grad=True)
2023-12-01 16:58:59,989:INFO::its now!!!!!!!!5
2023-12-01 16:59:00,138:INFO::its now!!!!!!!!0
2023-12-01 16:59:00,139:INFO::its now!!!!!!!!3
2023-12-01 16:59:00,183:INFO::its now!!!!!!!!5
2023-12-01 16:59:00,370:INFO::its now!!!!!!!!
2023-12-01 16:59:00,370:INFO::its now!!!!!!!! on 
2023-12-01 16:59:00,423:INFO::its now!!!!!!!!5
2023-12-01 16:59:00,584:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:00,586:INFO::Epoch 00128 | lr 0.00050 | Train_Loss 0.1983 | Train_Classification_Loss 0.2714 | Dmon_Loss -0.1462 | Val_Loss 0.4382 | Search Time(s) 0.4151 | Infer Time(s) 0.1815 | Time(s) 0.5966 
2023-12-01 16:59:00,629:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:00,630:INFO::Validation loss decreased (0.442950 --> 0.438180).  Saving model ...
2023-12-01 16:59:00,632:INFO::Epoch: 129
tensor([[1.0000, 0.9914, 0.9916, 0.9912],
        [0.9847, 1.0000, 0.9916, 0.9915],
        [1.0000, 0.9903, 0.9916, 0.9914],
        [1.0000, 0.9919, 0.9915, 0.9872]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:00,633:INFO::its now!!!!!!!!5
2023-12-01 16:59:00,791:INFO::its now!!!!!!!!0
2023-12-01 16:59:00,792:INFO::its now!!!!!!!!3
2023-12-01 16:59:00,834:INFO::its now!!!!!!!!5
2023-12-01 16:59:00,989:INFO::its now!!!!!!!!
2023-12-01 16:59:00,990:INFO::its now!!!!!!!! on 
2023-12-01 16:59:01,041:INFO::its now!!!!!!!!5
2023-12-01 16:59:01,235:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:01,237:INFO::Epoch 00129 | lr 0.00050 | Train_Loss 0.1873 | Train_Classification_Loss 0.2613 | Dmon_Loss -0.1480 | Val_Loss 0.4340 | Search Time(s) 0.3999 | Infer Time(s) 0.2050 | Time(s) 0.6050 
2023-12-01 16:59:01,287:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:01,287:INFO::Validation loss decreased (0.438180 --> 0.434037).  Saving model ...
2023-12-01 16:59:01,290:INFO::Epoch: 130
tensor([[1.0000, 0.9906, 0.9909, 0.9904],
        [0.9839, 1.0000, 0.9908, 0.9907],
        [1.0000, 0.9895, 0.9908, 0.9906],
        [1.0000, 0.9912, 0.9908, 0.9864]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:01,290:INFO::its now!!!!!!!!5
2023-12-01 16:59:01,447:INFO::its now!!!!!!!!0
2023-12-01 16:59:01,448:INFO::its now!!!!!!!!3
2023-12-01 16:59:01,491:INFO::its now!!!!!!!!5
2023-12-01 16:59:01,647:INFO::its now!!!!!!!!
2023-12-01 16:59:01,647:INFO::its now!!!!!!!! on 
2023-12-01 16:59:01,698:INFO::its now!!!!!!!!5
2023-12-01 16:59:01,850:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:01,851:INFO::Epoch 00130 | lr 0.00050 | Train_Loss 0.1755 | Train_Classification_Loss 0.2506 | Dmon_Loss -0.1501 | Val_Loss 0.4295 | Search Time(s) 0.3945 | Infer Time(s) 0.1676 | Time(s) 0.5621 
2023-12-01 16:59:01,897:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 1;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 1;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:01,898:INFO::Validation loss decreased (0.434037 --> 0.429534).  Saving model ...
2023-12-01 16:59:01,901:INFO::Epoch: 131
tensor([[1.0000, 0.9890, 0.9893, 0.9888],
        [0.9822, 1.0000, 0.9892, 0.9892],
        [1.0000, 0.9877, 0.9892, 0.9890],
        [1.0000, 0.9897, 0.9892, 0.9847]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:01,901:INFO::its now!!!!!!!!5
2023-12-01 16:59:02,041:INFO::its now!!!!!!!!0
2023-12-01 16:59:02,042:INFO::its now!!!!!!!!3
2023-12-01 16:59:02,084:INFO::its now!!!!!!!!5
2023-12-01 16:59:02,252:INFO::its now!!!!!!!!
2023-12-01 16:59:02,252:INFO::its now!!!!!!!! on 
2023-12-01 16:59:02,303:INFO::its now!!!!!!!!5
2023-12-01 16:59:02,476:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:02,478:INFO::Epoch 00131 | lr 0.00050 | Train_Loss 0.1695 | Train_Classification_Loss 0.2446 | Dmon_Loss -0.1502 | Val_Loss 0.4253 | Search Time(s) 0.3883 | Infer Time(s) 0.1905 | Time(s) 0.5788 
2023-12-01 16:59:02,530:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:02,531:INFO::Validation loss decreased (0.429534 --> 0.425255).  Saving model ...
2023-12-01 16:59:02,533:INFO::Epoch: 132
tensor([[1.0000, 0.9855, 0.9860, 0.9853],
        [0.9784, 1.0000, 0.9859, 0.9858],
        [1.0000, 0.9840, 0.9859, 0.9856],
        [1.0000, 0.9865, 0.9858, 0.9810]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:02,534:INFO::its now!!!!!!!!5
2023-12-01 16:59:02,696:INFO::its now!!!!!!!!0
2023-12-01 16:59:02,697:INFO::its now!!!!!!!!3
2023-12-01 16:59:02,739:INFO::its now!!!!!!!!5
2023-12-01 16:59:02,924:INFO::its now!!!!!!!!
2023-12-01 16:59:02,924:INFO::its now!!!!!!!! on 
2023-12-01 16:59:02,975:INFO::its now!!!!!!!!5
2023-12-01 16:59:03,134:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:03,136:INFO::Epoch 00132 | lr 0.00050 | Train_Loss 0.1591 | Train_Classification_Loss 0.2354 | Dmon_Loss -0.1526 | Val_Loss 0.4213 | Search Time(s) 0.4259 | Infer Time(s) 0.1771 | Time(s) 0.6030 
2023-12-01 16:59:03,188:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 1;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:03,189:INFO::Validation loss decreased (0.425255 --> 0.421348).  Saving model ...
2023-12-01 16:59:03,193:INFO::Epoch: 133
tensor([[1.0000, 0.9825, 0.9830, 0.9821],
        [0.9752, 1.0000, 0.9829, 0.9828],
        [1.0000, 0.9806, 0.9829, 0.9826],
        [1.0000, 0.9836, 0.9828, 0.9778]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:03,193:INFO::its now!!!!!!!!5
2023-12-01 16:59:03,362:INFO::its now!!!!!!!!0
2023-12-01 16:59:03,363:INFO::its now!!!!!!!!3
2023-12-01 16:59:03,407:INFO::its now!!!!!!!!5
2023-12-01 16:59:03,572:INFO::its now!!!!!!!!
2023-12-01 16:59:03,572:INFO::its now!!!!!!!! on 
2023-12-01 16:59:03,624:INFO::its now!!!!!!!!5
2023-12-01 16:59:03,810:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:03,812:INFO::Epoch 00133 | lr 0.00050 | Train_Loss 0.1578 | Train_Classification_Loss 0.2349 | Dmon_Loss -0.1540 | Val_Loss 0.4174 | Search Time(s) 0.4165 | Infer Time(s) 0.2045 | Time(s) 0.6209 
2023-12-01 16:59:03,880:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:03,882:INFO::Validation loss decreased (0.421348 --> 0.417356).  Saving model ...
2023-12-01 16:59:03,885:INFO::Epoch: 134
tensor([[1.0000, 0.9809, 0.9829, 0.9820],
        [0.9735, 1.0000, 0.9828, 0.9827],
        [1.0000, 0.9805, 0.9828, 0.9825],
        [1.0000, 0.9816, 0.9827, 0.9777]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:03,886:INFO::its now!!!!!!!!5
2023-12-01 16:59:04,063:INFO::its now!!!!!!!!0
2023-12-01 16:59:04,064:INFO::its now!!!!!!!!3
2023-12-01 16:59:04,107:INFO::its now!!!!!!!!5
2023-12-01 16:59:04,270:INFO::its now!!!!!!!!
2023-12-01 16:59:04,270:INFO::its now!!!!!!!! on 
2023-12-01 16:59:04,322:INFO::its now!!!!!!!!5
2023-12-01 16:59:04,493:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:04,495:INFO::Epoch 00134 | lr 0.00050 | Train_Loss 0.1506 | Train_Classification_Loss 0.2282 | Dmon_Loss -0.1552 | Val_Loss 0.4135 | Search Time(s) 0.4210 | Infer Time(s) 0.1905 | Time(s) 0.6115 
2023-12-01 16:59:04,535:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:04,536:INFO::Validation loss decreased (0.417356 --> 0.413465).  Saving model ...
2023-12-01 16:59:04,540:INFO::Epoch: 135
tensor([[1.0000, 0.9804, 0.9832, 0.9823],
        [0.9730, 1.0000, 0.9830, 0.9829],
        [1.0000, 0.9808, 0.9830, 0.9827],
        [1.0000, 0.9809, 0.9829, 0.9779]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:04,540:INFO::its now!!!!!!!!5
2023-12-01 16:59:04,692:INFO::its now!!!!!!!!0
2023-12-01 16:59:04,693:INFO::its now!!!!!!!!3
2023-12-01 16:59:04,736:INFO::its now!!!!!!!!5
2023-12-01 16:59:04,891:INFO::its now!!!!!!!!
2023-12-01 16:59:04,891:INFO::its now!!!!!!!! on 
2023-12-01 16:59:04,943:INFO::its now!!!!!!!!5
2023-12-01 16:59:05,088:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:05,090:INFO::Epoch 00135 | lr 0.00050 | Train_Loss 0.1530 | Train_Classification_Loss 0.2315 | Dmon_Loss -0.1571 | Val_Loss 0.4096 | Search Time(s) 0.3890 | Infer Time(s) 0.1625 | Time(s) 0.5515 
2023-12-01 16:59:05,127:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:05,128:INFO::Validation loss decreased (0.413465 --> 0.409585).  Saving model ...
2023-12-01 16:59:05,131:INFO::Epoch: 136
tensor([[1.0000, 0.9787, 0.9819, 0.9810],
        [0.9712, 1.0000, 0.9818, 0.9817],
        [1.0000, 0.9794, 0.9818, 0.9815],
        [1.0000, 0.9792, 0.9817, 0.9766]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:05,131:INFO::its now!!!!!!!!5
2023-12-01 16:59:05,275:INFO::its now!!!!!!!!0
2023-12-01 16:59:05,276:INFO::its now!!!!!!!!3
2023-12-01 16:59:05,319:INFO::its now!!!!!!!!5
2023-12-01 16:59:05,517:INFO::its now!!!!!!!!
2023-12-01 16:59:05,517:INFO::its now!!!!!!!! on 
2023-12-01 16:59:05,569:INFO::its now!!!!!!!!5
2023-12-01 16:59:05,717:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:05,718:INFO::Epoch 00136 | lr 0.00050 | Train_Loss 0.1395 | Train_Classification_Loss 0.2189 | Dmon_Loss -0.1588 | Val_Loss 0.4064 | Search Time(s) 0.4224 | Infer Time(s) 0.1656 | Time(s) 0.5880 
2023-12-01 16:59:05,769:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:05,770:INFO::Validation loss decreased (0.409585 --> 0.406373).  Saving model ...
2023-12-01 16:59:05,773:INFO::Epoch: 137
tensor([[1.0000, 0.9776, 0.9810, 0.9801],
        [0.9701, 1.0000, 0.9809, 0.9808],
        [1.0000, 0.9784, 0.9809, 0.9805],
        [1.0000, 0.9781, 0.9808, 0.9756]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:05,774:INFO::its now!!!!!!!!5
2023-12-01 16:59:05,961:INFO::its now!!!!!!!!0
2023-12-01 16:59:05,961:INFO::its now!!!!!!!!3
2023-12-01 16:59:06,005:INFO::its now!!!!!!!!5
2023-12-01 16:59:06,153:INFO::its now!!!!!!!!
2023-12-01 16:59:06,153:INFO::its now!!!!!!!! on 
2023-12-01 16:59:06,206:INFO::its now!!!!!!!!5
2023-12-01 16:59:06,364:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:06,365:INFO::Epoch 00137 | lr 0.00050 | Train_Loss 0.1371 | Train_Classification_Loss 0.2168 | Dmon_Loss -0.1594 | Val_Loss 0.4045 | Search Time(s) 0.4145 | Infer Time(s) 0.1781 | Time(s) 0.5926 
2023-12-01 16:59:06,409:INFO::cluster info:
0: 0;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:06,413:INFO::Validation loss decreased (0.406373 --> 0.404499).  Saving model ...
2023-12-01 16:59:06,419:INFO::Epoch: 138
tensor([[1.0000, 0.9735, 0.9772, 0.9760],
        [0.9657, 1.0000, 0.9770, 0.9769],
        [1.0000, 0.9741, 0.9770, 0.9766],
        [1.0000, 0.9743, 0.9769, 0.9714]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:06,420:INFO::its now!!!!!!!!5
2023-12-01 16:59:06,586:INFO::its now!!!!!!!!0
2023-12-01 16:59:06,587:INFO::its now!!!!!!!!3
2023-12-01 16:59:06,630:INFO::its now!!!!!!!!5
2023-12-01 16:59:06,798:INFO::its now!!!!!!!!
2023-12-01 16:59:06,798:INFO::its now!!!!!!!! on 
2023-12-01 16:59:06,848:INFO::its now!!!!!!!!5
2023-12-01 16:59:07,003:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:07,005:INFO::Epoch 00138 | lr 0.00050 | Train_Loss 0.1427 | Train_Classification_Loss 0.2226 | Dmon_Loss -0.1599 | Val_Loss 0.3998 | Search Time(s) 0.4169 | Infer Time(s) 0.1725 | Time(s) 0.5894 
2023-12-01 16:59:07,048:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:07,049:INFO::Validation loss decreased (0.404499 --> 0.399787).  Saving model ...
2023-12-01 16:59:07,052:INFO::Epoch: 139
tensor([[1.0000, 0.9714, 0.9751, 0.9738],
        [0.9634, 1.0000, 0.9750, 0.9748],
        [1.0000, 0.9718, 0.9749, 0.9745],
        [1.0000, 0.9723, 0.9748, 0.9692]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:07,053:INFO::its now!!!!!!!!5
2023-12-01 16:59:07,208:INFO::its now!!!!!!!!0
2023-12-01 16:59:07,209:INFO::its now!!!!!!!!3
2023-12-01 16:59:07,252:INFO::its now!!!!!!!!5
2023-12-01 16:59:07,433:INFO::its now!!!!!!!!
2023-12-01 16:59:07,433:INFO::its now!!!!!!!! on 
2023-12-01 16:59:07,492:INFO::its now!!!!!!!!5
2023-12-01 16:59:07,645:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:07,647:INFO::Epoch 00139 | lr 0.00050 | Train_Loss 0.1209 | Train_Classification_Loss 0.2021 | Dmon_Loss -0.1623 | Val_Loss 0.3970 | Search Time(s) 0.4231 | Infer Time(s) 0.1735 | Time(s) 0.5966 
2023-12-01 16:59:07,687:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:07,689:INFO::Validation loss decreased (0.399787 --> 0.396957).  Saving model ...
2023-12-01 16:59:07,692:INFO::Epoch: 140
tensor([[1.0000, 0.9689, 0.9727, 0.9713],
        [0.9607, 1.0000, 0.9725, 0.9724],
        [1.0000, 0.9691, 0.9725, 0.9721],
        [1.0000, 0.9699, 0.9724, 0.9666]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:07,693:INFO::its now!!!!!!!!5
2023-12-01 16:59:07,849:INFO::its now!!!!!!!!0
2023-12-01 16:59:07,850:INFO::its now!!!!!!!!3
2023-12-01 16:59:07,896:INFO::its now!!!!!!!!5
2023-12-01 16:59:08,070:INFO::its now!!!!!!!!
2023-12-01 16:59:08,070:INFO::its now!!!!!!!! on 
2023-12-01 16:59:08,122:INFO::its now!!!!!!!!5
2023-12-01 16:59:08,305:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:08,307:INFO::Epoch 00140 | lr 0.00050 | Train_Loss 0.1209 | Train_Classification_Loss 0.2024 | Dmon_Loss -0.1629 | Val_Loss 0.3940 | Search Time(s) 0.4165 | Infer Time(s) 0.1990 | Time(s) 0.6155 
2023-12-01 16:59:08,358:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:08,360:INFO::Validation loss decreased (0.396957 --> 0.394018).  Saving model ...
2023-12-01 16:59:08,362:INFO::Epoch: 141
tensor([[1.0000, 0.9675, 0.9793, 0.9782],
        [0.9679, 1.0000, 0.9713, 0.9790],
        [1.0000, 0.9764, 0.9713, 0.9787],
        [1.0000, 0.9762, 0.9790, 0.9649]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:08,363:INFO::its now!!!!!!!!5
2023-12-01 16:59:08,498:INFO::its now!!!!!!!!0
2023-12-01 16:59:08,499:INFO::its now!!!!!!!!3
2023-12-01 16:59:08,543:INFO::its now!!!!!!!!5
2023-12-01 16:59:08,774:INFO::its now!!!!!!!!
2023-12-01 16:59:08,775:INFO::its now!!!!!!!! on 
2023-12-01 16:59:08,826:INFO::its now!!!!!!!!5
2023-12-01 16:59:09,005:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:09,007:INFO::Epoch 00141 | lr 0.00050 | Train_Loss 0.1168 | Train_Classification_Loss 0.1991 | Dmon_Loss -0.1646 | Val_Loss 0.3911 | Search Time(s) 0.4468 | Infer Time(s) 0.1985 | Time(s) 0.6453 
2023-12-01 16:59:09,070:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:09,071:INFO::Validation loss decreased (0.394018 --> 0.391148).  Saving model ...
2023-12-01 16:59:09,075:INFO::Epoch: 142
tensor([[1.0000, 0.9657, 0.9816, 0.9807],
        [0.9705, 1.0000, 0.9698, 0.9814],
        [1.0000, 0.9790, 0.9698, 0.9812],
        [1.0000, 0.9785, 0.9814, 0.9631]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:09,077:INFO::its now!!!!!!!!5
2023-12-01 16:59:09,284:INFO::its now!!!!!!!!0
2023-12-01 16:59:09,285:INFO::its now!!!!!!!!3
2023-12-01 16:59:09,328:INFO::its now!!!!!!!!5
2023-12-01 16:59:09,509:INFO::its now!!!!!!!!
2023-12-01 16:59:09,509:INFO::its now!!!!!!!! on 
2023-12-01 16:59:09,560:INFO::its now!!!!!!!!5
2023-12-01 16:59:09,743:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:09,744:INFO::Epoch 00142 | lr 0.00050 | Train_Loss 0.1114 | Train_Classification_Loss 0.1945 | Dmon_Loss -0.1662 | Val_Loss 0.3883 | Search Time(s) 0.4679 | Infer Time(s) 0.2025 | Time(s) 0.6704 
2023-12-01 16:59:09,789:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:09,791:INFO::Validation loss decreased (0.391148 --> 0.388313).  Saving model ...
2023-12-01 16:59:09,794:INFO::Epoch: 143
tensor([[1.0000, 0.9655, 0.9834, 0.9825],
        [0.9724, 1.0000, 0.9696, 0.9832],
        [1.0000, 0.9810, 0.9696, 0.9830],
        [1.0000, 0.9802, 0.9832, 0.9628]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:09,794:INFO::its now!!!!!!!!5
2023-12-01 16:59:09,966:INFO::its now!!!!!!!!0
2023-12-01 16:59:09,967:INFO::its now!!!!!!!!3
2023-12-01 16:59:10,012:INFO::its now!!!!!!!!5
2023-12-01 16:59:10,175:INFO::its now!!!!!!!!
2023-12-01 16:59:10,175:INFO::its now!!!!!!!! on 
2023-12-01 16:59:10,228:INFO::its now!!!!!!!!5
2023-12-01 16:59:10,419:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:10,420:INFO::Epoch 00143 | lr 0.00050 | Train_Loss 0.1108 | Train_Classification_Loss 0.1941 | Dmon_Loss -0.1667 | Val_Loss 0.3855 | Search Time(s) 0.4174 | Infer Time(s) 0.2100 | Time(s) 0.6274 
2023-12-01 16:59:10,466:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:10,467:INFO::Validation loss decreased (0.388313 --> 0.385546).  Saving model ...
2023-12-01 16:59:10,470:INFO::Epoch: 144
tensor([[1.0000, 0.9630, 0.9820, 0.9810],
        [0.9709, 1.0000, 0.9671, 0.9818],
        [1.0000, 0.9794, 0.9671, 0.9815],
        [1.0000, 0.9789, 0.9818, 0.9601]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:10,471:INFO::its now!!!!!!!!5
2023-12-01 16:59:10,624:INFO::its now!!!!!!!!0
2023-12-01 16:59:10,624:INFO::its now!!!!!!!!3
2023-12-01 16:59:10,669:INFO::its now!!!!!!!!5
2023-12-01 16:59:10,820:INFO::its now!!!!!!!!
2023-12-01 16:59:10,820:INFO::its now!!!!!!!! on 
2023-12-01 16:59:10,873:INFO::its now!!!!!!!!5
2023-12-01 16:59:11,050:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:11,052:INFO::Epoch 00144 | lr 0.00050 | Train_Loss 0.1029 | Train_Classification_Loss 0.1864 | Dmon_Loss -0.1671 | Val_Loss 0.3828 | Search Time(s) 0.3890 | Infer Time(s) 0.1925 | Time(s) 0.5814 
2023-12-01 16:59:11,110:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:11,111:INFO::Validation loss decreased (0.385546 --> 0.382782).  Saving model ...
2023-12-01 16:59:11,114:INFO::Epoch: 145
tensor([[1.0000, 0.9599, 0.9797, 0.9786],
        [0.9683, 1.0000, 0.9642, 0.9794],
        [1.0000, 0.9768, 0.9642, 0.9791],
        [1.0000, 0.9766, 0.9794, 0.9569]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:11,115:INFO::its now!!!!!!!!5
2023-12-01 16:59:11,276:INFO::its now!!!!!!!!0
2023-12-01 16:59:11,277:INFO::its now!!!!!!!!3
2023-12-01 16:59:11,322:INFO::its now!!!!!!!!5
2023-12-01 16:59:11,492:INFO::its now!!!!!!!!
2023-12-01 16:59:11,492:INFO::its now!!!!!!!! on 
2023-12-01 16:59:11,547:INFO::its now!!!!!!!!5
2023-12-01 16:59:11,713:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:11,714:INFO::Epoch 00145 | lr 0.00050 | Train_Loss 0.1029 | Train_Classification_Loss 0.1871 | Dmon_Loss -0.1683 | Val_Loss 0.3801 | Search Time(s) 0.4154 | Infer Time(s) 0.1865 | Time(s) 0.6019 
2023-12-01 16:59:11,766:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:11,767:INFO::Validation loss decreased (0.382782 --> 0.380133).  Saving model ...
2023-12-01 16:59:11,770:INFO::Epoch: 146
tensor([[1.0000, 0.9578, 0.9780, 0.9768],
        [0.9664, 1.0000, 0.9621, 0.9777],
        [1.0000, 0.9750, 0.9621, 0.9774],
        [1.0000, 0.9750, 0.9777, 0.9547]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:11,771:INFO::its now!!!!!!!!5
2023-12-01 16:59:11,930:INFO::its now!!!!!!!!0
2023-12-01 16:59:11,931:INFO::its now!!!!!!!!3
2023-12-01 16:59:11,973:INFO::its now!!!!!!!!5
2023-12-01 16:59:12,142:INFO::its now!!!!!!!!
2023-12-01 16:59:12,142:INFO::its now!!!!!!!! on 
2023-12-01 16:59:12,192:INFO::its now!!!!!!!!5
2023-12-01 16:59:12,363:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:12,364:INFO::Epoch 00146 | lr 0.00050 | Train_Loss 0.0916 | Train_Classification_Loss 0.1766 | Dmon_Loss -0.1699 | Val_Loss 0.3775 | Search Time(s) 0.4075 | Infer Time(s) 0.1881 | Time(s) 0.5956 
2023-12-01 16:59:12,409:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 3;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 0;	26107: 3;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:12,410:INFO::Validation loss decreased (0.380133 --> 0.377490).  Saving model ...
2023-12-01 16:59:12,412:INFO::Epoch: 147
tensor([[1.0000, 0.9559, 0.9763, 0.9750],
        [0.9646, 1.0000, 0.9602, 0.9759],
        [1.0000, 0.9731, 0.9602, 0.9757],
        [1.0000, 0.9733, 0.9759, 0.9526]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:12,413:INFO::its now!!!!!!!!5
2023-12-01 16:59:12,570:INFO::its now!!!!!!!!0
2023-12-01 16:59:12,571:INFO::its now!!!!!!!!3
2023-12-01 16:59:12,617:INFO::its now!!!!!!!!5
2023-12-01 16:59:12,793:INFO::its now!!!!!!!!
2023-12-01 16:59:12,793:INFO::its now!!!!!!!! on 
2023-12-01 16:59:12,847:INFO::its now!!!!!!!!5
2023-12-01 16:59:12,998:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:13,000:INFO::Epoch 00147 | lr 0.00050 | Train_Loss 0.0915 | Train_Classification_Loss 0.1768 | Dmon_Loss -0.1705 | Val_Loss 0.3749 | Search Time(s) 0.4199 | Infer Time(s) 0.1676 | Time(s) 0.5874 
2023-12-01 16:59:13,050:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:13,052:INFO::Validation loss decreased (0.377490 --> 0.374942).  Saving model ...
2023-12-01 16:59:13,055:INFO::Epoch: 148
tensor([[1.0000, 0.9513, 0.9720, 0.9706],
        [0.9599, 1.0000, 0.9557, 0.9716],
        [1.0000, 0.9684, 0.9557, 0.9713],
        [1.0000, 0.9692, 0.9717, 0.9477]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:13,056:INFO::its now!!!!!!!!5
2023-12-01 16:59:13,250:INFO::its now!!!!!!!!0
2023-12-01 16:59:13,250:INFO::its now!!!!!!!!3
2023-12-01 16:59:13,292:INFO::its now!!!!!!!!5
2023-12-01 16:59:13,462:INFO::its now!!!!!!!!
2023-12-01 16:59:13,462:INFO::its now!!!!!!!! on 
2023-12-01 16:59:13,514:INFO::its now!!!!!!!!5
2023-12-01 16:59:13,678:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:13,680:INFO::Epoch 00148 | lr 0.00050 | Train_Loss 0.0862 | Train_Classification_Loss 0.1717 | Dmon_Loss -0.1711 | Val_Loss 0.3724 | Search Time(s) 0.4420 | Infer Time(s) 0.1845 | Time(s) 0.6265 
2023-12-01 16:59:13,730:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:13,731:INFO::Validation loss decreased (0.374942 --> 0.372413).  Saving model ...
2023-12-01 16:59:13,733:INFO::Epoch: 149
tensor([[1.0000, 0.9467, 0.9678, 0.9661],
        [0.9553, 1.0000, 0.9513, 0.9673],
        [1.0000, 0.9637, 0.9513, 0.9670],
        [1.0000, 0.9651, 0.9674, 0.9429]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:13,734:INFO::its now!!!!!!!!5
2023-12-01 16:59:13,901:INFO::its now!!!!!!!!0
2023-12-01 16:59:13,902:INFO::its now!!!!!!!!3
2023-12-01 16:59:13,945:INFO::its now!!!!!!!!5
2023-12-01 16:59:14,144:INFO::its now!!!!!!!!
2023-12-01 16:59:14,144:INFO::its now!!!!!!!! on 
2023-12-01 16:59:14,195:INFO::its now!!!!!!!!5
2023-12-01 16:59:14,368:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:14,369:INFO::Epoch 00149 | lr 0.00050 | Train_Loss 0.0798 | Train_Classification_Loss 0.1666 | Dmon_Loss -0.1736 | Val_Loss 0.3700 | Search Time(s) 0.4434 | Infer Time(s) 0.1931 | Time(s) 0.6365 
2023-12-01 16:59:14,418:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 3;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:14,419:INFO::Validation loss decreased (0.372413 --> 0.370036).  Saving model ...
2023-12-01 16:59:14,422:INFO::Epoch: 150
tensor([[1.0000, 0.9433, 0.9646, 0.9628],
        [0.9518, 1.0000, 0.9479, 0.9641],
        [1.0000, 0.9601, 0.9479, 0.9637],
        [1.0000, 0.9620, 0.9641, 0.9393]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:14,422:INFO::its now!!!!!!!!5
2023-12-01 16:59:14,619:INFO::its now!!!!!!!!0
2023-12-01 16:59:14,620:INFO::its now!!!!!!!!3
2023-12-01 16:59:14,666:INFO::its now!!!!!!!!5
2023-12-01 16:59:14,901:INFO::its now!!!!!!!!
2023-12-01 16:59:14,901:INFO::its now!!!!!!!! on 
2023-12-01 16:59:14,955:INFO::its now!!!!!!!!5
2023-12-01 16:59:15,133:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:15,134:INFO::Epoch 00150 | lr 0.00050 | Train_Loss 0.0749 | Train_Classification_Loss 0.1619 | Dmon_Loss -0.1741 | Val_Loss 0.3679 | Search Time(s) 0.5196 | Infer Time(s) 0.1931 | Time(s) 0.7127 
2023-12-01 16:59:15,178:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:15,179:INFO::Validation loss decreased (0.370036 --> 0.367885).  Saving model ...
2023-12-01 16:59:15,183:INFO::Epoch: 151
tensor([[1.0000, 0.9412, 0.9627, 0.9608],
        [0.9497, 1.0000, 0.9459, 0.9622],
        [1.0000, 0.9580, 0.9459, 0.9618],
        [1.0000, 0.9601, 0.9622, 0.9371]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:15,184:INFO::its now!!!!!!!!5
2023-12-01 16:59:15,340:INFO::its now!!!!!!!!0
2023-12-01 16:59:15,341:INFO::its now!!!!!!!!3
2023-12-01 16:59:15,384:INFO::its now!!!!!!!!5
2023-12-01 16:59:15,546:INFO::its now!!!!!!!!
2023-12-01 16:59:15,546:INFO::its now!!!!!!!! on 
2023-12-01 16:59:15,598:INFO::its now!!!!!!!!5
2023-12-01 16:59:15,761:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:15,763:INFO::Epoch 00151 | lr 0.00050 | Train_Loss 0.0731 | Train_Classification_Loss 0.1603 | Dmon_Loss -0.1744 | Val_Loss 0.3659 | Search Time(s) 0.4005 | Infer Time(s) 0.1805 | Time(s) 0.5810 
2023-12-01 16:59:15,819:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:15,820:INFO::Validation loss decreased (0.367885 --> 0.365880).  Saving model ...
2023-12-01 16:59:15,823:INFO::Epoch: 152
tensor([[1.0000, 0.9378, 0.9595, 0.9574],
        [0.9462, 1.0000, 0.9426, 0.9589],
        [1.0000, 0.9545, 0.9426, 0.9585],
        [1.0000, 0.9570, 0.9590, 0.9335]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:15,823:INFO::its now!!!!!!!!5
2023-12-01 16:59:15,999:INFO::its now!!!!!!!!0
2023-12-01 16:59:15,999:INFO::its now!!!!!!!!3
2023-12-01 16:59:16,046:INFO::its now!!!!!!!!5
2023-12-01 16:59:16,203:INFO::its now!!!!!!!!
2023-12-01 16:59:16,203:INFO::its now!!!!!!!! on 
2023-12-01 16:59:16,257:INFO::its now!!!!!!!!5
2023-12-01 16:59:16,439:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:16,441:INFO::Epoch 00152 | lr 0.00050 | Train_Loss 0.0678 | Train_Classification_Loss 0.1559 | Dmon_Loss -0.1763 | Val_Loss 0.3640 | Search Time(s) 0.4205 | Infer Time(s) 0.1990 | Time(s) 0.6195 
2023-12-01 16:59:16,491:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 3;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:16,493:INFO::Validation loss decreased (0.365880 --> 0.363976).  Saving model ...
2023-12-01 16:59:16,495:INFO::Epoch: 153
tensor([[1.0000, 0.9353, 0.9571, 0.9549],
        [0.9436, 1.0000, 0.9401, 0.9565],
        [1.0000, 0.9519, 0.9401, 0.9561],
        [1.0000, 0.9547, 0.9566, 0.9309]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:16,496:INFO::its now!!!!!!!!5
2023-12-01 16:59:16,689:INFO::its now!!!!!!!!0
2023-12-01 16:59:16,690:INFO::its now!!!!!!!!3
2023-12-01 16:59:16,733:INFO::its now!!!!!!!!5
2023-12-01 16:59:16,901:INFO::its now!!!!!!!!
2023-12-01 16:59:16,902:INFO::its now!!!!!!!! on 
2023-12-01 16:59:16,953:INFO::its now!!!!!!!!5
2023-12-01 16:59:17,137:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:17,138:INFO::Epoch 00153 | lr 0.00050 | Train_Loss 0.0631 | Train_Classification_Loss 0.1518 | Dmon_Loss -0.1775 | Val_Loss 0.3619 | Search Time(s) 0.4438 | Infer Time(s) 0.2000 | Time(s) 0.6438 
2023-12-01 16:59:17,178:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:17,179:INFO::Validation loss decreased (0.363976 --> 0.361930).  Saving model ...
2023-12-01 16:59:17,181:INFO::Epoch: 154
tensor([[1.0000, 0.9345, 0.9564, 0.9542],
        [0.9428, 1.0000, 0.9393, 0.9558],
        [1.0000, 0.9510, 0.9393, 0.9553],
        [1.0000, 0.9540, 0.9558, 0.9300]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:17,182:INFO::its now!!!!!!!!5
2023-12-01 16:59:17,352:INFO::its now!!!!!!!!0
2023-12-01 16:59:17,352:INFO::its now!!!!!!!!3
2023-12-01 16:59:17,395:INFO::its now!!!!!!!!5
2023-12-01 16:59:17,563:INFO::its now!!!!!!!!
2023-12-01 16:59:17,563:INFO::its now!!!!!!!! on 
2023-12-01 16:59:17,613:INFO::its now!!!!!!!!5
2023-12-01 16:59:17,776:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:17,778:INFO::Epoch 00154 | lr 0.00050 | Train_Loss 0.0634 | Train_Classification_Loss 0.1515 | Dmon_Loss -0.1763 | Val_Loss 0.3605 | Search Time(s) 0.4145 | Infer Time(s) 0.1825 | Time(s) 0.5970 
2023-12-01 16:59:17,839:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:17,840:INFO::Validation loss decreased (0.361930 --> 0.360519).  Saving model ...
2023-12-01 16:59:17,843:INFO::Epoch: 155
tensor([[1.0000, 0.9365, 0.9582, 0.9561],
        [0.9448, 1.0000, 0.9413, 0.9577],
        [1.0000, 0.9531, 0.9413, 0.9572],
        [1.0000, 0.9558, 0.9577, 0.9321]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:17,844:INFO::its now!!!!!!!!5
2023-12-01 16:59:18,020:INFO::its now!!!!!!!!0
2023-12-01 16:59:18,021:INFO::its now!!!!!!!!3
2023-12-01 16:59:18,070:INFO::its now!!!!!!!!5
2023-12-01 16:59:18,244:INFO::its now!!!!!!!!
2023-12-01 16:59:18,245:INFO::its now!!!!!!!! on 
2023-12-01 16:59:18,299:INFO::its now!!!!!!!!5
2023-12-01 16:59:18,485:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:18,487:INFO::Epoch 00155 | lr 0.00050 | Train_Loss 0.0589 | Train_Classification_Loss 0.1481 | Dmon_Loss -0.1785 | Val_Loss 0.3590 | Search Time(s) 0.4386 | Infer Time(s) 0.2070 | Time(s) 0.6456 
2023-12-01 16:59:18,528:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:18,529:INFO::Validation loss decreased (0.360519 --> 0.358967).  Saving model ...
2023-12-01 16:59:18,533:INFO::Epoch: 156
tensor([[1.0000, 0.9423, 0.9637, 0.9572],
        [0.9508, 1.0000, 0.9423, 0.9632],
        [1.0000, 0.9542, 0.9470, 0.9628],
        [1.0000, 0.9564, 0.9633, 0.9383]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:18,534:INFO::its now!!!!!!!!5
2023-12-01 16:59:18,721:INFO::its now!!!!!!!!0
2023-12-01 16:59:18,722:INFO::its now!!!!!!!!3
2023-12-01 16:59:18,763:INFO::its now!!!!!!!!5
2023-12-01 16:59:18,944:INFO::its now!!!!!!!!
2023-12-01 16:59:18,944:INFO::its now!!!!!!!! on 
2023-12-01 16:59:18,994:INFO::its now!!!!!!!!5
2023-12-01 16:59:19,170:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:19,171:INFO::Epoch 00156 | lr 0.00050 | Train_Loss 0.0534 | Train_Classification_Loss 0.1429 | Dmon_Loss -0.1790 | Val_Loss 0.3575 | Search Time(s) 0.4468 | Infer Time(s) 0.1931 | Time(s) 0.6399 
2023-12-01 16:59:19,233:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:19,234:INFO::Validation loss decreased (0.358967 --> 0.357461).  Saving model ...
2023-12-01 16:59:19,237:INFO::Epoch: 157
tensor([[1.0000, 0.9449, 0.9662, 0.9573],
        [0.9535, 1.0000, 0.9425, 0.9657],
        [1.0000, 0.9544, 0.9495, 0.9653],
        [1.0000, 0.9564, 0.9657, 0.9410]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:19,237:INFO::its now!!!!!!!!5
2023-12-01 16:59:19,423:INFO::its now!!!!!!!!0
2023-12-01 16:59:19,423:INFO::its now!!!!!!!!3
2023-12-01 16:59:19,470:INFO::its now!!!!!!!!5
2023-12-01 16:59:19,633:INFO::its now!!!!!!!!
2023-12-01 16:59:19,633:INFO::its now!!!!!!!! on 
2023-12-01 16:59:19,686:INFO::its now!!!!!!!!5
2023-12-01 16:59:19,864:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:19,867:INFO::Epoch 00157 | lr 0.00050 | Train_Loss 0.0532 | Train_Classification_Loss 0.1433 | Dmon_Loss -0.1802 | Val_Loss 0.3561 | Search Time(s) 0.4345 | Infer Time(s) 0.1955 | Time(s) 0.6299 
2023-12-01 16:59:19,924:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:19,925:INFO::Validation loss decreased (0.357461 --> 0.356133).  Saving model ...
2023-12-01 16:59:19,929:INFO::Epoch: 158
tensor([[1.0000, 0.9447, 0.9660, 0.9559],
        [0.9533, 1.0000, 0.9410, 0.9655],
        [1.0000, 0.9529, 0.9494, 0.9651],
        [1.0000, 0.9550, 0.9655, 0.9408]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:19,930:INFO::its now!!!!!!!!5
2023-12-01 16:59:20,087:INFO::its now!!!!!!!!0
2023-12-01 16:59:20,088:INFO::its now!!!!!!!!3
2023-12-01 16:59:20,133:INFO::its now!!!!!!!!5
2023-12-01 16:59:20,365:INFO::its now!!!!!!!!
2023-12-01 16:59:20,365:INFO::its now!!!!!!!! on 
2023-12-01 16:59:20,417:INFO::its now!!!!!!!!5
2023-12-01 16:59:20,608:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:20,610:INFO::Epoch 00158 | lr 0.00050 | Train_Loss 0.0511 | Train_Classification_Loss 0.1411 | Dmon_Loss -0.1800 | Val_Loss 0.3547 | Search Time(s) 0.4758 | Infer Time(s) 0.2074 | Time(s) 0.6833 
2023-12-01 16:59:20,665:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:20,665:INFO::Validation loss decreased (0.356133 --> 0.354712).  Saving model ...
2023-12-01 16:59:20,667:INFO::Epoch: 159
tensor([[1.0000, 0.9467, 0.9679, 0.9573],
        [0.9553, 1.0000, 0.9424, 0.9674],
        [1.0000, 0.9543, 0.9513, 0.9671],
        [1.0000, 0.9562, 0.9674, 0.9429]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:20,668:INFO::its now!!!!!!!!5
2023-12-01 16:59:20,855:INFO::its now!!!!!!!!0
2023-12-01 16:59:20,856:INFO::its now!!!!!!!!3
2023-12-01 16:59:20,902:INFO::its now!!!!!!!!5
2023-12-01 16:59:21,092:INFO::its now!!!!!!!!
2023-12-01 16:59:21,092:INFO::its now!!!!!!!! on 
2023-12-01 16:59:21,145:INFO::its now!!!!!!!!5
2023-12-01 16:59:21,309:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:21,310:INFO::Epoch 00159 | lr 0.00050 | Train_Loss 0.0443 | Train_Classification_Loss 0.1351 | Dmon_Loss -0.1818 | Val_Loss 0.3532 | Search Time(s) 0.4585 | Infer Time(s) 0.1851 | Time(s) 0.6436 
2023-12-01 16:59:21,356:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:21,357:INFO::Validation loss decreased (0.354712 --> 0.353187).  Saving model ...
2023-12-01 16:59:21,359:INFO::Epoch: 160
tensor([[1.0000, 0.9440, 0.9653, 0.9543],
        [0.9525, 1.0000, 0.9394, 0.9648],
        [1.0000, 0.9511, 0.9486, 0.9644],
        [1.0000, 0.9533, 0.9648, 0.9400]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:21,359:INFO::its now!!!!!!!!5
2023-12-01 16:59:21,526:INFO::its now!!!!!!!!0
2023-12-01 16:59:21,527:INFO::its now!!!!!!!!3
2023-12-01 16:59:21,570:INFO::its now!!!!!!!!5
2023-12-01 16:59:21,757:INFO::its now!!!!!!!!
2023-12-01 16:59:21,758:INFO::its now!!!!!!!! on 
2023-12-01 16:59:21,809:INFO::its now!!!!!!!!5
2023-12-01 16:59:21,974:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:21,976:INFO::Epoch 00160 | lr 0.00050 | Train_Loss 0.0409 | Train_Classification_Loss 0.1321 | Dmon_Loss -0.1824 | Val_Loss 0.3516 | Search Time(s) 0.4338 | Infer Time(s) 0.1825 | Time(s) 0.6164 
2023-12-01 16:59:22,014:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:22,015:INFO::Validation loss decreased (0.353187 --> 0.351637).  Saving model ...
2023-12-01 16:59:22,017:INFO::Epoch: 161
tensor([[1.0000, 0.9412, 0.9627, 0.9514],
        [0.9497, 1.0000, 0.9365, 0.9622],
        [1.0000, 0.9481, 0.9459, 0.9618],
        [1.0000, 0.9507, 0.9622, 0.9372]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:22,018:INFO::its now!!!!!!!!5
2023-12-01 16:59:22,191:INFO::its now!!!!!!!!0
2023-12-01 16:59:22,192:INFO::its now!!!!!!!!3
2023-12-01 16:59:22,238:INFO::its now!!!!!!!!5
2023-12-01 16:59:22,408:INFO::its now!!!!!!!!
2023-12-01 16:59:22,409:INFO::its now!!!!!!!! on 
2023-12-01 16:59:22,461:INFO::its now!!!!!!!!5
2023-12-01 16:59:22,621:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:22,623:INFO::Epoch 00161 | lr 0.00050 | Train_Loss 0.0417 | Train_Classification_Loss 0.1332 | Dmon_Loss -0.1828 | Val_Loss 0.3501 | Search Time(s) 0.4330 | Infer Time(s) 0.1735 | Time(s) 0.6065 
2023-12-01 16:59:22,666:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:22,667:INFO::Validation loss decreased (0.351637 --> 0.350060).  Saving model ...
2023-12-01 16:59:22,670:INFO::Epoch: 162
tensor([[1.0000, 0.9494, 0.9705, 0.9499],
        [0.9483, 1.0000, 0.9446, 0.9700],
        [1.0000, 0.9466, 0.9540, 0.9697],
        [1.0000, 0.9488, 0.9700, 0.9457]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:22,671:INFO::its now!!!!!!!!5
2023-12-01 16:59:22,823:INFO::its now!!!!!!!!0
2023-12-01 16:59:22,824:INFO::its now!!!!!!!!3
2023-12-01 16:59:22,864:INFO::its now!!!!!!!!5
2023-12-01 16:59:23,055:INFO::its now!!!!!!!!
2023-12-01 16:59:23,055:INFO::its now!!!!!!!! on 
2023-12-01 16:59:23,104:INFO::its now!!!!!!!!5
2023-12-01 16:59:23,284:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:23,286:INFO::Epoch 00162 | lr 0.00050 | Train_Loss 0.0420 | Train_Classification_Loss 0.1337 | Dmon_Loss -0.1836 | Val_Loss 0.3486 | Search Time(s) 0.4189 | Infer Time(s) 0.1980 | Time(s) 0.6169 
2023-12-01 16:59:23,342:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:23,343:INFO::Validation loss decreased (0.350060 --> 0.348560).  Saving model ...
2023-12-01 16:59:23,345:INFO::Epoch: 163
tensor([[1.0000, 0.9520, 0.9729, 0.9475],
        [0.9459, 1.0000, 0.9471, 0.9725],
        [1.0000, 0.9441, 0.9565, 0.9721],
        [1.0000, 0.9464, 0.9725, 0.9484]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:23,345:INFO::its now!!!!!!!!5
2023-12-01 16:59:23,534:INFO::its now!!!!!!!!0
2023-12-01 16:59:23,535:INFO::its now!!!!!!!!3
2023-12-01 16:59:23,577:INFO::its now!!!!!!!!5
2023-12-01 16:59:23,734:INFO::its now!!!!!!!!
2023-12-01 16:59:23,734:INFO::its now!!!!!!!! on 
2023-12-01 16:59:23,786:INFO::its now!!!!!!!!5
2023-12-01 16:59:23,969:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:23,970:INFO::Epoch 00163 | lr 0.00050 | Train_Loss 0.0309 | Train_Classification_Loss 0.1233 | Dmon_Loss -0.1848 | Val_Loss 0.3471 | Search Time(s) 0.4269 | Infer Time(s) 0.1985 | Time(s) 0.6253 
2023-12-01 16:59:24,026:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:24,027:INFO::Validation loss decreased (0.348560 --> 0.347066).  Saving model ...
2023-12-01 16:59:24,029:INFO::Epoch: 164
tensor([[1.0000, 0.9503, 0.9712, 0.9432],
        [0.9415, 1.0000, 0.9454, 0.9708],
        [1.0000, 0.9396, 0.9548, 0.9705],
        [1.0000, 0.9423, 0.9708, 0.9466]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:24,031:INFO::its now!!!!!!!!5
2023-12-01 16:59:24,186:INFO::its now!!!!!!!!0
2023-12-01 16:59:24,187:INFO::its now!!!!!!!!3
2023-12-01 16:59:24,214:INFO::its now!!!!!!!!5
2023-12-01 16:59:24,387:INFO::its now!!!!!!!!
2023-12-01 16:59:24,387:INFO::its now!!!!!!!! on 
2023-12-01 16:59:24,438:INFO::its now!!!!!!!!5
2023-12-01 16:59:24,581:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:24,583:INFO::Epoch 00164 | lr 0.00050 | Train_Loss 0.0285 | Train_Classification_Loss 0.1209 | Dmon_Loss -0.1846 | Val_Loss 0.3456 | Search Time(s) 0.3901 | Infer Time(s) 0.1636 | Time(s) 0.5537 
2023-12-01 16:59:24,626:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:24,627:INFO::Validation loss decreased (0.347066 --> 0.345610).  Saving model ...
2023-12-01 16:59:24,630:INFO::Epoch: 165
tensor([[1.0000, 0.9504, 0.9714, 0.9411],
        [0.9393, 1.0000, 0.9455, 0.9710],
        [1.0000, 0.9384, 0.9539, 0.9706],
        [1.0000, 0.9412, 0.9710, 0.9467]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:24,631:INFO::its now!!!!!!!!5
2023-12-01 16:59:24,796:INFO::its now!!!!!!!!0
2023-12-01 16:59:24,796:INFO::its now!!!!!!!!3
2023-12-01 16:59:24,836:INFO::its now!!!!!!!!5
2023-12-01 16:59:25,014:INFO::its now!!!!!!!!
2023-12-01 16:59:25,014:INFO::its now!!!!!!!! on 
2023-12-01 16:59:25,063:INFO::its now!!!!!!!!5
2023-12-01 16:59:25,203:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:25,204:INFO::Epoch 00165 | lr 0.00050 | Train_Loss 0.0308 | Train_Classification_Loss 0.1236 | Dmon_Loss -0.1855 | Val_Loss 0.3443 | Search Time(s) 0.4179 | Infer Time(s) 0.1571 | Time(s) 0.5750 
2023-12-01 16:59:25,257:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:25,258:INFO::Validation loss decreased (0.345610 --> 0.344270).  Saving model ...
2023-12-01 16:59:25,261:INFO::Epoch: 166
tensor([[1.0000, 0.9483, 0.9694, 0.9378],
        [0.9358, 1.0000, 0.9434, 0.9690],
        [1.0000, 0.9354, 0.9514, 0.9686],
        [1.0000, 0.9385, 0.9690, 0.9446]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:25,262:INFO::its now!!!!!!!!5
2023-12-01 16:59:25,410:INFO::its now!!!!!!!!0
2023-12-01 16:59:25,411:INFO::its now!!!!!!!!3
2023-12-01 16:59:25,457:INFO::its now!!!!!!!!5
2023-12-01 16:59:25,607:INFO::its now!!!!!!!!
2023-12-01 16:59:25,608:INFO::its now!!!!!!!! on 
2023-12-01 16:59:25,659:INFO::its now!!!!!!!!5
2023-12-01 16:59:25,859:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:25,861:INFO::Epoch 00166 | lr 0.00050 | Train_Loss 0.0262 | Train_Classification_Loss 0.1195 | Dmon_Loss -0.1867 | Val_Loss 0.3430 | Search Time(s) 0.3865 | Infer Time(s) 0.2144 | Time(s) 0.6009 
2023-12-01 16:59:25,927:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:25,928:INFO::Validation loss decreased (0.344270 --> 0.342962).  Saving model ...
2023-12-01 16:59:25,931:INFO::Epoch: 167
tensor([[1.0000, 0.9452, 0.9664, 0.9340],
        [0.9319, 1.0000, 0.9403, 0.9660],
        [1.0000, 0.9317, 0.9481, 0.9656],
        [1.0000, 0.9352, 0.9660, 0.9413]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:25,932:INFO::its now!!!!!!!!5
2023-12-01 16:59:26,109:INFO::its now!!!!!!!!0
2023-12-01 16:59:26,110:INFO::its now!!!!!!!!3
2023-12-01 16:59:26,152:INFO::its now!!!!!!!!5
2023-12-01 16:59:26,318:INFO::its now!!!!!!!!
2023-12-01 16:59:26,318:INFO::its now!!!!!!!! on 
2023-12-01 16:59:26,368:INFO::its now!!!!!!!!5
2023-12-01 16:59:26,527:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:26,529:INFO::Epoch 00167 | lr 0.00050 | Train_Loss 0.0230 | Train_Classification_Loss 0.1164 | Dmon_Loss -0.1867 | Val_Loss 0.3417 | Search Time(s) 0.4200 | Infer Time(s) 0.1795 | Time(s) 0.5995 
2023-12-01 16:59:26,577:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:26,578:INFO::Validation loss decreased (0.342962 --> 0.341666).  Saving model ...
2023-12-01 16:59:26,580:INFO::Epoch: 168
tensor([[1.0000, 0.9404, 0.9619, 0.9287],
        [0.9264, 1.0000, 0.9355, 0.9614],
        [1.0000, 0.9262, 0.9432, 0.9610],
        [1.0000, 0.9304, 0.9614, 0.9363]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:26,580:INFO::its now!!!!!!!!5
2023-12-01 16:59:26,728:INFO::its now!!!!!!!!0
2023-12-01 16:59:26,729:INFO::its now!!!!!!!!3
2023-12-01 16:59:26,771:INFO::its now!!!!!!!!5
2023-12-01 16:59:26,939:INFO::its now!!!!!!!!
2023-12-01 16:59:26,939:INFO::its now!!!!!!!! on 
2023-12-01 16:59:26,992:INFO::its now!!!!!!!!5
2023-12-01 16:59:27,158:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:27,160:INFO::Epoch 00168 | lr 0.00050 | Train_Loss 0.0263 | Train_Classification_Loss 0.1196 | Dmon_Loss -0.1867 | Val_Loss 0.3405 | Search Time(s) 0.3969 | Infer Time(s) 0.1831 | Time(s) 0.5800 
2023-12-01 16:59:27,204:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 3;	26119: 0;	26120: 0;	26121: 3;	26122: 3;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:27,206:INFO::Validation loss decreased (0.341666 --> 0.340534).  Saving model ...
2023-12-01 16:59:27,208:INFO::Epoch: 169
tensor([[1.0000, 0.9360, 0.9578, 0.9240],
        [0.9216, 1.0000, 0.9312, 0.9572],
        [1.0000, 0.9214, 0.9389, 0.9568],
        [1.0000, 0.9261, 0.9572, 0.9317]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:27,209:INFO::its now!!!!!!!!5
2023-12-01 16:59:27,355:INFO::its now!!!!!!!!0
2023-12-01 16:59:27,356:INFO::its now!!!!!!!!3
2023-12-01 16:59:27,396:INFO::its now!!!!!!!!5
2023-12-01 16:59:27,574:INFO::its now!!!!!!!!
2023-12-01 16:59:27,574:INFO::its now!!!!!!!! on 
2023-12-01 16:59:27,623:INFO::its now!!!!!!!!5
2023-12-01 16:59:27,791:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:27,792:INFO::Epoch 00169 | lr 0.00050 | Train_Loss 0.0193 | Train_Classification_Loss 0.1130 | Dmon_Loss -0.1875 | Val_Loss 0.3396 | Search Time(s) 0.3996 | Infer Time(s) 0.1855 | Time(s) 0.5851 
2023-12-01 16:59:27,846:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 3;	24: 3;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:27,847:INFO::Validation loss decreased (0.340534 --> 0.339570).  Saving model ...
2023-12-01 16:59:27,849:INFO::Epoch: 170
tensor([[1.0000, 0.9289, 0.9510, 0.9165],
        [0.9139, 1.0000, 0.9242, 0.9504],
        [1.0000, 0.9135, 0.9319, 0.9499],
        [1.0000, 0.9191, 0.9504, 0.9243]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:27,850:INFO::its now!!!!!!!!5
2023-12-01 16:59:28,011:INFO::its now!!!!!!!!0
2023-12-01 16:59:28,012:INFO::its now!!!!!!!!3
2023-12-01 16:59:28,057:INFO::its now!!!!!!!!5
2023-12-01 16:59:28,225:INFO::its now!!!!!!!!
2023-12-01 16:59:28,225:INFO::its now!!!!!!!! on 
2023-12-01 16:59:28,278:INFO::its now!!!!!!!!5
2023-12-01 16:59:28,427:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:28,428:INFO::Epoch 00170 | lr 0.00050 | Train_Loss 0.0164 | Train_Classification_Loss 0.1110 | Dmon_Loss -0.1892 | Val_Loss 0.3385 | Search Time(s) 0.4136 | Infer Time(s) 0.1671 | Time(s) 0.5807 
2023-12-01 16:59:28,483:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:28,484:INFO::Validation loss decreased (0.339570 --> 0.338544).  Saving model ...
2023-12-01 16:59:28,487:INFO::Epoch: 171
tensor([[1.0000, 0.9321, 0.9540, 0.9198],
        [0.9101, 1.0000, 0.9273, 0.9535],
        [1.0000, 0.9170, 0.9350, 0.9530],
        [1.0000, 0.9149, 0.9535, 0.9276]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:28,488:INFO::its now!!!!!!!!5
2023-12-01 16:59:28,642:INFO::its now!!!!!!!!0
2023-12-01 16:59:28,643:INFO::its now!!!!!!!!3
2023-12-01 16:59:28,689:INFO::its now!!!!!!!!5
2023-12-01 16:59:28,868:INFO::its now!!!!!!!!
2023-12-01 16:59:28,868:INFO::its now!!!!!!!! on 
2023-12-01 16:59:28,922:INFO::its now!!!!!!!!5
2023-12-01 16:59:29,076:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:29,078:INFO::Epoch 00171 | lr 0.00050 | Train_Loss 0.0153 | Train_Classification_Loss 0.1092 | Dmon_Loss -0.1878 | Val_Loss 0.3375 | Search Time(s) 0.4179 | Infer Time(s) 0.1735 | Time(s) 0.5914 
2023-12-01 16:59:29,145:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:29,146:INFO::Validation loss decreased (0.338544 --> 0.337486).  Saving model ...
2023-12-01 16:59:29,149:INFO::Epoch: 172
tensor([[1.0000, 0.9305, 0.9525, 0.9181],
        [0.9047, 1.0000, 0.9258, 0.9520],
        [1.0000, 0.9153, 0.9334, 0.9515],
        [1.0000, 0.9096, 0.9520, 0.9260]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:29,150:INFO::its now!!!!!!!!5
2023-12-01 16:59:29,305:INFO::its now!!!!!!!!0
2023-12-01 16:59:29,305:INFO::its now!!!!!!!!3
2023-12-01 16:59:29,333:INFO::its now!!!!!!!!5
2023-12-01 16:59:29,496:INFO::its now!!!!!!!!
2023-12-01 16:59:29,496:INFO::its now!!!!!!!! on 
2023-12-01 16:59:29,546:INFO::its now!!!!!!!!5
2023-12-01 16:59:29,721:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:29,722:INFO::Epoch 00172 | lr 0.00050 | Train_Loss 0.0133 | Train_Classification_Loss 0.1079 | Dmon_Loss -0.1891 | Val_Loss 0.3365 | Search Time(s) 0.3816 | Infer Time(s) 0.1935 | Time(s) 0.5751 
2023-12-01 16:59:29,774:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:29,775:INFO::Validation loss decreased (0.337486 --> 0.336489).  Saving model ...
2023-12-01 16:59:29,778:INFO::Epoch: 173
tensor([[1.0000, 0.9289, 0.9510, 0.9164],
        [0.9020, 1.0000, 0.9241, 0.9504],
        [0.9991, 0.9135, 0.9318, 0.9507],
        [1.0000, 0.9061, 0.9518, 0.9243]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:29,779:INFO::its now!!!!!!!!5
2023-12-01 16:59:29,951:INFO::its now!!!!!!!!0
2023-12-01 16:59:29,951:INFO::its now!!!!!!!!3
2023-12-01 16:59:29,992:INFO::its now!!!!!!!!5
2023-12-01 16:59:30,148:INFO::its now!!!!!!!!
2023-12-01 16:59:30,148:INFO::its now!!!!!!!! on 
2023-12-01 16:59:30,197:INFO::its now!!!!!!!!5
2023-12-01 16:59:30,389:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:30,391:INFO::Epoch 00173 | lr 0.00050 | Train_Loss 0.0114 | Train_Classification_Loss 0.1065 | Dmon_Loss -0.1903 | Val_Loss 0.3354 | Search Time(s) 0.4055 | Infer Time(s) 0.2080 | Time(s) 0.6135 
2023-12-01 16:59:30,440:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:30,441:INFO::Validation loss decreased (0.336489 --> 0.335415).  Saving model ...
2023-12-01 16:59:30,444:INFO::Epoch: 174
tensor([[1.0000, 0.9277, 0.9499, 0.9152],
        [0.9003, 1.0000, 0.9230, 0.9493],
        [0.9986, 0.9122, 0.9307, 0.9500],
        [1.0000, 0.9041, 0.9514, 0.9231]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:30,444:INFO::its now!!!!!!!!5
2023-12-01 16:59:30,583:INFO::its now!!!!!!!!0
2023-12-01 16:59:30,584:INFO::its now!!!!!!!!3
2023-12-01 16:59:30,630:INFO::its now!!!!!!!!5
2023-12-01 16:59:30,792:INFO::its now!!!!!!!!
2023-12-01 16:59:30,792:INFO::its now!!!!!!!! on 
2023-12-01 16:59:30,842:INFO::its now!!!!!!!!5
2023-12-01 16:59:31,020:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:31,022:INFO::Epoch 00174 | lr 0.00050 | Train_Loss 0.0082 | Train_Classification_Loss 0.1035 | Dmon_Loss -0.1905 | Val_Loss 0.3343 | Search Time(s) 0.3820 | Infer Time(s) 0.1955 | Time(s) 0.5775 
2023-12-01 16:59:31,088:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:31,089:INFO::Validation loss decreased (0.335415 --> 0.334252).  Saving model ...
2023-12-01 16:59:31,092:INFO::Epoch: 175
tensor([[1.0000, 0.9357, 0.9575, 0.9235],
        [0.9087, 1.0000, 0.9309, 0.9570],
        [1.0000, 0.9208, 0.9301, 0.9580],
        [1.0000, 0.9116, 0.9594, 0.9222]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:31,093:INFO::its now!!!!!!!!5
2023-12-01 16:59:31,314:INFO::its now!!!!!!!!0
2023-12-01 16:59:31,314:INFO::its now!!!!!!!!3
2023-12-01 16:59:31,358:INFO::its now!!!!!!!!5
2023-12-01 16:59:31,555:INFO::its now!!!!!!!!
2023-12-01 16:59:31,555:INFO::its now!!!!!!!! on 
2023-12-01 16:59:31,604:INFO::its now!!!!!!!!5
2023-12-01 16:59:31,763:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:31,764:INFO::Epoch 00175 | lr 0.00050 | Train_Loss 0.0060 | Train_Classification_Loss 0.1016 | Dmon_Loss -0.1912 | Val_Loss 0.3332 | Search Time(s) 0.4979 | Infer Time(s) 0.1765 | Time(s) 0.6744 
2023-12-01 16:59:31,803:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:31,804:INFO::Validation loss decreased (0.334252 --> 0.333182).  Saving model ...
2023-12-01 16:59:31,807:INFO::Epoch: 176
tensor([[1.0000, 0.9378, 0.9595, 0.9256],
        [0.9109, 1.0000, 0.9330, 0.9589],
        [1.0000, 0.9231, 0.9279, 0.9601],
        [1.0000, 0.9134, 0.9616, 0.9197]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:31,808:INFO::its now!!!!!!!!5
2023-12-01 16:59:31,963:INFO::its now!!!!!!!!0
2023-12-01 16:59:31,964:INFO::its now!!!!!!!!3
2023-12-01 16:59:32,005:INFO::its now!!!!!!!!5
2023-12-01 16:59:32,169:INFO::its now!!!!!!!!
2023-12-01 16:59:32,169:INFO::its now!!!!!!!! on 
2023-12-01 16:59:32,220:INFO::its now!!!!!!!!5
2023-12-01 16:59:32,372:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:32,374:INFO::Epoch 00176 | lr 0.00050 | Train_Loss 0.0075 | Train_Classification_Loss 0.1031 | Dmon_Loss -0.1912 | Val_Loss 0.3322 | Search Time(s) 0.3975 | Infer Time(s) 0.1711 | Time(s) 0.5686 
2023-12-01 16:59:32,436:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 0;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:32,438:INFO::Validation loss decreased (0.333182 --> 0.332170).  Saving model ...
2023-12-01 16:59:32,442:INFO::Epoch: 177
tensor([[1.0000, 0.9374, 0.9591, 0.9252],
        [0.9104, 1.0000, 0.9326, 0.9585],
        [1.0000, 0.9226, 0.9253, 0.9597],
        [1.0000, 0.9129, 0.9613, 0.9168]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:32,443:INFO::its now!!!!!!!!5
2023-12-01 16:59:32,623:INFO::its now!!!!!!!!0
2023-12-01 16:59:32,624:INFO::its now!!!!!!!!3
2023-12-01 16:59:32,669:INFO::its now!!!!!!!!5
2023-12-01 16:59:32,849:INFO::its now!!!!!!!!
2023-12-01 16:59:32,849:INFO::its now!!!!!!!! on 
2023-12-01 16:59:32,902:INFO::its now!!!!!!!!5
2023-12-01 16:59:33,055:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:33,058:INFO::Epoch 00177 | lr 0.00050 | Train_Loss 0.0013 | Train_Classification_Loss 0.0973 | Dmon_Loss -0.1919 | Val_Loss 0.3313 | Search Time(s) 0.4438 | Infer Time(s) 0.1725 | Time(s) 0.6164 
2023-12-01 16:59:33,109:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:33,110:INFO::Validation loss decreased (0.332170 --> 0.331257).  Saving model ...
2023-12-01 16:59:33,112:INFO::Epoch: 178
tensor([[1.0000, 0.9372, 0.9589, 0.9250],
        [0.9102, 1.0000, 0.9324, 0.9584],
        [1.0000, 0.9224, 0.9240, 0.9596],
        [1.0000, 0.9126, 0.9612, 0.9154]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:33,112:INFO::its now!!!!!!!!5
2023-12-01 16:59:33,284:INFO::its now!!!!!!!!0
2023-12-01 16:59:33,285:INFO::its now!!!!!!!!3
2023-12-01 16:59:33,328:INFO::its now!!!!!!!!5
2023-12-01 16:59:33,489:INFO::its now!!!!!!!!
2023-12-01 16:59:33,489:INFO::its now!!!!!!!! on 
2023-12-01 16:59:33,540:INFO::its now!!!!!!!!5
2023-12-01 16:59:33,696:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:33,698:INFO::Epoch 00178 | lr 0.00050 | Train_Loss -0.0015 | Train_Classification_Loss 0.0944 | Dmon_Loss -0.1919 | Val_Loss 0.3303 | Search Time(s) 0.4135 | Infer Time(s) 0.1725 | Time(s) 0.5860 
2023-12-01 16:59:33,760:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 3;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:33,761:INFO::Validation loss decreased (0.331257 --> 0.330302).  Saving model ...
2023-12-01 16:59:33,764:INFO::Epoch: 179
tensor([[1.0000, 0.9339, 0.9557, 0.9216],
        [0.9065, 1.0000, 0.9291, 0.9552],
        [1.0000, 0.9189, 0.9200, 0.9563],
        [1.0000, 0.9093, 0.9580, 0.9113]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:33,765:INFO::its now!!!!!!!!5
2023-12-01 16:59:33,928:INFO::its now!!!!!!!!0
2023-12-01 16:59:33,928:INFO::its now!!!!!!!!3
2023-12-01 16:59:33,968:INFO::its now!!!!!!!!5
2023-12-01 16:59:34,134:INFO::its now!!!!!!!!
2023-12-01 16:59:34,134:INFO::its now!!!!!!!! on 
2023-12-01 16:59:34,185:INFO::its now!!!!!!!!5
2023-12-01 16:59:34,330:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:34,332:INFO::Epoch 00179 | lr 0.00050 | Train_Loss -0.0013 | Train_Classification_Loss 0.0948 | Dmon_Loss -0.1921 | Val_Loss 0.3297 | Search Time(s) 0.4051 | Infer Time(s) 0.1641 | Time(s) 0.5692 
2023-12-01 16:59:34,383:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:34,385:INFO::Validation loss decreased (0.330302 --> 0.329701).  Saving model ...
2023-12-01 16:59:34,390:INFO::Epoch: 180
tensor([[1.0000, 0.9305, 0.9525, 0.9181],
        [0.9029, 1.0000, 0.9257, 0.9519],
        [1.0000, 0.9152, 0.9163, 0.9531],
        [1.0000, 0.9059, 0.9547, 0.9073]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:34,393:INFO::its now!!!!!!!!5
2023-12-01 16:59:34,533:INFO::its now!!!!!!!!0
2023-12-01 16:59:34,534:INFO::its now!!!!!!!!3
2023-12-01 16:59:34,574:INFO::its now!!!!!!!!5
2023-12-01 16:59:34,778:INFO::its now!!!!!!!!
2023-12-01 16:59:34,792:INFO::its now!!!!!!!! on 
2023-12-01 16:59:34,842:INFO::its now!!!!!!!!5
2023-12-01 16:59:35,002:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:35,004:INFO::Epoch 00180 | lr 0.00050 | Train_Loss -0.0026 | Train_Classification_Loss 0.0938 | Dmon_Loss -0.1927 | Val_Loss 0.3292 | Search Time(s) 0.4388 | Infer Time(s) 0.1785 | Time(s) 0.6173 
2023-12-01 16:59:35,059:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 3;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:35,060:INFO::Validation loss decreased (0.329701 --> 0.329186).  Saving model ...
2023-12-01 16:59:35,063:INFO::Epoch: 181
tensor([[1.0000, 0.9301, 0.9522, 0.9177],
        [0.9024, 1.0000, 0.9253, 0.9516],
        [1.0000, 0.9148, 0.9158, 0.9527],
        [1.0000, 0.9056, 0.9544, 0.9068]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:35,064:INFO::its now!!!!!!!!5
2023-12-01 16:59:35,239:INFO::its now!!!!!!!!0
2023-12-01 16:59:35,240:INFO::its now!!!!!!!!3
2023-12-01 16:59:35,281:INFO::its now!!!!!!!!5
2023-12-01 16:59:35,467:INFO::its now!!!!!!!!
2023-12-01 16:59:35,468:INFO::its now!!!!!!!! on 
2023-12-01 16:59:35,517:INFO::its now!!!!!!!!5
2023-12-01 16:59:35,702:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:35,703:INFO::Epoch 00181 | lr 0.00050 | Train_Loss -0.0057 | Train_Classification_Loss 0.0910 | Dmon_Loss -0.1933 | Val_Loss 0.3288 | Search Time(s) 0.4358 | Infer Time(s) 0.2064 | Time(s) 0.6423 
2023-12-01 16:59:35,748:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 0;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:35,749:INFO::Validation loss decreased (0.329186 --> 0.328807).  Saving model ...
2023-12-01 16:59:35,751:INFO::Epoch: 182
tensor([[0.9999, 0.9297, 0.9518, 0.9172],
        [0.9020, 1.0000, 0.9249, 0.9512],
        [1.0000, 0.9144, 0.9153, 0.9523],
        [1.0000, 0.9051, 0.9540, 0.9062]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:35,751:INFO::its now!!!!!!!!5
2023-12-01 16:59:35,885:INFO::its now!!!!!!!!0
2023-12-01 16:59:35,886:INFO::its now!!!!!!!!3
2023-12-01 16:59:35,930:INFO::its now!!!!!!!!5
2023-12-01 16:59:36,101:INFO::its now!!!!!!!!
2023-12-01 16:59:36,101:INFO::its now!!!!!!!! on 
2023-12-01 16:59:36,154:INFO::its now!!!!!!!!5
2023-12-01 16:59:36,308:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:36,309:INFO::Epoch 00182 | lr 0.00050 | Train_Loss -0.0093 | Train_Classification_Loss 0.0874 | Dmon_Loss -0.1935 | Val_Loss 0.3286 | Search Time(s) 0.3860 | Infer Time(s) 0.1725 | Time(s) 0.5585 
2023-12-01 16:59:36,353:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:36,354:INFO::Validation loss decreased (0.328807 --> 0.328553).  Saving model ...
2023-12-01 16:59:36,357:INFO::Epoch: 183
tensor([[0.9998, 0.9267, 0.9489, 0.9141],
        [0.8987, 1.0000, 0.9219, 0.9482],
        [1.0000, 0.9111, 0.9122, 0.9494],
        [1.0000, 0.9021, 0.9510, 0.9029]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:36,358:INFO::its now!!!!!!!!5
2023-12-01 16:59:36,528:INFO::its now!!!!!!!!0
2023-12-01 16:59:36,529:INFO::its now!!!!!!!!3
2023-12-01 16:59:36,570:INFO::its now!!!!!!!!5
2023-12-01 16:59:36,801:INFO::its now!!!!!!!!
2023-12-01 16:59:36,801:INFO::its now!!!!!!!! on 
2023-12-01 16:59:36,849:INFO::its now!!!!!!!!5
2023-12-01 16:59:37,010:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:37,011:INFO::Epoch 00183 | lr 0.00050 | Train_Loss -0.0121 | Train_Classification_Loss 0.0850 | Dmon_Loss -0.1942 | Val_Loss 0.3284 | Search Time(s) 0.4767 | Infer Time(s) 0.1785 | Time(s) 0.6552 
2023-12-01 16:59:37,065:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:37,066:INFO::Validation loss decreased (0.328553 --> 0.328381).  Saving model ...
2023-12-01 16:59:37,068:INFO::Epoch: 184
tensor([[0.9995, 0.9243, 0.9466, 0.9117],
        [0.8962, 1.0000, 0.9196, 0.9460],
        [1.0000, 0.9086, 0.9098, 0.9471],
        [1.0000, 0.8998, 0.9488, 0.9004]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:37,069:INFO::its now!!!!!!!!5
2023-12-01 16:59:37,225:INFO::its now!!!!!!!!0
2023-12-01 16:59:37,226:INFO::its now!!!!!!!!3
2023-12-01 16:59:37,268:INFO::its now!!!!!!!!5
2023-12-01 16:59:37,429:INFO::its now!!!!!!!!
2023-12-01 16:59:37,430:INFO::its now!!!!!!!! on 
2023-12-01 16:59:37,479:INFO::its now!!!!!!!!5
2023-12-01 16:59:37,630:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:37,631:INFO::Epoch 00184 | lr 0.00050 | Train_Loss -0.0103 | Train_Classification_Loss 0.0871 | Dmon_Loss -0.1949 | Val_Loss 0.3281 | Search Time(s) 0.3929 | Infer Time(s) 0.1715 | Time(s) 0.5645 
2023-12-01 16:59:37,674:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:37,675:INFO::Validation loss decreased (0.328381 --> 0.328112).  Saving model ...
2023-12-01 16:59:37,678:INFO::Epoch: 185
tensor([[0.9995, 0.9234, 0.9458, 0.9107],
        [0.8952, 1.0000, 0.9187, 0.9451],
        [1.0000, 0.9076, 0.9088, 0.9462],
        [1.0000, 0.8989, 0.9479, 0.8994]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:37,678:INFO::its now!!!!!!!!5
2023-12-01 16:59:37,867:INFO::its now!!!!!!!!0
2023-12-01 16:59:37,868:INFO::its now!!!!!!!!3
2023-12-01 16:59:37,909:INFO::its now!!!!!!!!5
2023-12-01 16:59:38,069:INFO::its now!!!!!!!!
2023-12-01 16:59:38,070:INFO::its now!!!!!!!! on 
2023-12-01 16:59:38,119:INFO::its now!!!!!!!!5
2023-12-01 16:59:38,282:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:38,284:INFO::Epoch 00185 | lr 0.00050 | Train_Loss -0.0142 | Train_Classification_Loss 0.0834 | Dmon_Loss -0.1953 | Val_Loss 0.3279 | Search Time(s) 0.4260 | Infer Time(s) 0.1804 | Time(s) 0.6064 
2023-12-01 16:59:38,321:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 3;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:38,321:INFO::Validation loss decreased (0.328112 --> 0.327944).  Saving model ...
2023-12-01 16:59:38,323:INFO::Epoch: 186
tensor([[0.9996, 0.9233, 0.9457, 0.9107],
        [0.8951, 1.0000, 0.9186, 0.9450],
        [1.0000, 0.9075, 0.9088, 0.9462],
        [1.0000, 0.8988, 0.9479, 0.8993]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:38,324:INFO::its now!!!!!!!!5
2023-12-01 16:59:38,491:INFO::its now!!!!!!!!0
2023-12-01 16:59:38,492:INFO::its now!!!!!!!!3
2023-12-01 16:59:38,537:INFO::its now!!!!!!!!5
2023-12-01 16:59:38,704:INFO::its now!!!!!!!!
2023-12-01 16:59:38,704:INFO::its now!!!!!!!! on 
2023-12-01 16:59:38,757:INFO::its now!!!!!!!!5
2023-12-01 16:59:38,911:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:38,913:INFO::Epoch 00186 | lr 0.00050 | Train_Loss -0.0137 | Train_Classification_Loss 0.0843 | Dmon_Loss -0.1961 | Val_Loss 0.3277 | Search Time(s) 0.4179 | Infer Time(s) 0.1705 | Time(s) 0.5884 
2023-12-01 16:59:38,964:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 0;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:38,965:INFO::Validation loss decreased (0.327944 --> 0.327714).  Saving model ...
2023-12-01 16:59:38,967:INFO::Epoch: 187
tensor([[0.9995, 0.9238, 0.9462, 0.9112],
        [0.8956, 1.0000, 0.9191, 0.9455],
        [1.0000, 0.9080, 0.9092, 0.9466],
        [1.0000, 0.8993, 0.9483, 0.8998]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:38,968:INFO::its now!!!!!!!!5
2023-12-01 16:59:39,124:INFO::its now!!!!!!!!0
2023-12-01 16:59:39,125:INFO::its now!!!!!!!!3
2023-12-01 16:59:39,166:INFO::its now!!!!!!!!5
2023-12-01 16:59:39,333:INFO::its now!!!!!!!!
2023-12-01 16:59:39,333:INFO::its now!!!!!!!! on 
2023-12-01 16:59:39,383:INFO::its now!!!!!!!!5
2023-12-01 16:59:39,532:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:39,534:INFO::Epoch 00187 | lr 0.00050 | Train_Loss -0.0167 | Train_Classification_Loss 0.0815 | Dmon_Loss -0.1963 | Val_Loss 0.3271 | Search Time(s) 0.3989 | Infer Time(s) 0.1685 | Time(s) 0.5675 
2023-12-01 16:59:39,576:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:39,577:INFO::Validation loss decreased (0.327714 --> 0.327084).  Saving model ...
2023-12-01 16:59:39,580:INFO::Epoch: 188
tensor([[0.9996, 0.9265, 0.9487, 0.9139],
        [0.8985, 1.0000, 0.9217, 0.9480],
        [1.0000, 0.9109, 0.9119, 0.9492],
        [1.0000, 0.9019, 0.9509, 0.9027]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:39,580:INFO::its now!!!!!!!!5
2023-12-01 16:59:39,737:INFO::its now!!!!!!!!0
2023-12-01 16:59:39,738:INFO::its now!!!!!!!!3
2023-12-01 16:59:39,780:INFO::its now!!!!!!!!5
2023-12-01 16:59:39,955:INFO::its now!!!!!!!!
2023-12-01 16:59:39,956:INFO::its now!!!!!!!! on 
2023-12-01 16:59:40,005:INFO::its now!!!!!!!!5
2023-12-01 16:59:40,165:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:40,167:INFO::Epoch 00188 | lr 0.00050 | Train_Loss -0.0139 | Train_Classification_Loss 0.0843 | Dmon_Loss -0.1965 | Val_Loss 0.3263 | Search Time(s) 0.4079 | Infer Time(s) 0.1795 | Time(s) 0.5874 
2023-12-01 16:59:40,219:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 3;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:40,221:INFO::Validation loss decreased (0.327084 --> 0.326291).  Saving model ...
2023-12-01 16:59:40,223:INFO::Epoch: 189
tensor([[0.9992, 0.9287, 0.9508, 0.9162],
        [0.9009, 1.0000, 0.9240, 0.9502],
        [1.0000, 0.9133, 0.9143, 0.9514],
        [1.0000, 0.9042, 0.9531, 0.9051]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:40,223:INFO::its now!!!!!!!!5
2023-12-01 16:59:40,376:INFO::its now!!!!!!!!0
2023-12-01 16:59:40,377:INFO::its now!!!!!!!!3
2023-12-01 16:59:40,420:INFO::its now!!!!!!!!5
2023-12-01 16:59:40,586:INFO::its now!!!!!!!!
2023-12-01 16:59:40,586:INFO::its now!!!!!!!! on 
2023-12-01 16:59:40,636:INFO::its now!!!!!!!!5
2023-12-01 16:59:40,786:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:40,787:INFO::Epoch 00189 | lr 0.00050 | Train_Loss -0.0164 | Train_Classification_Loss 0.0822 | Dmon_Loss -0.1973 | Val_Loss 0.3254 | Search Time(s) 0.3949 | Infer Time(s) 0.1686 | Time(s) 0.5635 
2023-12-01 16:59:40,826:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:40,827:INFO::Validation loss decreased (0.326291 --> 0.325412).  Saving model ...
2023-12-01 16:59:40,831:INFO::Epoch: 190
tensor([[0.9992, 0.9331, 0.9550, 0.9208],
        [0.9057, 1.0000, 0.9283, 0.9545],
        [1.0000, 0.9180, 0.9187, 0.9557],
        [1.0000, 0.9085, 0.9573, 0.9099]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:40,831:INFO::its now!!!!!!!!5
2023-12-01 16:59:41,011:INFO::its now!!!!!!!!0
2023-12-01 16:59:41,011:INFO::its now!!!!!!!!3
2023-12-01 16:59:41,043:INFO::its now!!!!!!!!5
2023-12-01 16:59:41,217:INFO::its now!!!!!!!!
2023-12-01 16:59:41,217:INFO::its now!!!!!!!! on 
2023-12-01 16:59:41,268:INFO::its now!!!!!!!!5
2023-12-01 16:59:41,423:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:41,424:INFO::Epoch 00190 | lr 0.00050 | Train_Loss -0.0223 | Train_Classification_Loss 0.0763 | Dmon_Loss -0.1972 | Val_Loss 0.3245 | Search Time(s) 0.4229 | Infer Time(s) 0.1725 | Time(s) 0.5954 
2023-12-01 16:59:41,461:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 3;	4: 3;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:41,462:INFO::Validation loss decreased (0.325412 --> 0.324509).  Saving model ...
2023-12-01 16:59:41,464:INFO::Epoch: 191
tensor([[0.9978, 0.9341, 0.9560, 0.9231],
        [0.9067, 0.9986, 0.9305, 0.9554],
        [1.0000, 0.9191, 0.9197, 0.9566],
        [1.0000, 0.9095, 0.9582, 0.9109]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:41,465:INFO::its now!!!!!!!!5
2023-12-01 16:59:41,630:INFO::its now!!!!!!!!0
2023-12-01 16:59:41,631:INFO::its now!!!!!!!!3
2023-12-01 16:59:41,671:INFO::its now!!!!!!!!5
2023-12-01 16:59:41,851:INFO::its now!!!!!!!!
2023-12-01 16:59:41,852:INFO::its now!!!!!!!! on 
2023-12-01 16:59:41,901:INFO::its now!!!!!!!!5
2023-12-01 16:59:42,084:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:42,085:INFO::Epoch 00191 | lr 0.00050 | Train_Loss -0.0192 | Train_Classification_Loss 0.0795 | Dmon_Loss -0.1974 | Val_Loss 0.3236 | Search Time(s) 0.4199 | Infer Time(s) 0.2025 | Time(s) 0.6223 
2023-12-01 16:59:42,147:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:42,148:INFO::Validation loss decreased (0.324509 --> 0.323632).  Saving model ...
2023-12-01 16:59:42,150:INFO::Epoch: 192
tensor([[0.9972, 0.9365, 0.9582, 0.9263],
        [0.9093, 0.9979, 0.9335, 0.9577],
        [1.0000, 0.9216, 0.9221, 0.9589],
        [1.0000, 0.9119, 0.9605, 0.9135]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:42,151:INFO::its now!!!!!!!!5
2023-12-01 16:59:42,343:INFO::its now!!!!!!!!0
2023-12-01 16:59:42,344:INFO::its now!!!!!!!!3
2023-12-01 16:59:42,385:INFO::its now!!!!!!!!5
2023-12-01 16:59:42,569:INFO::its now!!!!!!!!
2023-12-01 16:59:42,569:INFO::its now!!!!!!!! on 
2023-12-01 16:59:42,617:INFO::its now!!!!!!!!5
2023-12-01 16:59:42,759:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:42,761:INFO::Epoch 00192 | lr 0.00050 | Train_Loss -0.0207 | Train_Classification_Loss 0.0780 | Dmon_Loss -0.1974 | Val_Loss 0.3229 | Search Time(s) 0.4488 | Infer Time(s) 0.1616 | Time(s) 0.6104 
2023-12-01 16:59:42,810:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:42,811:INFO::Validation loss decreased (0.323632 --> 0.322869).  Saving model ...
2023-12-01 16:59:42,813:INFO::Epoch: 193
tensor([[0.9967, 0.9374, 0.9592, 0.9276],
        [0.9104, 0.9976, 0.9348, 0.9586],
        [1.0000, 0.9227, 0.9231, 0.9598],
        [1.0000, 0.9128, 0.9614, 0.9145]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:42,814:INFO::its now!!!!!!!!5
2023-12-01 16:59:42,975:INFO::its now!!!!!!!!0
2023-12-01 16:59:42,976:INFO::its now!!!!!!!!3
2023-12-01 16:59:43,018:INFO::its now!!!!!!!!5
2023-12-01 16:59:43,215:INFO::its now!!!!!!!!
2023-12-01 16:59:43,216:INFO::its now!!!!!!!! on 
2023-12-01 16:59:43,264:INFO::its now!!!!!!!!5
2023-12-01 16:59:43,418:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:43,420:INFO::Epoch 00193 | lr 0.00050 | Train_Loss -0.0224 | Train_Classification_Loss 0.0767 | Dmon_Loss -0.1982 | Val_Loss 0.3222 | Search Time(s) 0.4348 | Infer Time(s) 0.1715 | Time(s) 0.6064 
2023-12-01 16:59:43,496:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:43,497:INFO::Validation loss decreased (0.322869 --> 0.322214).  Saving model ...
2023-12-01 16:59:43,499:INFO::Epoch: 194
tensor([[0.9968, 0.9393, 0.9610, 0.9298],
        [0.9124, 0.9974, 0.9368, 0.9604],
        [1.0000, 0.9247, 0.9250, 0.9617],
        [1.0000, 0.9147, 0.9633, 0.9165]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:43,500:INFO::its now!!!!!!!!5
2023-12-01 16:59:43,653:INFO::its now!!!!!!!!0
2023-12-01 16:59:43,654:INFO::its now!!!!!!!!3
2023-12-01 16:59:43,695:INFO::its now!!!!!!!!5
2023-12-01 16:59:43,853:INFO::its now!!!!!!!!
2023-12-01 16:59:43,853:INFO::its now!!!!!!!! on 
2023-12-01 16:59:43,903:INFO::its now!!!!!!!!5
2023-12-01 16:59:44,068:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:44,069:INFO::Epoch 00194 | lr 0.00050 | Train_Loss -0.0227 | Train_Classification_Loss 0.0764 | Dmon_Loss -0.1982 | Val_Loss 0.3217 | Search Time(s) 0.3909 | Infer Time(s) 0.1805 | Time(s) 0.5715 
2023-12-01 16:59:44,123:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:44,124:INFO::Validation loss decreased (0.322214 --> 0.321714).  Saving model ...
2023-12-01 16:59:44,128:INFO::Epoch: 195
tensor([[0.9968, 0.9383, 0.9600, 0.9288],
        [0.9113, 0.9973, 0.9359, 0.9595],
        [1.0000, 0.9237, 0.9240, 0.9607],
        [1.0000, 0.9137, 0.9623, 0.9155]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:44,129:INFO::its now!!!!!!!!5
2023-12-01 16:59:44,309:INFO::its now!!!!!!!!0
2023-12-01 16:59:44,310:INFO::its now!!!!!!!!3
2023-12-01 16:59:44,355:INFO::its now!!!!!!!!5
2023-12-01 16:59:44,537:INFO::its now!!!!!!!!
2023-12-01 16:59:44,537:INFO::its now!!!!!!!! on 
2023-12-01 16:59:44,590:INFO::its now!!!!!!!!5
2023-12-01 16:59:44,782:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:44,783:INFO::Epoch 00195 | lr 0.00050 | Train_Loss -0.0276 | Train_Classification_Loss 0.0717 | Dmon_Loss -0.1987 | Val_Loss 0.3213 | Search Time(s) 0.4488 | Infer Time(s) 0.2095 | Time(s) 0.6583 
2023-12-01 16:59:44,822:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 3;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:44,822:INFO::Validation loss decreased (0.321714 --> 0.321276).  Saving model ...
2023-12-01 16:59:44,824:INFO::Epoch: 196
tensor([[0.9968, 0.9339, 0.9558, 0.9243],
        [0.9066, 0.9972, 0.9316, 0.9552],
        [1.0000, 0.9189, 0.9196, 0.9564],
        [1.0000, 0.9093, 0.9581, 0.9107]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:44,825:INFO::its now!!!!!!!!5
2023-12-01 16:59:44,982:INFO::its now!!!!!!!!0
2023-12-01 16:59:44,982:INFO::its now!!!!!!!!3
2023-12-01 16:59:45,024:INFO::its now!!!!!!!!5
2023-12-01 16:59:45,178:INFO::its now!!!!!!!!
2023-12-01 16:59:45,179:INFO::its now!!!!!!!! on 
2023-12-01 16:59:45,229:INFO::its now!!!!!!!!5
2023-12-01 16:59:45,386:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:45,388:INFO::Epoch 00196 | lr 0.00050 | Train_Loss -0.0289 | Train_Classification_Loss 0.0707 | Dmon_Loss -0.1992 | Val_Loss 0.3209 | Search Time(s) 0.3860 | Infer Time(s) 0.1765 | Time(s) 0.5625 
2023-12-01 16:59:45,440:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:45,441:INFO::Validation loss decreased (0.321276 --> 0.320874).  Saving model ...
2023-12-01 16:59:45,443:INFO::Epoch: 197
tensor([[0.9966, 0.9281, 0.9502, 0.9183],
        [0.9003, 0.9972, 0.9258, 0.9496],
        [1.0000, 0.9126, 0.9136, 0.9508],
        [1.0000, 0.9035, 0.9524, 0.9045]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:45,444:INFO::its now!!!!!!!!5
2023-12-01 16:59:45,608:INFO::its now!!!!!!!!0
2023-12-01 16:59:45,609:INFO::its now!!!!!!!!3
2023-12-01 16:59:45,650:INFO::its now!!!!!!!!5
2023-12-01 16:59:45,823:INFO::its now!!!!!!!!
2023-12-01 16:59:45,823:INFO::its now!!!!!!!! on 
2023-12-01 16:59:45,872:INFO::its now!!!!!!!!5
2023-12-01 16:59:46,016:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:46,017:INFO::Epoch 00197 | lr 0.00050 | Train_Loss -0.0284 | Train_Classification_Loss 0.0712 | Dmon_Loss -0.1992 | Val_Loss 0.3206 | Search Time(s) 0.4129 | Infer Time(s) 0.1616 | Time(s) 0.5745 
2023-12-01 16:59:46,066:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 3;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 3;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:46,067:INFO::Validation loss decreased (0.320874 --> 0.320571).  Saving model ...
2023-12-01 16:59:46,069:INFO::Epoch: 198
tensor([[0.9963, 0.9215, 0.9439, 0.9115],
        [0.8932, 0.9972, 0.9193, 0.9433],
        [1.0000, 0.9056, 0.9069, 0.9444],
        [1.0000, 0.8970, 0.9461, 0.8974]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:46,069:INFO::its now!!!!!!!!5
2023-12-01 16:59:46,222:INFO::its now!!!!!!!!0
2023-12-01 16:59:46,223:INFO::its now!!!!!!!!3
2023-12-01 16:59:46,265:INFO::its now!!!!!!!!5
2023-12-01 16:59:46,444:INFO::its now!!!!!!!!
2023-12-01 16:59:46,444:INFO::its now!!!!!!!! on 
2023-12-01 16:59:46,493:INFO::its now!!!!!!!!5
2023-12-01 16:59:46,650:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:46,651:INFO::Epoch 00198 | lr 0.00050 | Train_Loss -0.0320 | Train_Classification_Loss 0.0684 | Dmon_Loss -0.2006 | Val_Loss 0.3203 | Search Time(s) 0.4079 | Infer Time(s) 0.1755 | Time(s) 0.5834 
2023-12-01 16:59:46,708:INFO::cluster info:
0: 0;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:46,709:INFO::Validation loss decreased (0.320571 --> 0.320330).  Saving model ...
2023-12-01 16:59:46,712:INFO::Epoch: 199
tensor([[0.9962, 0.9195, 0.9420, 0.9094],
        [0.8910, 0.9972, 0.9173, 0.9413],
        [1.0000, 0.9034, 0.9048, 0.9424],
        [1.0000, 0.8950, 0.9441, 0.8952]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:46,713:INFO::its now!!!!!!!!5
2023-12-01 16:59:46,892:INFO::its now!!!!!!!!0
2023-12-01 16:59:46,893:INFO::its now!!!!!!!!3
2023-12-01 16:59:46,933:INFO::its now!!!!!!!!5
2023-12-01 16:59:47,110:INFO::its now!!!!!!!!
2023-12-01 16:59:47,110:INFO::its now!!!!!!!! on 
2023-12-01 16:59:47,160:INFO::its now!!!!!!!!5
2023-12-01 16:59:47,332:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:47,334:INFO::Epoch 00199 | lr 0.00050 | Train_Loss -0.0305 | Train_Classification_Loss 0.0699 | Dmon_Loss -0.2007 | Val_Loss 0.3202 | Search Time(s) 0.4308 | Infer Time(s) 0.1925 | Time(s) 0.6233 
2023-12-01 16:59:47,380:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 0;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:47,381:INFO::Validation loss decreased (0.320330 --> 0.320196).  Saving model ...
2023-12-01 16:59:47,386:INFO::Epoch: 200
tensor([[0.9959, 0.9188, 0.9414, 0.9087],
        [0.8903, 0.9972, 0.9166, 0.9407],
        [1.0000, 0.9027, 0.9042, 0.9418],
        [1.0000, 0.8943, 0.9435, 0.8945]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:47,387:INFO::its now!!!!!!!!5
2023-12-01 16:59:47,568:INFO::its now!!!!!!!!0
2023-12-01 16:59:47,568:INFO::its now!!!!!!!!3
2023-12-01 16:59:47,610:INFO::its now!!!!!!!!5
2023-12-01 16:59:47,839:INFO::its now!!!!!!!!
2023-12-01 16:59:47,839:INFO::its now!!!!!!!! on 
2023-12-01 16:59:47,888:INFO::its now!!!!!!!!5
2023-12-01 16:59:48,062:INFO::Epoch 00200 | lr 0.00050 | Train_Loss -0.0342 | Train_Classification_Loss 0.0660 | Dmon_Loss -0.2005 | Val_Loss 0.3205 | Search Time(s) 0.4897 | Infer Time(s) 0.1905 | Time(s) 0.6802 
2023-12-01 16:59:48,114:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:48,115:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 16:59:48,117:INFO::Epoch: 201
tensor([[0.9957, 0.9208, 0.9432, 0.9107],
        [0.8924, 0.9972, 0.9185, 0.9425],
        [1.0000, 0.9048, 0.9061, 0.9436],
        [1.0000, 0.8962, 0.9454, 0.8966]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:48,117:INFO::its now!!!!!!!!5
2023-12-01 16:59:48,287:INFO::its now!!!!!!!!0
2023-12-01 16:59:48,287:INFO::its now!!!!!!!!3
2023-12-01 16:59:48,328:INFO::its now!!!!!!!!5
2023-12-01 16:59:48,523:INFO::its now!!!!!!!!
2023-12-01 16:59:48,523:INFO::its now!!!!!!!! on 
2023-12-01 16:59:48,573:INFO::its now!!!!!!!!5
2023-12-01 16:59:48,757:INFO::Epoch 00201 | lr 0.00050 | Train_Loss -0.0373 | Train_Classification_Loss 0.0639 | Dmon_Loss -0.2023 | Val_Loss 0.3209 | Search Time(s) 0.4458 | Infer Time(s) 0.1945 | Time(s) 0.6403 
2023-12-01 16:59:48,826:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 0;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 0;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:48,827:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 16:59:48,831:INFO::Epoch: 202
tensor([[0.9957, 0.9213, 0.9437, 0.9113],
        [0.8930, 0.9972, 0.9191, 0.9431],
        [1.0000, 0.9054, 0.9067, 0.9442],
        [1.0000, 0.8968, 0.9459, 0.8972]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:48,833:INFO::its now!!!!!!!!5
2023-12-01 16:59:48,974:INFO::its now!!!!!!!!0
2023-12-01 16:59:48,975:INFO::its now!!!!!!!!3
2023-12-01 16:59:49,016:INFO::its now!!!!!!!!5
2023-12-01 16:59:49,186:INFO::its now!!!!!!!!
2023-12-01 16:59:49,186:INFO::its now!!!!!!!! on 
2023-12-01 16:59:49,237:INFO::its now!!!!!!!!5
2023-12-01 16:59:49,383:INFO::Epoch 00202 | lr 0.00050 | Train_Loss -0.0388 | Train_Classification_Loss 0.0622 | Dmon_Loss -0.2021 | Val_Loss 0.3214 | Search Time(s) 0.3920 | Infer Time(s) 0.1626 | Time(s) 0.5545 
2023-12-01 16:59:49,441:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 3;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 0;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:49,442:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 16:59:49,445:INFO::Epoch: 203
tensor([[0.9954, 0.9223, 0.9447, 0.9123],
        [0.8940, 0.9972, 0.9201, 0.9440],
        [1.0000, 0.9064, 0.9077, 0.9451],
        [1.0000, 0.8978, 0.9468, 0.8982]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:49,446:INFO::its now!!!!!!!!5
2023-12-01 16:59:49,584:INFO::its now!!!!!!!!0
2023-12-01 16:59:49,584:INFO::its now!!!!!!!!3
2023-12-01 16:59:49,626:INFO::its now!!!!!!!!5
2023-12-01 16:59:49,810:INFO::its now!!!!!!!!
2023-12-01 16:59:49,810:INFO::its now!!!!!!!! on 
2023-12-01 16:59:49,859:INFO::its now!!!!!!!!5
2023-12-01 16:59:50,007:INFO::Epoch 00203 | lr 0.00050 | Train_Loss -0.0402 | Train_Classification_Loss 0.0618 | Dmon_Loss -0.2040 | Val_Loss 0.3220 | Search Time(s) 0.3979 | Infer Time(s) 0.1666 | Time(s) 0.5645 
2023-12-01 16:59:50,045:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 3;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 3;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:50,046:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 16:59:50,049:INFO::Epoch: 204
tensor([[0.9951, 0.9240, 0.9463, 0.9140],
        [0.8958, 0.9972, 0.9217, 0.9456],
        [1.0000, 0.9082, 0.9094, 0.9467],
        [1.0000, 0.8994, 0.9484, 0.9000]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:50,050:INFO::its now!!!!!!!!5
2023-12-01 16:59:50,230:INFO::its now!!!!!!!!0
2023-12-01 16:59:50,231:INFO::its now!!!!!!!!3
2023-12-01 16:59:50,272:INFO::its now!!!!!!!!5
2023-12-01 16:59:50,425:INFO::its now!!!!!!!!
2023-12-01 16:59:50,425:INFO::its now!!!!!!!! on 
2023-12-01 16:59:50,481:INFO::its now!!!!!!!!5
2023-12-01 16:59:50,650:INFO::Epoch 00204 | lr 0.00050 | Train_Loss -0.0355 | Train_Classification_Loss 0.0663 | Dmon_Loss -0.2034 | Val_Loss 0.3225 | Search Time(s) 0.4199 | Infer Time(s) 0.1845 | Time(s) 0.6044 
2023-12-01 16:59:50,698:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:50,699:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 16:59:50,701:INFO::Epoch: 205
tensor([[0.9949, 0.9245, 0.9468, 0.9146],
        [0.8964, 0.9972, 0.9222, 0.9461],
        [1.0000, 0.9088, 0.9099, 0.9472],
        [1.0000, 0.8999, 0.9489, 0.9006]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:50,702:INFO::its now!!!!!!!!5
2023-12-01 16:59:50,849:INFO::its now!!!!!!!!0
2023-12-01 16:59:50,849:INFO::its now!!!!!!!!3
2023-12-01 16:59:50,891:INFO::its now!!!!!!!!5
2023-12-01 16:59:51,093:INFO::its now!!!!!!!!
2023-12-01 16:59:51,094:INFO::its now!!!!!!!! on 
2023-12-01 16:59:51,142:INFO::its now!!!!!!!!5
2023-12-01 16:59:51,294:INFO::Epoch 00205 | lr 0.00050 | Train_Loss -0.0379 | Train_Classification_Loss 0.0640 | Dmon_Loss -0.2039 | Val_Loss 0.3229 | Search Time(s) 0.4239 | Infer Time(s) 0.1706 | Time(s) 0.5944 
2023-12-01 16:59:51,360:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 0;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:51,362:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 16:59:51,364:INFO::Epoch: 206
tensor([[0.9948, 0.9257, 0.9479, 0.9159],
        [0.8977, 0.9972, 0.9235, 0.9473],
        [1.0000, 0.9101, 0.9112, 0.9484],
        [1.0000, 0.9012, 0.9501, 0.9019]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:51,364:INFO::its now!!!!!!!!5
2023-12-01 16:59:51,519:INFO::its now!!!!!!!!0
2023-12-01 16:59:51,520:INFO::its now!!!!!!!!3
2023-12-01 16:59:51,560:INFO::its now!!!!!!!!5
2023-12-01 16:59:51,741:INFO::its now!!!!!!!!
2023-12-01 16:59:51,741:INFO::its now!!!!!!!! on 
2023-12-01 16:59:51,790:INFO::its now!!!!!!!!5
2023-12-01 16:59:51,939:INFO::Epoch 00206 | lr 0.00050 | Train_Loss -0.0372 | Train_Classification_Loss 0.0646 | Dmon_Loss -0.2036 | Val_Loss 0.3231 | Search Time(s) 0.4109 | Infer Time(s) 0.1656 | Time(s) 0.5765 
2023-12-01 16:59:51,992:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 0;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 0;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:51,993:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 16:59:51,995:INFO::Epoch: 207
tensor([[0.9945, 0.9272, 0.9494, 0.9174],
        [0.8993, 0.9972, 0.9250, 0.9488],
        [1.0000, 0.9117, 0.9127, 0.9499],
        [1.0000, 0.9027, 0.9516, 0.9035]], device='cuda:0', requires_grad=True)
2023-12-01 16:59:51,996:INFO::its now!!!!!!!!5
2023-12-01 16:59:52,148:INFO::its now!!!!!!!!0
2023-12-01 16:59:52,149:INFO::its now!!!!!!!!3
2023-12-01 16:59:52,189:INFO::its now!!!!!!!!5
2023-12-01 16:59:52,362:INFO::its now!!!!!!!!
2023-12-01 16:59:52,363:INFO::its now!!!!!!!! on 
2023-12-01 16:59:52,414:INFO::its now!!!!!!!!5
2023-12-01 16:59:52,553:INFO::Epoch 00207 | lr 0.00050 | Train_Loss -0.0427 | Train_Classification_Loss 0.0596 | Dmon_Loss -0.2047 | Val_Loss 0.3229 | Search Time(s) 0.4199 | Infer Time(s) 0.1406 | Time(s) 0.5605 
2023-12-01 16:59:52,609:INFO::cluster info:
0: 3;	1: 3;	2: 0;	3: 3;	4: 0;	5: 3;	6: 3;	7: 0;	8: 3;	9: 0;	10: 3;	11: 0;	12: 0;	13: 3;	14: 0;	15: 0;	16: 0;	17: 3;	18: 3;	19: 3;	20: 0;	21: 0;	22: 3;	23: 0;	24: 0;	25: 0;	26: 3;	27: 0;	28: 3;	29: 3;	30: 3;	31: 3;	32: 0;	33: 3;	34: 3;	35: 0;	36: 3;	37: 3;	38: 3;	39: 0;	40: 3;	41: 3;	42: 0;	43: 3;	44
26098: 0;	26099: 0;	26100: 0;	26101: 0;	26102: 3;	26103: 0;	26104: 3;	26105: 0;	26106: 0;	26107: 0;	26108: 3;	26109: 0;	26110: 3;	26111: 0;	26112: 0;	26113: 3;	26114: 3;	26115: 0;	26116: 0;	26117: 3;	26118: 0;	26119: 0;	26120: 0;	26121: 3;	26122: 0;	26123: 0;	26124: 3;	26125: 3;	26126: 0;	26127: 0;	
2023-12-01 16:59:52,609:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 16:59:52,610:INFO::Eearly stopping!
2023-12-01 16:59:54,874:INFO::############### Search Stage Ends! ###############
2023-12-01 16:59:54,939:INFO::=============== Retrain Stage Starts:
2023-12-01 16:59:54,939:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:54,957:INFO::node_assign_Counter:
Counter({-1: 14328, 3: 7138, 0: 4662})
2023-12-01 16:59:54,957:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 16:59:55,369:INFO::============= repeat round: 3; seed: 1024
2023-12-01 16:59:55,406:INFO::arch_weights:
[[0.9959046  0.91883767 0.9413548  0.9087352 ]
 [0.8902818  0.997205   0.9166268  0.94066685]
 [0.99999493 0.90271664 0.90417105 0.9417582 ]
 [1.         0.8943259  0.94349635 0.8945387 ]]
2023-12-01 16:59:55,406:INFO::arch_weights_softmax:
[[0.2639037  0.2443294  0.24989343 0.24187352]
 [0.23859401 0.26551905 0.24496332 0.25092357]
 [0.26600313 0.24134558 0.24169685 0.25095445]
 [0.26704478 0.24026494 0.25237417 0.2403161 ]]
2023-12-01 16:59:55,406:INFO::genotype choice:
['gcn', 'ppnp', 'gcn', 'gcn']
2023-12-01 16:59:55,907:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.3789 | Val_Loss 1.3808 | Time(s) 0.4697
2023-12-01 16:59:56,322:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3751 | Val_Loss 1.3778 | Time(s) 0.3910
2023-12-01 16:59:56,331:INFO::Validation loss decreased (inf --> 1.377763).  Saving model ...
2023-12-01 16:59:56,718:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3715 | Val_Loss 1.3748 | Time(s) 0.3860
2023-12-01 16:59:56,729:INFO::Validation loss decreased (1.377763 --> 1.374808).  Saving model ...
2023-12-01 16:59:57,134:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.3674 | Val_Loss 1.3719 | Time(s) 0.4049
2023-12-01 16:59:57,144:INFO::Validation loss decreased (1.374808 --> 1.371922).  Saving model ...
2023-12-01 16:59:57,522:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.3640 | Val_Loss 1.3691 | Time(s) 0.3780
2023-12-01 16:59:57,530:INFO::Validation loss decreased (1.371922 --> 1.369062).  Saving model ...
2023-12-01 16:59:57,933:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.3579 | Val_Loss 1.3662 | Time(s) 0.4029
2023-12-01 16:59:57,942:INFO::Validation loss decreased (1.369062 --> 1.366207).  Saving model ...
2023-12-01 16:59:58,366:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.3542 | Val_Loss 1.3633 | Time(s) 0.4239
2023-12-01 16:59:58,398:INFO::Validation loss decreased (1.366207 --> 1.363341).  Saving model ...
2023-12-01 16:59:58,884:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.3490 | Val_Loss 1.3605 | Time(s) 0.4857
2023-12-01 16:59:58,893:INFO::Validation loss decreased (1.363341 --> 1.360466).  Saving model ...
2023-12-01 16:59:59,263:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.3430 | Val_Loss 1.3575 | Time(s) 0.3690
2023-12-01 16:59:59,272:INFO::Validation loss decreased (1.360466 --> 1.357543).  Saving model ...
2023-12-01 16:59:59,666:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.3415 | Val_Loss 1.3546 | Time(s) 0.3930
2023-12-01 16:59:59,678:INFO::Validation loss decreased (1.357543 --> 1.354593).  Saving model ...
2023-12-01 17:00:00,031:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.3360 | Val_Loss 1.3516 | Time(s) 0.3531
2023-12-01 17:00:00,040:INFO::Validation loss decreased (1.354593 --> 1.351579).  Saving model ...
2023-12-01 17:00:00,410:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.3339 | Val_Loss 1.3485 | Time(s) 0.3700
2023-12-01 17:00:00,432:INFO::Validation loss decreased (1.351579 --> 1.348495).  Saving model ...
2023-12-01 17:00:00,829:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 1.3295 | Val_Loss 1.3453 | Time(s) 0.3959
2023-12-01 17:00:00,837:INFO::Validation loss decreased (1.348495 --> 1.345340).  Saving model ...
2023-12-01 17:00:01,230:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 1.3249 | Val_Loss 1.3421 | Time(s) 0.3929
2023-12-01 17:00:01,239:INFO::Validation loss decreased (1.345340 --> 1.342071).  Saving model ...
2023-12-01 17:00:01,606:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 1.3178 | Val_Loss 1.3387 | Time(s) 0.3670
2023-12-01 17:00:01,616:INFO::Validation loss decreased (1.342071 --> 1.338695).  Saving model ...
2023-12-01 17:00:02,013:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 1.3150 | Val_Loss 1.3352 | Time(s) 0.3959
2023-12-01 17:00:02,021:INFO::Validation loss decreased (1.338695 --> 1.335185).  Saving model ...
2023-12-01 17:00:02,384:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 1.3102 | Val_Loss 1.3315 | Time(s) 0.3620
2023-12-01 17:00:02,393:INFO::Validation loss decreased (1.335185 --> 1.331519).  Saving model ...
2023-12-01 17:00:02,790:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 1.3052 | Val_Loss 1.3277 | Time(s) 0.3969
2023-12-01 17:00:02,801:INFO::Validation loss decreased (1.331519 --> 1.327693).  Saving model ...
2023-12-01 17:00:03,190:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 1.3020 | Val_Loss 1.3237 | Time(s) 0.3890
2023-12-01 17:00:03,204:INFO::Validation loss decreased (1.327693 --> 1.323678).  Saving model ...
2023-12-01 17:00:03,552:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 1.2937 | Val_Loss 1.3195 | Time(s) 0.3471
2023-12-01 17:00:03,560:INFO::Validation loss decreased (1.323678 --> 1.319474).  Saving model ...
2023-12-01 17:00:03,940:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 1.2898 | Val_Loss 1.3151 | Time(s) 0.3790
2023-12-01 17:00:03,952:INFO::Validation loss decreased (1.319474 --> 1.315052).  Saving model ...
2023-12-01 17:00:04,407:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 1.2835 | Val_Loss 1.3104 | Time(s) 0.4538
2023-12-01 17:00:04,416:INFO::Validation loss decreased (1.315052 --> 1.310398).  Saving model ...
2023-12-01 17:00:04,801:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 1.2762 | Val_Loss 1.3055 | Time(s) 0.3840
2023-12-01 17:00:05,077:INFO::Validation loss decreased (1.310398 --> 1.305498).  Saving model ...
2023-12-01 17:00:05,602:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 1.2686 | Val_Loss 1.3004 | Time(s) 0.5246
2023-12-01 17:00:05,611:INFO::Validation loss decreased (1.305498 --> 1.300353).  Saving model ...
2023-12-01 17:00:06,024:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 1.2670 | Val_Loss 1.2949 | Time(s) 0.4129
2023-12-01 17:00:06,032:INFO::Validation loss decreased (1.300353 --> 1.294946).  Saving model ...
2023-12-01 17:00:06,435:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 1.2550 | Val_Loss 1.2893 | Time(s) 0.4029
2023-12-01 17:00:08,037:INFO::Validation loss decreased (1.294946 --> 1.289273).  Saving model ...
2023-12-01 17:00:08,554:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 1.2524 | Val_Loss 1.2833 | Time(s) 0.5166
2023-12-01 17:00:08,565:INFO::Validation loss decreased (1.289273 --> 1.283317).  Saving model ...
2023-12-01 17:00:08,923:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 1.2418 | Val_Loss 1.2771 | Time(s) 0.3570
2023-12-01 17:00:08,932:INFO::Validation loss decreased (1.283317 --> 1.277091).  Saving model ...
2023-12-01 17:00:09,326:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 1.2371 | Val_Loss 1.2706 | Time(s) 0.3939
2023-12-01 17:00:09,336:INFO::Validation loss decreased (1.277091 --> 1.270559).  Saving model ...
2023-12-01 17:00:09,798:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 1.2283 | Val_Loss 1.2637 | Time(s) 0.4618
2023-12-01 17:00:09,811:INFO::Validation loss decreased (1.270559 --> 1.263747).  Saving model ...
2023-12-01 17:00:10,189:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 1.2228 | Val_Loss 1.2566 | Time(s) 0.3780
2023-12-01 17:00:10,198:INFO::Validation loss decreased (1.263747 --> 1.256622).  Saving model ...
2023-12-01 17:00:10,572:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 1.2138 | Val_Loss 1.2492 | Time(s) 0.3730
2023-12-01 17:00:10,581:INFO::Validation loss decreased (1.256622 --> 1.249190).  Saving model ...
2023-12-01 17:00:10,962:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 1.2044 | Val_Loss 1.2414 | Time(s) 0.3800
2023-12-01 17:00:10,974:INFO::Validation loss decreased (1.249190 --> 1.241436).  Saving model ...
2023-12-01 17:00:11,392:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 1.1970 | Val_Loss 1.2334 | Time(s) 0.4179
2023-12-01 17:00:11,400:INFO::Validation loss decreased (1.241436 --> 1.233390).  Saving model ...
2023-12-01 17:00:11,771:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 1.1846 | Val_Loss 1.2250 | Time(s) 0.3700
2023-12-01 17:00:11,779:INFO::Validation loss decreased (1.233390 --> 1.225037).  Saving model ...
2023-12-01 17:00:12,167:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 1.1724 | Val_Loss 1.2164 | Time(s) 0.3880
2023-12-01 17:00:12,176:INFO::Validation loss decreased (1.225037 --> 1.216375).  Saving model ...
2023-12-01 17:00:12,581:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 1.1683 | Val_Loss 1.2074 | Time(s) 0.4049
2023-12-01 17:00:12,592:INFO::Validation loss decreased (1.216375 --> 1.207418).  Saving model ...
2023-12-01 17:00:13,011:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 1.1582 | Val_Loss 1.1982 | Time(s) 0.4189
2023-12-01 17:00:13,019:INFO::Validation loss decreased (1.207418 --> 1.198171).  Saving model ...
2023-12-01 17:00:13,410:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 1.1419 | Val_Loss 1.1887 | Time(s) 0.3890
2023-12-01 17:00:13,419:INFO::Validation loss decreased (1.198171 --> 1.188652).  Saving model ...
2023-12-01 17:00:13,771:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 1.1375 | Val_Loss 1.1788 | Time(s) 0.3521
2023-12-01 17:00:13,780:INFO::Validation loss decreased (1.188652 --> 1.178845).  Saving model ...
2023-12-01 17:00:14,139:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 1.1224 | Val_Loss 1.1688 | Time(s) 0.3590
2023-12-01 17:00:14,149:INFO::Validation loss decreased (1.178845 --> 1.168766).  Saving model ...
2023-12-01 17:00:14,530:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 1.1141 | Val_Loss 1.1584 | Time(s) 0.3810
2023-12-01 17:00:14,541:INFO::Validation loss decreased (1.168766 --> 1.158406).  Saving model ...
2023-12-01 17:00:14,932:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 1.1028 | Val_Loss 1.1478 | Time(s) 0.3910
2023-12-01 17:00:14,941:INFO::Validation loss decreased (1.158406 --> 1.147757).  Saving model ...
2023-12-01 17:00:15,409:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 1.0872 | Val_Loss 1.1369 | Time(s) 0.4677
2023-12-01 17:00:15,420:INFO::Validation loss decreased (1.147757 --> 1.136878).  Saving model ...
2023-12-01 17:00:15,784:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 1.0762 | Val_Loss 1.1258 | Time(s) 0.3640
2023-12-01 17:00:15,793:INFO::Validation loss decreased (1.136878 --> 1.125761).  Saving model ...
2023-12-01 17:00:16,163:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 1.0601 | Val_Loss 1.1145 | Time(s) 0.3700
2023-12-01 17:00:16,172:INFO::Validation loss decreased (1.125761 --> 1.114464).  Saving model ...
2023-12-01 17:00:16,593:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 1.0517 | Val_Loss 1.1029 | Time(s) 0.4209
2023-12-01 17:00:16,601:INFO::Validation loss decreased (1.114464 --> 1.102943).  Saving model ...
2023-12-01 17:00:16,966:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 1.0363 | Val_Loss 1.0912 | Time(s) 0.3650
2023-12-01 17:00:16,974:INFO::Validation loss decreased (1.102943 --> 1.091244).  Saving model ...
2023-12-01 17:00:17,337:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 1.0256 | Val_Loss 1.0793 | Time(s) 0.3630
2023-12-01 17:00:17,347:INFO::Validation loss decreased (1.091244 --> 1.079349).  Saving model ...
2023-12-01 17:00:17,752:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 1.0142 | Val_Loss 1.0673 | Time(s) 0.4049
2023-12-01 17:00:17,762:INFO::Validation loss decreased (1.079349 --> 1.067265).  Saving model ...
2023-12-01 17:00:18,123:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 0.9955 | Val_Loss 1.0550 | Time(s) 0.3590
2023-12-01 17:00:18,130:INFO::Validation loss decreased (1.067265 --> 1.054978).  Saving model ...
2023-12-01 17:00:18,497:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.9808 | Val_Loss 1.0425 | Time(s) 0.3650
2023-12-01 17:00:18,504:INFO::Validation loss decreased (1.054978 --> 1.042519).  Saving model ...
2023-12-01 17:00:18,865:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.9668 | Val_Loss 1.0299 | Time(s) 0.3600
2023-12-01 17:00:18,875:INFO::Validation loss decreased (1.042519 --> 1.029899).  Saving model ...
2023-12-01 17:00:19,205:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 0.9473 | Val_Loss 1.0171 | Time(s) 0.3291
2023-12-01 17:00:19,213:INFO::Validation loss decreased (1.029899 --> 1.017120).  Saving model ...
2023-12-01 17:00:19,644:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.9413 | Val_Loss 1.0042 | Time(s) 0.4299
2023-12-01 17:00:19,657:INFO::Validation loss decreased (1.017120 --> 1.004171).  Saving model ...
2023-12-01 17:00:20,041:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.9167 | Val_Loss 0.9911 | Time(s) 0.3840
2023-12-01 17:00:20,050:INFO::Validation loss decreased (1.004171 --> 0.991062).  Saving model ...
2023-12-01 17:00:20,416:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.9109 | Val_Loss 0.9778 | Time(s) 0.3660
2023-12-01 17:00:20,424:INFO::Validation loss decreased (0.991062 --> 0.977844).  Saving model ...
2023-12-01 17:00:20,910:INFO::Epoch 00057 | lr 0.00050 |Train_Loss 0.8900 | Val_Loss 0.9645 | Time(s) 0.4858
2023-12-01 17:00:20,919:INFO::Validation loss decreased (0.977844 --> 0.964530).  Saving model ...
2023-12-01 17:00:21,334:INFO::Epoch 00058 | lr 0.00050 |Train_Loss 0.8845 | Val_Loss 0.9512 | Time(s) 0.4151
2023-12-01 17:00:21,343:INFO::Validation loss decreased (0.964530 --> 0.951189).  Saving model ...
2023-12-01 17:00:21,711:INFO::Epoch 00059 | lr 0.00050 |Train_Loss 0.8589 | Val_Loss 0.9378 | Time(s) 0.3680
2023-12-01 17:00:21,719:INFO::Validation loss decreased (0.951189 --> 0.937761).  Saving model ...
2023-12-01 17:00:22,103:INFO::Epoch 00060 | lr 0.00050 |Train_Loss 0.8475 | Val_Loss 0.9243 | Time(s) 0.3835
2023-12-01 17:00:22,113:INFO::Validation loss decreased (0.937761 --> 0.924273).  Saving model ...
2023-12-01 17:00:22,470:INFO::Epoch 00061 | lr 0.00050 |Train_Loss 0.8268 | Val_Loss 0.9107 | Time(s) 0.3576
2023-12-01 17:00:22,478:INFO::Validation loss decreased (0.924273 --> 0.910733).  Saving model ...
2023-12-01 17:00:22,852:INFO::Epoch 00062 | lr 0.00050 |Train_Loss 0.8197 | Val_Loss 0.8971 | Time(s) 0.3740
2023-12-01 17:00:22,861:INFO::Validation loss decreased (0.910733 --> 0.897136).  Saving model ...
2023-12-01 17:00:23,252:INFO::Epoch 00063 | lr 0.00050 |Train_Loss 0.7969 | Val_Loss 0.8835 | Time(s) 0.3905
2023-12-01 17:00:23,262:INFO::Validation loss decreased (0.897136 --> 0.883524).  Saving model ...
2023-12-01 17:00:23,637:INFO::Epoch 00064 | lr 0.00050 |Train_Loss 0.7794 | Val_Loss 0.8699 | Time(s) 0.3756
2023-12-01 17:00:23,648:INFO::Validation loss decreased (0.883524 --> 0.869906).  Saving model ...
2023-12-01 17:00:24,040:INFO::Epoch 00065 | lr 0.00050 |Train_Loss 0.7670 | Val_Loss 0.8563 | Time(s) 0.3915
2023-12-01 17:00:24,052:INFO::Validation loss decreased (0.869906 --> 0.856291).  Saving model ...
2023-12-01 17:00:24,406:INFO::Epoch 00066 | lr 0.00050 |Train_Loss 0.7565 | Val_Loss 0.8427 | Time(s) 0.3543
2023-12-01 17:00:24,422:INFO::Validation loss decreased (0.856291 --> 0.842712).  Saving model ...
2023-12-01 17:00:24,776:INFO::Epoch 00067 | lr 0.00050 |Train_Loss 0.7362 | Val_Loss 0.8291 | Time(s) 0.3541
2023-12-01 17:00:24,785:INFO::Validation loss decreased (0.842712 --> 0.829146).  Saving model ...
2023-12-01 17:00:25,153:INFO::Epoch 00068 | lr 0.00050 |Train_Loss 0.7196 | Val_Loss 0.8157 | Time(s) 0.3676
2023-12-01 17:00:25,161:INFO::Validation loss decreased (0.829146 --> 0.815663).  Saving model ...
2023-12-01 17:00:25,536:INFO::Epoch 00069 | lr 0.00050 |Train_Loss 0.7002 | Val_Loss 0.8023 | Time(s) 0.3736
2023-12-01 17:00:25,545:INFO::Validation loss decreased (0.815663 --> 0.802258).  Saving model ...
2023-12-01 17:00:25,905:INFO::Epoch 00070 | lr 0.00050 |Train_Loss 0.6871 | Val_Loss 0.7890 | Time(s) 0.3596
2023-12-01 17:00:25,915:INFO::Validation loss decreased (0.802258 --> 0.788961).  Saving model ...
2023-12-01 17:00:26,378:INFO::Epoch 00071 | lr 0.00050 |Train_Loss 0.6771 | Val_Loss 0.7758 | Time(s) 0.4619
2023-12-01 17:00:26,387:INFO::Validation loss decreased (0.788961 --> 0.775805).  Saving model ...
2023-12-01 17:00:26,763:INFO::Epoch 00072 | lr 0.00050 |Train_Loss 0.6564 | Val_Loss 0.7628 | Time(s) 0.3760
2023-12-01 17:00:26,771:INFO::Validation loss decreased (0.775805 --> 0.762808).  Saving model ...
2023-12-01 17:00:27,143:INFO::Epoch 00073 | lr 0.00050 |Train_Loss 0.6475 | Val_Loss 0.7500 | Time(s) 0.3706
2023-12-01 17:00:27,151:INFO::Validation loss decreased (0.762808 --> 0.750011).  Saving model ...
2023-12-01 17:00:27,541:INFO::Epoch 00074 | lr 0.00050 |Train_Loss 0.6275 | Val_Loss 0.7374 | Time(s) 0.3895
2023-12-01 17:00:27,552:INFO::Validation loss decreased (0.750011 --> 0.737392).  Saving model ...
2023-12-01 17:00:27,922:INFO::Epoch 00075 | lr 0.00050 |Train_Loss 0.6138 | Val_Loss 0.7249 | Time(s) 0.3690
2023-12-01 17:00:27,930:INFO::Validation loss decreased (0.737392 --> 0.724921).  Saving model ...
2023-12-01 17:00:28,278:INFO::Epoch 00076 | lr 0.00050 |Train_Loss 0.6037 | Val_Loss 0.7126 | Time(s) 0.3486
2023-12-01 17:00:28,289:INFO::Validation loss decreased (0.724921 --> 0.712643).  Saving model ...
2023-12-01 17:00:28,705:INFO::Epoch 00077 | lr 0.00050 |Train_Loss 0.5851 | Val_Loss 0.7006 | Time(s) 0.4149
2023-12-01 17:00:28,718:INFO::Validation loss decreased (0.712643 --> 0.700555).  Saving model ...
2023-12-01 17:00:29,107:INFO::Epoch 00078 | lr 0.00050 |Train_Loss 0.5758 | Val_Loss 0.6887 | Time(s) 0.3886
2023-12-01 17:00:29,115:INFO::Validation loss decreased (0.700555 --> 0.688732).  Saving model ...
2023-12-01 17:00:29,520:INFO::Epoch 00079 | lr 0.00050 |Train_Loss 0.5555 | Val_Loss 0.6771 | Time(s) 0.4049
2023-12-01 17:00:29,527:INFO::Validation loss decreased (0.688732 --> 0.677093).  Saving model ...
2023-12-01 17:00:29,891:INFO::Epoch 00080 | lr 0.00050 |Train_Loss 0.5457 | Val_Loss 0.6657 | Time(s) 0.3630
2023-12-01 17:00:29,900:INFO::Validation loss decreased (0.677093 --> 0.665688).  Saving model ...
2023-12-01 17:00:30,274:INFO::Epoch 00081 | lr 0.00050 |Train_Loss 0.5302 | Val_Loss 0.6545 | Time(s) 0.3736
2023-12-01 17:00:30,283:INFO::Validation loss decreased (0.665688 --> 0.654506).  Saving model ...
2023-12-01 17:00:30,645:INFO::Epoch 00082 | lr 0.00050 |Train_Loss 0.5211 | Val_Loss 0.6436 | Time(s) 0.3616
2023-12-01 17:00:30,654:INFO::Validation loss decreased (0.654506 --> 0.643562).  Saving model ...
2023-12-01 17:00:31,060:INFO::Epoch 00083 | lr 0.00050 |Train_Loss 0.5024 | Val_Loss 0.6329 | Time(s) 0.4049
2023-12-01 17:00:31,069:INFO::Validation loss decreased (0.643562 --> 0.632879).  Saving model ...
2023-12-01 17:00:31,451:INFO::Epoch 00084 | lr 0.00050 |Train_Loss 0.4978 | Val_Loss 0.6225 | Time(s) 0.3812
2023-12-01 17:00:31,464:INFO::Validation loss decreased (0.632879 --> 0.622462).  Saving model ...
2023-12-01 17:00:31,929:INFO::Epoch 00085 | lr 0.00050 |Train_Loss 0.4759 | Val_Loss 0.6123 | Time(s) 0.4658
2023-12-01 17:00:31,941:INFO::Validation loss decreased (0.622462 --> 0.612293).  Saving model ...
2023-12-01 17:00:32,298:INFO::Epoch 00086 | lr 0.00050 |Train_Loss 0.4670 | Val_Loss 0.6024 | Time(s) 0.3569
2023-12-01 17:00:32,306:INFO::Validation loss decreased (0.612293 --> 0.602368).  Saving model ...
2023-12-01 17:00:32,735:INFO::Epoch 00087 | lr 0.00050 |Train_Loss 0.4494 | Val_Loss 0.5927 | Time(s) 0.4289
2023-12-01 17:00:32,746:INFO::Validation loss decreased (0.602368 --> 0.592689).  Saving model ...
2023-12-01 17:00:33,138:INFO::Epoch 00088 | lr 0.00050 |Train_Loss 0.4387 | Val_Loss 0.5832 | Time(s) 0.3905
2023-12-01 17:00:33,148:INFO::Validation loss decreased (0.592689 --> 0.583237).  Saving model ...
2023-12-01 17:00:33,546:INFO::Epoch 00089 | lr 0.00050 |Train_Loss 0.4265 | Val_Loss 0.5741 | Time(s) 0.3975
2023-12-01 17:00:33,557:INFO::Validation loss decreased (0.583237 --> 0.574064).  Saving model ...
2023-12-01 17:00:33,946:INFO::Epoch 00090 | lr 0.00050 |Train_Loss 0.4250 | Val_Loss 0.5651 | Time(s) 0.3880
2023-12-01 17:00:33,956:INFO::Validation loss decreased (0.574064 --> 0.565094).  Saving model ...
2023-12-01 17:00:34,334:INFO::Epoch 00091 | lr 0.00050 |Train_Loss 0.4144 | Val_Loss 0.5564 | Time(s) 0.3767
2023-12-01 17:00:34,342:INFO::Validation loss decreased (0.565094 --> 0.556353).  Saving model ...
2023-12-01 17:00:34,749:INFO::Epoch 00092 | lr 0.00050 |Train_Loss 0.4004 | Val_Loss 0.5479 | Time(s) 0.4069
2023-12-01 17:00:34,764:INFO::Validation loss decreased (0.556353 --> 0.547873).  Saving model ...
2023-12-01 17:00:35,153:INFO::Epoch 00093 | lr 0.00050 |Train_Loss 0.3943 | Val_Loss 0.5397 | Time(s) 0.3895
2023-12-01 17:00:35,163:INFO::Validation loss decreased (0.547873 --> 0.539666).  Saving model ...
2023-12-01 17:00:35,527:INFO::Epoch 00094 | lr 0.00050 |Train_Loss 0.3837 | Val_Loss 0.5317 | Time(s) 0.3636
2023-12-01 17:00:35,536:INFO::Validation loss decreased (0.539666 --> 0.531704).  Saving model ...
2023-12-01 17:00:35,913:INFO::Epoch 00095 | lr 0.00050 |Train_Loss 0.3735 | Val_Loss 0.5239 | Time(s) 0.3770
2023-12-01 17:00:35,925:INFO::Validation loss decreased (0.531704 --> 0.523938).  Saving model ...
2023-12-01 17:00:36,287:INFO::Epoch 00096 | lr 0.00050 |Train_Loss 0.3725 | Val_Loss 0.5164 | Time(s) 0.3621
2023-12-01 17:00:36,296:INFO::Validation loss decreased (0.523938 --> 0.516429).  Saving model ...
2023-12-01 17:00:36,672:INFO::Epoch 00097 | lr 0.00050 |Train_Loss 0.3615 | Val_Loss 0.5091 | Time(s) 0.3760
2023-12-01 17:00:36,680:INFO::Validation loss decreased (0.516429 --> 0.509123).  Saving model ...
2023-12-01 17:00:37,056:INFO::Epoch 00098 | lr 0.00050 |Train_Loss 0.3438 | Val_Loss 0.5020 | Time(s) 0.3760
2023-12-01 17:00:37,070:INFO::Validation loss decreased (0.509123 --> 0.502002).  Saving model ...
2023-12-01 17:00:37,533:INFO::Epoch 00099 | lr 0.00050 |Train_Loss 0.3368 | Val_Loss 0.4951 | Time(s) 0.4635
2023-12-01 17:00:37,544:INFO::Validation loss decreased (0.502002 --> 0.495077).  Saving model ...
2023-12-01 17:00:37,914:INFO::Epoch 00100 | lr 0.00050 |Train_Loss 0.3358 | Val_Loss 0.4884 | Time(s) 0.3700
2023-12-01 17:00:37,923:INFO::Validation loss decreased (0.495077 --> 0.488418).  Saving model ...
2023-12-01 17:00:38,289:INFO::Epoch 00101 | lr 0.00050 |Train_Loss 0.3305 | Val_Loss 0.4820 | Time(s) 0.3656
2023-12-01 17:00:38,298:INFO::Validation loss decreased (0.488418 --> 0.481972).  Saving model ...
2023-12-01 17:00:38,691:INFO::Epoch 00102 | lr 0.00050 |Train_Loss 0.3135 | Val_Loss 0.4757 | Time(s) 0.3930
2023-12-01 17:00:38,699:INFO::Validation loss decreased (0.481972 --> 0.475733).  Saving model ...
2023-12-01 17:00:39,079:INFO::Epoch 00103 | lr 0.00050 |Train_Loss 0.3105 | Val_Loss 0.4697 | Time(s) 0.3794
2023-12-01 17:00:39,090:INFO::Validation loss decreased (0.475733 --> 0.469720).  Saving model ...
2023-12-01 17:00:39,491:INFO::Epoch 00104 | lr 0.00050 |Train_Loss 0.2953 | Val_Loss 0.4639 | Time(s) 0.4009
2023-12-01 17:00:39,499:INFO::Validation loss decreased (0.469720 --> 0.463937).  Saving model ...
2023-12-01 17:00:39,860:INFO::Epoch 00105 | lr 0.00050 |Train_Loss 0.3012 | Val_Loss 0.4584 | Time(s) 0.3610
2023-12-01 17:00:39,871:INFO::Validation loss decreased (0.463937 --> 0.458371).  Saving model ...
2023-12-01 17:00:40,247:INFO::Epoch 00106 | lr 0.00050 |Train_Loss 0.2881 | Val_Loss 0.4530 | Time(s) 0.3745
2023-12-01 17:00:40,255:INFO::Validation loss decreased (0.458371 --> 0.452990).  Saving model ...
2023-12-01 17:00:40,620:INFO::Epoch 00107 | lr 0.00050 |Train_Loss 0.2786 | Val_Loss 0.4478 | Time(s) 0.3646
2023-12-01 17:00:40,629:INFO::Validation loss decreased (0.452990 --> 0.447754).  Saving model ...
2023-12-01 17:00:41,018:INFO::Epoch 00108 | lr 0.00050 |Train_Loss 0.2703 | Val_Loss 0.4427 | Time(s) 0.3890
2023-12-01 17:00:41,027:INFO::Validation loss decreased (0.447754 --> 0.442723).  Saving model ...
2023-12-01 17:00:41,438:INFO::Epoch 00109 | lr 0.00050 |Train_Loss 0.2690 | Val_Loss 0.4378 | Time(s) 0.4090
2023-12-01 17:00:41,445:INFO::Validation loss decreased (0.442723 --> 0.437833).  Saving model ...
2023-12-01 17:00:41,823:INFO::Epoch 00110 | lr 0.00050 |Train_Loss 0.2606 | Val_Loss 0.4331 | Time(s) 0.3780
2023-12-01 17:00:41,832:INFO::Validation loss decreased (0.437833 --> 0.433127).  Saving model ...
2023-12-01 17:00:42,216:INFO::Epoch 00111 | lr 0.00050 |Train_Loss 0.2499 | Val_Loss 0.4286 | Time(s) 0.3835
2023-12-01 17:00:42,225:INFO::Validation loss decreased (0.433127 --> 0.428611).  Saving model ...
2023-12-01 17:00:42,615:INFO::Epoch 00112 | lr 0.00050 |Train_Loss 0.2526 | Val_Loss 0.4243 | Time(s) 0.3886
2023-12-01 17:00:42,627:INFO::Validation loss decreased (0.428611 --> 0.424330).  Saving model ...
2023-12-01 17:00:43,097:INFO::Epoch 00113 | lr 0.00050 |Train_Loss 0.2373 | Val_Loss 0.4202 | Time(s) 0.4707
2023-12-01 17:00:43,107:INFO::Validation loss decreased (0.424330 --> 0.420244).  Saving model ...
2023-12-01 17:00:43,518:INFO::Epoch 00114 | lr 0.00050 |Train_Loss 0.2392 | Val_Loss 0.4162 | Time(s) 0.4105
2023-12-01 17:00:43,526:INFO::Validation loss decreased (0.420244 --> 0.416197).  Saving model ...
2023-12-01 17:00:43,902:INFO::Epoch 00115 | lr 0.00050 |Train_Loss 0.2358 | Val_Loss 0.4122 | Time(s) 0.3760
2023-12-01 17:00:43,911:INFO::Validation loss decreased (0.416197 --> 0.412228).  Saving model ...
2023-12-01 17:00:44,297:INFO::Epoch 00116 | lr 0.00050 |Train_Loss 0.2355 | Val_Loss 0.4083 | Time(s) 0.3862
2023-12-01 17:00:44,306:INFO::Validation loss decreased (0.412228 --> 0.408332).  Saving model ...
2023-12-01 17:00:44,704:INFO::Epoch 00117 | lr 0.00050 |Train_Loss 0.2214 | Val_Loss 0.4045 | Time(s) 0.3969
2023-12-01 17:00:44,714:INFO::Validation loss decreased (0.408332 --> 0.404536).  Saving model ...
2023-12-01 17:00:45,097:INFO::Epoch 00118 | lr 0.00050 |Train_Loss 0.2096 | Val_Loss 0.4008 | Time(s) 0.3830
2023-12-01 17:00:45,105:INFO::Validation loss decreased (0.404536 --> 0.400786).  Saving model ...
2023-12-01 17:00:45,486:INFO::Epoch 00119 | lr 0.00050 |Train_Loss 0.2109 | Val_Loss 0.3972 | Time(s) 0.3806
2023-12-01 17:00:45,498:INFO::Validation loss decreased (0.400786 --> 0.397184).  Saving model ...
2023-12-01 17:00:45,884:INFO::Epoch 00120 | lr 0.00050 |Train_Loss 0.2077 | Val_Loss 0.3937 | Time(s) 0.3850
2023-12-01 17:00:45,892:INFO::Validation loss decreased (0.397184 --> 0.393721).  Saving model ...
2023-12-01 17:00:46,236:INFO::Epoch 00121 | lr 0.00050 |Train_Loss 0.2034 | Val_Loss 0.3904 | Time(s) 0.3436
2023-12-01 17:00:46,246:INFO::Validation loss decreased (0.393721 --> 0.390392).  Saving model ...
2023-12-01 17:00:46,626:INFO::Epoch 00122 | lr 0.00050 |Train_Loss 0.1953 | Val_Loss 0.3871 | Time(s) 0.3806
2023-12-01 17:00:46,637:INFO::Validation loss decreased (0.390392 --> 0.387124).  Saving model ...
2023-12-01 17:00:47,030:INFO::Epoch 00123 | lr 0.00050 |Train_Loss 0.2002 | Val_Loss 0.3839 | Time(s) 0.3929
2023-12-01 17:00:47,039:INFO::Validation loss decreased (0.387124 --> 0.383947).  Saving model ...
2023-12-01 17:00:47,391:INFO::Epoch 00124 | lr 0.00050 |Train_Loss 0.1994 | Val_Loss 0.3809 | Time(s) 0.3513
2023-12-01 17:00:47,402:INFO::Validation loss decreased (0.383947 --> 0.380854).  Saving model ...
2023-12-01 17:00:47,780:INFO::Epoch 00125 | lr 0.00050 |Train_Loss 0.1833 | Val_Loss 0.3778 | Time(s) 0.3780
2023-12-01 17:00:47,791:INFO::Validation loss decreased (0.380854 --> 0.377826).  Saving model ...
2023-12-01 17:00:48,168:INFO::Epoch 00126 | lr 0.00050 |Train_Loss 0.1880 | Val_Loss 0.3749 | Time(s) 0.3776
2023-12-01 17:00:48,176:INFO::Validation loss decreased (0.377826 --> 0.374906).  Saving model ...
2023-12-01 17:00:48,655:INFO::Epoch 00127 | lr 0.00050 |Train_Loss 0.1687 | Val_Loss 0.3722 | Time(s) 0.4793
2023-12-01 17:00:48,666:INFO::Validation loss decreased (0.374906 --> 0.372176).  Saving model ...
2023-12-01 17:00:49,063:INFO::Epoch 00128 | lr 0.00050 |Train_Loss 0.1761 | Val_Loss 0.3696 | Time(s) 0.3965
2023-12-01 17:00:49,076:INFO::Validation loss decreased (0.372176 --> 0.369573).  Saving model ...
2023-12-01 17:00:49,444:INFO::Epoch 00129 | lr 0.00050 |Train_Loss 0.1688 | Val_Loss 0.3671 | Time(s) 0.3682
2023-12-01 17:00:49,453:INFO::Validation loss decreased (0.369573 --> 0.367131).  Saving model ...
2023-12-01 17:00:49,812:INFO::Epoch 00130 | lr 0.00050 |Train_Loss 0.1674 | Val_Loss 0.3648 | Time(s) 0.3590
2023-12-01 17:00:49,825:INFO::Validation loss decreased (0.367131 --> 0.364837).  Saving model ...
2023-12-01 17:00:50,196:INFO::Epoch 00131 | lr 0.00050 |Train_Loss 0.1638 | Val_Loss 0.3626 | Time(s) 0.3696
2023-12-01 17:00:50,205:INFO::Validation loss decreased (0.364837 --> 0.362640).  Saving model ...
2023-12-01 17:00:50,556:INFO::Epoch 00132 | lr 0.00050 |Train_Loss 0.1611 | Val_Loss 0.3605 | Time(s) 0.3507
2023-12-01 17:00:50,565:INFO::Validation loss decreased (0.362640 --> 0.360519).  Saving model ...
2023-12-01 17:00:50,964:INFO::Epoch 00133 | lr 0.00050 |Train_Loss 0.1550 | Val_Loss 0.3584 | Time(s) 0.3989
2023-12-01 17:00:50,973:INFO::Validation loss decreased (0.360519 --> 0.358445).  Saving model ...
2023-12-01 17:00:51,359:INFO::Epoch 00134 | lr 0.00050 |Train_Loss 0.1499 | Val_Loss 0.3565 | Time(s) 0.3861
2023-12-01 17:00:51,367:INFO::Validation loss decreased (0.358445 --> 0.356480).  Saving model ...
2023-12-01 17:00:51,724:INFO::Epoch 00135 | lr 0.00050 |Train_Loss 0.1555 | Val_Loss 0.3546 | Time(s) 0.3570
2023-12-01 17:00:51,732:INFO::Validation loss decreased (0.356480 --> 0.354574).  Saving model ...
2023-12-01 17:00:52,094:INFO::Epoch 00136 | lr 0.00050 |Train_Loss 0.1508 | Val_Loss 0.3527 | Time(s) 0.3600
2023-12-01 17:00:52,103:INFO::Validation loss decreased (0.354574 --> 0.352658).  Saving model ...
2023-12-01 17:00:52,508:INFO::Epoch 00137 | lr 0.00050 |Train_Loss 0.1523 | Val_Loss 0.3508 | Time(s) 0.4055
2023-12-01 17:00:52,520:INFO::Validation loss decreased (0.352658 --> 0.350847).  Saving model ...
2023-12-01 17:00:52,886:INFO::Epoch 00138 | lr 0.00050 |Train_Loss 0.1441 | Val_Loss 0.3491 | Time(s) 0.3660
2023-12-01 17:00:52,895:INFO::Validation loss decreased (0.350847 --> 0.349104).  Saving model ...
2023-12-01 17:00:53,278:INFO::Epoch 00139 | lr 0.00050 |Train_Loss 0.1378 | Val_Loss 0.3473 | Time(s) 0.3827
2023-12-01 17:00:53,286:INFO::Validation loss decreased (0.349104 --> 0.347340).  Saving model ...
2023-12-01 17:00:53,647:INFO::Epoch 00140 | lr 0.00050 |Train_Loss 0.1343 | Val_Loss 0.3456 | Time(s) 0.3590
2023-12-01 17:00:53,655:INFO::Validation loss decreased (0.347340 --> 0.345567).  Saving model ...
2023-12-01 17:00:54,108:INFO::Epoch 00141 | lr 0.00050 |Train_Loss 0.1325 | Val_Loss 0.3438 | Time(s) 0.4523
2023-12-01 17:00:54,120:INFO::Validation loss decreased (0.345567 --> 0.343767).  Saving model ...
2023-12-01 17:00:54,513:INFO::Epoch 00142 | lr 0.00050 |Train_Loss 0.1323 | Val_Loss 0.3421 | Time(s) 0.3935
2023-12-01 17:00:54,522:INFO::Validation loss decreased (0.343767 --> 0.342072).  Saving model ...
2023-12-01 17:00:54,891:INFO::Epoch 00143 | lr 0.00050 |Train_Loss 0.1293 | Val_Loss 0.3404 | Time(s) 0.3691
2023-12-01 17:00:54,902:INFO::Validation loss decreased (0.342072 --> 0.340386).  Saving model ...
2023-12-01 17:00:55,277:INFO::Epoch 00144 | lr 0.00050 |Train_Loss 0.1270 | Val_Loss 0.3388 | Time(s) 0.3741
2023-12-01 17:00:55,286:INFO::Validation loss decreased (0.340386 --> 0.338829).  Saving model ...
2023-12-01 17:00:55,666:INFO::Epoch 00145 | lr 0.00050 |Train_Loss 0.1282 | Val_Loss 0.3373 | Time(s) 0.3796
2023-12-01 17:00:55,679:INFO::Validation loss decreased (0.338829 --> 0.337295).  Saving model ...
2023-12-01 17:00:56,068:INFO::Epoch 00146 | lr 0.00050 |Train_Loss 0.1209 | Val_Loss 0.3358 | Time(s) 0.3890
2023-12-01 17:00:56,077:INFO::Validation loss decreased (0.337295 --> 0.335819).  Saving model ...
2023-12-01 17:00:56,467:INFO::Epoch 00147 | lr 0.00050 |Train_Loss 0.1177 | Val_Loss 0.3345 | Time(s) 0.3901
2023-12-01 17:00:56,475:INFO::Validation loss decreased (0.335819 --> 0.334459).  Saving model ...
2023-12-01 17:00:56,872:INFO::Epoch 00148 | lr 0.00050 |Train_Loss 0.1205 | Val_Loss 0.3332 | Time(s) 0.3959
2023-12-01 17:00:56,880:INFO::Validation loss decreased (0.334459 --> 0.333185).  Saving model ...
2023-12-01 17:00:57,284:INFO::Epoch 00149 | lr 0.00050 |Train_Loss 0.1170 | Val_Loss 0.3320 | Time(s) 0.4040
2023-12-01 17:00:57,292:INFO::Validation loss decreased (0.333185 --> 0.331990).  Saving model ...
2023-12-01 17:00:57,640:INFO::Epoch 00150 | lr 0.00050 |Train_Loss 0.1134 | Val_Loss 0.3308 | Time(s) 0.3481
2023-12-01 17:00:57,649:INFO::Validation loss decreased (0.331990 --> 0.330813).  Saving model ...
2023-12-01 17:00:58,014:INFO::Epoch 00151 | lr 0.00050 |Train_Loss 0.1129 | Val_Loss 0.3297 | Time(s) 0.3640
2023-12-01 17:00:58,021:INFO::Validation loss decreased (0.330813 --> 0.329654).  Saving model ...
2023-12-01 17:00:58,431:INFO::Epoch 00152 | lr 0.00050 |Train_Loss 0.1090 | Val_Loss 0.3285 | Time(s) 0.4090
2023-12-01 17:00:58,441:INFO::Validation loss decreased (0.329654 --> 0.328497).  Saving model ...
2023-12-01 17:00:58,797:INFO::Epoch 00153 | lr 0.00050 |Train_Loss 0.1063 | Val_Loss 0.3274 | Time(s) 0.3560
2023-12-01 17:00:58,808:INFO::Validation loss decreased (0.328497 --> 0.327399).  Saving model ...
2023-12-01 17:00:59,194:INFO::Epoch 00154 | lr 0.00050 |Train_Loss 0.1054 | Val_Loss 0.3263 | Time(s) 0.3865
2023-12-01 17:00:59,203:INFO::Validation loss decreased (0.327399 --> 0.326321).  Saving model ...
2023-12-01 17:00:59,683:INFO::Epoch 00155 | lr 0.00050 |Train_Loss 0.1058 | Val_Loss 0.3253 | Time(s) 0.4793
2023-12-01 17:00:59,692:INFO::Validation loss decreased (0.326321 --> 0.325288).  Saving model ...
2023-12-01 17:01:00,059:INFO::Epoch 00156 | lr 0.00050 |Train_Loss 0.1007 | Val_Loss 0.3243 | Time(s) 0.3666
2023-12-01 17:01:00,069:INFO::Validation loss decreased (0.325288 --> 0.324326).  Saving model ...
2023-12-01 17:01:00,414:INFO::Epoch 00157 | lr 0.00050 |Train_Loss 0.1023 | Val_Loss 0.3235 | Time(s) 0.3453
2023-12-01 17:01:00,425:INFO::Validation loss decreased (0.324326 --> 0.323465).  Saving model ...
2023-12-01 17:01:00,779:INFO::Epoch 00158 | lr 0.00050 |Train_Loss 0.0988 | Val_Loss 0.3226 | Time(s) 0.3531
2023-12-01 17:01:00,789:INFO::Validation loss decreased (0.323465 --> 0.322600).  Saving model ...
2023-12-01 17:01:01,176:INFO::Epoch 00159 | lr 0.00050 |Train_Loss 0.0939 | Val_Loss 0.3218 | Time(s) 0.3855
2023-12-01 17:01:01,187:INFO::Validation loss decreased (0.322600 --> 0.321780).  Saving model ...
2023-12-01 17:01:01,579:INFO::Epoch 00160 | lr 0.00050 |Train_Loss 0.0951 | Val_Loss 0.3210 | Time(s) 0.3925
2023-12-01 17:01:01,590:INFO::Validation loss decreased (0.321780 --> 0.321009).  Saving model ...
2023-12-01 17:01:01,968:INFO::Epoch 00161 | lr 0.00050 |Train_Loss 0.0933 | Val_Loss 0.3204 | Time(s) 0.3770
2023-12-01 17:01:01,976:INFO::Validation loss decreased (0.321009 --> 0.320408).  Saving model ...
2023-12-01 17:01:02,344:INFO::Epoch 00162 | lr 0.00050 |Train_Loss 0.0950 | Val_Loss 0.3198 | Time(s) 0.3672
2023-12-01 17:01:02,356:INFO::Validation loss decreased (0.320408 --> 0.319793).  Saving model ...
2023-12-01 17:01:02,771:INFO::Epoch 00163 | lr 0.00050 |Train_Loss 0.0930 | Val_Loss 0.3192 | Time(s) 0.4149
2023-12-01 17:01:02,781:INFO::Validation loss decreased (0.319793 --> 0.319247).  Saving model ...
2023-12-01 17:01:03,178:INFO::Epoch 00164 | lr 0.00050 |Train_Loss 0.0882 | Val_Loss 0.3187 | Time(s) 0.3965
2023-12-01 17:01:03,188:INFO::Validation loss decreased (0.319247 --> 0.318747).  Saving model ...
2023-12-01 17:01:03,556:INFO::Epoch 00165 | lr 0.00050 |Train_Loss 0.0812 | Val_Loss 0.3182 | Time(s) 0.3686
2023-12-01 17:01:03,565:INFO::Validation loss decreased (0.318747 --> 0.318176).  Saving model ...
2023-12-01 17:01:03,940:INFO::Epoch 00166 | lr 0.00050 |Train_Loss 0.0849 | Val_Loss 0.3176 | Time(s) 0.3750
2023-12-01 17:01:03,951:INFO::Validation loss decreased (0.318176 --> 0.317575).  Saving model ...
2023-12-01 17:01:04,314:INFO::Epoch 00167 | lr 0.00050 |Train_Loss 0.0827 | Val_Loss 0.3170 | Time(s) 0.3621
2023-12-01 17:01:04,325:INFO::Validation loss decreased (0.317575 --> 0.316988).  Saving model ...
2023-12-01 17:01:04,684:INFO::Epoch 00168 | lr 0.00050 |Train_Loss 0.0818 | Val_Loss 0.3164 | Time(s) 0.3590
2023-12-01 17:01:04,694:INFO::Validation loss decreased (0.316988 --> 0.316433).  Saving model ...
2023-12-01 17:01:05,178:INFO::Epoch 00169 | lr 0.00050 |Train_Loss 0.0864 | Val_Loss 0.3158 | Time(s) 0.4843
2023-12-01 17:01:05,188:INFO::Validation loss decreased (0.316433 --> 0.315791).  Saving model ...
2023-12-01 17:01:05,581:INFO::Epoch 00170 | lr 0.00050 |Train_Loss 0.0794 | Val_Loss 0.3152 | Time(s) 0.3927
2023-12-01 17:01:05,590:INFO::Validation loss decreased (0.315791 --> 0.315183).  Saving model ...
2023-12-01 17:01:05,927:INFO::Epoch 00171 | lr 0.00050 |Train_Loss 0.0808 | Val_Loss 0.3146 | Time(s) 0.3361
2023-12-01 17:01:05,936:INFO::Validation loss decreased (0.315183 --> 0.314577).  Saving model ...
2023-12-01 17:01:06,336:INFO::Epoch 00172 | lr 0.00050 |Train_Loss 0.0743 | Val_Loss 0.3139 | Time(s) 0.4000
2023-12-01 17:01:06,345:INFO::Validation loss decreased (0.314577 --> 0.313924).  Saving model ...
2023-12-01 17:01:06,698:INFO::Epoch 00173 | lr 0.00050 |Train_Loss 0.0756 | Val_Loss 0.3133 | Time(s) 0.3511
2023-12-01 17:01:06,707:INFO::Validation loss decreased (0.313924 --> 0.313312).  Saving model ...
2023-12-01 17:01:07,090:INFO::Epoch 00174 | lr 0.00050 |Train_Loss 0.0747 | Val_Loss 0.3128 | Time(s) 0.3830
2023-12-01 17:01:07,097:INFO::Validation loss decreased (0.313312 --> 0.312843).  Saving model ...
2023-12-01 17:01:07,476:INFO::Epoch 00175 | lr 0.00050 |Train_Loss 0.0743 | Val_Loss 0.3124 | Time(s) 0.3771
2023-12-01 17:01:07,486:INFO::Validation loss decreased (0.312843 --> 0.312366).  Saving model ...
2023-12-01 17:01:07,842:INFO::Epoch 00176 | lr 0.00050 |Train_Loss 0.0710 | Val_Loss 0.3119 | Time(s) 0.3551
2023-12-01 17:01:07,851:INFO::Validation loss decreased (0.312366 --> 0.311926).  Saving model ...
2023-12-01 17:01:08,239:INFO::Epoch 00177 | lr 0.00050 |Train_Loss 0.0696 | Val_Loss 0.3116 | Time(s) 0.3886
2023-12-01 17:01:08,248:INFO::Validation loss decreased (0.311926 --> 0.311550).  Saving model ...
2023-12-01 17:01:08,649:INFO::Epoch 00178 | lr 0.00050 |Train_Loss 0.0703 | Val_Loss 0.3112 | Time(s) 0.4005
2023-12-01 17:01:08,661:INFO::Validation loss decreased (0.311550 --> 0.311222).  Saving model ...
2023-12-01 17:01:09,008:INFO::Epoch 00179 | lr 0.00050 |Train_Loss 0.0714 | Val_Loss 0.3109 | Time(s) 0.3461
2023-12-01 17:01:09,016:INFO::Validation loss decreased (0.311222 --> 0.310885).  Saving model ...
2023-12-01 17:01:09,420:INFO::Epoch 00180 | lr 0.00050 |Train_Loss 0.0691 | Val_Loss 0.3106 | Time(s) 0.4032
2023-12-01 17:01:09,427:INFO::Validation loss decreased (0.310885 --> 0.310605).  Saving model ...
2023-12-01 17:01:09,807:INFO::Epoch 00181 | lr 0.00050 |Train_Loss 0.0676 | Val_Loss 0.3103 | Time(s) 0.3790
2023-12-01 17:01:09,818:INFO::Validation loss decreased (0.310605 --> 0.310285).  Saving model ...
2023-12-01 17:01:10,214:INFO::Epoch 00182 | lr 0.00050 |Train_Loss 0.0717 | Val_Loss 0.3100 | Time(s) 0.3965
2023-12-01 17:01:10,227:INFO::Validation loss decreased (0.310285 --> 0.309958).  Saving model ...
2023-12-01 17:01:10,742:INFO::Epoch 00183 | lr 0.00050 |Train_Loss 0.0622 | Val_Loss 0.3097 | Time(s) 0.5148
2023-12-01 17:01:10,755:INFO::Validation loss decreased (0.309958 --> 0.309705).  Saving model ...
2023-12-01 17:01:11,169:INFO::Epoch 00184 | lr 0.00050 |Train_Loss 0.0624 | Val_Loss 0.3095 | Time(s) 0.4135
2023-12-01 17:01:11,178:INFO::Validation loss decreased (0.309705 --> 0.309464).  Saving model ...
2023-12-01 17:01:11,570:INFO::Epoch 00185 | lr 0.00050 |Train_Loss 0.0648 | Val_Loss 0.3093 | Time(s) 0.3915
2023-12-01 17:01:11,580:INFO::Validation loss decreased (0.309464 --> 0.309256).  Saving model ...
2023-12-01 17:01:11,993:INFO::Epoch 00186 | lr 0.00050 |Train_Loss 0.0606 | Val_Loss 0.3091 | Time(s) 0.4119
2023-12-01 17:01:12,001:INFO::Validation loss decreased (0.309256 --> 0.309097).  Saving model ...
2023-12-01 17:01:12,360:INFO::Epoch 00187 | lr 0.00050 |Train_Loss 0.0621 | Val_Loss 0.3089 | Time(s) 0.3582
2023-12-01 17:01:12,368:INFO::Validation loss decreased (0.309097 --> 0.308928).  Saving model ...
2023-12-01 17:01:12,772:INFO::Epoch 00188 | lr 0.00050 |Train_Loss 0.0636 | Val_Loss 0.3088 | Time(s) 0.4039
2023-12-01 17:01:12,780:INFO::Validation loss decreased (0.308928 --> 0.308802).  Saving model ...
2023-12-01 17:01:13,178:INFO::Epoch 00189 | lr 0.00050 |Train_Loss 0.0606 | Val_Loss 0.3086 | Time(s) 0.3965
2023-12-01 17:01:13,187:INFO::Validation loss decreased (0.308802 --> 0.308627).  Saving model ...
2023-12-01 17:01:13,560:INFO::Epoch 00190 | lr 0.00050 |Train_Loss 0.0613 | Val_Loss 0.3085 | Time(s) 0.3736
2023-12-01 17:01:13,571:INFO::Validation loss decreased (0.308627 --> 0.308458).  Saving model ...
2023-12-01 17:01:13,973:INFO::Epoch 00191 | lr 0.00050 |Train_Loss 0.0618 | Val_Loss 0.3083 | Time(s) 0.4019
2023-12-01 17:01:13,985:INFO::Validation loss decreased (0.308458 --> 0.308277).  Saving model ...
2023-12-01 17:01:14,368:INFO::Epoch 00192 | lr 0.00050 |Train_Loss 0.0609 | Val_Loss 0.3081 | Time(s) 0.3832
2023-12-01 17:01:14,376:INFO::Validation loss decreased (0.308277 --> 0.308126).  Saving model ...
2023-12-01 17:01:14,780:INFO::Epoch 00193 | lr 0.00050 |Train_Loss 0.0524 | Val_Loss 0.3080 | Time(s) 0.4029
2023-12-01 17:01:14,791:INFO::Validation loss decreased (0.308126 --> 0.307972).  Saving model ...
2023-12-01 17:01:15,200:INFO::Epoch 00194 | lr 0.00050 |Train_Loss 0.0571 | Val_Loss 0.3078 | Time(s) 0.4075
2023-12-01 17:01:15,210:INFO::Validation loss decreased (0.307972 --> 0.307750).  Saving model ...
2023-12-01 17:01:15,607:INFO::Epoch 00195 | lr 0.00050 |Train_Loss 0.0583 | Val_Loss 0.3074 | Time(s) 0.3975
2023-12-01 17:01:15,617:INFO::Validation loss decreased (0.307750 --> 0.307445).  Saving model ...
2023-12-01 17:01:16,057:INFO::Epoch 00196 | lr 0.00050 |Train_Loss 0.0539 | Val_Loss 0.3071 | Time(s) 0.4388
2023-12-01 17:01:16,069:INFO::Validation loss decreased (0.307445 --> 0.307095).  Saving model ...
2023-12-01 17:01:16,496:INFO::Epoch 00197 | lr 0.00050 |Train_Loss 0.0557 | Val_Loss 0.3068 | Time(s) 0.4274
2023-12-01 17:01:16,507:INFO::Validation loss decreased (0.307095 --> 0.306766).  Saving model ...
2023-12-01 17:01:16,870:INFO::Epoch 00198 | lr 0.00050 |Train_Loss 0.0548 | Val_Loss 0.3065 | Time(s) 0.3630
2023-12-01 17:01:16,878:INFO::Validation loss decreased (0.306766 --> 0.306458).  Saving model ...
2023-12-01 17:01:17,257:INFO::Epoch 00199 | lr 0.00050 |Train_Loss 0.0516 | Val_Loss 0.3062 | Time(s) 0.3786
2023-12-01 17:01:17,269:INFO::Validation loss decreased (0.306458 --> 0.306237).  Saving model ...
2023-12-01 17:01:17,648:INFO::Epoch 00200 | lr 0.00050 |Train_Loss 0.0536 | Val_Loss 0.3060 | Time(s) 0.3790
2023-12-01 17:01:17,660:INFO::Validation loss decreased (0.306237 --> 0.306029).  Saving model ...
2023-12-01 17:01:18,063:INFO::Epoch 00201 | lr 0.00050 |Train_Loss 0.0514 | Val_Loss 0.3058 | Time(s) 0.4029
2023-12-01 17:01:18,074:INFO::Validation loss decreased (0.306029 --> 0.305822).  Saving model ...
2023-12-01 17:01:18,462:INFO::Epoch 00202 | lr 0.00050 |Train_Loss 0.0519 | Val_Loss 0.3057 | Time(s) 0.3882
2023-12-01 17:01:18,472:INFO::Validation loss decreased (0.305822 --> 0.305668).  Saving model ...
2023-12-01 17:01:18,844:INFO::Epoch 00203 | lr 0.00050 |Train_Loss 0.0482 | Val_Loss 0.3055 | Time(s) 0.3710
2023-12-01 17:01:18,855:INFO::Validation loss decreased (0.305668 --> 0.305519).  Saving model ...
2023-12-01 17:01:19,235:INFO::Epoch 00204 | lr 0.00050 |Train_Loss 0.0457 | Val_Loss 0.3054 | Time(s) 0.3792
2023-12-01 17:01:19,246:INFO::Validation loss decreased (0.305519 --> 0.305422).  Saving model ...
2023-12-01 17:01:19,632:INFO::Epoch 00205 | lr 0.00050 |Train_Loss 0.0495 | Val_Loss 0.3053 | Time(s) 0.3846
2023-12-01 17:01:19,640:INFO::Validation loss decreased (0.305422 --> 0.305280).  Saving model ...
2023-12-01 17:01:19,988:INFO::Epoch 00206 | lr 0.00050 |Train_Loss 0.0483 | Val_Loss 0.3053 | Time(s) 0.3471
2023-12-01 17:01:19,998:INFO::Validation loss decreased (0.305280 --> 0.305252).  Saving model ...
2023-12-01 17:01:20,379:INFO::Epoch 00207 | lr 0.00050 |Train_Loss 0.0492 | Val_Loss 0.3052 | Time(s) 0.3812
2023-12-01 17:01:20,402:INFO::Validation loss decreased (0.305252 --> 0.305232).  Saving model ...
2023-12-01 17:01:20,745:INFO::Epoch 00208 | lr 0.00050 |Train_Loss 0.0466 | Val_Loss 0.3052 | Time(s) 0.3431
2023-12-01 17:01:20,756:INFO::Validation loss decreased (0.305232 --> 0.305199).  Saving model ...
2023-12-01 17:01:21,163:INFO::Epoch 00209 | lr 0.00050 |Train_Loss 0.0475 | Val_Loss 0.3052 | Time(s) 0.4075
2023-12-01 17:01:21,173:INFO::Validation loss decreased (0.305199 --> 0.305167).  Saving model ...
2023-12-01 17:01:21,597:INFO::Epoch 00210 | lr 0.00050 |Train_Loss 0.0438 | Val_Loss 0.3052 | Time(s) 0.4234
2023-12-01 17:01:21,598:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:01:21,992:INFO::Epoch 00211 | lr 0.00050 |Train_Loss 0.0467 | Val_Loss 0.3052 | Time(s) 0.3949
2023-12-01 17:01:21,992:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:01:22,363:INFO::Epoch 00212 | lr 0.00050 |Train_Loss 0.0459 | Val_Loss 0.3052 | Time(s) 0.3701
2023-12-01 17:01:22,364:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 17:01:22,740:INFO::Epoch 00213 | lr 0.00050 |Train_Loss 0.0451 | Val_Loss 0.3052 | Time(s) 0.3765
2023-12-01 17:01:22,741:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 17:01:23,123:INFO::Epoch 00214 | lr 0.00050 |Train_Loss 0.0422 | Val_Loss 0.3051 | Time(s) 0.3815
2023-12-01 17:01:23,131:INFO::Validation loss decreased (0.305167 --> 0.305105).  Saving model ...
2023-12-01 17:01:23,526:INFO::Epoch 00215 | lr 0.00050 |Train_Loss 0.0410 | Val_Loss 0.3050 | Time(s) 0.3945
2023-12-01 17:01:23,536:INFO::Validation loss decreased (0.305105 --> 0.305035).  Saving model ...
2023-12-01 17:01:23,906:INFO::Epoch 00216 | lr 0.00050 |Train_Loss 0.0415 | Val_Loss 0.3049 | Time(s) 0.3690
2023-12-01 17:01:23,915:INFO::Validation loss decreased (0.305035 --> 0.304944).  Saving model ...
2023-12-01 17:01:24,311:INFO::Epoch 00217 | lr 0.00050 |Train_Loss 0.0431 | Val_Loss 0.3049 | Time(s) 0.3961
2023-12-01 17:01:24,323:INFO::Validation loss decreased (0.304944 --> 0.304869).  Saving model ...
2023-12-01 17:01:24,741:INFO::Epoch 00218 | lr 0.00050 |Train_Loss 0.0438 | Val_Loss 0.3048 | Time(s) 0.4179
2023-12-01 17:01:24,751:INFO::Validation loss decreased (0.304869 --> 0.304794).  Saving model ...
2023-12-01 17:01:25,134:INFO::Epoch 00219 | lr 0.00050 |Train_Loss 0.0417 | Val_Loss 0.3048 | Time(s) 0.3826
2023-12-01 17:01:25,144:INFO::Validation loss decreased (0.304794 --> 0.304773).  Saving model ...
2023-12-01 17:01:25,514:INFO::Epoch 00220 | lr 0.00050 |Train_Loss 0.0425 | Val_Loss 0.3047 | Time(s) 0.3706
2023-12-01 17:01:25,526:INFO::Validation loss decreased (0.304773 --> 0.304678).  Saving model ...
2023-12-01 17:01:25,929:INFO::Epoch 00221 | lr 0.00050 |Train_Loss 0.0424 | Val_Loss 0.3045 | Time(s) 0.4029
2023-12-01 17:01:25,937:INFO::Validation loss decreased (0.304678 --> 0.304532).  Saving model ...
2023-12-01 17:01:26,318:INFO::Epoch 00222 | lr 0.00050 |Train_Loss 0.0392 | Val_Loss 0.3044 | Time(s) 0.3801
2023-12-01 17:01:26,330:INFO::Validation loss decreased (0.304532 --> 0.304427).  Saving model ...
2023-12-01 17:01:26,721:INFO::Epoch 00223 | lr 0.00050 |Train_Loss 0.0399 | Val_Loss 0.3043 | Time(s) 0.3910
2023-12-01 17:01:26,733:INFO::Validation loss decreased (0.304427 --> 0.304324).  Saving model ...
2023-12-01 17:01:27,179:INFO::Epoch 00224 | lr 0.00050 |Train_Loss 0.0377 | Val_Loss 0.3043 | Time(s) 0.4464
2023-12-01 17:01:27,188:INFO::Validation loss decreased (0.304324 --> 0.304272).  Saving model ...
2023-12-01 17:01:27,635:INFO::Epoch 00225 | lr 0.00050 |Train_Loss 0.0374 | Val_Loss 0.3043 | Time(s) 0.4464
2023-12-01 17:01:27,636:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:01:27,989:INFO::Epoch 00226 | lr 0.00050 |Train_Loss 0.0388 | Val_Loss 0.3043 | Time(s) 0.3538
2023-12-01 17:01:27,990:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:01:28,388:INFO::Epoch 00227 | lr 0.00050 |Train_Loss 0.0405 | Val_Loss 0.3044 | Time(s) 0.3971
2023-12-01 17:01:28,389:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 17:01:28,760:INFO::Epoch 00228 | lr 0.00050 |Train_Loss 0.0364 | Val_Loss 0.3045 | Time(s) 0.3710
2023-12-01 17:01:28,761:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 17:01:29,144:INFO::Epoch 00229 | lr 0.00050 |Train_Loss 0.0360 | Val_Loss 0.3047 | Time(s) 0.3836
2023-12-01 17:01:29,145:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 17:01:29,526:INFO::Epoch 00230 | lr 0.00050 |Train_Loss 0.0403 | Val_Loss 0.3050 | Time(s) 0.3806
2023-12-01 17:01:29,526:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 17:01:29,916:INFO::Epoch 00231 | lr 0.00050 |Train_Loss 0.0360 | Val_Loss 0.3052 | Time(s) 0.3890
2023-12-01 17:01:29,916:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 17:01:30,257:INFO::Epoch 00232 | lr 0.00050 |Train_Loss 0.0334 | Val_Loss 0.3055 | Time(s) 0.3406
2023-12-01 17:01:30,258:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 17:01:30,258:INFO::Eearly stopping!
2023-12-01 17:01:30,258:INFO::
testing...
2023-12-01 17:01:30,298:INFO::submit dir: submit/submit_gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:30,498:INFO::{'micro-f1': 0.8852112676056338, 'macro-f1': 0.877879349822617}
2023-12-01 17:01:30,622:INFO::############### Retrain Stage Ends! #################
2023-12-01 17:01:30,623:INFO::=============== Search Args:
Namespace(dataset='DBLP', feats_type=6, gnn_model='gcn', valid_attributed_type=1, cluster_num=4, cluster_eps=1e-05, att_comp_dim=64, hidden_dim=64, num_heads=8, attn_vec_dim=128, search_epoch=350, retrain_epoch=500, inner_epoch=1, patience_search=8, patience_retrain=8, batch_size=8, batch_size_test=32, momentum=0.9, lr=0.0005, lr_rate_min=3e-05, num_layers=2, dropout=0.5, weight_decay=0.0001, slope=0.05, grad_clip=5, network_momentum=0.9, arch_learning_rate=0.005, arch_weight_decay=1e-05, repeat=5, cluster_epoch=4, save_postfix='DBLP', feats_opt='1011', cuda=False, unrolled=False, useSGD=False, useTypeLinear=False, l2norm=False, cluster_norm=False, usedropout=False, is_unrolled='False', is_use_type_linear='False', is_use_SGD='False', is_use_dropout='False', time_line='2023-12-01-16-46-32', edge_feats=64, warmup_epoch=0, clusterupdate_round=1, searcher_name='nasp', rnn_type='RotatE0', neighbor_samples=100, use_minibatch=False, shared_ops=True, e_greedy=0.1, usebn=False, seed=2022, use_5seeds=True, no_use_fixseeds=False, use_dmon=True, collapse_regularization=0.1, dmon_loss_alpha=0.5, tau=1.0, schedule_step=350, schedule_step_retrain=500, use_norm=False, use_adamw=False, use_skip=False, cur_repeat=4, last_hidden_dim=64, logger=<Logger log_output (INFO)>)
2023-12-01 17:01:50,991:INFO::node_type_num: 4
2023-12-01 17:01:51,018:INFO::=============== Prepare basic data stage finish, use 20.395496368408203 time.
2023-12-01 17:01:51,178:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:52,540:INFO::Epoch: 0
tensor([[0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:52,541:INFO::its now!!!!!!!!5
2023-12-01 17:01:52,812:INFO::its now!!!!!!!!0
2023-12-01 17:01:52,813:INFO::its now!!!!!!!!3
2023-12-01 17:01:52,842:INFO::its now!!!!!!!!5
2023-12-01 17:01:53,039:INFO::its now!!!!!!!!
2023-12-01 17:01:53,039:INFO::its now!!!!!!!! on 
2023-12-01 17:01:53,076:INFO::its now!!!!!!!!5
2023-12-01 17:01:53,234:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:53,236:INFO::Epoch 00000 | lr 0.00050 | Train_Loss 1.3562 | Train_Classification_Loss 1.3869 | Dmon_Loss -0.0614 | Val_Loss 1.3823 | Search Time(s) 0.5346 | Infer Time(s) 0.1642 | Time(s) 0.6988 
2023-12-01 17:01:53,298:INFO::cluster info:
0: 3;	1: 1;	2: 0;	3: 1;	4: 3;	5: 3;	6: 3;	7: 3;	8: 1;	9: 3;	10: 3;	11: 3;	12: 1;	13: 1;	14: 1;	15: 3;	16: 1;	17: 3;	18: 1;	19: 1;	20: 1;	21: 3;	22: 1;	23: 1;	24: 3;	25: 1;	26: 1;	27: 3;	28: 1;	29: 1;	30: 3;	31: 1;	32: 1;	33: 3;	34: 3;	35: 3;	36: 1;	37: 3;	38: 3;	39: 3;	40: 3;	41: 1;	42: 1;	43: 1;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 17:01:53,303:INFO::Epoch: 1
tensor([[0.5050, 0.4950, 0.4950, 0.4950],
        [0.4950, 0.4950, 0.4950, 0.4950],
        [0.5050, 0.4950, 0.4950, 0.4950],
        [0.5050, 0.4950, 0.4950, 0.4950]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:53,303:INFO::its now!!!!!!!!5
2023-12-01 17:01:53,484:INFO::its now!!!!!!!!0
2023-12-01 17:01:53,485:INFO::its now!!!!!!!!3
2023-12-01 17:01:53,512:INFO::its now!!!!!!!!5
2023-12-01 17:01:53,687:INFO::its now!!!!!!!!
2023-12-01 17:01:53,687:INFO::its now!!!!!!!! on 
2023-12-01 17:01:53,741:INFO::its now!!!!!!!!5
2023-12-01 17:01:53,918:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:53,920:INFO::Epoch 00001 | lr 0.00050 | Train_Loss 1.3526 | Train_Classification_Loss 1.3832 | Dmon_Loss -0.0613 | Val_Loss 1.3791 | Search Time(s) 0.4219 | Infer Time(s) 0.1974 | Time(s) 0.6193 
2023-12-01 17:01:53,973:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 2;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 2;	20: 3;	21: 2;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 2;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 2;	26109: 2;	26110: 2;	26111: 2;	26112: 2;	26113: 2;	26114: 2;	26115: 2;	26116: 2;	26117: 2;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 2;	26124: 2;	26125: 2;	26126: 2;	26127: 3;	
2023-12-01 17:01:53,974:INFO::Validation loss decreased (inf --> 1.379063).  Saving model ...
2023-12-01 17:01:53,976:INFO::Epoch: 2
tensor([[0.5092, 0.4901, 0.4901, 0.4901],
        [0.4898, 0.4901, 0.4901, 0.4901],
        [0.5066, 0.4901, 0.4901, 0.4901],
        [0.5074, 0.4901, 0.4901, 0.4901]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:53,976:INFO::its now!!!!!!!!5
2023-12-01 17:01:54,140:INFO::its now!!!!!!!!0
2023-12-01 17:01:54,141:INFO::its now!!!!!!!!3
2023-12-01 17:01:54,188:INFO::its now!!!!!!!!5
2023-12-01 17:01:54,638:INFO::its now!!!!!!!!
2023-12-01 17:01:54,638:INFO::its now!!!!!!!! on 
2023-12-01 17:01:54,681:INFO::its now!!!!!!!!5
2023-12-01 17:01:54,898:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:54,900:INFO::Epoch 00002 | lr 0.00050 | Train_Loss 1.3478 | Train_Classification_Loss 1.3787 | Dmon_Loss -0.0619 | Val_Loss 1.3741 | Search Time(s) 0.7069 | Infer Time(s) 0.2174 | Time(s) 0.9243 
2023-12-01 17:01:54,972:INFO::cluster info:
0: 1;	1: 3;	2: 3;	3: 1;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 1;	15: 3;	16: 1;	17: 3;	18: 3;	19: 1;	20: 1;	21: 3;	22: 3;	23: 1;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 1;	39: 3;	40: 3;	41: 3;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 17:01:54,974:INFO::Validation loss decreased (1.379063 --> 1.374098).  Saving model ...
2023-12-01 17:01:54,977:INFO::Epoch: 3
tensor([[0.5043, 0.4850, 0.4876, 0.4850],
        [0.4848, 0.4850, 0.4850, 0.4876],
        [0.5016, 0.4876, 0.4850, 0.4850],
        [0.5024, 0.4875, 0.4850, 0.4850]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:54,978:INFO::its now!!!!!!!!5
2023-12-01 17:01:55,137:INFO::its now!!!!!!!!0
2023-12-01 17:01:55,138:INFO::its now!!!!!!!!3
2023-12-01 17:01:55,172:INFO::its now!!!!!!!!5
2023-12-01 17:01:55,359:INFO::its now!!!!!!!!
2023-12-01 17:01:55,359:INFO::its now!!!!!!!! on 
2023-12-01 17:01:55,406:INFO::its now!!!!!!!!5
2023-12-01 17:01:55,594:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:55,595:INFO::Epoch 00003 | lr 0.00050 | Train_Loss 1.3422 | Train_Classification_Loss 1.3734 | Dmon_Loss -0.0626 | Val_Loss 1.3715 | Search Time(s) 0.4280 | Infer Time(s) 0.1915 | Time(s) 0.6195 
2023-12-01 17:01:55,634:INFO::cluster info:
0: 1;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:01:55,635:INFO::Validation loss decreased (1.374098 --> 1.371458).  Saving model ...
2023-12-01 17:01:55,638:INFO::Epoch: 4
tensor([[0.5016, 0.4809, 0.4844, 0.4809],
        [0.4802, 0.4809, 0.4809, 0.4862],
        [0.4971, 0.4844, 0.4809, 0.4822],
        [0.4979, 0.4844, 0.4822, 0.4809]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:55,638:INFO::its now!!!!!!!!5
2023-12-01 17:01:55,779:INFO::its now!!!!!!!!0
2023-12-01 17:01:55,780:INFO::its now!!!!!!!!3
2023-12-01 17:01:55,809:INFO::its now!!!!!!!!5
2023-12-01 17:01:55,962:INFO::its now!!!!!!!!
2023-12-01 17:01:55,962:INFO::its now!!!!!!!! on 
2023-12-01 17:01:55,999:INFO::its now!!!!!!!!5
2023-12-01 17:01:56,194:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:56,196:INFO::Epoch 00004 | lr 0.00050 | Train_Loss 1.3388 | Train_Classification_Loss 1.3699 | Dmon_Loss -0.0622 | Val_Loss 1.3666 | Search Time(s) 0.3620 | Infer Time(s) 0.1970 | Time(s) 0.5591 
2023-12-01 17:01:56,233:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 1;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 1;	11: 3;	12: 3;	13: 3;	14: 1;	15: 3;	16: 3;	17: 3;	18: 3;	19: 1;	20: 1;	21: 3;	22: 1;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 17:01:56,234:INFO::Validation loss decreased (1.371458 --> 1.366629).  Saving model ...
2023-12-01 17:01:56,236:INFO::Epoch: 5
tensor([[0.5002, 0.4758, 0.4794, 0.4758],
        [0.4744, 0.4758, 0.4758, 0.4854],
        [0.4946, 0.4794, 0.4758, 0.4777],
        [0.4954, 0.4794, 0.4777, 0.4758]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:56,237:INFO::its now!!!!!!!!5
2023-12-01 17:01:56,400:INFO::its now!!!!!!!!0
2023-12-01 17:01:56,401:INFO::its now!!!!!!!!3
2023-12-01 17:01:56,431:INFO::its now!!!!!!!!5
2023-12-01 17:01:56,619:INFO::its now!!!!!!!!
2023-12-01 17:01:56,620:INFO::its now!!!!!!!! on 
2023-12-01 17:01:56,658:INFO::its now!!!!!!!!5
2023-12-01 17:01:56,849:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:56,851:INFO::Epoch 00005 | lr 0.00050 | Train_Loss 1.3330 | Train_Classification_Loss 1.3643 | Dmon_Loss -0.0626 | Val_Loss 1.3640 | Search Time(s) 0.4204 | Infer Time(s) 0.1945 | Time(s) 0.6149 
2023-12-01 17:01:56,920:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 17:01:56,921:INFO::Validation loss decreased (1.366629 --> 1.364009).  Saving model ...
2023-12-01 17:01:56,924:INFO::Epoch: 6
tensor([[0.4994, 0.4723, 0.4758, 0.4723],
        [0.4703, 0.4723, 0.4723, 0.4851],
        [0.4932, 0.4758, 0.4723, 0.4744],
        [0.4942, 0.4757, 0.4745, 0.4723]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:56,925:INFO::its now!!!!!!!!5
2023-12-01 17:01:57,081:INFO::its now!!!!!!!!0
2023-12-01 17:01:57,082:INFO::its now!!!!!!!!3
2023-12-01 17:01:57,111:INFO::its now!!!!!!!!5
2023-12-01 17:01:57,288:INFO::its now!!!!!!!!
2023-12-01 17:01:57,288:INFO::its now!!!!!!!! on 
2023-12-01 17:01:57,328:INFO::its now!!!!!!!!5
2023-12-01 17:01:57,501:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:57,502:INFO::Epoch 00006 | lr 0.00050 | Train_Loss 1.3290 | Train_Classification_Loss 1.3602 | Dmon_Loss -0.0623 | Val_Loss 1.3591 | Search Time(s) 0.4030 | Infer Time(s) 0.1765 | Time(s) 0.5796 
2023-12-01 17:01:57,546:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 1;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 1;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 1;	26120: 1;	26121: 1;	26122: 1;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 17:01:57,548:INFO::Validation loss decreased (1.364009 --> 1.359091).  Saving model ...
2023-12-01 17:01:57,551:INFO::Epoch: 7
tensor([[0.4990, 0.4675, 0.4706, 0.4675],
        [0.4647, 0.4675, 0.4675, 0.4848],
        [0.4925, 0.4706, 0.4675, 0.4697],
        [0.4936, 0.4705, 0.4698, 0.4675]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:57,552:INFO::its now!!!!!!!!5
2023-12-01 17:01:57,739:INFO::its now!!!!!!!!0
2023-12-01 17:01:57,740:INFO::its now!!!!!!!!3
2023-12-01 17:01:57,773:INFO::its now!!!!!!!!5
2023-12-01 17:01:57,981:INFO::its now!!!!!!!!
2023-12-01 17:01:57,981:INFO::its now!!!!!!!! on 
2023-12-01 17:01:58,023:INFO::its now!!!!!!!!5
2023-12-01 17:01:58,185:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:58,186:INFO::Epoch 00007 | lr 0.00050 | Train_Loss 1.3272 | Train_Classification_Loss 1.3585 | Dmon_Loss -0.0627 | Val_Loss 1.3567 | Search Time(s) 0.4717 | Infer Time(s) 0.1653 | Time(s) 0.6370 
2023-12-01 17:01:58,231:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 1;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:01:58,232:INFO::Validation loss decreased (1.359091 --> 1.356702).  Saving model ...
2023-12-01 17:01:58,235:INFO::Epoch: 8
tensor([[0.4987, 0.4635, 0.4662, 0.4635],
        [0.4601, 0.4635, 0.4635, 0.4847],
        [0.4921, 0.4662, 0.4635, 0.4657],
        [0.4934, 0.4662, 0.4658, 0.4635]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:58,236:INFO::its now!!!!!!!!5
2023-12-01 17:01:58,388:INFO::its now!!!!!!!!0
2023-12-01 17:01:58,389:INFO::its now!!!!!!!!3
2023-12-01 17:01:58,420:INFO::its now!!!!!!!!5
2023-12-01 17:01:58,581:INFO::its now!!!!!!!!
2023-12-01 17:01:58,581:INFO::its now!!!!!!!! on 
2023-12-01 17:01:58,620:INFO::its now!!!!!!!!5
2023-12-01 17:01:58,772:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:58,773:INFO::Epoch 00008 | lr 0.00050 | Train_Loss 1.3203 | Train_Classification_Loss 1.3515 | Dmon_Loss -0.0624 | Val_Loss 1.3514 | Search Time(s) 0.3865 | Infer Time(s) 0.1526 | Time(s) 0.5391 
2023-12-01 17:01:58,821:INFO::cluster info:
0: 3;	1: 3;	2: 1;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 1;	26111: 1;	26112: 1;	26113: 1;	26114: 1;	26115: 1;	26116: 1;	26117: 1;	26118: 1;	26119: 3;	26120: 1;	26121: 1;	26122: 3;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 17:01:58,822:INFO::Validation loss decreased (1.356702 --> 1.351440).  Saving model ...
2023-12-01 17:01:58,824:INFO::Epoch: 9
tensor([[0.4986, 0.4602, 0.4626, 0.4602],
        [0.4563, 0.4602, 0.4602, 0.4847],
        [0.4919, 0.4626, 0.4602, 0.4624],
        [0.4935, 0.4626, 0.4624, 0.4602]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:58,825:INFO::its now!!!!!!!!5
2023-12-01 17:01:58,979:INFO::its now!!!!!!!!0
2023-12-01 17:01:58,980:INFO::its now!!!!!!!!3
2023-12-01 17:01:59,009:INFO::its now!!!!!!!!5
2023-12-01 17:01:59,197:INFO::its now!!!!!!!!
2023-12-01 17:01:59,197:INFO::its now!!!!!!!! on 
2023-12-01 17:01:59,235:INFO::its now!!!!!!!!5
2023-12-01 17:01:59,420:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:01:59,422:INFO::Epoch 00009 | lr 0.00050 | Train_Loss 1.3159 | Train_Classification_Loss 1.3473 | Dmon_Loss -0.0627 | Val_Loss 1.3495 | Search Time(s) 0.4104 | Infer Time(s) 0.1881 | Time(s) 0.5985 
2023-12-01 17:01:59,475:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:01:59,476:INFO::Validation loss decreased (1.351440 --> 1.349497).  Saving model ...
2023-12-01 17:01:59,479:INFO::Epoch: 10
tensor([[0.4986, 0.4565, 0.4585, 0.4565],
        [0.4520, 0.4565, 0.4565, 0.4846],
        [0.4918, 0.4585, 0.4565, 0.4586],
        [0.4936, 0.4585, 0.4587, 0.4565]], device='cuda:0', requires_grad=True)
2023-12-01 17:01:59,479:INFO::its now!!!!!!!!5
2023-12-01 17:01:59,628:INFO::its now!!!!!!!!0
2023-12-01 17:01:59,628:INFO::its now!!!!!!!!3
2023-12-01 17:01:59,659:INFO::its now!!!!!!!!5
2023-12-01 17:01:59,835:INFO::its now!!!!!!!!
2023-12-01 17:01:59,835:INFO::its now!!!!!!!! on 
2023-12-01 17:01:59,873:INFO::its now!!!!!!!!5
2023-12-01 17:02:00,076:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:00,078:INFO::Epoch 00010 | lr 0.00050 | Train_Loss 1.3120 | Train_Classification_Loss 1.3433 | Dmon_Loss -0.0626 | Val_Loss 1.3438 | Search Time(s) 0.3969 | Infer Time(s) 0.2035 | Time(s) 0.6004 
2023-12-01 17:02:00,165:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 1;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 1;	26110: 3;	26111: 3;	26112: 1;	26113: 1;	26114: 1;	26115: 3;	26116: 1;	26117: 1;	26118: 1;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 1;	26124: 1;	26125: 1;	26126: 1;	26127: 3;	
2023-12-01 17:02:00,166:INFO::Validation loss decreased (1.349497 --> 1.343823).  Saving model ...
2023-12-01 17:02:00,171:INFO::Epoch: 11
tensor([[0.4985, 0.4525, 0.4543, 0.4525],
        [0.4475, 0.4525, 0.4525, 0.4846],
        [0.4918, 0.4542, 0.4525, 0.4547],
        [0.4939, 0.4542, 0.4547, 0.4525]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:00,172:INFO::its now!!!!!!!!5
2023-12-01 17:02:00,358:INFO::its now!!!!!!!!0
2023-12-01 17:02:00,359:INFO::its now!!!!!!!!3
2023-12-01 17:02:00,390:INFO::its now!!!!!!!!5
2023-12-01 17:02:00,573:INFO::its now!!!!!!!!
2023-12-01 17:02:00,573:INFO::its now!!!!!!!! on 
2023-12-01 17:02:00,611:INFO::its now!!!!!!!!5
2023-12-01 17:02:00,781:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:00,782:INFO::Epoch 00011 | lr 0.00050 | Train_Loss 1.3112 | Train_Classification_Loss 1.3425 | Dmon_Loss -0.0628 | Val_Loss 1.3417 | Search Time(s) 0.4404 | Infer Time(s) 0.1735 | Time(s) 0.6139 
2023-12-01 17:02:00,827:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:00,828:INFO::Validation loss decreased (1.343823 --> 1.341681).  Saving model ...
2023-12-01 17:02:00,830:INFO::Epoch: 12
tensor([[0.4985, 0.4489, 0.4503, 0.4489],
        [0.4433, 0.4489, 0.4489, 0.4846],
        [0.4917, 0.4502, 0.4489, 0.4509],
        [0.4943, 0.4502, 0.4510, 0.4489]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:00,831:INFO::its now!!!!!!!!5
2023-12-01 17:02:00,999:INFO::its now!!!!!!!!0
2023-12-01 17:02:01,000:INFO::its now!!!!!!!!3
2023-12-01 17:02:01,037:INFO::its now!!!!!!!!5
2023-12-01 17:02:01,244:INFO::its now!!!!!!!!
2023-12-01 17:02:01,244:INFO::its now!!!!!!!! on 
2023-12-01 17:02:01,283:INFO::its now!!!!!!!!5
2023-12-01 17:02:01,460:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:01,462:INFO::Epoch 00012 | lr 0.00050 | Train_Loss 1.3039 | Train_Classification_Loss 1.3352 | Dmon_Loss -0.0627 | Val_Loss 1.3362 | Search Time(s) 0.4529 | Infer Time(s) 0.1785 | Time(s) 0.6314 
2023-12-01 17:02:01,500:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 1;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 1;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:01,501:INFO::Validation loss decreased (1.341681 --> 1.336198).  Saving model ...
2023-12-01 17:02:01,504:INFO::Epoch: 13
tensor([[0.4985, 0.4471, 0.4483, 0.4471],
        [0.4412, 0.4471, 0.4471, 0.4847],
        [0.4917, 0.4483, 0.4471, 0.4491],
        [0.4949, 0.4482, 0.4491, 0.4471]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:01,504:INFO::its now!!!!!!!!5
2023-12-01 17:02:01,665:INFO::its now!!!!!!!!0
2023-12-01 17:02:01,666:INFO::its now!!!!!!!!3
2023-12-01 17:02:01,695:INFO::its now!!!!!!!!5
2023-12-01 17:02:01,872:INFO::its now!!!!!!!!
2023-12-01 17:02:01,872:INFO::its now!!!!!!!! on 
2023-12-01 17:02:01,908:INFO::its now!!!!!!!!5
2023-12-01 17:02:02,072:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:02,073:INFO::Epoch 00013 | lr 0.00050 | Train_Loss 1.2985 | Train_Classification_Loss 1.3298 | Dmon_Loss -0.0628 | Val_Loss 1.3338 | Search Time(s) 0.4032 | Infer Time(s) 0.1656 | Time(s) 0.5687 
2023-12-01 17:02:02,125:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 1;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 1;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:02,127:INFO::Validation loss decreased (1.336198 --> 1.333784).  Saving model ...
2023-12-01 17:02:02,130:INFO::Epoch: 14
tensor([[0.4985, 0.4462, 0.4473, 0.4462],
        [0.4403, 0.4462, 0.4462, 0.4847],
        [0.4917, 0.4473, 0.4462, 0.4482],
        [0.4954, 0.4473, 0.4483, 0.4462]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:02,131:INFO::its now!!!!!!!!5
2023-12-01 17:02:02,292:INFO::its now!!!!!!!!0
2023-12-01 17:02:02,292:INFO::its now!!!!!!!!3
2023-12-01 17:02:02,325:INFO::its now!!!!!!!!5
2023-12-01 17:02:02,486:INFO::its now!!!!!!!!
2023-12-01 17:02:02,486:INFO::its now!!!!!!!! on 
2023-12-01 17:02:02,527:INFO::its now!!!!!!!!5
2023-12-01 17:02:02,680:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:02,682:INFO::Epoch 00014 | lr 0.00050 | Train_Loss 1.2915 | Train_Classification_Loss 1.3229 | Dmon_Loss -0.0628 | Val_Loss 1.3285 | Search Time(s) 0.3965 | Infer Time(s) 0.1556 | Time(s) 0.5521 
2023-12-01 17:02:02,734:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 1;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:02,735:INFO::Validation loss decreased (1.333784 --> 1.328504).  Saving model ...
2023-12-01 17:02:02,737:INFO::Epoch: 15
tensor([[0.4985, 0.4438, 0.4447, 0.4438],
        [0.4375, 0.4438, 0.4438, 0.4847],
        [0.4917, 0.4447, 0.4438, 0.4458],
        [0.4962, 0.4446, 0.4458, 0.4438]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:02,738:INFO::its now!!!!!!!!5
2023-12-01 17:02:02,920:INFO::its now!!!!!!!!0
2023-12-01 17:02:02,921:INFO::its now!!!!!!!!3
2023-12-01 17:02:02,971:INFO::its now!!!!!!!!5
2023-12-01 17:02:03,183:INFO::its now!!!!!!!!
2023-12-01 17:02:03,183:INFO::its now!!!!!!!! on 
2023-12-01 17:02:03,225:INFO::its now!!!!!!!!5
2023-12-01 17:02:03,386:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:03,387:INFO::Epoch 00015 | lr 0.00050 | Train_Loss 1.2910 | Train_Classification_Loss 1.3224 | Dmon_Loss -0.0628 | Val_Loss 1.3245 | Search Time(s) 0.4893 | Infer Time(s) 0.1622 | Time(s) 0.6514 
2023-12-01 17:02:03,445:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:03,446:INFO::Validation loss decreased (1.328504 --> 1.324546).  Saving model ...
2023-12-01 17:02:03,448:INFO::Epoch: 16
tensor([[0.4939, 0.4406, 0.4412, 0.4425],
        [0.4361, 0.4406, 0.4406, 0.4807],
        [0.4875, 0.4433, 0.4406, 0.4425],
        [0.4970, 0.4411, 0.4425, 0.4406]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:03,449:INFO::its now!!!!!!!!5
2023-12-01 17:02:03,614:INFO::its now!!!!!!!!0
2023-12-01 17:02:03,615:INFO::its now!!!!!!!!3
2023-12-01 17:02:03,644:INFO::its now!!!!!!!!5
2023-12-01 17:02:03,800:INFO::its now!!!!!!!!
2023-12-01 17:02:03,801:INFO::its now!!!!!!!! on 
2023-12-01 17:02:03,838:INFO::its now!!!!!!!!5
2023-12-01 17:02:04,011:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:04,012:INFO::Epoch 00016 | lr 0.00050 | Train_Loss 1.2835 | Train_Classification_Loss 1.3150 | Dmon_Loss -0.0629 | Val_Loss 1.3211 | Search Time(s) 0.3880 | Infer Time(s) 0.1765 | Time(s) 0.5645 
2023-12-01 17:02:04,059:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:04,060:INFO::Validation loss decreased (1.324546 --> 1.321116).  Saving model ...
2023-12-01 17:02:04,063:INFO::Epoch: 17
tensor([[0.4916, 0.4372, 0.4376, 0.4401],
        [0.4334, 0.4372, 0.4372, 0.4787],
        [0.4853, 0.4407, 0.4372, 0.4391],
        [0.4978, 0.4375, 0.4391, 0.4372]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:04,063:INFO::its now!!!!!!!!5
2023-12-01 17:02:04,219:INFO::its now!!!!!!!!0
2023-12-01 17:02:04,220:INFO::its now!!!!!!!!3
2023-12-01 17:02:04,249:INFO::its now!!!!!!!!5
2023-12-01 17:02:04,422:INFO::its now!!!!!!!!
2023-12-01 17:02:04,422:INFO::its now!!!!!!!! on 
2023-12-01 17:02:04,459:INFO::its now!!!!!!!!5
2023-12-01 17:02:04,639:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:04,641:INFO::Epoch 00017 | lr 0.00050 | Train_Loss 1.2788 | Train_Classification_Loss 1.3103 | Dmon_Loss -0.0630 | Val_Loss 1.3156 | Search Time(s) 0.3978 | Infer Time(s) 0.1805 | Time(s) 0.5783 
2023-12-01 17:02:04,684:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:04,685:INFO::Validation loss decreased (1.321116 --> 1.315590).  Saving model ...
2023-12-01 17:02:04,689:INFO::Epoch: 18
tensor([[0.4904, 0.4353, 0.4355, 0.4387],
        [0.4320, 0.4353, 0.4353, 0.4774],
        [0.4838, 0.4392, 0.4355, 0.4372],
        [0.4989, 0.4355, 0.4372, 0.4353]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:04,690:INFO::its now!!!!!!!!5
2023-12-01 17:02:04,863:INFO::its now!!!!!!!!0
2023-12-01 17:02:04,863:INFO::its now!!!!!!!!3
2023-12-01 17:02:04,894:INFO::its now!!!!!!!!5
2023-12-01 17:02:05,079:INFO::its now!!!!!!!!
2023-12-01 17:02:05,079:INFO::its now!!!!!!!! on 
2023-12-01 17:02:05,119:INFO::its now!!!!!!!!5
2023-12-01 17:02:05,299:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:05,301:INFO::Epoch 00018 | lr 0.00050 | Train_Loss 1.2773 | Train_Classification_Loss 1.3088 | Dmon_Loss -0.0631 | Val_Loss 1.3121 | Search Time(s) 0.4304 | Infer Time(s) 0.1831 | Time(s) 0.6136 
2023-12-01 17:02:05,364:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:05,364:INFO::Validation loss decreased (1.315590 --> 1.312079).  Saving model ...
2023-12-01 17:02:05,368:INFO::Epoch: 19
tensor([[0.4898, 0.4336, 0.4337, 0.4373],
        [0.4304, 0.4336, 0.4336, 0.4767],
        [0.4831, 0.4376, 0.4338, 0.4355],
        [0.5000, 0.4336, 0.4355, 0.4336]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:05,369:INFO::its now!!!!!!!!5
2023-12-01 17:02:05,558:INFO::its now!!!!!!!!0
2023-12-01 17:02:05,558:INFO::its now!!!!!!!!3
2023-12-01 17:02:05,589:INFO::its now!!!!!!!!5
2023-12-01 17:02:05,815:INFO::its now!!!!!!!!
2023-12-01 17:02:05,815:INFO::its now!!!!!!!! on 
2023-12-01 17:02:05,854:INFO::its now!!!!!!!!5
2023-12-01 17:02:06,059:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:06,060:INFO::Epoch 00019 | lr 0.00050 | Train_Loss 1.2657 | Train_Classification_Loss 1.2973 | Dmon_Loss -0.0631 | Val_Loss 1.3063 | Search Time(s) 0.4877 | Infer Time(s) 0.2064 | Time(s) 0.6941 
2023-12-01 17:02:06,118:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:06,119:INFO::Validation loss decreased (1.312079 --> 1.306328).  Saving model ...
2023-12-01 17:02:06,121:INFO::Epoch: 20
tensor([[0.4894, 0.4332, 0.4333, 0.4370],
        [0.4301, 0.4332, 0.4332, 0.4763],
        [0.4827, 0.4373, 0.4335, 0.4351],
        [0.5013, 0.4332, 0.4351, 0.4332]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:06,122:INFO::its now!!!!!!!!5
2023-12-01 17:02:06,256:INFO::its now!!!!!!!!0
2023-12-01 17:02:06,257:INFO::its now!!!!!!!!3
2023-12-01 17:02:06,287:INFO::its now!!!!!!!!5
2023-12-01 17:02:06,457:INFO::its now!!!!!!!!
2023-12-01 17:02:06,458:INFO::its now!!!!!!!! on 
2023-12-01 17:02:06,495:INFO::its now!!!!!!!!5
2023-12-01 17:02:06,652:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:06,653:INFO::Epoch 00020 | lr 0.00050 | Train_Loss 1.2647 | Train_Classification_Loss 1.2963 | Dmon_Loss -0.0632 | Val_Loss 1.3013 | Search Time(s) 0.3736 | Infer Time(s) 0.1603 | Time(s) 0.5338 
2023-12-01 17:02:06,714:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:06,715:INFO::Validation loss decreased (1.306328 --> 1.301278).  Saving model ...
2023-12-01 17:02:06,734:INFO::Epoch: 21
tensor([[0.4893, 0.4311, 0.4310, 0.4349],
        [0.4279, 0.4311, 0.4311, 0.4761],
        [0.4825, 0.4351, 0.4314, 0.4329],
        [0.5027, 0.4310, 0.4330, 0.4311]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:06,734:INFO::its now!!!!!!!!5
2023-12-01 17:02:06,944:INFO::its now!!!!!!!!0
2023-12-01 17:02:06,945:INFO::its now!!!!!!!!3
2023-12-01 17:02:06,988:INFO::its now!!!!!!!!5
2023-12-01 17:02:07,183:INFO::its now!!!!!!!!
2023-12-01 17:02:07,183:INFO::its now!!!!!!!! on 
2023-12-01 17:02:07,218:INFO::its now!!!!!!!!5
2023-12-01 17:02:07,351:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:07,352:INFO::Epoch 00021 | lr 0.00050 | Train_Loss 1.2556 | Train_Classification_Loss 1.2873 | Dmon_Loss -0.0633 | Val_Loss 1.2961 | Search Time(s) 0.4973 | Infer Time(s) 0.1372 | Time(s) 0.6345 
2023-12-01 17:02:07,392:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 1;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:07,393:INFO::Validation loss decreased (1.301278 --> 1.296147).  Saving model ...
2023-12-01 17:02:07,397:INFO::Epoch: 22
tensor([[0.4939, 0.4301, 0.4322, 0.4361],
        [0.4267, 0.4322, 0.4322, 0.4802],
        [0.4869, 0.4340, 0.4325, 0.4341],
        [0.5043, 0.4321, 0.4341, 0.4322]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:07,397:INFO::its now!!!!!!!!5
2023-12-01 17:02:07,572:INFO::its now!!!!!!!!0
2023-12-01 17:02:07,573:INFO::its now!!!!!!!!3
2023-12-01 17:02:07,600:INFO::its now!!!!!!!!5
2023-12-01 17:02:07,748:INFO::its now!!!!!!!!
2023-12-01 17:02:07,748:INFO::its now!!!!!!!! on 
2023-12-01 17:02:07,784:INFO::its now!!!!!!!!5
2023-12-01 17:02:07,952:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:07,954:INFO::Epoch 00022 | lr 0.00050 | Train_Loss 1.2522 | Train_Classification_Loss 1.2839 | Dmon_Loss -0.0634 | Val_Loss 1.2908 | Search Time(s) 0.3870 | Infer Time(s) 0.1726 | Time(s) 0.5595 
2023-12-01 17:02:08,004:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:08,004:INFO::Validation loss decreased (1.296147 --> 1.290810).  Saving model ...
2023-12-01 17:02:08,007:INFO::Epoch: 23
tensor([[0.4963, 0.4304, 0.4337, 0.4375],
        [0.4271, 0.4336, 0.4336, 0.4823],
        [0.4891, 0.4343, 0.4339, 0.4355],
        [0.5061, 0.4336, 0.4355, 0.4336]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:08,007:INFO::its now!!!!!!!!5
2023-12-01 17:02:08,186:INFO::its now!!!!!!!!0
2023-12-01 17:02:08,187:INFO::its now!!!!!!!!3
2023-12-01 17:02:08,216:INFO::its now!!!!!!!!5
2023-12-01 17:02:08,381:INFO::its now!!!!!!!!
2023-12-01 17:02:08,381:INFO::its now!!!!!!!! on 
2023-12-01 17:02:08,418:INFO::its now!!!!!!!!5
2023-12-01 17:02:08,583:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:08,584:INFO::Epoch 00023 | lr 0.00050 | Train_Loss 1.2417 | Train_Classification_Loss 1.2734 | Dmon_Loss -0.0634 | Val_Loss 1.2852 | Search Time(s) 0.4081 | Infer Time(s) 0.1697 | Time(s) 0.5779 
2023-12-01 17:02:08,622:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:08,623:INFO::Validation loss decreased (1.290810 --> 1.285214).  Saving model ...
2023-12-01 17:02:08,625:INFO::Epoch: 24
tensor([[0.4975, 0.4298, 0.4337, 0.4375],
        [0.4264, 0.4336, 0.4336, 0.4834],
        [0.4903, 0.4337, 0.4339, 0.4354],
        [0.5082, 0.4336, 0.4355, 0.4336]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:08,626:INFO::its now!!!!!!!!5
2023-12-01 17:02:08,811:INFO::its now!!!!!!!!0
2023-12-01 17:02:08,811:INFO::its now!!!!!!!!3
2023-12-01 17:02:08,841:INFO::its now!!!!!!!!5
2023-12-01 17:02:08,989:INFO::its now!!!!!!!!
2023-12-01 17:02:08,990:INFO::its now!!!!!!!! on 
2023-12-01 17:02:09,028:INFO::its now!!!!!!!!5
2023-12-01 17:02:09,194:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:09,195:INFO::Epoch 00024 | lr 0.00050 | Train_Loss 1.2426 | Train_Classification_Loss 1.2743 | Dmon_Loss -0.0635 | Val_Loss 1.2795 | Search Time(s) 0.4019 | Infer Time(s) 0.1697 | Time(s) 0.5716 
2023-12-01 17:02:09,273:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:09,275:INFO::Validation loss decreased (1.285214 --> 1.279542).  Saving model ...
2023-12-01 17:02:09,279:INFO::Epoch: 25
tensor([[0.4982, 0.4314, 0.4357, 0.4394],
        [0.4283, 0.4355, 0.4355, 0.4840],
        [0.4909, 0.4355, 0.4358, 0.4373],
        [0.5104, 0.4356, 0.4374, 0.4355]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:09,280:INFO::its now!!!!!!!!5
2023-12-01 17:02:09,468:INFO::its now!!!!!!!!0
2023-12-01 17:02:09,468:INFO::its now!!!!!!!!3
2023-12-01 17:02:09,497:INFO::its now!!!!!!!!5
2023-12-01 17:02:09,697:INFO::its now!!!!!!!!
2023-12-01 17:02:09,698:INFO::its now!!!!!!!! on 
2023-12-01 17:02:09,736:INFO::its now!!!!!!!!5
2023-12-01 17:02:09,910:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:09,911:INFO::Epoch 00025 | lr 0.00050 | Train_Loss 1.2370 | Train_Classification_Loss 1.2689 | Dmon_Loss -0.0637 | Val_Loss 1.2733 | Search Time(s) 0.4574 | Infer Time(s) 0.1775 | Time(s) 0.6349 
2023-12-01 17:02:09,947:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:09,948:INFO::Validation loss decreased (1.279542 --> 1.273339).  Saving model ...
2023-12-01 17:02:09,951:INFO::Epoch: 26
tensor([[0.4985, 0.4327, 0.4372, 0.4408],
        [0.4297, 0.4368, 0.4368, 0.4842],
        [0.4911, 0.4368, 0.4371, 0.4387],
        [0.5128, 0.4371, 0.4387, 0.4368]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:09,952:INFO::its now!!!!!!!!5
2023-12-01 17:02:10,120:INFO::its now!!!!!!!!0
2023-12-01 17:02:10,120:INFO::its now!!!!!!!!3
2023-12-01 17:02:10,151:INFO::its now!!!!!!!!5
2023-12-01 17:02:10,317:INFO::its now!!!!!!!!
2023-12-01 17:02:10,317:INFO::its now!!!!!!!! on 
2023-12-01 17:02:10,355:INFO::its now!!!!!!!!5
2023-12-01 17:02:10,541:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:10,543:INFO::Epoch 00026 | lr 0.00050 | Train_Loss 1.2244 | Train_Classification_Loss 1.2562 | Dmon_Loss -0.0637 | Val_Loss 1.2671 | Search Time(s) 0.4065 | Infer Time(s) 0.1855 | Time(s) 0.5920 
2023-12-01 17:02:10,597:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:10,599:INFO::Validation loss decreased (1.273339 --> 1.267095).  Saving model ...
2023-12-01 17:02:10,602:INFO::Epoch: 27
tensor([[0.4986, 0.4339, 0.4386, 0.4422],
        [0.4312, 0.4382, 0.4382, 0.4844],
        [0.4913, 0.4383, 0.4385, 0.4401],
        [0.5154, 0.4385, 0.4401, 0.4382]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:10,603:INFO::its now!!!!!!!!5
2023-12-01 17:02:10,775:INFO::its now!!!!!!!!0
2023-12-01 17:02:10,776:INFO::its now!!!!!!!!3
2023-12-01 17:02:10,807:INFO::its now!!!!!!!!5
2023-12-01 17:02:11,017:INFO::its now!!!!!!!!
2023-12-01 17:02:11,017:INFO::its now!!!!!!!! on 
2023-12-01 17:02:11,058:INFO::its now!!!!!!!!5
2023-12-01 17:02:11,251:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:11,252:INFO::Epoch 00027 | lr 0.00050 | Train_Loss 1.2171 | Train_Classification_Loss 1.2490 | Dmon_Loss -0.0638 | Val_Loss 1.2604 | Search Time(s) 0.4588 | Infer Time(s) 0.1931 | Time(s) 0.6519 
2023-12-01 17:02:11,316:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:11,317:INFO::Validation loss decreased (1.267095 --> 1.260397).  Saving model ...
2023-12-01 17:02:11,320:INFO::Epoch: 28
tensor([[0.4987, 0.4365, 0.4413, 0.4447],
        [0.4340, 0.4407, 0.4407, 0.4845],
        [0.4914, 0.4410, 0.4410, 0.4426],
        [0.5183, 0.4412, 0.4426, 0.4407]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:11,321:INFO::its now!!!!!!!!5
2023-12-01 17:02:11,543:INFO::its now!!!!!!!!0
2023-12-01 17:02:11,543:INFO::its now!!!!!!!!3
2023-12-01 17:02:11,570:INFO::its now!!!!!!!!5
2023-12-01 17:02:11,745:INFO::its now!!!!!!!!
2023-12-01 17:02:11,745:INFO::its now!!!!!!!! on 
2023-12-01 17:02:11,779:INFO::its now!!!!!!!!5
2023-12-01 17:02:11,919:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:11,921:INFO::Epoch 00028 | lr 0.00050 | Train_Loss 1.2117 | Train_Classification_Loss 1.2437 | Dmon_Loss -0.0639 | Val_Loss 1.2535 | Search Time(s) 0.4588 | Infer Time(s) 0.1433 | Time(s) 0.6021 
2023-12-01 17:02:11,986:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:11,988:INFO::Validation loss decreased (1.260397 --> 1.253467).  Saving model ...
2023-12-01 17:02:11,991:INFO::Epoch: 29
tensor([[0.4988, 0.4392, 0.4441, 0.4474],
        [0.4371, 0.4434, 0.4434, 0.4845],
        [0.4914, 0.4440, 0.4436, 0.4453],
        [0.5216, 0.4441, 0.4454, 0.4434]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:11,992:INFO::its now!!!!!!!!5
2023-12-01 17:02:12,164:INFO::its now!!!!!!!!0
2023-12-01 17:02:12,165:INFO::its now!!!!!!!!3
2023-12-01 17:02:12,191:INFO::its now!!!!!!!!5
2023-12-01 17:02:12,376:INFO::its now!!!!!!!!
2023-12-01 17:02:12,376:INFO::its now!!!!!!!! on 
2023-12-01 17:02:12,415:INFO::its now!!!!!!!!5
2023-12-01 17:02:12,596:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:12,598:INFO::Epoch 00029 | lr 0.00050 | Train_Loss 1.2055 | Train_Classification_Loss 1.2374 | Dmon_Loss -0.0639 | Val_Loss 1.2463 | Search Time(s) 0.4261 | Infer Time(s) 0.1815 | Time(s) 0.6076 
2023-12-01 17:02:12,647:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:12,649:INFO::Validation loss decreased (1.253467 --> 1.246282).  Saving model ...
2023-12-01 17:02:12,651:INFO::Epoch: 30
tensor([[0.4988, 0.4418, 0.4470, 0.4501],
        [0.4401, 0.4460, 0.4460, 0.4845],
        [0.4914, 0.4469, 0.4463, 0.4480],
        [0.5253, 0.4469, 0.4480, 0.4460]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:12,652:INFO::its now!!!!!!!!5
2023-12-01 17:02:12,829:INFO::its now!!!!!!!!0
2023-12-01 17:02:12,829:INFO::its now!!!!!!!!3
2023-12-01 17:02:12,855:INFO::its now!!!!!!!!5
2023-12-01 17:02:13,023:INFO::its now!!!!!!!!
2023-12-01 17:02:13,023:INFO::its now!!!!!!!! on 
2023-12-01 17:02:13,059:INFO::its now!!!!!!!!5
2023-12-01 17:02:13,217:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:13,218:INFO::Epoch 00030 | lr 0.00050 | Train_Loss 1.1949 | Train_Classification_Loss 1.2270 | Dmon_Loss -0.0642 | Val_Loss 1.2388 | Search Time(s) 0.4069 | Infer Time(s) 0.1601 | Time(s) 0.5670 
2023-12-01 17:02:13,264:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:13,265:INFO::Validation loss decreased (1.246282 --> 1.238772).  Saving model ...
2023-12-01 17:02:13,268:INFO::Epoch: 31
tensor([[0.4988, 0.4450, 0.4503, 0.4533],
        [0.4437, 0.4491, 0.4491, 0.4845],
        [0.4914, 0.4504, 0.4494, 0.4512],
        [0.5292, 0.4502, 0.4512, 0.4491]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:13,269:INFO::its now!!!!!!!!5
2023-12-01 17:02:13,453:INFO::its now!!!!!!!!0
2023-12-01 17:02:13,454:INFO::its now!!!!!!!!3
2023-12-01 17:02:13,489:INFO::its now!!!!!!!!5
2023-12-01 17:02:13,691:INFO::its now!!!!!!!!
2023-12-01 17:02:13,692:INFO::its now!!!!!!!! on 
2023-12-01 17:02:13,734:INFO::its now!!!!!!!!5
2023-12-01 17:02:13,900:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:13,902:INFO::Epoch 00031 | lr 0.00050 | Train_Loss 1.1867 | Train_Classification_Loss 1.2188 | Dmon_Loss -0.0643 | Val_Loss 1.2310 | Search Time(s) 0.4652 | Infer Time(s) 0.1696 | Time(s) 0.6347 
2023-12-01 17:02:13,950:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:13,951:INFO::Validation loss decreased (1.238772 --> 1.231039).  Saving model ...
2023-12-01 17:02:13,954:INFO::Epoch: 32
tensor([[0.4988, 0.4461, 0.4515, 0.4544],
        [0.4449, 0.4502, 0.4502, 0.4846],
        [0.4914, 0.4516, 0.4505, 0.4523],
        [0.5334, 0.4514, 0.4523, 0.4502]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:13,955:INFO::its now!!!!!!!!5
2023-12-01 17:02:14,112:INFO::its now!!!!!!!!0
2023-12-01 17:02:14,113:INFO::its now!!!!!!!!3
2023-12-01 17:02:14,139:INFO::its now!!!!!!!!5
2023-12-01 17:02:14,342:INFO::its now!!!!!!!!
2023-12-01 17:02:14,342:INFO::its now!!!!!!!! on 
2023-12-01 17:02:14,377:INFO::its now!!!!!!!!5
2023-12-01 17:02:14,530:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:14,531:INFO::Epoch 00032 | lr 0.00050 | Train_Loss 1.1802 | Train_Classification_Loss 1.2124 | Dmon_Loss -0.0645 | Val_Loss 1.2229 | Search Time(s) 0.4220 | Infer Time(s) 0.1576 | Time(s) 0.5796 
2023-12-01 17:02:14,585:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:14,587:INFO::Validation loss decreased (1.231039 --> 1.222891).  Saving model ...
2023-12-01 17:02:14,589:INFO::Epoch: 33
tensor([[0.4988, 0.4447, 0.4500, 0.4530],
        [0.4433, 0.4488, 0.4488, 0.4846],
        [0.4914, 0.4500, 0.4491, 0.4509],
        [0.5379, 0.4499, 0.4509, 0.4488]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:14,589:INFO::its now!!!!!!!!5
2023-12-01 17:02:14,784:INFO::its now!!!!!!!!0
2023-12-01 17:02:14,785:INFO::its now!!!!!!!!3
2023-12-01 17:02:14,812:INFO::its now!!!!!!!!5
2023-12-01 17:02:14,975:INFO::its now!!!!!!!!
2023-12-01 17:02:14,975:INFO::its now!!!!!!!! on 
2023-12-01 17:02:15,010:INFO::its now!!!!!!!!5
2023-12-01 17:02:15,155:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:15,156:INFO::Epoch 00033 | lr 0.00050 | Train_Loss 1.1663 | Train_Classification_Loss 1.1986 | Dmon_Loss -0.0647 | Val_Loss 1.2144 | Search Time(s) 0.4199 | Infer Time(s) 0.1482 | Time(s) 0.5680 
2023-12-01 17:02:15,221:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:15,222:INFO::Validation loss decreased (1.222891 --> 1.214423).  Saving model ...
2023-12-01 17:02:15,225:INFO::Epoch: 34
tensor([[0.4988, 0.4486, 0.4540, 0.4569],
        [0.4476, 0.4526, 0.4526, 0.4846],
        [0.4915, 0.4542, 0.4529, 0.4547],
        [0.5428, 0.4539, 0.4547, 0.4526]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:15,226:INFO::its now!!!!!!!!5
2023-12-01 17:02:15,382:INFO::its now!!!!!!!!0
2023-12-01 17:02:15,382:INFO::its now!!!!!!!!3
2023-12-01 17:02:15,412:INFO::its now!!!!!!!!5
2023-12-01 17:02:15,588:INFO::its now!!!!!!!!
2023-12-01 17:02:15,588:INFO::its now!!!!!!!! on 
2023-12-01 17:02:15,626:INFO::its now!!!!!!!!5
2023-12-01 17:02:15,806:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:15,807:INFO::Epoch 00034 | lr 0.00050 | Train_Loss 1.1611 | Train_Classification_Loss 1.1935 | Dmon_Loss -0.0647 | Val_Loss 1.2058 | Search Time(s) 0.3995 | Infer Time(s) 0.1835 | Time(s) 0.5830 
2023-12-01 17:02:15,874:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:15,875:INFO::Validation loss decreased (1.214423 --> 1.205777).  Saving model ...
2023-12-01 17:02:15,879:INFO::Epoch: 35
tensor([[0.4988, 0.4521, 0.4578, 0.4605],
        [0.4516, 0.4562, 0.4562, 0.4846],
        [0.4914, 0.4580, 0.4565, 0.4583],
        [0.5482, 0.4577, 0.4583, 0.4562]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:15,879:INFO::its now!!!!!!!!5
2023-12-01 17:02:16,041:INFO::its now!!!!!!!!0
2023-12-01 17:02:16,041:INFO::its now!!!!!!!!3
2023-12-01 17:02:16,066:INFO::its now!!!!!!!!5
2023-12-01 17:02:16,234:INFO::its now!!!!!!!!
2023-12-01 17:02:16,234:INFO::its now!!!!!!!! on 
2023-12-01 17:02:16,269:INFO::its now!!!!!!!!5
2023-12-01 17:02:16,426:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:16,428:INFO::Epoch 00035 | lr 0.00050 | Train_Loss 1.1525 | Train_Classification_Loss 1.1850 | Dmon_Loss -0.0650 | Val_Loss 1.1969 | Search Time(s) 0.3906 | Infer Time(s) 0.1601 | Time(s) 0.5507 
2023-12-01 17:02:16,474:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:16,474:INFO::Validation loss decreased (1.205777 --> 1.196920).  Saving model ...
2023-12-01 17:02:16,476:INFO::Epoch: 36
tensor([[0.5078, 0.4583, 0.4642, 0.4623],
        [0.4583, 0.4622, 0.4580, 0.4929],
        [0.5001, 0.4646, 0.4583, 0.4644],
        [0.5592, 0.4641, 0.4601, 0.4622]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:16,477:INFO::its now!!!!!!!!5
2023-12-01 17:02:16,634:INFO::its now!!!!!!!!0
2023-12-01 17:02:16,635:INFO::its now!!!!!!!!3
2023-12-01 17:02:16,663:INFO::its now!!!!!!!!5
2023-12-01 17:02:16,901:INFO::its now!!!!!!!!
2023-12-01 17:02:16,902:INFO::its now!!!!!!!! on 
2023-12-01 17:02:16,937:INFO::its now!!!!!!!!5
2023-12-01 17:02:17,153:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:17,155:INFO::Epoch 00036 | lr 0.00050 | Train_Loss 1.1393 | Train_Classification_Loss 1.1718 | Dmon_Loss -0.0651 | Val_Loss 1.1878 | Search Time(s) 0.4604 | Infer Time(s) 0.2180 | Time(s) 0.6783 
2023-12-01 17:02:17,202:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:17,203:INFO::Validation loss decreased (1.196920 --> 1.187804).  Saving model ...
2023-12-01 17:02:17,205:INFO::Epoch: 37
tensor([[0.5123, 0.4659, 0.4720, 0.4680],
        [0.4666, 0.4698, 0.4636, 0.4971],
        [0.5045, 0.4727, 0.4639, 0.4720],
        [0.5673, 0.4720, 0.4658, 0.4698]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:17,206:INFO::its now!!!!!!!!5
2023-12-01 17:02:17,366:INFO::its now!!!!!!!!0
2023-12-01 17:02:17,367:INFO::its now!!!!!!!!3
2023-12-01 17:02:17,395:INFO::its now!!!!!!!!5
2023-12-01 17:02:17,582:INFO::its now!!!!!!!!
2023-12-01 17:02:17,582:INFO::its now!!!!!!!! on 
2023-12-01 17:02:17,619:INFO::its now!!!!!!!!5
2023-12-01 17:02:17,783:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:17,785:INFO::Epoch 00037 | lr 0.00050 | Train_Loss 1.1307 | Train_Classification_Loss 1.1633 | Dmon_Loss -0.0652 | Val_Loss 1.1799 | Search Time(s) 0.4125 | Infer Time(s) 0.1676 | Time(s) 0.5800 
2023-12-01 17:02:17,836:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:17,837:INFO::Validation loss decreased (1.187804 --> 1.179932).  Saving model ...
2023-12-01 17:02:17,839:INFO::Epoch: 38
tensor([[0.5146, 0.4686, 0.4748, 0.4697],
        [0.4695, 0.4724, 0.4653, 0.4992],
        [0.5067, 0.4756, 0.4656, 0.4747],
        [0.5740, 0.4747, 0.4675, 0.4724]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:17,840:INFO::its now!!!!!!!!5
2023-12-01 17:02:18,015:INFO::its now!!!!!!!!0
2023-12-01 17:02:18,015:INFO::its now!!!!!!!!3
2023-12-01 17:02:18,042:INFO::its now!!!!!!!!5
2023-12-01 17:02:18,231:INFO::its now!!!!!!!!
2023-12-01 17:02:18,231:INFO::its now!!!!!!!! on 
2023-12-01 17:02:18,265:INFO::its now!!!!!!!!5
2023-12-01 17:02:18,434:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:18,436:INFO::Epoch 00038 | lr 0.00050 | Train_Loss 1.1197 | Train_Classification_Loss 1.1525 | Dmon_Loss -0.0655 | Val_Loss 1.1688 | Search Time(s) 0.4245 | Infer Time(s) 0.1721 | Time(s) 0.5966 
2023-12-01 17:02:18,479:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:18,480:INFO::Validation loss decreased (1.179932 --> 1.168775).  Saving model ...
2023-12-01 17:02:18,482:INFO::Epoch: 39
tensor([[0.5158, 0.4722, 0.4785, 0.4728],
        [0.4734, 0.4760, 0.4684, 0.5003],
        [0.5078, 0.4794, 0.4687, 0.4783],
        [0.5802, 0.4784, 0.4707, 0.4760]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:18,483:INFO::its now!!!!!!!!5
2023-12-01 17:02:18,658:INFO::its now!!!!!!!!0
2023-12-01 17:02:18,658:INFO::its now!!!!!!!!3
2023-12-01 17:02:18,688:INFO::its now!!!!!!!!5
2023-12-01 17:02:18,843:INFO::its now!!!!!!!!
2023-12-01 17:02:18,843:INFO::its now!!!!!!!! on 
2023-12-01 17:02:18,882:INFO::its now!!!!!!!!5
2023-12-01 17:02:19,058:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:19,060:INFO::Epoch 00039 | lr 0.00050 | Train_Loss 1.1060 | Train_Classification_Loss 1.1388 | Dmon_Loss -0.0657 | Val_Loss 1.1586 | Search Time(s) 0.4020 | Infer Time(s) 0.1755 | Time(s) 0.5775 
2023-12-01 17:02:19,102:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:19,103:INFO::Validation loss decreased (1.168775 --> 1.158633).  Saving model ...
2023-12-01 17:02:19,106:INFO::Epoch: 40
tensor([[0.5164, 0.4757, 0.4822, 0.4762],
        [0.4772, 0.4795, 0.4718, 0.5008],
        [0.5084, 0.4831, 0.4720, 0.4818],
        [0.5866, 0.4821, 0.4741, 0.4795]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:19,106:INFO::its now!!!!!!!!5
2023-12-01 17:02:19,285:INFO::its now!!!!!!!!0
2023-12-01 17:02:19,286:INFO::its now!!!!!!!!3
2023-12-01 17:02:19,315:INFO::its now!!!!!!!!5
2023-12-01 17:02:19,505:INFO::its now!!!!!!!!
2023-12-01 17:02:19,505:INFO::its now!!!!!!!! on 
2023-12-01 17:02:19,542:INFO::its now!!!!!!!!5
2023-12-01 17:02:19,689:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:19,691:INFO::Epoch 00040 | lr 0.00050 | Train_Loss 1.0969 | Train_Classification_Loss 1.1299 | Dmon_Loss -0.0659 | Val_Loss 1.1519 | Search Time(s) 0.4353 | Infer Time(s) 0.1508 | Time(s) 0.5861 
2023-12-01 17:02:19,736:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:19,738:INFO::Validation loss decreased (1.158633 --> 1.151884).  Saving model ...
2023-12-01 17:02:19,741:INFO::Epoch: 41
tensor([[0.5167, 0.4809, 0.4876, 0.4815],
        [0.4828, 0.4846, 0.4770, 0.5011],
        [0.5087, 0.4886, 0.4773, 0.4870],
        [0.5929, 0.4875, 0.4794, 0.4846]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:19,741:INFO::its now!!!!!!!!5
2023-12-01 17:02:19,918:INFO::its now!!!!!!!!0
2023-12-01 17:02:19,918:INFO::its now!!!!!!!!3
2023-12-01 17:02:19,948:INFO::its now!!!!!!!!5
2023-12-01 17:02:20,119:INFO::its now!!!!!!!!
2023-12-01 17:02:20,119:INFO::its now!!!!!!!! on 
2023-12-01 17:02:20,158:INFO::its now!!!!!!!!5
2023-12-01 17:02:20,334:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:20,335:INFO::Epoch 00041 | lr 0.00050 | Train_Loss 1.0839 | Train_Classification_Loss 1.1170 | Dmon_Loss -0.0663 | Val_Loss 1.1394 | Search Time(s) 0.4174 | Infer Time(s) 0.1781 | Time(s) 0.5956 
2023-12-01 17:02:20,382:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:20,384:INFO::Validation loss decreased (1.151884 --> 1.139356).  Saving model ...
2023-12-01 17:02:20,388:INFO::Epoch: 42
tensor([[0.5168, 0.4858, 0.4927, 0.4866],
        [0.4882, 0.4895, 0.4820, 0.5012],
        [0.5088, 0.4938, 0.4823, 0.4919],
        [0.5994, 0.4926, 0.4844, 0.4895]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:20,389:INFO::its now!!!!!!!!5
2023-12-01 17:02:20,567:INFO::its now!!!!!!!!0
2023-12-01 17:02:20,568:INFO::its now!!!!!!!!3
2023-12-01 17:02:20,597:INFO::its now!!!!!!!!5
2023-12-01 17:02:20,780:INFO::its now!!!!!!!!
2023-12-01 17:02:20,781:INFO::its now!!!!!!!! on 
2023-12-01 17:02:20,819:INFO::its now!!!!!!!!5
2023-12-01 17:02:20,993:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:20,995:INFO::Epoch 00042 | lr 0.00050 | Train_Loss 1.0718 | Train_Classification_Loss 1.1049 | Dmon_Loss -0.0662 | Val_Loss 1.1296 | Search Time(s) 0.4308 | Infer Time(s) 0.1775 | Time(s) 0.6084 
2023-12-01 17:02:21,079:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:21,081:INFO::Validation loss decreased (1.139356 --> 1.129614).  Saving model ...
2023-12-01 17:02:21,084:INFO::Epoch: 43
tensor([[0.5169, 0.4933, 0.5004, 0.4943],
        [0.4961, 0.4969, 0.4896, 0.5013],
        [0.5089, 0.5017, 0.4899, 0.4994],
        [0.6060, 0.5003, 0.4921, 0.4969]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:21,085:INFO::its now!!!!!!!!5
2023-12-01 17:02:21,263:INFO::its now!!!!!!!!0
2023-12-01 17:02:21,263:INFO::its now!!!!!!!!3
2023-12-01 17:02:21,289:INFO::its now!!!!!!!!5
2023-12-01 17:02:21,486:INFO::its now!!!!!!!!
2023-12-01 17:02:21,487:INFO::its now!!!!!!!! on 
2023-12-01 17:02:21,538:INFO::its now!!!!!!!!5
2023-12-01 17:02:21,697:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:21,698:INFO::Epoch 00043 | lr 0.00050 | Train_Loss 1.0648 | Train_Classification_Loss 1.0980 | Dmon_Loss -0.0663 | Val_Loss 1.1211 | Search Time(s) 0.4409 | Infer Time(s) 0.1755 | Time(s) 0.6165 
2023-12-01 17:02:21,750:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:21,751:INFO::Validation loss decreased (1.129614 --> 1.121115).  Saving model ...
2023-12-01 17:02:21,754:INFO::Epoch: 44
tensor([[0.5170, 0.5011, 0.5084, 0.5023],
        [0.5044, 0.5046, 0.4976, 0.5014],
        [0.5090, 0.5099, 0.4978, 0.5072],
        [0.6128, 0.5083, 0.5001, 0.5046]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:21,754:INFO::its now!!!!!!!!5
2023-12-01 17:02:21,934:INFO::its now!!!!!!!!0
2023-12-01 17:02:21,934:INFO::its now!!!!!!!!3
2023-12-01 17:02:21,980:INFO::its now!!!!!!!!5
2023-12-01 17:02:22,151:INFO::its now!!!!!!!!
2023-12-01 17:02:22,151:INFO::its now!!!!!!!! on 
2023-12-01 17:02:22,187:INFO::its now!!!!!!!!5
2023-12-01 17:02:22,418:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:22,420:INFO::Epoch 00044 | lr 0.00050 | Train_Loss 1.0514 | Train_Classification_Loss 1.0848 | Dmon_Loss -0.0668 | Val_Loss 1.1044 | Search Time(s) 0.4304 | Infer Time(s) 0.2353 | Time(s) 0.6658 
2023-12-01 17:02:22,477:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:22,479:INFO::Validation loss decreased (1.121115 --> 1.104387).  Saving model ...
2023-12-01 17:02:22,482:INFO::Epoch: 45
tensor([[0.5170, 0.5083, 0.5157, 0.5097],
        [0.5120, 0.5086, 0.5049, 0.5084],
        [0.5162, 0.5140, 0.5052, 0.5143],
        [0.6198, 0.5156, 0.5074, 0.5118]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:22,483:INFO::its now!!!!!!!!5
2023-12-01 17:02:22,661:INFO::its now!!!!!!!!0
2023-12-01 17:02:22,661:INFO::its now!!!!!!!!3
2023-12-01 17:02:22,686:INFO::its now!!!!!!!!5
2023-12-01 17:02:22,866:INFO::its now!!!!!!!!
2023-12-01 17:02:22,866:INFO::its now!!!!!!!! on 
2023-12-01 17:02:22,904:INFO::its now!!!!!!!!5
2023-12-01 17:02:23,084:INFO::Epoch 00045 | lr 0.00050 | Train_Loss 1.0430 | Train_Classification_Loss 1.0762 | Dmon_Loss -0.0665 | Val_Loss 1.1046 | Search Time(s) 0.4219 | Infer Time(s) 0.1825 | Time(s) 0.6044 
2023-12-01 17:02:23,130:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:23,131:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:23,135:INFO::Epoch: 46
tensor([[0.5170, 0.5141, 0.5217, 0.5157],
        [0.5161, 0.5128, 0.5108, 0.5164],
        [0.5199, 0.5184, 0.5111, 0.5201],
        [0.6266, 0.5216, 0.5134, 0.5176]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:23,137:INFO::its now!!!!!!!!5
2023-12-01 17:02:23,287:INFO::its now!!!!!!!!0
2023-12-01 17:02:23,287:INFO::its now!!!!!!!!3
2023-12-01 17:02:23,316:INFO::its now!!!!!!!!5
2023-12-01 17:02:23,515:INFO::its now!!!!!!!!
2023-12-01 17:02:23,515:INFO::its now!!!!!!!! on 
2023-12-01 17:02:23,550:INFO::its now!!!!!!!!5
2023-12-01 17:02:23,698:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:23,700:INFO::Epoch 00046 | lr 0.00050 | Train_Loss 1.0218 | Train_Classification_Loss 1.0556 | Dmon_Loss -0.0676 | Val_Loss 1.0809 | Search Time(s) 0.4115 | Infer Time(s) 0.1551 | Time(s) 0.5666 
2023-12-01 17:02:23,755:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:23,757:INFO::Validation loss decreased (1.104387 --> 1.080947).  Saving model ...
2023-12-01 17:02:23,759:INFO::Epoch: 47
tensor([[0.5233, 0.5197, 0.5247, 0.5214],
        [0.5210, 0.5176, 0.5165, 0.5204],
        [0.5273, 0.5235, 0.5168, 0.5231],
        [0.6341, 0.5273, 0.5191, 0.5231]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:23,760:INFO::its now!!!!!!!!5
2023-12-01 17:02:23,919:INFO::its now!!!!!!!!0
2023-12-01 17:02:23,919:INFO::its now!!!!!!!!3
2023-12-01 17:02:23,947:INFO::its now!!!!!!!!5
2023-12-01 17:02:24,101:INFO::its now!!!!!!!!
2023-12-01 17:02:24,101:INFO::its now!!!!!!!! on 
2023-12-01 17:02:24,136:INFO::its now!!!!!!!!5
2023-12-01 17:02:24,302:INFO::Epoch 00047 | lr 0.00050 | Train_Loss 1.0244 | Train_Classification_Loss 1.0579 | Dmon_Loss -0.0671 | Val_Loss 1.0817 | Search Time(s) 0.3786 | Infer Time(s) 0.1657 | Time(s) 0.5442 
2023-12-01 17:02:24,343:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:24,344:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:24,347:INFO::Epoch: 48
tensor([[0.5291, 0.5236, 0.5263, 0.5255],
        [0.5238, 0.5211, 0.5205, 0.5248],
        [0.5311, 0.5272, 0.5208, 0.5257],
        [0.6413, 0.5314, 0.5232, 0.5270]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:24,347:INFO::its now!!!!!!!!5
2023-12-01 17:02:24,500:INFO::its now!!!!!!!!0
2023-12-01 17:02:24,501:INFO::its now!!!!!!!!3
2023-12-01 17:02:24,527:INFO::its now!!!!!!!!5
2023-12-01 17:02:24,709:INFO::its now!!!!!!!!
2023-12-01 17:02:24,709:INFO::its now!!!!!!!! on 
2023-12-01 17:02:24,744:INFO::its now!!!!!!!!5
2023-12-01 17:02:24,912:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:24,914:INFO::Epoch 00048 | lr 0.00050 | Train_Loss 0.9992 | Train_Classification_Loss 1.0332 | Dmon_Loss -0.0680 | Val_Loss 1.0572 | Search Time(s) 0.3975 | Infer Time(s) 0.1705 | Time(s) 0.5680 
2023-12-01 17:02:24,970:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 1;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:24,971:INFO::Validation loss decreased (1.080947 --> 1.057176).  Saving model ...
2023-12-01 17:02:24,974:INFO::Epoch: 49
tensor([[0.5320, 0.5265, 0.5280, 0.5284],
        [0.5262, 0.5238, 0.5234, 0.5270],
        [0.5330, 0.5301, 0.5237, 0.5279],
        [0.6492, 0.5343, 0.5261, 0.5298]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:24,974:INFO::its now!!!!!!!!5
2023-12-01 17:02:25,133:INFO::its now!!!!!!!!0
2023-12-01 17:02:25,134:INFO::its now!!!!!!!!3
2023-12-01 17:02:25,161:INFO::its now!!!!!!!!5
2023-12-01 17:02:25,347:INFO::its now!!!!!!!!
2023-12-01 17:02:25,347:INFO::its now!!!!!!!! on 
2023-12-01 17:02:25,381:INFO::its now!!!!!!!!5
2023-12-01 17:02:25,544:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:25,546:INFO::Epoch 00049 | lr 0.00050 | Train_Loss 0.9800 | Train_Classification_Loss 1.0143 | Dmon_Loss -0.0685 | Val_Loss 1.0441 | Search Time(s) 0.4041 | Infer Time(s) 0.1686 | Time(s) 0.5727 
2023-12-01 17:02:25,603:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:25,605:INFO::Validation loss decreased (1.057176 --> 1.044099).  Saving model ...
2023-12-01 17:02:25,609:INFO::Epoch: 50
tensor([[0.5335, 0.5304, 0.5314, 0.5325],
        [0.5300, 0.5277, 0.5275, 0.5281],
        [0.5342, 0.5341, 0.5277, 0.5316],
        [0.6569, 0.5383, 0.5302, 0.5337]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:25,610:INFO::its now!!!!!!!!5
2023-12-01 17:02:25,778:INFO::its now!!!!!!!!0
2023-12-01 17:02:25,779:INFO::its now!!!!!!!!3
2023-12-01 17:02:25,804:INFO::its now!!!!!!!!5
2023-12-01 17:02:25,969:INFO::its now!!!!!!!!
2023-12-01 17:02:25,969:INFO::its now!!!!!!!! on 
2023-12-01 17:02:26,024:INFO::its now!!!!!!!!5
2023-12-01 17:02:26,192:INFO::Epoch 00050 | lr 0.00050 | Train_Loss 0.9916 | Train_Classification_Loss 1.0253 | Dmon_Loss -0.0673 | Val_Loss 1.0519 | Search Time(s) 0.4169 | Infer Time(s) 0.1701 | Time(s) 0.5870 
2023-12-01 17:02:26,236:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:26,238:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:26,241:INFO::Epoch: 51
tensor([[0.5343, 0.5363, 0.5372, 0.5385],
        [0.5323, 0.5336, 0.5334, 0.5361],
        [0.5353, 0.5403, 0.5337, 0.5373],
        [0.6644, 0.5443, 0.5362, 0.5395]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:26,243:INFO::its now!!!!!!!!5
2023-12-01 17:02:26,389:INFO::its now!!!!!!!!0
2023-12-01 17:02:26,389:INFO::its now!!!!!!!!3
2023-12-01 17:02:26,437:INFO::its now!!!!!!!!5
2023-12-01 17:02:26,637:INFO::its now!!!!!!!!
2023-12-01 17:02:26,637:INFO::its now!!!!!!!! on 
2023-12-01 17:02:26,694:INFO::its now!!!!!!!!5
2023-12-01 17:02:26,853:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:26,854:INFO::Epoch 00051 | lr 0.00050 | Train_Loss 0.9572 | Train_Classification_Loss 0.9918 | Dmon_Loss -0.0692 | Val_Loss 1.0187 | Search Time(s) 0.4523 | Infer Time(s) 0.1626 | Time(s) 0.6149 
2023-12-01 17:02:26,910:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:26,911:INFO::Validation loss decreased (1.044099 --> 1.018692).  Saving model ...
2023-12-01 17:02:26,914:INFO::Epoch: 52
tensor([[0.5430, 0.5429, 0.5439, 0.5415],
        [0.5375, 0.5403, 0.5402, 0.5402],
        [0.5434, 0.5434, 0.5405, 0.5440],
        [0.6730, 0.5511, 0.5430, 0.5462]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:26,915:INFO::its now!!!!!!!!5
2023-12-01 17:02:27,090:INFO::its now!!!!!!!!0
2023-12-01 17:02:27,091:INFO::its now!!!!!!!!3
2023-12-01 17:02:27,138:INFO::its now!!!!!!!!5
2023-12-01 17:02:27,298:INFO::its now!!!!!!!!
2023-12-01 17:02:27,298:INFO::its now!!!!!!!! on 
2023-12-01 17:02:27,337:INFO::its now!!!!!!!!5
2023-12-01 17:02:27,541:INFO::Epoch 00052 | lr 0.00050 | Train_Loss 0.9596 | Train_Classification_Loss 0.9938 | Dmon_Loss -0.0684 | Val_Loss 1.0256 | Search Time(s) 0.4256 | Infer Time(s) 0.2045 | Time(s) 0.6300 
2023-12-01 17:02:27,595:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:27,596:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:27,599:INFO::Epoch: 53
tensor([[0.5575, 0.5521, 0.5473, 0.5492],
        [0.5464, 0.5437, 0.5495, 0.5522],
        [0.5571, 0.5513, 0.5498, 0.5473],
        [0.6811, 0.5604, 0.5523, 0.5552]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:27,601:INFO::its now!!!!!!!!5
2023-12-01 17:02:27,784:INFO::its now!!!!!!!!0
2023-12-01 17:02:27,784:INFO::its now!!!!!!!!3
2023-12-01 17:02:27,811:INFO::its now!!!!!!!!5
2023-12-01 17:02:28,043:INFO::its now!!!!!!!!
2023-12-01 17:02:28,043:INFO::its now!!!!!!!! on 
2023-12-01 17:02:28,078:INFO::its now!!!!!!!!5
2023-12-01 17:02:28,247:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:28,249:INFO::Epoch 00053 | lr 0.00050 | Train_Loss 0.9213 | Train_Classification_Loss 0.9563 | Dmon_Loss -0.0700 | Val_Loss 0.9938 | Search Time(s) 0.4747 | Infer Time(s) 0.1761 | Time(s) 0.6508 
2023-12-01 17:02:28,302:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:28,303:INFO::Validation loss decreased (1.018692 --> 0.993757).  Saving model ...
2023-12-01 17:02:28,307:INFO::Epoch: 54
tensor([[0.5648, 0.5616, 0.5545, 0.5582],
        [0.5562, 0.5508, 0.5592, 0.5582],
        [0.5641, 0.5605, 0.5595, 0.5544],
        [0.6899, 0.5702, 0.5620, 0.5647]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:28,307:INFO::its now!!!!!!!!5
2023-12-01 17:02:28,491:INFO::its now!!!!!!!!0
2023-12-01 17:02:28,491:INFO::its now!!!!!!!!3
2023-12-01 17:02:28,517:INFO::its now!!!!!!!!5
2023-12-01 17:02:28,715:INFO::its now!!!!!!!!
2023-12-01 17:02:28,715:INFO::its now!!!!!!!! on 
2023-12-01 17:02:28,750:INFO::its now!!!!!!!!5
2023-12-01 17:02:28,902:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:28,903:INFO::Epoch 00054 | lr 0.00050 | Train_Loss 0.9178 | Train_Classification_Loss 0.9531 | Dmon_Loss -0.0706 | Val_Loss 0.9856 | Search Time(s) 0.4368 | Infer Time(s) 0.1616 | Time(s) 0.5984 
2023-12-01 17:02:28,958:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:28,959:INFO::Validation loss decreased (0.993757 --> 0.985640).  Saving model ...
2023-12-01 17:02:28,962:INFO::Epoch: 55
tensor([[0.5685, 0.5677, 0.5595, 0.5641],
        [0.5624, 0.5556, 0.5641, 0.5634],
        [0.5686, 0.5665, 0.5656, 0.5592],
        [0.6982, 0.5763, 0.5682, 0.5707]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:28,963:INFO::its now!!!!!!!!5
2023-12-01 17:02:29,128:INFO::its now!!!!!!!!0
2023-12-01 17:02:29,129:INFO::its now!!!!!!!!3
2023-12-01 17:02:29,156:INFO::its now!!!!!!!!5
2023-12-01 17:02:29,340:INFO::its now!!!!!!!!
2023-12-01 17:02:29,340:INFO::its now!!!!!!!! on 
2023-12-01 17:02:29,392:INFO::its now!!!!!!!!5
2023-12-01 17:02:29,550:INFO::Epoch 00055 | lr 0.00050 | Train_Loss 0.9233 | Train_Classification_Loss 0.9578 | Dmon_Loss -0.0688 | Val_Loss 0.9923 | Search Time(s) 0.4320 | Infer Time(s) 0.1586 | Time(s) 0.5906 
2023-12-01 17:02:29,598:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:29,599:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:29,601:INFO::Epoch: 56
tensor([[0.5703, 0.5739, 0.5654, 0.5703],
        [0.5690, 0.5615, 0.5665, 0.5714],
        [0.5714, 0.5729, 0.5719, 0.5651],
        [0.7064, 0.5826, 0.5745, 0.5769]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:29,602:INFO::its now!!!!!!!!5
2023-12-01 17:02:29,764:INFO::its now!!!!!!!!0
2023-12-01 17:02:29,765:INFO::its now!!!!!!!!3
2023-12-01 17:02:29,811:INFO::its now!!!!!!!!5
2023-12-01 17:02:29,974:INFO::its now!!!!!!!!
2023-12-01 17:02:29,974:INFO::its now!!!!!!!! on 
2023-12-01 17:02:30,031:INFO::its now!!!!!!!!5
2023-12-01 17:02:30,214:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:30,216:INFO::Epoch 00056 | lr 0.00050 | Train_Loss 0.8804 | Train_Classification_Loss 0.9163 | Dmon_Loss -0.0718 | Val_Loss 0.9539 | Search Time(s) 0.4289 | Infer Time(s) 0.1861 | Time(s) 0.6150 
2023-12-01 17:02:30,267:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 0;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 3;	26121: 2;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:30,268:INFO::Validation loss decreased (0.985640 --> 0.953904).  Saving model ...
2023-12-01 17:02:30,271:INFO::Epoch: 57
tensor([[0.5766, 0.5770, 0.5714, 0.5763],
        [0.5752, 0.5674, 0.5678, 0.5801],
        [0.5778, 0.5761, 0.5778, 0.5709],
        [0.7155, 0.5886, 0.5805, 0.5828]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:30,272:INFO::its now!!!!!!!!5
2023-12-01 17:02:30,432:INFO::its now!!!!!!!!0
2023-12-01 17:02:30,433:INFO::its now!!!!!!!!3
2023-12-01 17:02:30,484:INFO::its now!!!!!!!!5
2023-12-01 17:02:30,656:INFO::its now!!!!!!!!
2023-12-01 17:02:30,656:INFO::its now!!!!!!!! on 
2023-12-01 17:02:30,699:INFO::its now!!!!!!!!5
2023-12-01 17:02:30,847:INFO::Epoch 00057 | lr 0.00050 | Train_Loss 0.8804 | Train_Classification_Loss 0.9161 | Dmon_Loss -0.0714 | Val_Loss 0.9601 | Search Time(s) 0.4294 | Infer Time(s) 0.1486 | Time(s) 0.5780 
2023-12-01 17:02:30,900:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:30,902:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:30,905:INFO::Epoch: 58
tensor([[0.5889, 0.5786, 0.5803, 0.5850],
        [0.5842, 0.5761, 0.5742, 0.5845],
        [0.5899, 0.5837, 0.5809, 0.5797],
        [0.7235, 0.5972, 0.5891, 0.5912]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:30,906:INFO::its now!!!!!!!!5
2023-12-01 17:02:31,118:INFO::its now!!!!!!!!0
2023-12-01 17:02:31,119:INFO::its now!!!!!!!!3
2023-12-01 17:02:31,150:INFO::its now!!!!!!!!5
2023-12-01 17:02:31,309:INFO::its now!!!!!!!!
2023-12-01 17:02:31,309:INFO::its now!!!!!!!! on 
2023-12-01 17:02:31,347:INFO::its now!!!!!!!!5
2023-12-01 17:02:31,562:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:31,564:INFO::Epoch 00058 | lr 0.00050 | Train_Loss 0.8458 | Train_Classification_Loss 0.8823 | Dmon_Loss -0.0730 | Val_Loss 0.9260 | Search Time(s) 0.4369 | Infer Time(s) 0.2224 | Time(s) 0.6593 
2023-12-01 17:02:31,611:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:31,613:INFO::Validation loss decreased (0.953904 --> 0.925961).  Saving model ...
2023-12-01 17:02:31,616:INFO::Epoch: 59
tensor([[0.5951, 0.5841, 0.5895, 0.5939],
        [0.5933, 0.5851, 0.5820, 0.5867],
        [0.5965, 0.5921, 0.5871, 0.5886],
        [0.7318, 0.6060, 0.5979, 0.5998]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:31,616:INFO::its now!!!!!!!!5
2023-12-01 17:02:31,802:INFO::its now!!!!!!!!0
2023-12-01 17:02:31,802:INFO::its now!!!!!!!!3
2023-12-01 17:02:31,827:INFO::its now!!!!!!!!5
2023-12-01 17:02:32,007:INFO::its now!!!!!!!!
2023-12-01 17:02:32,008:INFO::its now!!!!!!!! on 
2023-12-01 17:02:32,043:INFO::its now!!!!!!!!5
2023-12-01 17:02:32,202:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:32,203:INFO::Epoch 00059 | lr 0.00050 | Train_Loss 0.8309 | Train_Classification_Loss 0.8679 | Dmon_Loss -0.0740 | Val_Loss 0.9124 | Search Time(s) 0.4269 | Infer Time(s) 0.1621 | Time(s) 0.5890 
2023-12-01 17:02:32,251:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 1;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:32,252:INFO::Validation loss decreased (0.925961 --> 0.912382).  Saving model ...
2023-12-01 17:02:32,256:INFO::Epoch: 60
tensor([[0.5983, 0.5911, 0.5983, 0.6025],
        [0.5983, 0.5938, 0.5901, 0.5948],
        [0.6006, 0.6006, 0.5944, 0.5973],
        [0.7394, 0.6144, 0.6063, 0.6081]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:32,257:INFO::its now!!!!!!!!5
2023-12-01 17:02:32,433:INFO::its now!!!!!!!!0
2023-12-01 17:02:32,434:INFO::its now!!!!!!!!3
2023-12-01 17:02:32,463:INFO::its now!!!!!!!!5
2023-12-01 17:02:32,637:INFO::its now!!!!!!!!
2023-12-01 17:02:32,637:INFO::its now!!!!!!!! on 
2023-12-01 17:02:32,695:INFO::its now!!!!!!!!5
2023-12-01 17:02:32,861:INFO::Epoch 00060 | lr 0.00050 | Train_Loss 0.8702 | Train_Classification_Loss 0.9045 | Dmon_Loss -0.0686 | Val_Loss 0.9453 | Search Time(s) 0.4404 | Infer Time(s) 0.1686 | Time(s) 0.6089 
2023-12-01 17:02:32,901:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:32,902:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:32,905:INFO::Epoch: 61
tensor([[0.6064, 0.5986, 0.6067, 0.6068],
        [0.6013, 0.6021, 0.5980, 0.6051],
        [0.6037, 0.6088, 0.6021, 0.6056],
        [0.7468, 0.6224, 0.6144, 0.6160]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:32,906:INFO::its now!!!!!!!!5
2023-12-01 17:02:33,105:INFO::its now!!!!!!!!0
2023-12-01 17:02:33,105:INFO::its now!!!!!!!!3
2023-12-01 17:02:33,151:INFO::its now!!!!!!!!5
2023-12-01 17:02:33,317:INFO::its now!!!!!!!!
2023-12-01 17:02:33,318:INFO::its now!!!!!!!! on 
2023-12-01 17:02:33,373:INFO::its now!!!!!!!!5
2023-12-01 17:02:33,604:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:33,605:INFO::Epoch 00061 | lr 0.00050 | Train_Loss 0.8052 | Train_Classification_Loss 0.8430 | Dmon_Loss -0.0757 | Val_Loss 0.8857 | Search Time(s) 0.4679 | Infer Time(s) 0.2335 | Time(s) 0.7014 
2023-12-01 17:02:33,685:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 1;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:33,685:INFO::Validation loss decreased (0.912382 --> 0.885738).  Saving model ...
2023-12-01 17:02:33,688:INFO::Epoch: 62
tensor([[0.6178, 0.6023, 0.6158, 0.6138],
        [0.6079, 0.6110, 0.6020, 0.6173],
        [0.6129, 0.6178, 0.6107, 0.6098],
        [0.7584, 0.6311, 0.6186, 0.6245]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:33,689:INFO::its now!!!!!!!!5
2023-12-01 17:02:33,845:INFO::its now!!!!!!!!0
2023-12-01 17:02:33,846:INFO::its now!!!!!!!!3
2023-12-01 17:02:33,891:INFO::its now!!!!!!!!5
2023-12-01 17:02:34,048:INFO::its now!!!!!!!!
2023-12-01 17:02:34,048:INFO::its now!!!!!!!! on 
2023-12-01 17:02:34,085:INFO::its now!!!!!!!!5
2023-12-01 17:02:34,259:INFO::Epoch 00062 | lr 0.00050 | Train_Loss 0.8077 | Train_Classification_Loss 0.8456 | Dmon_Loss -0.0757 | Val_Loss 0.8891 | Search Time(s) 0.3989 | Infer Time(s) 0.1751 | Time(s) 0.5740 
2023-12-01 17:02:34,307:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:34,308:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:34,310:INFO::Epoch: 63
tensor([[0.6236, 0.6104, 0.6263, 0.6232],
        [0.6174, 0.6213, 0.6101, 0.6235],
        [0.6261, 0.6224, 0.6210, 0.6180],
        [0.7676, 0.6412, 0.6266, 0.6344]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:34,311:INFO::its now!!!!!!!!5
2023-12-01 17:02:34,477:INFO::its now!!!!!!!!0
2023-12-01 17:02:34,477:INFO::its now!!!!!!!!3
2023-12-01 17:02:34,509:INFO::its now!!!!!!!!5
2023-12-01 17:02:34,714:INFO::its now!!!!!!!!
2023-12-01 17:02:34,714:INFO::its now!!!!!!!! on 
2023-12-01 17:02:34,769:INFO::its now!!!!!!!!5
2023-12-01 17:02:34,931:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:34,932:INFO::Epoch 00063 | lr 0.00050 | Train_Loss 0.7881 | Train_Classification_Loss 0.8267 | Dmon_Loss -0.0771 | Val_Loss 0.8717 | Search Time(s) 0.4408 | Infer Time(s) 0.1825 | Time(s) 0.6233 
2023-12-01 17:02:34,988:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 3;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:34,989:INFO::Validation loss decreased (0.885738 --> 0.871708).  Saving model ...
2023-12-01 17:02:34,992:INFO::Epoch: 64
tensor([[0.6323, 0.6183, 0.6316, 0.6317],
        [0.6260, 0.6302, 0.6179, 0.6267],
        [0.6336, 0.6286, 0.6298, 0.6259],
        [0.7759, 0.6498, 0.6344, 0.6429]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:34,993:INFO::its now!!!!!!!!5
2023-12-01 17:02:35,160:INFO::its now!!!!!!!!0
2023-12-01 17:02:35,161:INFO::its now!!!!!!!!3
2023-12-01 17:02:35,208:INFO::its now!!!!!!!!5
2023-12-01 17:02:35,380:INFO::its now!!!!!!!!
2023-12-01 17:02:35,381:INFO::its now!!!!!!!! on 
2023-12-01 17:02:35,439:INFO::its now!!!!!!!!5
2023-12-01 17:02:35,602:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:35,603:INFO::Epoch 00064 | lr 0.00050 | Train_Loss 0.7647 | Train_Classification_Loss 0.8038 | Dmon_Loss -0.0782 | Val_Loss 0.8548 | Search Time(s) 0.4469 | Infer Time(s) 0.1656 | Time(s) 0.6125 
2023-12-01 17:02:35,651:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 2;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:35,653:INFO::Validation loss decreased (0.871708 --> 0.854777).  Saving model ...
2023-12-01 17:02:35,657:INFO::Epoch: 65
tensor([[0.6367, 0.6260, 0.6381, 0.6396],
        [0.6342, 0.6347, 0.6256, 0.6342],
        [0.6385, 0.6357, 0.6379, 0.6337],
        [0.7837, 0.6577, 0.6420, 0.6508]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:35,658:INFO::its now!!!!!!!!5
2023-12-01 17:02:35,815:INFO::its now!!!!!!!!0
2023-12-01 17:02:35,816:INFO::its now!!!!!!!!3
2023-12-01 17:02:35,862:INFO::its now!!!!!!!!5
2023-12-01 17:02:36,036:INFO::its now!!!!!!!!
2023-12-01 17:02:36,037:INFO::its now!!!!!!!! on 
2023-12-01 17:02:36,092:INFO::its now!!!!!!!!5
2023-12-01 17:02:36,245:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:36,247:INFO::Epoch 00065 | lr 0.00050 | Train_Loss 0.7586 | Train_Classification_Loss 0.7981 | Dmon_Loss -0.0791 | Val_Loss 0.8463 | Search Time(s) 0.4368 | Infer Time(s) 0.1561 | Time(s) 0.5930 
2023-12-01 17:02:36,306:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 2;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:36,307:INFO::Validation loss decreased (0.854777 --> 0.846305).  Saving model ...
2023-12-01 17:02:36,310:INFO::Epoch: 66
tensor([[0.6363, 0.6299, 0.6396, 0.6420],
        [0.6366, 0.6370, 0.6278, 0.6353],
        [0.6420, 0.6375, 0.6404, 0.6359],
        [0.7847, 0.6616, 0.6441, 0.6531]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:36,311:INFO::its now!!!!!!!!5
2023-12-01 17:02:36,485:INFO::its now!!!!!!!!0
2023-12-01 17:02:36,485:INFO::its now!!!!!!!!3
2023-12-01 17:02:36,532:INFO::its now!!!!!!!!5
2023-12-01 17:02:36,693:INFO::its now!!!!!!!!
2023-12-01 17:02:36,714:INFO::its now!!!!!!!! on 
2023-12-01 17:02:36,752:INFO::its now!!!!!!!!5
2023-12-01 17:02:36,897:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:36,898:INFO::Epoch 00066 | lr 0.00050 | Train_Loss 0.7205 | Train_Classification_Loss 0.7610 | Dmon_Loss -0.0811 | Val_Loss 0.8188 | Search Time(s) 0.4408 | Infer Time(s) 0.1496 | Time(s) 0.5904 
2023-12-01 17:02:36,948:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 2;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:36,949:INFO::Validation loss decreased (0.846305 --> 0.818758).  Saving model ...
2023-12-01 17:02:36,952:INFO::Epoch: 67
tensor([[0.6370, 0.6325, 0.6410, 0.6432],
        [0.6383, 0.6382, 0.6295, 0.6368],
        [0.6449, 0.6390, 0.6422, 0.6376],
        [0.7862, 0.6641, 0.6458, 0.6542]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:36,952:INFO::its now!!!!!!!!5
2023-12-01 17:02:37,108:INFO::its now!!!!!!!!0
2023-12-01 17:02:37,109:INFO::its now!!!!!!!!3
2023-12-01 17:02:37,137:INFO::its now!!!!!!!!5
2023-12-01 17:02:37,300:INFO::its now!!!!!!!!
2023-12-01 17:02:37,301:INFO::its now!!!!!!!! on 
2023-12-01 17:02:37,340:INFO::its now!!!!!!!!5
2023-12-01 17:02:37,508:INFO::Epoch 00067 | lr 0.00050 | Train_Loss 0.7296 | Train_Classification_Loss 0.7700 | Dmon_Loss -0.0808 | Val_Loss 0.8273 | Search Time(s) 0.3861 | Infer Time(s) 0.1715 | Time(s) 0.5577 
2023-12-01 17:02:37,576:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 3;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:37,577:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:37,579:INFO::Epoch: 68
tensor([[0.6435, 0.6378, 0.6458, 0.6438],
        [0.6397, 0.6428, 0.6343, 0.6435],
        [0.6474, 0.6439, 0.6470, 0.6425],
        [0.7905, 0.6692, 0.6506, 0.6586]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:37,580:INFO::its now!!!!!!!!5
2023-12-01 17:02:37,757:INFO::its now!!!!!!!!0
2023-12-01 17:02:37,757:INFO::its now!!!!!!!!3
2023-12-01 17:02:37,792:INFO::its now!!!!!!!!5
2023-12-01 17:02:37,980:INFO::its now!!!!!!!!
2023-12-01 17:02:37,980:INFO::its now!!!!!!!! on 
2023-12-01 17:02:38,039:INFO::its now!!!!!!!!5
2023-12-01 17:02:38,214:INFO::Epoch 00068 | lr 0.00050 | Train_Loss 0.7496 | Train_Classification_Loss 0.7870 | Dmon_Loss -0.0748 | Val_Loss 0.8417 | Search Time(s) 0.4398 | Infer Time(s) 0.1971 | Time(s) 0.6369 
2023-12-01 17:02:38,261:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:38,262:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:02:38,266:INFO::Epoch: 69
tensor([[0.6526, 0.6445, 0.6481, 0.6480],
        [0.6445, 0.6491, 0.6407, 0.6470],
        [0.6498, 0.6504, 0.6534, 0.6489],
        [0.7967, 0.6756, 0.6568, 0.6645]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:38,267:INFO::its now!!!!!!!!5
2023-12-01 17:02:38,432:INFO::its now!!!!!!!!0
2023-12-01 17:02:38,434:INFO::its now!!!!!!!!3
2023-12-01 17:02:38,478:INFO::its now!!!!!!!!5
2023-12-01 17:02:38,677:INFO::its now!!!!!!!!
2023-12-01 17:02:38,677:INFO::its now!!!!!!!! on 
2023-12-01 17:02:38,730:INFO::its now!!!!!!!!5
2023-12-01 17:02:38,928:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:38,930:INFO::Epoch 00069 | lr 0.00050 | Train_Loss 0.6905 | Train_Classification_Loss 0.7324 | Dmon_Loss -0.0838 | Val_Loss 0.7893 | Search Time(s) 0.4480 | Infer Time(s) 0.2164 | Time(s) 0.6644 
2023-12-01 17:02:39,004:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 1;	34: 1;	35: 3;	36: 2;	37: 2;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:39,005:INFO::Validation loss decreased (0.818758 --> 0.789271).  Saving model ...
2023-12-01 17:02:39,008:INFO::Epoch: 70
tensor([[0.6572, 0.6478, 0.6493, 0.6501],
        [0.6468, 0.6523, 0.6438, 0.6486],
        [0.6509, 0.6537, 0.6565, 0.6521],
        [0.8048, 0.6787, 0.6599, 0.6674]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:39,009:INFO::its now!!!!!!!!5
2023-12-01 17:02:39,225:INFO::its now!!!!!!!!0
2023-12-01 17:02:39,226:INFO::its now!!!!!!!!3
2023-12-01 17:02:39,273:INFO::its now!!!!!!!!5
2023-12-01 17:02:39,452:INFO::its now!!!!!!!!
2023-12-01 17:02:39,453:INFO::its now!!!!!!!! on 
2023-12-01 17:02:39,510:INFO::its now!!!!!!!!5
2023-12-01 17:02:39,654:INFO::Epoch 00070 | lr 0.00050 | Train_Loss 0.7357 | Train_Classification_Loss 0.7728 | Dmon_Loss -0.0741 | Val_Loss 0.8295 | Search Time(s) 0.5023 | Infer Time(s) 0.1466 | Time(s) 0.6490 
2023-12-01 17:02:39,698:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:39,699:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:39,702:INFO::Epoch: 71
tensor([[0.6595, 0.6571, 0.6577, 0.6588],
        [0.6559, 0.6541, 0.6529, 0.6601],
        [0.6623, 0.6630, 0.6582, 0.6613],
        [0.8124, 0.6876, 0.6689, 0.6761]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:39,703:INFO::its now!!!!!!!!5
2023-12-01 17:02:39,858:INFO::its now!!!!!!!!0
2023-12-01 17:02:39,859:INFO::its now!!!!!!!!3
2023-12-01 17:02:39,910:INFO::its now!!!!!!!!5
2023-12-01 17:02:40,091:INFO::its now!!!!!!!!
2023-12-01 17:02:40,091:INFO::its now!!!!!!!! on 
2023-12-01 17:02:40,131:INFO::its now!!!!!!!!5
2023-12-01 17:02:40,295:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:40,296:INFO::Epoch 00071 | lr 0.00050 | Train_Loss 0.6468 | Train_Classification_Loss 0.6906 | Dmon_Loss -0.0875 | Val_Loss 0.7552 | Search Time(s) 0.4284 | Infer Time(s) 0.1671 | Time(s) 0.5955 
2023-12-01 17:02:40,342:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 1;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 1;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:40,344:INFO::Validation loss decreased (0.789271 --> 0.755158).  Saving model ...
2023-12-01 17:02:40,347:INFO::Epoch: 72
tensor([[0.6607, 0.6636, 0.6638, 0.6650],
        [0.6623, 0.6570, 0.6594, 0.6659],
        [0.6707, 0.6678, 0.6610, 0.6678],
        [0.8214, 0.6939, 0.6753, 0.6822]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:40,348:INFO::its now!!!!!!!!5
2023-12-01 17:02:40,524:INFO::its now!!!!!!!!0
2023-12-01 17:02:40,525:INFO::its now!!!!!!!!3
2023-12-01 17:02:40,553:INFO::its now!!!!!!!!5
2023-12-01 17:02:40,727:INFO::its now!!!!!!!!
2023-12-01 17:02:40,727:INFO::its now!!!!!!!! on 
2023-12-01 17:02:40,766:INFO::its now!!!!!!!!5
2023-12-01 17:02:40,928:INFO::Epoch 00072 | lr 0.00050 | Train_Loss 0.6506 | Train_Classification_Loss 0.6945 | Dmon_Loss -0.0878 | Val_Loss 0.7581 | Search Time(s) 0.4199 | Infer Time(s) 0.1646 | Time(s) 0.5844 
2023-12-01 17:02:40,986:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 1;	26106: 1;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:40,988:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:40,992:INFO::Epoch: 73
tensor([[0.6662, 0.6700, 0.6701, 0.6681],
        [0.6687, 0.6618, 0.6657, 0.6690],
        [0.6763, 0.6734, 0.6657, 0.6741],
        [0.8292, 0.7000, 0.6815, 0.6883]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:40,993:INFO::its now!!!!!!!!5
2023-12-01 17:02:41,189:INFO::its now!!!!!!!!0
2023-12-01 17:02:41,189:INFO::its now!!!!!!!!3
2023-12-01 17:02:41,220:INFO::its now!!!!!!!!5
2023-12-01 17:02:41,394:INFO::its now!!!!!!!!
2023-12-01 17:02:41,394:INFO::its now!!!!!!!! on 
2023-12-01 17:02:41,457:INFO::its now!!!!!!!!5
2023-12-01 17:02:41,632:INFO::Epoch 00073 | lr 0.00050 | Train_Loss 0.6681 | Train_Classification_Loss 0.7098 | Dmon_Loss -0.0833 | Val_Loss 0.7722 | Search Time(s) 0.4670 | Infer Time(s) 0.1765 | Time(s) 0.6435 
2023-12-01 17:02:41,701:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 1;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 1;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 1;	26122: 3;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:41,702:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:02:41,705:INFO::Epoch: 74
tensor([[0.6742, 0.6766, 0.6732, 0.6731],
        [0.6754, 0.6678, 0.6722, 0.6706],
        [0.6803, 0.6796, 0.6716, 0.6807],
        [0.8366, 0.7063, 0.6879, 0.6945]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:41,706:INFO::its now!!!!!!!!5
2023-12-01 17:02:41,882:INFO::its now!!!!!!!!0
2023-12-01 17:02:41,883:INFO::its now!!!!!!!!3
2023-12-01 17:02:41,934:INFO::its now!!!!!!!!5
2023-12-01 17:02:42,092:INFO::its now!!!!!!!!
2023-12-01 17:02:42,092:INFO::its now!!!!!!!! on 
2023-12-01 17:02:42,129:INFO::its now!!!!!!!!5
2023-12-01 17:02:42,309:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:42,310:INFO::Epoch 00074 | lr 0.00050 | Train_Loss 0.5938 | Train_Classification_Loss 0.6396 | Dmon_Loss -0.0915 | Val_Loss 0.7182 | Search Time(s) 0.4165 | Infer Time(s) 0.1901 | Time(s) 0.6065 
2023-12-01 17:02:42,374:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 1;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 1;	39: 3;	40: 1;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:42,375:INFO::Validation loss decreased (0.755158 --> 0.718201).  Saving model ...
2023-12-01 17:02:42,379:INFO::Epoch: 75
tensor([[0.6802, 0.6800, 0.6761, 0.6769],
        [0.6796, 0.6721, 0.6767, 0.6732],
        [0.6841, 0.6841, 0.6759, 0.6840],
        [0.8442, 0.7107, 0.6924, 0.6988]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:42,380:INFO::its now!!!!!!!!5
2023-12-01 17:02:42,575:INFO::its now!!!!!!!!0
2023-12-01 17:02:42,576:INFO::its now!!!!!!!!3
2023-12-01 17:02:42,603:INFO::its now!!!!!!!!5
2023-12-01 17:02:42,757:INFO::its now!!!!!!!!
2023-12-01 17:02:42,758:INFO::its now!!!!!!!! on 
2023-12-01 17:02:42,792:INFO::its now!!!!!!!!5
2023-12-01 17:02:42,948:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:42,949:INFO::Epoch 00075 | lr 0.00050 | Train_Loss 0.5892 | Train_Classification_Loss 0.6355 | Dmon_Loss -0.0926 | Val_Loss 0.7061 | Search Time(s) 0.4089 | Infer Time(s) 0.1636 | Time(s) 0.5725 
2023-12-01 17:02:42,994:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:42,995:INFO::Validation loss decreased (0.718201 --> 0.706053).  Saving model ...
2023-12-01 17:02:42,998:INFO::Epoch: 76
tensor([[0.6832, 0.6817, 0.6776, 0.6789],
        [0.6823, 0.6744, 0.6790, 0.6746],
        [0.6870, 0.6863, 0.6781, 0.6857],
        [0.8514, 0.7130, 0.6947, 0.7011]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:42,999:INFO::its now!!!!!!!!5
2023-12-01 17:02:43,159:INFO::its now!!!!!!!!0
2023-12-01 17:02:43,160:INFO::its now!!!!!!!!3
2023-12-01 17:02:43,187:INFO::its now!!!!!!!!5
2023-12-01 17:02:43,370:INFO::its now!!!!!!!!
2023-12-01 17:02:43,370:INFO::its now!!!!!!!! on 
2023-12-01 17:02:43,408:INFO::its now!!!!!!!!5
2023-12-01 17:02:43,563:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:43,565:INFO::Epoch 00076 | lr 0.00050 | Train_Loss 0.5732 | Train_Classification_Loss 0.6209 | Dmon_Loss -0.0953 | Val_Loss 0.6940 | Search Time(s) 0.4041 | Infer Time(s) 0.1626 | Time(s) 0.5666 
2023-12-01 17:02:43,629:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 3;	39: 3;	40: 1;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 1;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:43,630:INFO::Validation loss decreased (0.706053 --> 0.693959).  Saving model ...
2023-12-01 17:02:43,632:INFO::Epoch: 77
tensor([[0.6847, 0.6839, 0.6797, 0.6811],
        [0.6843, 0.6769, 0.6815, 0.6771],
        [0.6894, 0.6888, 0.6805, 0.6879],
        [0.8584, 0.7154, 0.6971, 0.7034]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:43,633:INFO::its now!!!!!!!!5
2023-12-01 17:02:43,781:INFO::its now!!!!!!!!0
2023-12-01 17:02:43,781:INFO::its now!!!!!!!!3
2023-12-01 17:02:43,808:INFO::its now!!!!!!!!5
2023-12-01 17:02:43,980:INFO::its now!!!!!!!!
2023-12-01 17:02:43,980:INFO::its now!!!!!!!! on 
2023-12-01 17:02:44,032:INFO::its now!!!!!!!!5
2023-12-01 17:02:44,162:INFO::Epoch 00077 | lr 0.00050 | Train_Loss 0.6136 | Train_Classification_Loss 0.6586 | Dmon_Loss -0.0900 | Val_Loss 0.7284 | Search Time(s) 0.3815 | Infer Time(s) 0.1506 | Time(s) 0.5321 
2023-12-01 17:02:44,220:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 1;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 2;	26122: 3;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:44,221:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:44,223:INFO::Epoch: 78
tensor([[0.6854, 0.6872, 0.6830, 0.6845],
        [0.6855, 0.6805, 0.6849, 0.6816],
        [0.6918, 0.6923, 0.6841, 0.6912],
        [0.8654, 0.7187, 0.7005, 0.7067]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:44,223:INFO::its now!!!!!!!!5
2023-12-01 17:02:44,399:INFO::its now!!!!!!!!0
2023-12-01 17:02:44,400:INFO::its now!!!!!!!!3
2023-12-01 17:02:44,443:INFO::its now!!!!!!!!5
2023-12-01 17:02:44,673:INFO::its now!!!!!!!!
2023-12-01 17:02:44,673:INFO::its now!!!!!!!! on 
2023-12-01 17:02:44,709:INFO::its now!!!!!!!!5
2023-12-01 17:02:44,900:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:44,902:INFO::Epoch 00078 | lr 0.00050 | Train_Loss 0.5619 | Train_Classification_Loss 0.6103 | Dmon_Loss -0.0968 | Val_Loss 0.6815 | Search Time(s) 0.4837 | Infer Time(s) 0.1955 | Time(s) 0.6792 
2023-12-01 17:02:44,947:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 1;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:44,949:INFO::Validation loss decreased (0.693959 --> 0.681458).  Saving model ...
2023-12-01 17:02:44,951:INFO::Epoch: 79
tensor([[0.6937, 0.6889, 0.6900, 0.6915],
        [0.6865, 0.6879, 0.6918, 0.6909],
        [0.7003, 0.6943, 0.6914, 0.6981],
        [0.8729, 0.7254, 0.7073, 0.7133]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:44,952:INFO::its now!!!!!!!!5
2023-12-01 17:02:45,127:INFO::its now!!!!!!!!0
2023-12-01 17:02:45,128:INFO::its now!!!!!!!!3
2023-12-01 17:02:45,159:INFO::its now!!!!!!!!5
2023-12-01 17:02:45,342:INFO::its now!!!!!!!!
2023-12-01 17:02:45,342:INFO::its now!!!!!!!! on 
2023-12-01 17:02:45,380:INFO::its now!!!!!!!!5
2023-12-01 17:02:45,551:INFO::Epoch 00079 | lr 0.00050 | Train_Loss 0.5613 | Train_Classification_Loss 0.6101 | Dmon_Loss -0.0976 | Val_Loss 0.6841 | Search Time(s) 0.4308 | Infer Time(s) 0.1716 | Time(s) 0.6024 
2023-12-01 17:02:45,596:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 3;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 1;	35: 3;	36: 2;	37: 2;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 1;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:45,597:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:45,599:INFO::Epoch: 80
tensor([[0.6978, 0.6939, 0.6976, 0.6989],
        [0.6912, 0.6957, 0.6954, 0.7010],
        [0.7059, 0.6994, 0.6991, 0.7055],
        [0.8802, 0.7326, 0.7146, 0.7204]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:45,600:INFO::its now!!!!!!!!5
2023-12-01 17:02:45,762:INFO::its now!!!!!!!!0
2023-12-01 17:02:45,763:INFO::its now!!!!!!!!3
2023-12-01 17:02:45,792:INFO::its now!!!!!!!!5
2023-12-01 17:02:45,958:INFO::its now!!!!!!!!
2023-12-01 17:02:45,958:INFO::its now!!!!!!!! on 
2023-12-01 17:02:45,999:INFO::its now!!!!!!!!5
2023-12-01 17:02:46,135:INFO::Epoch 00080 | lr 0.00050 | Train_Loss 0.6027 | Train_Classification_Loss 0.6434 | Dmon_Loss -0.0813 | Val_Loss 0.7231 | Search Time(s) 0.3989 | Infer Time(s) 0.1396 | Time(s) 0.5386 
2023-12-01 17:02:46,177:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 3;	14: 3;	15: 3;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 3;	25: 3;	26: 3;	27: 3;	28: 3;	29: 3;	30: 3;	31: 3;	32: 3;	33: 3;	34: 3;	35: 3;	36: 3;	37: 3;	38: 3;	39: 3;	40: 3;	41: 3;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 3;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 3;	26114: 3;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 3;	26125: 3;	26126: 3;	26127: 3;	
2023-12-01 17:02:46,202:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:02:46,205:INFO::Epoch: 81
tensor([[0.7040, 0.6992, 0.7043, 0.7027],
        [0.6965, 0.7026, 0.7000, 0.7061],
        [0.7101, 0.7050, 0.7059, 0.7120],
        [0.8872, 0.7389, 0.7210, 0.7266]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:46,206:INFO::its now!!!!!!!!5
2023-12-01 17:02:46,392:INFO::its now!!!!!!!!0
2023-12-01 17:02:46,393:INFO::its now!!!!!!!!3
2023-12-01 17:02:46,421:INFO::its now!!!!!!!!5
2023-12-01 17:02:46,600:INFO::its now!!!!!!!!
2023-12-01 17:02:46,600:INFO::its now!!!!!!!! on 
2023-12-01 17:02:46,637:INFO::its now!!!!!!!!5
2023-12-01 17:02:46,826:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:46,828:INFO::Epoch 00081 | lr 0.00050 | Train_Loss 0.5156 | Train_Classification_Loss 0.5664 | Dmon_Loss -0.1016 | Val_Loss 0.6442 | Search Time(s) 0.4328 | Infer Time(s) 0.1895 | Time(s) 0.6223 
2023-12-01 17:02:46,888:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 3;	37: 2;	38: 2;	39: 3;	40: 1;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 1;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:46,889:INFO::Validation loss decreased (0.681458 --> 0.644203).  Saving model ...
2023-12-01 17:02:46,890:INFO::Epoch: 82
tensor([[0.7082, 0.7026, 0.7076, 0.7053],
        [0.6999, 0.7068, 0.7030, 0.7088],
        [0.7131, 0.7085, 0.7100, 0.7152],
        [0.8958, 0.7427, 0.7249, 0.7304]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:46,891:INFO::its now!!!!!!!!5
2023-12-01 17:02:47,073:INFO::its now!!!!!!!!0
2023-12-01 17:02:47,073:INFO::its now!!!!!!!!3
2023-12-01 17:02:47,104:INFO::its now!!!!!!!!5
2023-12-01 17:02:47,281:INFO::its now!!!!!!!!
2023-12-01 17:02:47,281:INFO::its now!!!!!!!! on 
2023-12-01 17:02:47,337:INFO::its now!!!!!!!!5
2023-12-01 17:02:47,501:INFO::Epoch 00082 | lr 0.00050 | Train_Loss 0.5187 | Train_Classification_Loss 0.5701 | Dmon_Loss -0.1027 | Val_Loss 0.6501 | Search Time(s) 0.4279 | Infer Time(s) 0.1835 | Time(s) 0.6114 
2023-12-01 17:02:47,552:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 3;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 1;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 1;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:47,554:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:47,556:INFO::Epoch: 83
tensor([[0.7103, 0.7128, 0.7177, 0.7149],
        [0.7103, 0.7175, 0.7128, 0.7103],
        [0.7256, 0.7188, 0.7206, 0.7170],
        [0.9032, 0.7525, 0.7349, 0.7402]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:47,557:INFO::its now!!!!!!!!5
2023-12-01 17:02:47,755:INFO::its now!!!!!!!!0
2023-12-01 17:02:47,756:INFO::its now!!!!!!!!3
2023-12-01 17:02:47,806:INFO::its now!!!!!!!!5
2023-12-01 17:02:48,005:INFO::its now!!!!!!!!
2023-12-01 17:02:48,005:INFO::its now!!!!!!!! on 
2023-12-01 17:02:48,065:INFO::its now!!!!!!!!5
2023-12-01 17:02:48,274:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:48,275:INFO::Epoch 00083 | lr 0.00050 | Train_Loss 0.4957 | Train_Classification_Loss 0.5483 | Dmon_Loss -0.1052 | Val_Loss 0.6208 | Search Time(s) 0.4947 | Infer Time(s) 0.2254 | Time(s) 0.7201 
2023-12-01 17:02:48,322:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:48,323:INFO::Validation loss decreased (0.644203 --> 0.620808).  Saving model ...
2023-12-01 17:02:48,325:INFO::Epoch: 84
tensor([[0.7146, 0.7199, 0.7228, 0.7218],
        [0.7175, 0.7228, 0.7197, 0.7140],
        [0.7332, 0.7260, 0.7279, 0.7200],
        [0.9102, 0.7594, 0.7419, 0.7470]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:48,326:INFO::its now!!!!!!!!5
2023-12-01 17:02:48,528:INFO::its now!!!!!!!!0
2023-12-01 17:02:48,529:INFO::its now!!!!!!!!3
2023-12-01 17:02:48,575:INFO::its now!!!!!!!!5
2023-12-01 17:02:48,748:INFO::its now!!!!!!!!
2023-12-01 17:02:48,748:INFO::its now!!!!!!!! on 
2023-12-01 17:02:48,805:INFO::its now!!!!!!!!5
2023-12-01 17:02:48,996:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:48,998:INFO::Epoch 00084 | lr 0.00050 | Train_Loss 0.4737 | Train_Classification_Loss 0.5278 | Dmon_Loss -0.1083 | Val_Loss 0.6171 | Search Time(s) 0.4807 | Infer Time(s) 0.1925 | Time(s) 0.6732 
2023-12-01 17:02:49,063:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 1;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 0;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:49,065:INFO::Validation loss decreased (0.620808 --> 0.617068).  Saving model ...
2023-12-01 17:02:49,068:INFO::Epoch: 85
tensor([[0.7174, 0.7239, 0.7253, 0.7256],
        [0.7216, 0.7256, 0.7235, 0.7164],
        [0.7384, 0.7300, 0.7320, 0.7219],
        [0.9171, 0.7632, 0.7457, 0.7508]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:49,069:INFO::its now!!!!!!!!5
2023-12-01 17:02:49,220:INFO::its now!!!!!!!!0
2023-12-01 17:02:49,221:INFO::its now!!!!!!!!3
2023-12-01 17:02:49,268:INFO::its now!!!!!!!!5
2023-12-01 17:02:49,437:INFO::its now!!!!!!!!
2023-12-01 17:02:49,437:INFO::its now!!!!!!!! on 
2023-12-01 17:02:49,474:INFO::its now!!!!!!!!5
2023-12-01 17:02:49,635:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:49,636:INFO::Epoch 00085 | lr 0.00050 | Train_Loss 0.4540 | Train_Classification_Loss 0.5090 | Dmon_Loss -0.1100 | Val_Loss 0.6021 | Search Time(s) 0.4019 | Infer Time(s) 0.1686 | Time(s) 0.5705 
2023-12-01 17:02:49,681:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 1;	39: 3;	40: 1;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:49,682:INFO::Validation loss decreased (0.617068 --> 0.602148).  Saving model ...
2023-12-01 17:02:49,685:INFO::Epoch: 86
tensor([[0.7220, 0.7280, 0.7287, 0.7275],
        [0.7257, 0.7271, 0.7275, 0.7205],
        [0.7423, 0.7342, 0.7362, 0.7250],
        [0.9239, 0.7671, 0.7497, 0.7546]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:49,686:INFO::its now!!!!!!!!5
2023-12-01 17:02:49,906:INFO::its now!!!!!!!!0
2023-12-01 17:02:49,907:INFO::its now!!!!!!!!3
2023-12-01 17:02:49,938:INFO::its now!!!!!!!!5
2023-12-01 17:02:50,174:INFO::its now!!!!!!!!
2023-12-01 17:02:50,174:INFO::its now!!!!!!!! on 
2023-12-01 17:02:50,210:INFO::its now!!!!!!!!5
2023-12-01 17:02:50,397:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:50,399:INFO::Epoch 00086 | lr 0.00050 | Train_Loss 0.4612 | Train_Classification_Loss 0.5169 | Dmon_Loss -0.1113 | Val_Loss 0.6011 | Search Time(s) 0.5196 | Infer Time(s) 0.1955 | Time(s) 0.7151 
2023-12-01 17:02:50,457:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 3;	39: 3;	40: 3;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:50,458:INFO::Validation loss decreased (0.602148 --> 0.601088).  Saving model ...
2023-12-01 17:02:50,461:INFO::Epoch: 87
tensor([[0.7235, 0.7295, 0.7304, 0.7279],
        [0.7272, 0.7273, 0.7296, 0.7219],
        [0.7456, 0.7357, 0.7377, 0.7261],
        [0.9306, 0.7685, 0.7511, 0.7560]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:50,462:INFO::its now!!!!!!!!5
2023-12-01 17:02:50,637:INFO::its now!!!!!!!!0
2023-12-01 17:02:50,638:INFO::its now!!!!!!!!3
2023-12-01 17:02:50,669:INFO::its now!!!!!!!!5
2023-12-01 17:02:50,847:INFO::its now!!!!!!!!
2023-12-01 17:02:50,847:INFO::its now!!!!!!!! on 
2023-12-01 17:02:50,905:INFO::its now!!!!!!!!5
2023-12-01 17:02:51,099:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:51,101:INFO::Epoch 00087 | lr 0.00050 | Train_Loss 0.4363 | Train_Classification_Loss 0.4929 | Dmon_Loss -0.1132 | Val_Loss 0.5862 | Search Time(s) 0.4219 | Infer Time(s) 0.2184 | Time(s) 0.6403 
2023-12-01 17:02:51,157:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 1;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:51,158:INFO::Validation loss decreased (0.601088 --> 0.586232).  Saving model ...
2023-12-01 17:02:51,160:INFO::Epoch: 88
tensor([[0.7269, 0.7320, 0.7312, 0.7299],
        [0.7298, 0.7292, 0.7308, 0.7250],
        [0.7486, 0.7382, 0.7402, 0.7284],
        [0.9370, 0.7709, 0.7535, 0.7584]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:51,161:INFO::its now!!!!!!!!5
2023-12-01 17:02:51,305:INFO::its now!!!!!!!!0
2023-12-01 17:02:51,305:INFO::its now!!!!!!!!3
2023-12-01 17:02:51,351:INFO::its now!!!!!!!!5
2023-12-01 17:02:51,539:INFO::its now!!!!!!!!
2023-12-01 17:02:51,539:INFO::its now!!!!!!!! on 
2023-12-01 17:02:51,576:INFO::its now!!!!!!!!5
2023-12-01 17:02:51,752:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:51,754:INFO::Epoch 00088 | lr 0.00050 | Train_Loss 0.4126 | Train_Classification_Loss 0.4710 | Dmon_Loss -0.1167 | Val_Loss 0.5653 | Search Time(s) 0.4099 | Infer Time(s) 0.1845 | Time(s) 0.5944 
2023-12-01 17:02:51,793:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 1;	39: 3;	40: 1;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:51,794:INFO::Validation loss decreased (0.586232 --> 0.565271).  Saving model ...
2023-12-01 17:02:51,798:INFO::Epoch: 89
tensor([[0.7345, 0.7332, 0.7355, 0.7347],
        [0.7350, 0.7342, 0.7315, 0.7320],
        [0.7514, 0.7434, 0.7454, 0.7336],
        [0.9434, 0.7758, 0.7585, 0.7632]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:51,799:INFO::its now!!!!!!!!5
2023-12-01 17:02:51,966:INFO::its now!!!!!!!!0
2023-12-01 17:02:51,967:INFO::its now!!!!!!!!3
2023-12-01 17:02:52,000:INFO::its now!!!!!!!!5
2023-12-01 17:02:52,205:INFO::its now!!!!!!!!
2023-12-01 17:02:52,205:INFO::its now!!!!!!!! on 
2023-12-01 17:02:52,244:INFO::its now!!!!!!!!5
2023-12-01 17:02:52,412:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:52,414:INFO::Epoch 00089 | lr 0.00050 | Train_Loss 0.4040 | Train_Classification_Loss 0.4628 | Dmon_Loss -0.1177 | Val_Loss 0.5557 | Search Time(s) 0.4408 | Infer Time(s) 0.1766 | Time(s) 0.6174 
2023-12-01 17:02:52,465:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 1;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 3;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 1;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:52,466:INFO::Validation loss decreased (0.565271 --> 0.555733).  Saving model ...
2023-12-01 17:02:52,468:INFO::Epoch: 90
tensor([[0.7400, 0.7350, 0.7377, 0.7382],
        [0.7380, 0.7378, 0.7330, 0.7370],
        [0.7541, 0.7472, 0.7491, 0.7374],
        [0.9498, 0.7793, 0.7620, 0.7667]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:52,469:INFO::its now!!!!!!!!5
2023-12-01 17:02:52,629:INFO::its now!!!!!!!!0
2023-12-01 17:02:52,630:INFO::its now!!!!!!!!3
2023-12-01 17:02:52,657:INFO::its now!!!!!!!!5
2023-12-01 17:02:52,852:INFO::its now!!!!!!!!
2023-12-01 17:02:52,852:INFO::its now!!!!!!!! on 
2023-12-01 17:02:52,890:INFO::its now!!!!!!!!5
2023-12-01 17:02:53,087:INFO::Epoch 00090 | lr 0.00050 | Train_Loss 0.4046 | Train_Classification_Loss 0.4644 | Dmon_Loss -0.1196 | Val_Loss 0.5570 | Search Time(s) 0.4209 | Infer Time(s) 0.1995 | Time(s) 0.6203 
2023-12-01 17:02:53,130:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 1;	35: 3;	36: 2;	37: 1;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:53,131:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:53,135:INFO::Epoch: 91
tensor([[0.7428, 0.7376, 0.7405, 0.7416],
        [0.7397, 0.7414, 0.7354, 0.7420],
        [0.7568, 0.7508, 0.7527, 0.7411],
        [0.9562, 0.7826, 0.7654, 0.7700]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:53,136:INFO::its now!!!!!!!!5
2023-12-01 17:02:53,294:INFO::its now!!!!!!!!0
2023-12-01 17:02:53,295:INFO::its now!!!!!!!!3
2023-12-01 17:02:53,324:INFO::its now!!!!!!!!5
2023-12-01 17:02:53,489:INFO::its now!!!!!!!!
2023-12-01 17:02:53,489:INFO::its now!!!!!!!! on 
2023-12-01 17:02:53,545:INFO::its now!!!!!!!!5
2023-12-01 17:02:53,733:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:53,735:INFO::Epoch 00091 | lr 0.00050 | Train_Loss 0.3942 | Train_Classification_Loss 0.4547 | Dmon_Loss -0.1210 | Val_Loss 0.5488 | Search Time(s) 0.4119 | Infer Time(s) 0.1895 | Time(s) 0.6014 
2023-12-01 17:02:53,779:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 1;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:53,780:INFO::Validation loss decreased (0.555733 --> 0.548820).  Saving model ...
2023-12-01 17:02:53,783:INFO::Epoch: 92
tensor([[0.7442, 0.7412, 0.7442, 0.7456],
        [0.7428, 0.7454, 0.7389, 0.7445],
        [0.7596, 0.7549, 0.7568, 0.7453],
        [0.9625, 0.7864, 0.7693, 0.7738]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:53,783:INFO::its now!!!!!!!!5
2023-12-01 17:02:53,947:INFO::its now!!!!!!!!0
2023-12-01 17:02:53,947:INFO::its now!!!!!!!!3
2023-12-01 17:02:53,996:INFO::its now!!!!!!!!5
2023-12-01 17:02:54,168:INFO::its now!!!!!!!!
2023-12-01 17:02:54,168:INFO::its now!!!!!!!! on 
2023-12-01 17:02:54,207:INFO::its now!!!!!!!!5
2023-12-01 17:02:54,378:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:54,380:INFO::Epoch 00092 | lr 0.00050 | Train_Loss 0.3772 | Train_Classification_Loss 0.4389 | Dmon_Loss -0.1233 | Val_Loss 0.5349 | Search Time(s) 0.4250 | Infer Time(s) 0.1722 | Time(s) 0.5973 
2023-12-01 17:02:54,421:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 1;	39: 3;	40: 1;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:54,422:INFO::Validation loss decreased (0.548820 --> 0.534888).  Saving model ...
2023-12-01 17:02:54,425:INFO::Epoch: 93
tensor([[0.7492, 0.7459, 0.7489, 0.7476],
        [0.7473, 0.7475, 0.7435, 0.7498],
        [0.7626, 0.7598, 0.7617, 0.7503],
        [0.9686, 0.7911, 0.7739, 0.7783]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:54,426:INFO::its now!!!!!!!!5
2023-12-01 17:02:54,608:INFO::its now!!!!!!!!0
2023-12-01 17:02:54,608:INFO::its now!!!!!!!!3
2023-12-01 17:02:54,639:INFO::its now!!!!!!!!5
2023-12-01 17:02:54,815:INFO::its now!!!!!!!!
2023-12-01 17:02:54,816:INFO::its now!!!!!!!! on 
2023-12-01 17:02:54,856:INFO::its now!!!!!!!!5
2023-12-01 17:02:55,075:INFO::Epoch 00093 | lr 0.00050 | Train_Loss 0.4555 | Train_Classification_Loss 0.5071 | Dmon_Loss -0.1032 | Val_Loss 0.5973 | Search Time(s) 0.4308 | Infer Time(s) 0.2224 | Time(s) 0.6532 
2023-12-01 17:02:55,127:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 1;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 3;	31: 3;	32: 3;	33: 2;	34: 3;	35: 3;	36: 3;	37: 2;	38: 3;	39: 3;	40: 3;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 3;	26116: 3;	26117: 3;	26118: 3;	26119: 3;	26120: 3;	26121: 3;	26122: 3;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:55,128:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:55,131:INFO::Epoch: 94
tensor([[0.7517, 0.7498, 0.7528, 0.7502],
        [0.7512, 0.7502, 0.7473, 0.7526],
        [0.7657, 0.7639, 0.7657, 0.7545],
        [0.9747, 0.7949, 0.7778, 0.7821]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:55,132:INFO::its now!!!!!!!!5
2023-12-01 17:02:55,304:INFO::its now!!!!!!!!0
2023-12-01 17:02:55,305:INFO::its now!!!!!!!!3
2023-12-01 17:02:55,337:INFO::its now!!!!!!!!5
2023-12-01 17:02:55,566:INFO::its now!!!!!!!!
2023-12-01 17:02:55,566:INFO::its now!!!!!!!! on 
2023-12-01 17:02:55,599:INFO::its now!!!!!!!!5
2023-12-01 17:02:55,792:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:55,793:INFO::Epoch 00094 | lr 0.00050 | Train_Loss 0.3525 | Train_Classification_Loss 0.4164 | Dmon_Loss -0.1278 | Val_Loss 0.5117 | Search Time(s) 0.4663 | Infer Time(s) 0.1965 | Time(s) 0.6628 
2023-12-01 17:02:55,844:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 1;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:55,846:INFO::Validation loss decreased (0.534888 --> 0.511745).  Saving model ...
2023-12-01 17:02:55,848:INFO::Epoch: 95
tensor([[0.7602, 0.7567, 0.7548, 0.7563],
        [0.7581, 0.7566, 0.7541, 0.7541],
        [0.7736, 0.7708, 0.7679, 0.7617],
        [0.9820, 0.8014, 0.7844, 0.7886]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:55,849:INFO::its now!!!!!!!!5
2023-12-01 17:02:55,998:INFO::its now!!!!!!!!0
2023-12-01 17:02:55,998:INFO::its now!!!!!!!!3
2023-12-01 17:02:56,048:INFO::its now!!!!!!!!5
2023-12-01 17:02:56,201:INFO::its now!!!!!!!!
2023-12-01 17:02:56,201:INFO::its now!!!!!!!! on 
2023-12-01 17:02:56,239:INFO::its now!!!!!!!!5
2023-12-01 17:02:56,411:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:56,413:INFO::Epoch 00095 | lr 0.00050 | Train_Loss 0.3350 | Train_Classification_Loss 0.4000 | Dmon_Loss -0.1300 | Val_Loss 0.5036 | Search Time(s) 0.3827 | Infer Time(s) 0.1821 | Time(s) 0.5647 
2023-12-01 17:02:56,469:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 1;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:56,470:INFO::Validation loss decreased (0.511745 --> 0.503635).  Saving model ...
2023-12-01 17:02:56,472:INFO::Epoch: 96
tensor([[0.7644, 0.7596, 0.7552, 0.7588],
        [0.7610, 0.7600, 0.7570, 0.7540],
        [0.7768, 0.7738, 0.7684, 0.7654],
        [0.9848, 0.8041, 0.7872, 0.7914]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:56,473:INFO::its now!!!!!!!!5
2023-12-01 17:02:56,624:INFO::its now!!!!!!!!0
2023-12-01 17:02:56,625:INFO::its now!!!!!!!!3
2023-12-01 17:02:56,651:INFO::its now!!!!!!!!5
2023-12-01 17:02:56,807:INFO::its now!!!!!!!!
2023-12-01 17:02:56,807:INFO::its now!!!!!!!! on 
2023-12-01 17:02:56,860:INFO::its now!!!!!!!!5
2023-12-01 17:02:57,031:INFO::Epoch 00096 | lr 0.00050 | Train_Loss 0.3458 | Train_Classification_Loss 0.4109 | Dmon_Loss -0.1301 | Val_Loss 0.5091 | Search Time(s) 0.3710 | Infer Time(s) 0.1897 | Time(s) 0.5607 
2023-12-01 17:02:57,098:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:57,099:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:02:57,102:INFO::Epoch: 97
tensor([[0.7665, 0.7627, 0.7570, 0.7616],
        [0.7628, 0.7633, 0.7600, 0.7562],
        [0.7798, 0.7768, 0.7703, 0.7689],
        [0.9891, 0.8070, 0.7901, 0.7942]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:57,103:INFO::its now!!!!!!!!5
2023-12-01 17:02:57,287:INFO::its now!!!!!!!!0
2023-12-01 17:02:57,287:INFO::its now!!!!!!!!3
2023-12-01 17:02:57,331:INFO::its now!!!!!!!!5
2023-12-01 17:02:57,526:INFO::its now!!!!!!!!
2023-12-01 17:02:57,527:INFO::its now!!!!!!!! on 
2023-12-01 17:02:57,577:INFO::its now!!!!!!!!5
2023-12-01 17:02:57,758:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:57,760:INFO::Epoch 00097 | lr 0.00050 | Train_Loss 0.3319 | Train_Classification_Loss 0.3980 | Dmon_Loss -0.1323 | Val_Loss 0.4987 | Search Time(s) 0.4604 | Infer Time(s) 0.1985 | Time(s) 0.6589 
2023-12-01 17:02:57,822:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 1;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 1;	26126: 3;	26127: 3;	
2023-12-01 17:02:57,823:INFO::Validation loss decreased (0.503635 --> 0.498672).  Saving model ...
2023-12-01 17:02:57,826:INFO::Epoch: 98
tensor([[0.7676, 0.7631, 0.7569, 0.7620],
        [0.7626, 0.7651, 0.7604, 0.7558],
        [0.7828, 0.7773, 0.7701, 0.7695],
        [0.9941, 0.8074, 0.7905, 0.7947]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:57,826:INFO::its now!!!!!!!!5
2023-12-01 17:02:57,978:INFO::its now!!!!!!!!0
2023-12-01 17:02:57,979:INFO::its now!!!!!!!!3
2023-12-01 17:02:58,025:INFO::its now!!!!!!!!5
2023-12-01 17:02:58,192:INFO::its now!!!!!!!!
2023-12-01 17:02:58,192:INFO::its now!!!!!!!! on 
2023-12-01 17:02:58,245:INFO::its now!!!!!!!!5
2023-12-01 17:02:58,408:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:58,410:INFO::Epoch 00098 | lr 0.00050 | Train_Loss 0.3123 | Train_Classification_Loss 0.3798 | Dmon_Loss -0.1349 | Val_Loss 0.4893 | Search Time(s) 0.4065 | Infer Time(s) 0.1791 | Time(s) 0.5856 
2023-12-01 17:02:58,454:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:58,454:INFO::Validation loss decreased (0.498672 --> 0.489317).  Saving model ...
2023-12-01 17:02:58,457:INFO::Epoch: 99
tensor([[0.7681, 0.7638, 0.7573, 0.7627],
        [0.7630, 0.7660, 0.7611, 0.7563],
        [0.7858, 0.7780, 0.7705, 0.7703],
        [0.9996, 0.8081, 0.7912, 0.7953]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:58,458:INFO::its now!!!!!!!!5
2023-12-01 17:02:58,646:INFO::its now!!!!!!!!0
2023-12-01 17:02:58,647:INFO::its now!!!!!!!!3
2023-12-01 17:02:58,694:INFO::its now!!!!!!!!5
2023-12-01 17:02:58,858:INFO::its now!!!!!!!!
2023-12-01 17:02:58,859:INFO::its now!!!!!!!! on 
2023-12-01 17:02:58,913:INFO::its now!!!!!!!!5
2023-12-01 17:02:59,068:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:59,069:INFO::Epoch 00099 | lr 0.00050 | Train_Loss 0.3049 | Train_Classification_Loss 0.3732 | Dmon_Loss -0.1366 | Val_Loss 0.4797 | Search Time(s) 0.4348 | Infer Time(s) 0.1775 | Time(s) 0.6124 
2023-12-01 17:02:59,134:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 3;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 1;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:59,135:INFO::Validation loss decreased (0.489317 --> 0.479661).  Saving model ...
2023-12-01 17:02:59,138:INFO::Epoch: 100
tensor([[0.7684, 0.7630, 0.7562, 0.7618],
        [0.7619, 0.7666, 0.7602, 0.7548],
        [0.7888, 0.7771, 0.7695, 0.7695],
        [1.0000, 0.8073, 0.7904, 0.7945]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:59,139:INFO::its now!!!!!!!!5
2023-12-01 17:02:59,309:INFO::its now!!!!!!!!0
2023-12-01 17:02:59,310:INFO::its now!!!!!!!!3
2023-12-01 17:02:59,352:INFO::its now!!!!!!!!5
2023-12-01 17:02:59,511:INFO::its now!!!!!!!!
2023-12-01 17:02:59,511:INFO::its now!!!!!!!! on 
2023-12-01 17:02:59,562:INFO::its now!!!!!!!!5
2023-12-01 17:02:59,755:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:02:59,756:INFO::Epoch 00100 | lr 0.00050 | Train_Loss 0.2974 | Train_Classification_Loss 0.3664 | Dmon_Loss -0.1380 | Val_Loss 0.4741 | Search Time(s) 0.4081 | Infer Time(s) 0.2124 | Time(s) 0.6205 
2023-12-01 17:02:59,801:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 1;	41: 1;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 3;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:02:59,802:INFO::Validation loss decreased (0.479661 --> 0.474081).  Saving model ...
2023-12-01 17:02:59,817:INFO::Epoch: 101
tensor([[0.7685, 0.7629, 0.7561, 0.7617],
        [0.7618, 0.7669, 0.7602, 0.7546],
        [0.7917, 0.7771, 0.7694, 0.7695],
        [1.0000, 0.8073, 0.7904, 0.7945]], device='cuda:0', requires_grad=True)
2023-12-01 17:02:59,818:INFO::its now!!!!!!!!5
2023-12-01 17:02:59,980:INFO::its now!!!!!!!!0
2023-12-01 17:02:59,981:INFO::its now!!!!!!!!3
2023-12-01 17:03:00,027:INFO::its now!!!!!!!!5
2023-12-01 17:03:00,186:INFO::its now!!!!!!!!
2023-12-01 17:03:00,186:INFO::its now!!!!!!!! on 
2023-12-01 17:03:00,242:INFO::its now!!!!!!!!5
2023-12-01 17:03:00,430:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:00,432:INFO::Epoch 00101 | lr 0.00050 | Train_Loss 0.2898 | Train_Classification_Loss 0.3597 | Dmon_Loss -0.1398 | Val_Loss 0.4624 | Search Time(s) 0.4125 | Infer Time(s) 0.2140 | Time(s) 0.6265 
2023-12-01 17:03:00,477:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 1;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:00,478:INFO::Validation loss decreased (0.474081 --> 0.462357).  Saving model ...
2023-12-01 17:03:00,480:INFO::Epoch: 102
tensor([[0.7686, 0.7611, 0.7542, 0.7599],
        [0.7599, 0.7671, 0.7584, 0.7520],
        [0.7946, 0.7752, 0.7674, 0.7676],
        [1.0000, 0.8055, 0.7886, 0.7928]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:00,481:INFO::its now!!!!!!!!5
2023-12-01 17:03:00,646:INFO::its now!!!!!!!!0
2023-12-01 17:03:00,647:INFO::its now!!!!!!!!3
2023-12-01 17:03:00,692:INFO::its now!!!!!!!!5
2023-12-01 17:03:00,866:INFO::its now!!!!!!!!
2023-12-01 17:03:00,866:INFO::its now!!!!!!!! on 
2023-12-01 17:03:00,920:INFO::its now!!!!!!!!5
2023-12-01 17:03:01,128:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:01,130:INFO::Epoch 00102 | lr 0.00050 | Train_Loss 0.2711 | Train_Classification_Loss 0.3428 | Dmon_Loss -0.1433 | Val_Loss 0.4559 | Search Time(s) 0.4249 | Infer Time(s) 0.2259 | Time(s) 0.6508 
2023-12-01 17:03:01,195:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:01,196:INFO::Validation loss decreased (0.462357 --> 0.455894).  Saving model ...
2023-12-01 17:03:01,199:INFO::Epoch: 103
tensor([[0.7686, 0.7616, 0.7547, 0.7605],
        [0.7604, 0.7672, 0.7589, 0.7527],
        [0.7978, 0.7758, 0.7680, 0.7682],
        [1.0000, 0.8060, 0.7891, 0.7933]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:01,200:INFO::its now!!!!!!!!5
2023-12-01 17:03:01,397:INFO::its now!!!!!!!!0
2023-12-01 17:03:01,398:INFO::its now!!!!!!!!3
2023-12-01 17:03:01,450:INFO::its now!!!!!!!!5
2023-12-01 17:03:01,642:INFO::its now!!!!!!!!
2023-12-01 17:03:01,642:INFO::its now!!!!!!!! on 
2023-12-01 17:03:01,695:INFO::its now!!!!!!!!5
2023-12-01 17:03:01,875:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:01,877:INFO::Epoch 00103 | lr 0.00050 | Train_Loss 0.2670 | Train_Classification_Loss 0.3389 | Dmon_Loss -0.1439 | Val_Loss 0.4485 | Search Time(s) 0.4783 | Infer Time(s) 0.2005 | Time(s) 0.6788 
2023-12-01 17:03:01,915:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 3;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:01,916:INFO::Validation loss decreased (0.455894 --> 0.448537).  Saving model ...
2023-12-01 17:03:01,918:INFO::Epoch: 104
tensor([[0.7686, 0.7606, 0.7537, 0.7594],
        [0.7594, 0.7673, 0.7579, 0.7513],
        [0.8009, 0.7747, 0.7669, 0.7671],
        [1.0000, 0.8051, 0.7881, 0.7923]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:01,918:INFO::its now!!!!!!!!5
2023-12-01 17:03:02,107:INFO::its now!!!!!!!!0
2023-12-01 17:03:02,108:INFO::its now!!!!!!!!3
2023-12-01 17:03:02,151:INFO::its now!!!!!!!!5
2023-12-01 17:03:02,335:INFO::its now!!!!!!!!
2023-12-01 17:03:02,335:INFO::its now!!!!!!!! on 
2023-12-01 17:03:02,388:INFO::its now!!!!!!!!5
2023-12-01 17:03:02,556:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:02,567:INFO::Epoch 00104 | lr 0.00050 | Train_Loss 0.2540 | Train_Classification_Loss 0.3272 | Dmon_Loss -0.1464 | Val_Loss 0.4426 | Search Time(s) 0.4555 | Infer Time(s) 0.1845 | Time(s) 0.6400 
2023-12-01 17:03:02,617:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:02,618:INFO::Validation loss decreased (0.448537 --> 0.442624).  Saving model ...
2023-12-01 17:03:02,621:INFO::Epoch: 105
tensor([[0.7686, 0.7604, 0.7535, 0.7593],
        [0.7592, 0.7674, 0.7578, 0.7511],
        [0.8041, 0.7746, 0.7668, 0.7670],
        [1.0000, 0.8049, 0.7880, 0.7922]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:02,622:INFO::its now!!!!!!!!5
2023-12-01 17:03:02,789:INFO::its now!!!!!!!!0
2023-12-01 17:03:02,790:INFO::its now!!!!!!!!3
2023-12-01 17:03:02,835:INFO::its now!!!!!!!!5
2023-12-01 17:03:03,000:INFO::its now!!!!!!!!
2023-12-01 17:03:03,001:INFO::its now!!!!!!!! on 
2023-12-01 17:03:03,054:INFO::its now!!!!!!!!5
2023-12-01 17:03:03,202:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:03,203:INFO::Epoch 00105 | lr 0.00050 | Train_Loss 0.2445 | Train_Classification_Loss 0.3184 | Dmon_Loss -0.1479 | Val_Loss 0.4397 | Search Time(s) 0.4159 | Infer Time(s) 0.1681 | Time(s) 0.5840 
2023-12-01 17:03:03,248:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:03,250:INFO::Validation loss decreased (0.442624 --> 0.439701).  Saving model ...
2023-12-01 17:03:03,253:INFO::Epoch: 106
tensor([[0.7686, 0.7621, 0.7552, 0.7610],
        [0.7610, 0.7674, 0.7594, 0.7534],
        [0.8072, 0.7763, 0.7685, 0.7687],
        [1.0000, 0.8065, 0.7896, 0.7938]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:03,254:INFO::its now!!!!!!!!5
2023-12-01 17:03:03,415:INFO::its now!!!!!!!!0
2023-12-01 17:03:03,416:INFO::its now!!!!!!!!3
2023-12-01 17:03:03,468:INFO::its now!!!!!!!!5
2023-12-01 17:03:03,632:INFO::its now!!!!!!!!
2023-12-01 17:03:03,632:INFO::its now!!!!!!!! on 
2023-12-01 17:03:03,683:INFO::its now!!!!!!!!5
2023-12-01 17:03:03,868:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:03,870:INFO::Epoch 00106 | lr 0.00050 | Train_Loss 0.2343 | Train_Classification_Loss 0.3099 | Dmon_Loss -0.1512 | Val_Loss 0.4294 | Search Time(s) 0.4135 | Infer Time(s) 0.2045 | Time(s) 0.6180 
2023-12-01 17:03:03,923:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:03,924:INFO::Validation loss decreased (0.439701 --> 0.429370).  Saving model ...
2023-12-01 17:03:03,926:INFO::Epoch: 107
tensor([[0.7686, 0.7623, 0.7554, 0.7611],
        [0.7611, 0.7675, 0.7596, 0.7537],
        [0.8104, 0.7765, 0.7687, 0.7689],
        [1.0000, 0.8067, 0.7898, 0.7940]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:03,927:INFO::its now!!!!!!!!5
2023-12-01 17:03:04,087:INFO::its now!!!!!!!!0
2023-12-01 17:03:04,088:INFO::its now!!!!!!!!3
2023-12-01 17:03:04,133:INFO::its now!!!!!!!!5
2023-12-01 17:03:04,311:INFO::its now!!!!!!!!
2023-12-01 17:03:04,311:INFO::its now!!!!!!!! on 
2023-12-01 17:03:04,364:INFO::its now!!!!!!!!5
2023-12-01 17:03:04,534:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:04,536:INFO::Epoch 00107 | lr 0.00050 | Train_Loss 0.2288 | Train_Classification_Loss 0.3058 | Dmon_Loss -0.1540 | Val_Loss 0.4245 | Search Time(s) 0.4190 | Infer Time(s) 0.1905 | Time(s) 0.6095 
2023-12-01 17:03:04,589:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:04,591:INFO::Validation loss decreased (0.429370 --> 0.424547).  Saving model ...
2023-12-01 17:03:04,594:INFO::Epoch: 108
tensor([[0.7686, 0.7637, 0.7568, 0.7625],
        [0.7625, 0.7675, 0.7610, 0.7556],
        [0.8136, 0.7779, 0.7701, 0.7703],
        [1.0000, 0.8080, 0.7911, 0.7953]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:04,595:INFO::its now!!!!!!!!5
2023-12-01 17:03:04,755:INFO::its now!!!!!!!!0
2023-12-01 17:03:04,755:INFO::its now!!!!!!!!3
2023-12-01 17:03:04,800:INFO::its now!!!!!!!!5
2023-12-01 17:03:04,984:INFO::its now!!!!!!!!
2023-12-01 17:03:04,984:INFO::its now!!!!!!!! on 
2023-12-01 17:03:05,041:INFO::its now!!!!!!!!5
2023-12-01 17:03:05,205:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:05,206:INFO::Epoch 00108 | lr 0.00050 | Train_Loss 0.2207 | Train_Classification_Loss 0.2985 | Dmon_Loss -0.1557 | Val_Loss 0.4165 | Search Time(s) 0.4458 | Infer Time(s) 0.1681 | Time(s) 0.6139 
2023-12-01 17:03:05,256:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 1;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:05,257:INFO::Validation loss decreased (0.424547 --> 0.416470).  Saving model ...
2023-12-01 17:03:05,259:INFO::Epoch: 109
tensor([[0.7615, 0.7595, 0.7526, 0.7632],
        [0.7583, 0.7675, 0.7568, 0.7498],
        [0.8090, 0.7787, 0.7658, 0.7660],
        [0.9960, 0.8077, 0.7871, 0.7913]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:05,260:INFO::its now!!!!!!!!5
2023-12-01 17:03:05,432:INFO::its now!!!!!!!!0
2023-12-01 17:03:05,432:INFO::its now!!!!!!!!3
2023-12-01 17:03:05,481:INFO::its now!!!!!!!!5
2023-12-01 17:03:05,634:INFO::its now!!!!!!!!
2023-12-01 17:03:05,634:INFO::its now!!!!!!!! on 
2023-12-01 17:03:05,693:INFO::its now!!!!!!!!5
2023-12-01 17:03:05,850:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:05,851:INFO::Epoch 00109 | lr 0.00050 | Train_Loss 0.2115 | Train_Classification_Loss 0.2901 | Dmon_Loss -0.1572 | Val_Loss 0.4141 | Search Time(s) 0.4334 | Infer Time(s) 0.1596 | Time(s) 0.5929 
2023-12-01 17:03:05,891:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:05,892:INFO::Validation loss decreased (0.416470 --> 0.414102).  Saving model ...
2023-12-01 17:03:05,895:INFO::Epoch: 110
tensor([[0.7574, 0.7570, 0.7501, 0.7635],
        [0.7558, 0.7675, 0.7544, 0.7465],
        [0.8081, 0.7788, 0.7633, 0.7635],
        [0.9965, 0.8072, 0.7847, 0.7890]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:05,896:INFO::its now!!!!!!!!5
2023-12-01 17:03:06,095:INFO::its now!!!!!!!!0
2023-12-01 17:03:06,096:INFO::its now!!!!!!!!3
2023-12-01 17:03:06,142:INFO::its now!!!!!!!!5
2023-12-01 17:03:06,314:INFO::its now!!!!!!!!
2023-12-01 17:03:06,314:INFO::its now!!!!!!!! on 
2023-12-01 17:03:06,368:INFO::its now!!!!!!!!5
2023-12-01 17:03:06,535:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:06,537:INFO::Epoch 00110 | lr 0.00050 | Train_Loss 0.1995 | Train_Classification_Loss 0.2802 | Dmon_Loss -0.1614 | Val_Loss 0.4064 | Search Time(s) 0.4738 | Infer Time(s) 0.1685 | Time(s) 0.6424 
2023-12-01 17:03:06,600:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:06,601:INFO::Validation loss decreased (0.414102 --> 0.406400).  Saving model ...
2023-12-01 17:03:06,603:INFO::Epoch: 111
tensor([[0.7534, 0.7545, 0.7475, 0.7637],
        [0.7532, 0.7675, 0.7519, 0.7430],
        [0.8093, 0.7774, 0.7607, 0.7608],
        [0.9993, 0.8056, 0.7823, 0.7866]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:06,604:INFO::its now!!!!!!!!5
2023-12-01 17:03:06,830:INFO::its now!!!!!!!!0
2023-12-01 17:03:06,831:INFO::its now!!!!!!!!3
2023-12-01 17:03:06,876:INFO::its now!!!!!!!!5
2023-12-01 17:03:07,041:INFO::its now!!!!!!!!
2023-12-01 17:03:07,041:INFO::its now!!!!!!!! on 
2023-12-01 17:03:07,095:INFO::its now!!!!!!!!5
2023-12-01 17:03:07,260:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:07,262:INFO::Epoch 00111 | lr 0.00050 | Train_Loss 0.1984 | Train_Classification_Loss 0.2799 | Dmon_Loss -0.1628 | Val_Loss 0.4010 | Search Time(s) 0.4907 | Infer Time(s) 0.1683 | Time(s) 0.6590 
2023-12-01 17:03:07,313:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:07,314:INFO::Validation loss decreased (0.406400 --> 0.401012).  Saving model ...
2023-12-01 17:03:07,317:INFO::Epoch: 112
tensor([[0.7517, 0.7533, 0.7463, 0.7638],
        [0.7520, 0.7675, 0.7507, 0.7414],
        [0.8114, 0.7769, 0.7595, 0.7597],
        [1.0000, 0.8050, 0.7812, 0.7855]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:07,318:INFO::its now!!!!!!!!5
2023-12-01 17:03:07,469:INFO::its now!!!!!!!!0
2023-12-01 17:03:07,469:INFO::its now!!!!!!!!3
2023-12-01 17:03:07,513:INFO::its now!!!!!!!!5
2023-12-01 17:03:07,673:INFO::its now!!!!!!!!
2023-12-01 17:03:07,673:INFO::its now!!!!!!!! on 
2023-12-01 17:03:07,727:INFO::its now!!!!!!!!5
2023-12-01 17:03:07,909:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:07,911:INFO::Epoch 00112 | lr 0.00050 | Train_Loss 0.1894 | Train_Classification_Loss 0.2714 | Dmon_Loss -0.1639 | Val_Loss 0.3971 | Search Time(s) 0.4099 | Infer Time(s) 0.1844 | Time(s) 0.5943 
2023-12-01 17:03:07,952:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:07,953:INFO::Validation loss decreased (0.401012 --> 0.397149).  Saving model ...
2023-12-01 17:03:07,955:INFO::Epoch: 113
tensor([[0.7518, 0.7535, 0.7465, 0.7638],
        [0.7522, 0.7675, 0.7509, 0.7416],
        [0.8140, 0.7774, 0.7597, 0.7598],
        [1.0000, 0.8054, 0.7813, 0.7857]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:07,956:INFO::its now!!!!!!!!5
2023-12-01 17:03:08,141:INFO::its now!!!!!!!!0
2023-12-01 17:03:08,142:INFO::its now!!!!!!!!3
2023-12-01 17:03:08,188:INFO::its now!!!!!!!!5
2023-12-01 17:03:08,372:INFO::its now!!!!!!!!
2023-12-01 17:03:08,372:INFO::its now!!!!!!!! on 
2023-12-01 17:03:08,426:INFO::its now!!!!!!!!5
2023-12-01 17:03:08,562:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:08,564:INFO::Epoch 00113 | lr 0.00050 | Train_Loss 0.1881 | Train_Classification_Loss 0.2712 | Dmon_Loss -0.1660 | Val_Loss 0.3923 | Search Time(s) 0.4698 | Infer Time(s) 0.1386 | Time(s) 0.6085 
2023-12-01 17:03:08,611:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:08,612:INFO::Validation loss decreased (0.397149 --> 0.392347).  Saving model ...
2023-12-01 17:03:08,615:INFO::Epoch: 114
tensor([[0.7504, 0.7525, 0.7455, 0.7639],
        [0.7512, 0.7674, 0.7499, 0.7403],
        [0.8167, 0.7766, 0.7587, 0.7588],
        [1.0000, 0.8046, 0.7804, 0.7848]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:08,616:INFO::its now!!!!!!!!5
2023-12-01 17:03:08,793:INFO::its now!!!!!!!!0
2023-12-01 17:03:08,793:INFO::its now!!!!!!!!3
2023-12-01 17:03:08,839:INFO::its now!!!!!!!!5
2023-12-01 17:03:09,030:INFO::its now!!!!!!!!
2023-12-01 17:03:09,030:INFO::its now!!!!!!!! on 
2023-12-01 17:03:09,083:INFO::its now!!!!!!!!5
2023-12-01 17:03:09,255:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:09,257:INFO::Epoch 00114 | lr 0.00050 | Train_Loss 0.1712 | Train_Classification_Loss 0.2558 | Dmon_Loss -0.1691 | Val_Loss 0.3854 | Search Time(s) 0.4687 | Infer Time(s) 0.1747 | Time(s) 0.6434 
2023-12-01 17:03:09,301:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:09,302:INFO::Validation loss decreased (0.392347 --> 0.385370).  Saving model ...
2023-12-01 17:03:09,305:INFO::Epoch: 115
tensor([[0.7496, 0.7520, 0.7450, 0.7639],
        [0.7507, 0.7674, 0.7494, 0.7396],
        [0.8196, 0.7761, 0.7582, 0.7583],
        [1.0000, 0.8041, 0.7799, 0.7843]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:09,306:INFO::its now!!!!!!!!5
2023-12-01 17:03:09,498:INFO::its now!!!!!!!!0
2023-12-01 17:03:09,499:INFO::its now!!!!!!!!3
2023-12-01 17:03:09,548:INFO::its now!!!!!!!!5
2023-12-01 17:03:09,730:INFO::its now!!!!!!!!
2023-12-01 17:03:09,731:INFO::its now!!!!!!!! on 
2023-12-01 17:03:09,790:INFO::its now!!!!!!!!5
2023-12-01 17:03:09,954:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:09,956:INFO::Epoch 00115 | lr 0.00050 | Train_Loss 0.1604 | Train_Classification_Loss 0.2454 | Dmon_Loss -0.1701 | Val_Loss 0.3826 | Search Time(s) 0.4857 | Infer Time(s) 0.1656 | Time(s) 0.6513 
2023-12-01 17:03:09,996:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:09,997:INFO::Validation loss decreased (0.385370 --> 0.382612).  Saving model ...
2023-12-01 17:03:09,999:INFO::Epoch: 116
tensor([[0.7480, 0.7509, 0.7439, 0.7639],
        [0.7496, 0.7673, 0.7484, 0.7381],
        [0.8225, 0.7750, 0.7571, 0.7572],
        [1.0000, 0.8031, 0.7789, 0.7833]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:10,000:INFO::its now!!!!!!!!5
2023-12-01 17:03:10,153:INFO::its now!!!!!!!!0
2023-12-01 17:03:10,154:INFO::its now!!!!!!!!3
2023-12-01 17:03:10,199:INFO::its now!!!!!!!!5
2023-12-01 17:03:10,392:INFO::its now!!!!!!!!
2023-12-01 17:03:10,392:INFO::its now!!!!!!!! on 
2023-12-01 17:03:10,461:INFO::its now!!!!!!!!5
2023-12-01 17:03:10,627:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:10,628:INFO::Epoch 00116 | lr 0.00050 | Train_Loss 0.1637 | Train_Classification_Loss 0.2496 | Dmon_Loss -0.1718 | Val_Loss 0.3774 | Search Time(s) 0.4638 | Infer Time(s) 0.1666 | Time(s) 0.6304 
2023-12-01 17:03:10,666:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:10,667:INFO::Validation loss decreased (0.382612 --> 0.377414).  Saving model ...
2023-12-01 17:03:10,670:INFO::Epoch: 117
tensor([[0.7460, 0.7495, 0.7424, 0.7639],
        [0.7481, 0.7673, 0.7469, 0.7362],
        [0.8253, 0.7736, 0.7556, 0.7557],
        [1.0000, 0.8018, 0.7775, 0.7819]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:10,671:INFO::its now!!!!!!!!5
2023-12-01 17:03:10,825:INFO::its now!!!!!!!!0
2023-12-01 17:03:10,826:INFO::its now!!!!!!!!3
2023-12-01 17:03:10,873:INFO::its now!!!!!!!!5
2023-12-01 17:03:11,066:INFO::its now!!!!!!!!
2023-12-01 17:03:11,066:INFO::its now!!!!!!!! on 
2023-12-01 17:03:11,120:INFO::its now!!!!!!!!5
2023-12-01 17:03:11,313:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:11,314:INFO::Epoch 00117 | lr 0.00050 | Train_Loss 0.1553 | Train_Classification_Loss 0.2428 | Dmon_Loss -0.1750 | Val_Loss 0.3716 | Search Time(s) 0.4524 | Infer Time(s) 0.1940 | Time(s) 0.6464 
2023-12-01 17:03:11,361:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 1;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:11,363:INFO::Validation loss decreased (0.377414 --> 0.371565).  Saving model ...
2023-12-01 17:03:11,365:INFO::Epoch: 118
tensor([[0.7415, 0.7463, 0.7393, 0.7639],
        [0.7450, 0.7673, 0.7439, 0.7319],
        [0.8280, 0.7704, 0.7524, 0.7525],
        [1.0000, 0.7988, 0.7746, 0.7790]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:11,366:INFO::its now!!!!!!!!5
2023-12-01 17:03:11,546:INFO::its now!!!!!!!!0
2023-12-01 17:03:11,547:INFO::its now!!!!!!!!3
2023-12-01 17:03:11,592:INFO::its now!!!!!!!!5
2023-12-01 17:03:11,749:INFO::its now!!!!!!!!
2023-12-01 17:03:11,750:INFO::its now!!!!!!!! on 
2023-12-01 17:03:11,805:INFO::its now!!!!!!!!5
2023-12-01 17:03:11,959:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:11,960:INFO::Epoch 00118 | lr 0.00050 | Train_Loss 0.1474 | Train_Classification_Loss 0.2351 | Dmon_Loss -0.1753 | Val_Loss 0.3689 | Search Time(s) 0.4383 | Infer Time(s) 0.1576 | Time(s) 0.5958 
2023-12-01 17:03:12,018:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 3;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:12,019:INFO::Validation loss decreased (0.371565 --> 0.368941).  Saving model ...
2023-12-01 17:03:12,023:INFO::Epoch: 119
tensor([[0.7416, 0.7464, 0.7393, 0.7639],
        [0.7451, 0.7672, 0.7439, 0.7321],
        [0.8308, 0.7705, 0.7525, 0.7526],
        [1.0000, 0.7989, 0.7746, 0.7791]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:12,024:INFO::its now!!!!!!!!5
2023-12-01 17:03:12,267:INFO::its now!!!!!!!!0
2023-12-01 17:03:12,268:INFO::its now!!!!!!!!3
2023-12-01 17:03:12,315:INFO::its now!!!!!!!!5
2023-12-01 17:03:12,520:INFO::its now!!!!!!!!
2023-12-01 17:03:12,520:INFO::its now!!!!!!!! on 
2023-12-01 17:03:12,573:INFO::its now!!!!!!!!5
2023-12-01 17:03:12,758:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:12,760:INFO::Epoch 00119 | lr 0.00050 | Train_Loss 0.1393 | Train_Classification_Loss 0.2285 | Dmon_Loss -0.1783 | Val_Loss 0.3630 | Search Time(s) 0.5496 | Infer Time(s) 0.1885 | Time(s) 0.7381 
2023-12-01 17:03:12,806:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:12,807:INFO::Validation loss decreased (0.368941 --> 0.363002).  Saving model ...
2023-12-01 17:03:12,810:INFO::Epoch: 120
tensor([[0.7421, 0.7468, 0.7397, 0.7639],
        [0.7454, 0.7672, 0.7443, 0.7325],
        [0.8335, 0.7709, 0.7529, 0.7529],
        [1.0000, 0.7992, 0.7750, 0.7794]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:12,810:INFO::its now!!!!!!!!5
2023-12-01 17:03:12,973:INFO::its now!!!!!!!!0
2023-12-01 17:03:12,973:INFO::its now!!!!!!!!3
2023-12-01 17:03:13,020:INFO::its now!!!!!!!!5
2023-12-01 17:03:13,184:INFO::its now!!!!!!!!
2023-12-01 17:03:13,184:INFO::its now!!!!!!!! on 
2023-12-01 17:03:13,241:INFO::its now!!!!!!!!5
2023-12-01 17:03:13,402:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:13,403:INFO::Epoch 00120 | lr 0.00050 | Train_Loss 0.1323 | Train_Classification_Loss 0.2222 | Dmon_Loss -0.1798 | Val_Loss 0.3603 | Search Time(s) 0.4322 | Infer Time(s) 0.1631 | Time(s) 0.5954 
2023-12-01 17:03:13,460:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:13,461:INFO::Validation loss decreased (0.363002 --> 0.360286).  Saving model ...
2023-12-01 17:03:13,464:INFO::Epoch: 121
tensor([[0.7436, 0.7478, 0.7408, 0.7639],
        [0.7465, 0.7671, 0.7453, 0.7340],
        [0.8364, 0.7720, 0.7540, 0.7540],
        [1.0000, 0.8002, 0.7760, 0.7804]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:13,465:INFO::its now!!!!!!!!5
2023-12-01 17:03:13,637:INFO::its now!!!!!!!!0
2023-12-01 17:03:13,638:INFO::its now!!!!!!!!3
2023-12-01 17:03:13,685:INFO::its now!!!!!!!!5
2023-12-01 17:03:13,968:INFO::its now!!!!!!!!
2023-12-01 17:03:13,968:INFO::its now!!!!!!!! on 
2023-12-01 17:03:14,027:INFO::its now!!!!!!!!5
2023-12-01 17:03:14,274:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:14,276:INFO::Epoch 00121 | lr 0.00050 | Train_Loss 0.1283 | Train_Classification_Loss 0.2195 | Dmon_Loss -0.1824 | Val_Loss 0.3560 | Search Time(s) 0.5645 | Infer Time(s) 0.2473 | Time(s) 0.8118 
2023-12-01 17:03:14,359:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:14,361:INFO::Validation loss decreased (0.360286 --> 0.355985).  Saving model ...
2023-12-01 17:03:14,364:INFO::Epoch: 122
tensor([[0.7426, 0.7472, 0.7401, 0.7639],
        [0.7458, 0.7671, 0.7447, 0.7331],
        [0.8392, 0.7713, 0.7533, 0.7533],
        [1.0000, 0.7996, 0.7753, 0.7798]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:14,365:INFO::its now!!!!!!!!5
2023-12-01 17:03:14,588:INFO::its now!!!!!!!!0
2023-12-01 17:03:14,589:INFO::its now!!!!!!!!3
2023-12-01 17:03:14,635:INFO::its now!!!!!!!!5
2023-12-01 17:03:14,818:INFO::its now!!!!!!!!
2023-12-01 17:03:14,818:INFO::its now!!!!!!!! on 
2023-12-01 17:03:14,873:INFO::its now!!!!!!!!5
2023-12-01 17:03:15,028:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:15,029:INFO::Epoch 00122 | lr 0.00050 | Train_Loss 0.1196 | Train_Classification_Loss 0.2114 | Dmon_Loss -0.1836 | Val_Loss 0.3524 | Search Time(s) 0.5086 | Infer Time(s) 0.1576 | Time(s) 0.6662 
2023-12-01 17:03:15,091:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:15,092:INFO::Validation loss decreased (0.355985 --> 0.352387).  Saving model ...
2023-12-01 17:03:15,095:INFO::Epoch: 123
tensor([[0.7409, 0.7460, 0.7389, 0.7639],
        [0.7446, 0.7671, 0.7435, 0.7314],
        [0.8420, 0.7701, 0.7521, 0.7521],
        [1.0000, 0.7984, 0.7742, 0.7787]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:15,095:INFO::its now!!!!!!!!5
2023-12-01 17:03:15,273:INFO::its now!!!!!!!!0
2023-12-01 17:03:15,273:INFO::its now!!!!!!!!3
2023-12-01 17:03:15,318:INFO::its now!!!!!!!!5
2023-12-01 17:03:15,492:INFO::its now!!!!!!!!
2023-12-01 17:03:15,492:INFO::its now!!!!!!!! on 
2023-12-01 17:03:15,545:INFO::its now!!!!!!!!5
2023-12-01 17:03:15,709:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:15,710:INFO::Epoch 00123 | lr 0.00050 | Train_Loss 0.1193 | Train_Classification_Loss 0.2125 | Dmon_Loss -0.1864 | Val_Loss 0.3482 | Search Time(s) 0.4498 | Infer Time(s) 0.1666 | Time(s) 0.6164 
2023-12-01 17:03:15,758:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:15,759:INFO::Validation loss decreased (0.352387 --> 0.348189).  Saving model ...
2023-12-01 17:03:15,762:INFO::Epoch: 124
tensor([[0.7403, 0.7455, 0.7384, 0.7639],
        [0.7441, 0.7670, 0.7430, 0.7308],
        [0.8447, 0.7696, 0.7516, 0.7516],
        [1.0000, 0.7980, 0.7738, 0.7782]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:15,763:INFO::its now!!!!!!!!5
2023-12-01 17:03:15,936:INFO::its now!!!!!!!!0
2023-12-01 17:03:15,937:INFO::its now!!!!!!!!3
2023-12-01 17:03:15,983:INFO::its now!!!!!!!!5
2023-12-01 17:03:16,146:INFO::its now!!!!!!!!
2023-12-01 17:03:16,146:INFO::its now!!!!!!!! on 
2023-12-01 17:03:16,198:INFO::its now!!!!!!!!5
2023-12-01 17:03:16,346:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:16,347:INFO::Epoch 00124 | lr 0.00050 | Train_Loss 0.1206 | Train_Classification_Loss 0.2143 | Dmon_Loss -0.1875 | Val_Loss 0.3452 | Search Time(s) 0.4368 | Infer Time(s) 0.1506 | Time(s) 0.5874 
2023-12-01 17:03:16,405:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:16,406:INFO::Validation loss decreased (0.348189 --> 0.345206).  Saving model ...
2023-12-01 17:03:16,408:INFO::Epoch: 125
tensor([[0.7407, 0.7458, 0.7388, 0.7639],
        [0.7445, 0.7670, 0.7434, 0.7313],
        [0.8476, 0.7699, 0.7519, 0.7520],
        [1.0000, 0.7983, 0.7741, 0.7786]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:16,409:INFO::its now!!!!!!!!5
2023-12-01 17:03:16,585:INFO::its now!!!!!!!!0
2023-12-01 17:03:16,586:INFO::its now!!!!!!!!3
2023-12-01 17:03:16,631:INFO::its now!!!!!!!!5
2023-12-01 17:03:16,827:INFO::its now!!!!!!!!
2023-12-01 17:03:16,827:INFO::its now!!!!!!!! on 
2023-12-01 17:03:16,881:INFO::its now!!!!!!!!5
2023-12-01 17:03:17,081:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:17,083:INFO::Epoch 00125 | lr 0.00050 | Train_Loss 0.1123 | Train_Classification_Loss 0.2066 | Dmon_Loss -0.1885 | Val_Loss 0.3407 | Search Time(s) 0.4724 | Infer Time(s) 0.2025 | Time(s) 0.6748 
2023-12-01 17:03:17,131:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:17,132:INFO::Validation loss decreased (0.345206 --> 0.340673).  Saving model ...
2023-12-01 17:03:17,135:INFO::Epoch: 126
tensor([[0.7409, 0.7459, 0.7388, 0.7639],
        [0.7446, 0.7669, 0.7434, 0.7314],
        [0.8505, 0.7700, 0.7520, 0.7521],
        [1.0000, 0.7984, 0.7742, 0.7786]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:17,135:INFO::its now!!!!!!!!5
2023-12-01 17:03:17,300:INFO::its now!!!!!!!!0
2023-12-01 17:03:17,301:INFO::its now!!!!!!!!3
2023-12-01 17:03:17,348:INFO::its now!!!!!!!!5
2023-12-01 17:03:17,533:INFO::its now!!!!!!!!
2023-12-01 17:03:17,533:INFO::its now!!!!!!!! on 
2023-12-01 17:03:17,590:INFO::its now!!!!!!!!5
2023-12-01 17:03:17,823:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:17,824:INFO::Epoch 00126 | lr 0.00050 | Train_Loss 0.1020 | Train_Classification_Loss 0.1973 | Dmon_Loss -0.1906 | Val_Loss 0.3389 | Search Time(s) 0.4544 | Infer Time(s) 0.2344 | Time(s) 0.6888 
2023-12-01 17:03:17,874:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:17,875:INFO::Validation loss decreased (0.340673 --> 0.338897).  Saving model ...
2023-12-01 17:03:17,878:INFO::Epoch: 127
tensor([[0.7375, 0.7436, 0.7365, 0.7639],
        [0.7422, 0.7669, 0.7412, 0.7282],
        [0.8532, 0.7676, 0.7496, 0.7497],
        [1.0000, 0.7962, 0.7719, 0.7765]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:17,879:INFO::its now!!!!!!!!5
2023-12-01 17:03:18,062:INFO::its now!!!!!!!!0
2023-12-01 17:03:18,063:INFO::its now!!!!!!!!3
2023-12-01 17:03:18,108:INFO::its now!!!!!!!!5
2023-12-01 17:03:18,286:INFO::its now!!!!!!!!
2023-12-01 17:03:18,287:INFO::its now!!!!!!!! on 
2023-12-01 17:03:18,341:INFO::its now!!!!!!!!5
2023-12-01 17:03:18,512:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:18,514:INFO::Epoch 00127 | lr 0.00050 | Train_Loss 0.1070 | Train_Classification_Loss 0.2025 | Dmon_Loss -0.1911 | Val_Loss 0.3338 | Search Time(s) 0.4650 | Infer Time(s) 0.1725 | Time(s) 0.6375 
2023-12-01 17:03:18,558:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:18,559:INFO::Validation loss decreased (0.338897 --> 0.333841).  Saving model ...
2023-12-01 17:03:18,561:INFO::Epoch: 128
tensor([[0.7336, 0.7408, 0.7337, 0.7639],
        [0.7394, 0.7669, 0.7384, 0.7245],
        [0.8558, 0.7648, 0.7468, 0.7468],
        [1.0000, 0.7935, 0.7693, 0.7738]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:18,562:INFO::its now!!!!!!!!5
2023-12-01 17:03:18,713:INFO::its now!!!!!!!!0
2023-12-01 17:03:18,714:INFO::its now!!!!!!!!3
2023-12-01 17:03:18,762:INFO::its now!!!!!!!!5
2023-12-01 17:03:19,027:INFO::its now!!!!!!!!
2023-12-01 17:03:19,027:INFO::its now!!!!!!!! on 
2023-12-01 17:03:19,087:INFO::its now!!!!!!!!5
2023-12-01 17:03:19,369:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:19,371:INFO::Epoch 00128 | lr 0.00050 | Train_Loss 0.0881 | Train_Classification_Loss 0.1847 | Dmon_Loss -0.1933 | Val_Loss 0.3312 | Search Time(s) 0.5256 | Infer Time(s) 0.2844 | Time(s) 0.8100 
2023-12-01 17:03:19,455:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:19,456:INFO::Validation loss decreased (0.333841 --> 0.331157).  Saving model ...
2023-12-01 17:03:19,460:INFO::Epoch: 129
tensor([[0.7298, 0.7381, 0.7310, 0.7639],
        [0.7367, 0.7669, 0.7358, 0.7209],
        [0.8584, 0.7621, 0.7441, 0.7441],
        [1.0000, 0.7909, 0.7667, 0.7714]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:19,461:INFO::its now!!!!!!!!5
2023-12-01 17:03:19,705:INFO::its now!!!!!!!!0
2023-12-01 17:03:19,706:INFO::its now!!!!!!!!3
2023-12-01 17:03:19,751:INFO::its now!!!!!!!!5
2023-12-01 17:03:19,919:INFO::its now!!!!!!!!
2023-12-01 17:03:19,919:INFO::its now!!!!!!!! on 
2023-12-01 17:03:19,972:INFO::its now!!!!!!!!5
2023-12-01 17:03:20,118:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:20,120:INFO::Epoch 00129 | lr 0.00050 | Train_Loss 0.0869 | Train_Classification_Loss 0.1847 | Dmon_Loss -0.1954 | Val_Loss 0.3306 | Search Time(s) 0.5114 | Infer Time(s) 0.1491 | Time(s) 0.6606 
2023-12-01 17:03:20,171:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:20,172:INFO::Validation loss decreased (0.331157 --> 0.330557).  Saving model ...
2023-12-01 17:03:20,175:INFO::Epoch: 130
tensor([[0.7306, 0.7387, 0.7316, 0.7639],
        [0.7373, 0.7669, 0.7364, 0.7217],
        [0.8612, 0.7627, 0.7447, 0.7447],
        [1.0000, 0.7915, 0.7673, 0.7719]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:20,176:INFO::its now!!!!!!!!5
2023-12-01 17:03:20,341:INFO::its now!!!!!!!!0
2023-12-01 17:03:20,342:INFO::its now!!!!!!!!3
2023-12-01 17:03:20,386:INFO::its now!!!!!!!!5
2023-12-01 17:03:20,555:INFO::its now!!!!!!!!
2023-12-01 17:03:20,555:INFO::its now!!!!!!!! on 
2023-12-01 17:03:20,608:INFO::its now!!!!!!!!5
2023-12-01 17:03:20,786:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:20,788:INFO::Epoch 00130 | lr 0.00050 | Train_Loss 0.0809 | Train_Classification_Loss 0.1791 | Dmon_Loss -0.1963 | Val_Loss 0.3249 | Search Time(s) 0.4314 | Infer Time(s) 0.1815 | Time(s) 0.6129 
2023-12-01 17:03:20,857:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:20,858:INFO::Validation loss decreased (0.330557 --> 0.324948).  Saving model ...
2023-12-01 17:03:20,860:INFO::Epoch: 131
tensor([[0.7316, 0.7394, 0.7323, 0.7639],
        [0.7380, 0.7669, 0.7371, 0.7227],
        [0.8638, 0.7634, 0.7454, 0.7454],
        [1.0000, 0.7922, 0.7680, 0.7726]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:20,861:INFO::its now!!!!!!!!5
2023-12-01 17:03:21,043:INFO::its now!!!!!!!!0
2023-12-01 17:03:21,044:INFO::its now!!!!!!!!3
2023-12-01 17:03:21,091:INFO::its now!!!!!!!!5
2023-12-01 17:03:21,284:INFO::its now!!!!!!!!
2023-12-01 17:03:21,284:INFO::its now!!!!!!!! on 
2023-12-01 17:03:21,338:INFO::its now!!!!!!!!5
2023-12-01 17:03:21,522:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:21,523:INFO::Epoch 00131 | lr 0.00050 | Train_Loss 0.0738 | Train_Classification_Loss 0.1728 | Dmon_Loss -0.1980 | Val_Loss 0.3222 | Search Time(s) 0.4789 | Infer Time(s) 0.1846 | Time(s) 0.6635 
2023-12-01 17:03:21,561:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:21,562:INFO::Validation loss decreased (0.324948 --> 0.322207).  Saving model ...
2023-12-01 17:03:21,564:INFO::Epoch: 132
tensor([[0.7358, 0.7424, 0.7353, 0.7639],
        [0.7410, 0.7669, 0.7400, 0.7266],
        [0.8667, 0.7664, 0.7484, 0.7485],
        [1.0000, 0.7950, 0.7708, 0.7754]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:21,565:INFO::its now!!!!!!!!5
2023-12-01 17:03:21,731:INFO::its now!!!!!!!!0
2023-12-01 17:03:21,732:INFO::its now!!!!!!!!3
2023-12-01 17:03:21,777:INFO::its now!!!!!!!!5
2023-12-01 17:03:21,950:INFO::its now!!!!!!!!
2023-12-01 17:03:21,950:INFO::its now!!!!!!!! on 
2023-12-01 17:03:22,006:INFO::its now!!!!!!!!5
2023-12-01 17:03:22,166:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:22,168:INFO::Epoch 00132 | lr 0.00050 | Train_Loss 0.0783 | Train_Classification_Loss 0.1782 | Dmon_Loss -0.1999 | Val_Loss 0.3196 | Search Time(s) 0.4428 | Infer Time(s) 0.1611 | Time(s) 0.6039 
2023-12-01 17:03:22,213:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:22,214:INFO::Validation loss decreased (0.322207 --> 0.319567).  Saving model ...
2023-12-01 17:03:22,216:INFO::Epoch: 133
tensor([[0.7363, 0.7427, 0.7356, 0.7639],
        [0.7413, 0.7669, 0.7403, 0.7270],
        [0.8694, 0.7668, 0.7488, 0.7488],
        [1.0000, 0.7953, 0.7711, 0.7756]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:22,217:INFO::its now!!!!!!!!5
2023-12-01 17:03:22,379:INFO::its now!!!!!!!!0
2023-12-01 17:03:22,380:INFO::its now!!!!!!!!3
2023-12-01 17:03:22,423:INFO::its now!!!!!!!!5
2023-12-01 17:03:22,619:INFO::its now!!!!!!!!
2023-12-01 17:03:22,620:INFO::its now!!!!!!!! on 
2023-12-01 17:03:22,672:INFO::its now!!!!!!!!5
2023-12-01 17:03:22,851:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:22,853:INFO::Epoch 00133 | lr 0.00050 | Train_Loss 0.0754 | Train_Classification_Loss 0.1757 | Dmon_Loss -0.2007 | Val_Loss 0.3183 | Search Time(s) 0.4544 | Infer Time(s) 0.1825 | Time(s) 0.6369 
2023-12-01 17:03:22,910:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:22,910:INFO::Validation loss decreased (0.319567 --> 0.318289).  Saving model ...
2023-12-01 17:03:22,913:INFO::Epoch: 134
tensor([[0.7393, 0.7449, 0.7378, 0.7639],
        [0.7435, 0.7668, 0.7424, 0.7299],
        [0.8721, 0.7690, 0.7509, 0.7510],
        [1.0000, 0.7974, 0.7732, 0.7777]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:22,913:INFO::its now!!!!!!!!5
2023-12-01 17:03:23,103:INFO::its now!!!!!!!!0
2023-12-01 17:03:23,103:INFO::its now!!!!!!!!3
2023-12-01 17:03:23,153:INFO::its now!!!!!!!!5
2023-12-01 17:03:23,378:INFO::its now!!!!!!!!
2023-12-01 17:03:23,378:INFO::its now!!!!!!!! on 
2023-12-01 17:03:23,443:INFO::its now!!!!!!!!5
2023-12-01 17:03:23,646:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:23,647:INFO::Epoch 00134 | lr 0.00050 | Train_Loss 0.0717 | Train_Classification_Loss 0.1723 | Dmon_Loss -0.2012 | Val_Loss 0.3145 | Search Time(s) 0.5307 | Infer Time(s) 0.2045 | Time(s) 0.7352 
2023-12-01 17:03:23,696:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:23,697:INFO::Validation loss decreased (0.318289 --> 0.314487).  Saving model ...
2023-12-01 17:03:23,699:INFO::Epoch: 135
tensor([[0.7406, 0.7458, 0.7387, 0.7639],
        [0.7444, 0.7668, 0.7433, 0.7311],
        [0.8746, 0.7699, 0.7519, 0.7519],
        [1.0000, 0.7983, 0.7740, 0.7785]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:23,700:INFO::its now!!!!!!!!5
2023-12-01 17:03:23,873:INFO::its now!!!!!!!!0
2023-12-01 17:03:23,874:INFO::its now!!!!!!!!3
2023-12-01 17:03:23,921:INFO::its now!!!!!!!!5
2023-12-01 17:03:24,119:INFO::its now!!!!!!!!
2023-12-01 17:03:24,119:INFO::its now!!!!!!!! on 
2023-12-01 17:03:24,172:INFO::its now!!!!!!!!5
2023-12-01 17:03:24,334:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:24,335:INFO::Epoch 00135 | lr 0.00050 | Train_Loss 0.0646 | Train_Classification_Loss 0.1662 | Dmon_Loss -0.2032 | Val_Loss 0.3121 | Search Time(s) 0.4713 | Infer Time(s) 0.1644 | Time(s) 0.6357 
2023-12-01 17:03:24,383:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:24,385:INFO::Validation loss decreased (0.314487 --> 0.312059).  Saving model ...
2023-12-01 17:03:24,387:INFO::Epoch: 136
tensor([[0.7432, 0.7476, 0.7406, 0.7639],
        [0.7463, 0.7668, 0.7451, 0.7336],
        [0.8774, 0.7718, 0.7538, 0.7538],
        [1.0000, 0.8001, 0.7758, 0.7803]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:24,388:INFO::its now!!!!!!!!5
2023-12-01 17:03:24,550:INFO::its now!!!!!!!!0
2023-12-01 17:03:24,551:INFO::its now!!!!!!!!3
2023-12-01 17:03:24,597:INFO::its now!!!!!!!!5
2023-12-01 17:03:24,786:INFO::its now!!!!!!!!
2023-12-01 17:03:24,787:INFO::its now!!!!!!!! on 
2023-12-01 17:03:24,840:INFO::its now!!!!!!!!5
2023-12-01 17:03:24,999:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:25,001:INFO::Epoch 00136 | lr 0.00050 | Train_Loss 0.0606 | Train_Classification_Loss 0.1630 | Dmon_Loss -0.2048 | Val_Loss 0.3105 | Search Time(s) 0.4524 | Infer Time(s) 0.1616 | Time(s) 0.6139 
2023-12-01 17:03:25,043:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:25,044:INFO::Validation loss decreased (0.312059 --> 0.310528).  Saving model ...
2023-12-01 17:03:25,046:INFO::Epoch: 137
tensor([[0.7445, 0.7508, 0.7438, 0.7662],
        [0.7495, 0.7692, 0.7460, 0.7378],
        [0.8815, 0.7727, 0.7569, 0.7570],
        [1.0000, 0.8031, 0.7769, 0.7832]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:25,047:INFO::its now!!!!!!!!5
2023-12-01 17:03:25,216:INFO::its now!!!!!!!!0
2023-12-01 17:03:25,217:INFO::its now!!!!!!!!3
2023-12-01 17:03:25,262:INFO::its now!!!!!!!!5
2023-12-01 17:03:25,422:INFO::its now!!!!!!!!
2023-12-01 17:03:25,422:INFO::its now!!!!!!!! on 
2023-12-01 17:03:25,479:INFO::its now!!!!!!!!5
2023-12-01 17:03:25,667:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:25,669:INFO::Epoch 00137 | lr 0.00050 | Train_Loss 0.0595 | Train_Classification_Loss 0.1613 | Dmon_Loss -0.2035 | Val_Loss 0.3076 | Search Time(s) 0.4320 | Infer Time(s) 0.1915 | Time(s) 0.6235 
2023-12-01 17:03:25,714:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:25,715:INFO::Validation loss decreased (0.310528 --> 0.307615).  Saving model ...
2023-12-01 17:03:25,717:INFO::Epoch: 138
tensor([[0.7472, 0.7538, 0.7468, 0.7673],
        [0.7526, 0.7704, 0.7479, 0.7418],
        [0.8848, 0.7747, 0.7600, 0.7602],
        [1.0000, 0.8060, 0.7788, 0.7861]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:25,718:INFO::its now!!!!!!!!5
2023-12-01 17:03:25,907:INFO::its now!!!!!!!!0
2023-12-01 17:03:25,908:INFO::its now!!!!!!!!3
2023-12-01 17:03:25,953:INFO::its now!!!!!!!!5
2023-12-01 17:03:26,123:INFO::its now!!!!!!!!
2023-12-01 17:03:26,123:INFO::its now!!!!!!!! on 
2023-12-01 17:03:26,178:INFO::its now!!!!!!!!5
2023-12-01 17:03:26,378:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:26,379:INFO::Epoch 00138 | lr 0.00050 | Train_Loss 0.0523 | Train_Classification_Loss 0.1553 | Dmon_Loss -0.2060 | Val_Loss 0.3056 | Search Time(s) 0.4603 | Infer Time(s) 0.2030 | Time(s) 0.6634 
2023-12-01 17:03:26,420:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:26,421:INFO::Validation loss decreased (0.307615 --> 0.305622).  Saving model ...
2023-12-01 17:03:26,423:INFO::Epoch: 139
tensor([[0.7488, 0.7555, 0.7485, 0.7679],
        [0.7542, 0.7710, 0.7490, 0.7440],
        [0.8878, 0.7758, 0.7617, 0.7619],
        [1.0000, 0.8076, 0.7799, 0.7876]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:26,424:INFO::its now!!!!!!!!5
2023-12-01 17:03:26,590:INFO::its now!!!!!!!!0
2023-12-01 17:03:26,591:INFO::its now!!!!!!!!3
2023-12-01 17:03:26,637:INFO::its now!!!!!!!!5
2023-12-01 17:03:26,798:INFO::its now!!!!!!!!
2023-12-01 17:03:26,798:INFO::its now!!!!!!!! on 
2023-12-01 17:03:26,851:INFO::its now!!!!!!!!5
2023-12-01 17:03:27,022:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:27,023:INFO::Epoch 00139 | lr 0.00050 | Train_Loss 0.0477 | Train_Classification_Loss 0.1510 | Dmon_Loss -0.2067 | Val_Loss 0.3035 | Search Time(s) 0.4269 | Infer Time(s) 0.1735 | Time(s) 0.6004 
2023-12-01 17:03:27,075:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:27,077:INFO::Validation loss decreased (0.305622 --> 0.303474).  Saving model ...
2023-12-01 17:03:27,079:INFO::Epoch: 140
tensor([[0.7491, 0.7560, 0.7490, 0.7682],
        [0.7548, 0.7713, 0.7492, 0.7447],
        [0.8903, 0.7761, 0.7622, 0.7624],
        [1.0000, 0.8081, 0.7802, 0.7881]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:27,080:INFO::its now!!!!!!!!5
2023-12-01 17:03:27,221:INFO::its now!!!!!!!!0
2023-12-01 17:03:27,222:INFO::its now!!!!!!!!3
2023-12-01 17:03:27,267:INFO::its now!!!!!!!!5
2023-12-01 17:03:27,460:INFO::its now!!!!!!!!
2023-12-01 17:03:27,460:INFO::its now!!!!!!!! on 
2023-12-01 17:03:27,512:INFO::its now!!!!!!!!5
2023-12-01 17:03:27,672:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:27,674:INFO::Epoch 00140 | lr 0.00050 | Train_Loss 0.0471 | Train_Classification_Loss 0.1509 | Dmon_Loss -0.2076 | Val_Loss 0.3019 | Search Time(s) 0.4320 | Infer Time(s) 0.1626 | Time(s) 0.5945 
2023-12-01 17:03:27,727:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:27,728:INFO::Validation loss decreased (0.303474 --> 0.301874).  Saving model ...
2023-12-01 17:03:27,731:INFO::Epoch: 141
tensor([[0.7523, 0.7584, 0.7515, 0.7683],
        [0.7572, 0.7714, 0.7515, 0.7479],
        [0.8928, 0.7784, 0.7647, 0.7649],
        [1.0000, 0.8104, 0.7824, 0.7904]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:27,731:INFO::its now!!!!!!!!5
2023-12-01 17:03:27,891:INFO::its now!!!!!!!!0
2023-12-01 17:03:27,892:INFO::its now!!!!!!!!3
2023-12-01 17:03:27,938:INFO::its now!!!!!!!!5
2023-12-01 17:03:28,105:INFO::its now!!!!!!!!
2023-12-01 17:03:28,105:INFO::its now!!!!!!!! on 
2023-12-01 17:03:28,160:INFO::its now!!!!!!!!5
2023-12-01 17:03:28,311:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:28,313:INFO::Epoch 00141 | lr 0.00050 | Train_Loss 0.0403 | Train_Classification_Loss 0.1441 | Dmon_Loss -0.2076 | Val_Loss 0.2989 | Search Time(s) 0.4284 | Infer Time(s) 0.1541 | Time(s) 0.5825 
2023-12-01 17:03:28,365:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:28,366:INFO::Validation loss decreased (0.301874 --> 0.298864).  Saving model ...
2023-12-01 17:03:28,369:INFO::Epoch: 142
tensor([[0.7486, 0.7558, 0.7489, 0.7684],
        [0.7546, 0.7715, 0.7488, 0.7445],
        [0.8954, 0.7757, 0.7621, 0.7622],
        [1.0000, 0.8079, 0.7798, 0.7879]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:28,369:INFO::its now!!!!!!!!5
2023-12-01 17:03:28,557:INFO::its now!!!!!!!!0
2023-12-01 17:03:28,557:INFO::its now!!!!!!!!3
2023-12-01 17:03:28,602:INFO::its now!!!!!!!!5
2023-12-01 17:03:28,832:INFO::its now!!!!!!!!
2023-12-01 17:03:28,832:INFO::its now!!!!!!!! on 
2023-12-01 17:03:28,887:INFO::its now!!!!!!!!5
2023-12-01 17:03:29,075:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:29,077:INFO::Epoch 00142 | lr 0.00050 | Train_Loss 0.0393 | Train_Classification_Loss 0.1437 | Dmon_Loss -0.2086 | Val_Loss 0.2979 | Search Time(s) 0.5176 | Infer Time(s) 0.1905 | Time(s) 0.7081 
2023-12-01 17:03:29,140:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:29,141:INFO::Validation loss decreased (0.298864 --> 0.297929).  Saving model ...
2023-12-01 17:03:29,146:INFO::Epoch: 143
tensor([[0.7485, 0.7558, 0.7488, 0.7684],
        [0.7545, 0.7715, 0.7488, 0.7444],
        [0.8979, 0.7756, 0.7620, 0.7622],
        [1.0000, 0.8079, 0.7798, 0.7879]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:29,147:INFO::its now!!!!!!!!5
2023-12-01 17:03:29,294:INFO::its now!!!!!!!!0
2023-12-01 17:03:29,295:INFO::its now!!!!!!!!3
2023-12-01 17:03:29,341:INFO::its now!!!!!!!!5
2023-12-01 17:03:29,518:INFO::its now!!!!!!!!
2023-12-01 17:03:29,518:INFO::its now!!!!!!!! on 
2023-12-01 17:03:29,571:INFO::its now!!!!!!!!5
2023-12-01 17:03:29,723:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:29,725:INFO::Epoch 00143 | lr 0.00050 | Train_Loss 0.0385 | Train_Classification_Loss 0.1438 | Dmon_Loss -0.2104 | Val_Loss 0.2949 | Search Time(s) 0.4290 | Infer Time(s) 0.1536 | Time(s) 0.5826 
2023-12-01 17:03:29,764:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:29,765:INFO::Validation loss decreased (0.297929 --> 0.294948).  Saving model ...
2023-12-01 17:03:29,768:INFO::Epoch: 144
tensor([[0.7451, 0.7533, 0.7463, 0.7684],
        [0.7520, 0.7715, 0.7463, 0.7412],
        [0.9001, 0.7731, 0.7595, 0.7597],
        [1.0000, 0.8055, 0.7774, 0.7856]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:29,770:INFO::its now!!!!!!!!5
2023-12-01 17:03:29,929:INFO::its now!!!!!!!!0
2023-12-01 17:03:29,929:INFO::its now!!!!!!!!3
2023-12-01 17:03:29,975:INFO::its now!!!!!!!!5
2023-12-01 17:03:30,154:INFO::its now!!!!!!!!
2023-12-01 17:03:30,154:INFO::its now!!!!!!!! on 
2023-12-01 17:03:30,209:INFO::its now!!!!!!!!5
2023-12-01 17:03:30,364:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:30,366:INFO::Epoch 00144 | lr 0.00050 | Train_Loss 0.0351 | Train_Classification_Loss 0.1402 | Dmon_Loss -0.2103 | Val_Loss 0.2941 | Search Time(s) 0.4404 | Infer Time(s) 0.1581 | Time(s) 0.5985 
2023-12-01 17:03:30,423:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:30,424:INFO::Validation loss decreased (0.294948 --> 0.294134).  Saving model ...
2023-12-01 17:03:30,426:INFO::Epoch: 145
tensor([[0.7465, 0.7544, 0.7474, 0.7685],
        [0.7531, 0.7715, 0.7473, 0.7426],
        [0.9025, 0.7741, 0.7606, 0.7608],
        [1.0000, 0.8065, 0.7784, 0.7866]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:30,427:INFO::its now!!!!!!!!5
2023-12-01 17:03:30,605:INFO::its now!!!!!!!!0
2023-12-01 17:03:30,606:INFO::its now!!!!!!!!3
2023-12-01 17:03:30,653:INFO::its now!!!!!!!!5
2023-12-01 17:03:30,839:INFO::its now!!!!!!!!
2023-12-01 17:03:30,840:INFO::its now!!!!!!!! on 
2023-12-01 17:03:30,892:INFO::its now!!!!!!!!5
2023-12-01 17:03:31,091:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:31,093:INFO::Epoch 00145 | lr 0.00050 | Train_Loss 0.0323 | Train_Classification_Loss 0.1378 | Dmon_Loss -0.2110 | Val_Loss 0.2915 | Search Time(s) 0.4687 | Infer Time(s) 0.1985 | Time(s) 0.6672 
2023-12-01 17:03:31,138:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:31,139:INFO::Validation loss decreased (0.294134 --> 0.291451).  Saving model ...
2023-12-01 17:03:31,143:INFO::Epoch: 146
tensor([[0.7460, 0.7540, 0.7470, 0.7685],
        [0.7528, 0.7715, 0.7470, 0.7421],
        [0.9048, 0.7738, 0.7602, 0.7604],
        [1.0000, 0.8062, 0.7781, 0.7862]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:31,144:INFO::its now!!!!!!!!5
2023-12-01 17:03:31,322:INFO::its now!!!!!!!!0
2023-12-01 17:03:31,323:INFO::its now!!!!!!!!3
2023-12-01 17:03:31,373:INFO::its now!!!!!!!!5
2023-12-01 17:03:31,547:INFO::its now!!!!!!!!
2023-12-01 17:03:31,547:INFO::its now!!!!!!!! on 
2023-12-01 17:03:31,608:INFO::its now!!!!!!!!5
2023-12-01 17:03:31,771:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:31,772:INFO::Epoch 00146 | lr 0.00050 | Train_Loss 0.0310 | Train_Classification_Loss 0.1373 | Dmon_Loss -0.2126 | Val_Loss 0.2898 | Search Time(s) 0.4663 | Infer Time(s) 0.1656 | Time(s) 0.6319 
2023-12-01 17:03:31,826:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:31,826:INFO::Validation loss decreased (0.291451 --> 0.289791).  Saving model ...
2023-12-01 17:03:31,829:INFO::Epoch: 147
tensor([[0.7428, 0.7517, 0.7447, 0.7685],
        [0.7504, 0.7715, 0.7447, 0.7391],
        [0.9071, 0.7714, 0.7579, 0.7580],
        [1.0000, 0.8039, 0.7758, 0.7840]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:31,829:INFO::its now!!!!!!!!5
2023-12-01 17:03:31,972:INFO::its now!!!!!!!!0
2023-12-01 17:03:31,973:INFO::its now!!!!!!!!3
2023-12-01 17:03:32,020:INFO::its now!!!!!!!!5
2023-12-01 17:03:32,208:INFO::its now!!!!!!!!
2023-12-01 17:03:32,208:INFO::its now!!!!!!!! on 
2023-12-01 17:03:32,262:INFO::its now!!!!!!!!5
2023-12-01 17:03:32,410:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:32,411:INFO::Epoch 00147 | lr 0.00050 | Train_Loss 0.0278 | Train_Classification_Loss 0.1343 | Dmon_Loss -0.2131 | Val_Loss 0.2881 | Search Time(s) 0.4324 | Infer Time(s) 0.1511 | Time(s) 0.5835 
2023-12-01 17:03:32,472:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:32,473:INFO::Validation loss decreased (0.289791 --> 0.288122).  Saving model ...
2023-12-01 17:03:32,475:INFO::Epoch: 148
tensor([[0.7393, 0.7492, 0.7421, 0.7685],
        [0.7479, 0.7714, 0.7422, 0.7358],
        [0.9092, 0.7688, 0.7553, 0.7554],
        [1.0000, 0.8015, 0.7734, 0.7817]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:32,476:INFO::its now!!!!!!!!5
2023-12-01 17:03:32,649:INFO::its now!!!!!!!!0
2023-12-01 17:03:32,650:INFO::its now!!!!!!!!3
2023-12-01 17:03:32,695:INFO::its now!!!!!!!!5
2023-12-01 17:03:32,843:INFO::its now!!!!!!!!
2023-12-01 17:03:32,843:INFO::its now!!!!!!!! on 
2023-12-01 17:03:32,898:INFO::its now!!!!!!!!5
2023-12-01 17:03:33,077:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:33,079:INFO::Epoch 00148 | lr 0.00050 | Train_Loss 0.0206 | Train_Classification_Loss 0.1271 | Dmon_Loss -0.2131 | Val_Loss 0.2865 | Search Time(s) 0.4209 | Infer Time(s) 0.1835 | Time(s) 0.6044 
2023-12-01 17:03:33,133:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:33,134:INFO::Validation loss decreased (0.288122 --> 0.286544).  Saving model ...
2023-12-01 17:03:33,136:INFO::Epoch: 149
tensor([[0.7533, 0.7479, 0.7531, 0.7811],
        [0.7588, 0.7714, 0.7530, 0.7492],
        [0.9246, 0.7799, 0.7663, 0.7544],
        [1.0000, 0.8120, 0.7839, 0.7920]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:33,137:INFO::its now!!!!!!!!5
2023-12-01 17:03:33,294:INFO::its now!!!!!!!!0
2023-12-01 17:03:33,295:INFO::its now!!!!!!!!3
2023-12-01 17:03:33,340:INFO::its now!!!!!!!!5
2023-12-01 17:03:33,526:INFO::its now!!!!!!!!
2023-12-01 17:03:33,526:INFO::its now!!!!!!!! on 
2023-12-01 17:03:33,582:INFO::its now!!!!!!!!5
2023-12-01 17:03:33,745:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:33,747:INFO::Epoch 00149 | lr 0.00050 | Train_Loss 0.0283 | Train_Classification_Loss 0.1355 | Dmon_Loss -0.2142 | Val_Loss 0.2859 | Search Time(s) 0.4473 | Infer Time(s) 0.1636 | Time(s) 0.6109 
2023-12-01 17:03:33,792:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:33,794:INFO::Validation loss decreased (0.286544 --> 0.285860).  Saving model ...
2023-12-01 17:03:33,796:INFO::Epoch: 150
tensor([[0.7615, 0.7483, 0.7596, 0.7874],
        [0.7653, 0.7714, 0.7593, 0.7571],
        [0.9336, 0.7864, 0.7721, 0.7550],
        [1.0000, 0.8182, 0.7893, 0.7981]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:33,797:INFO::its now!!!!!!!!5
2023-12-01 17:03:33,940:INFO::its now!!!!!!!!0
2023-12-01 17:03:33,941:INFO::its now!!!!!!!!3
2023-12-01 17:03:33,986:INFO::its now!!!!!!!!5
2023-12-01 17:03:34,143:INFO::its now!!!!!!!!
2023-12-01 17:03:34,143:INFO::its now!!!!!!!! on 
2023-12-01 17:03:34,197:INFO::its now!!!!!!!!5
2023-12-01 17:03:34,438:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:34,440:INFO::Epoch 00150 | lr 0.00050 | Train_Loss 0.0151 | Train_Classification_Loss 0.1224 | Dmon_Loss -0.2146 | Val_Loss 0.2840 | Search Time(s) 0.4025 | Infer Time(s) 0.2420 | Time(s) 0.6445 
2023-12-01 17:03:34,496:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:34,497:INFO::Validation loss decreased (0.285860 --> 0.283969).  Saving model ...
2023-12-01 17:03:34,500:INFO::Epoch: 151
tensor([[0.7613, 0.7449, 0.7594, 0.7906],
        [0.7651, 0.7714, 0.7591, 0.7569],
        [0.9389, 0.7862, 0.7716, 0.7515],
        [1.0000, 0.8181, 0.7887, 0.7979]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:34,501:INFO::its now!!!!!!!!5
2023-12-01 17:03:34,667:INFO::its now!!!!!!!!0
2023-12-01 17:03:34,668:INFO::its now!!!!!!!!3
2023-12-01 17:03:34,714:INFO::its now!!!!!!!!5
2023-12-01 17:03:34,892:INFO::its now!!!!!!!!
2023-12-01 17:03:34,893:INFO::its now!!!!!!!! on 
2023-12-01 17:03:34,946:INFO::its now!!!!!!!!5
2023-12-01 17:03:35,103:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:35,105:INFO::Epoch 00151 | lr 0.00050 | Train_Loss 0.0064 | Train_Classification_Loss 0.1141 | Dmon_Loss -0.2154 | Val_Loss 0.2822 | Search Time(s) 0.4448 | Infer Time(s) 0.1607 | Time(s) 0.6055 
2023-12-01 17:03:35,173:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:35,174:INFO::Validation loss decreased (0.283969 --> 0.282193).  Saving model ...
2023-12-01 17:03:35,178:INFO::Epoch: 152
tensor([[0.7628, 0.7445, 0.7606, 0.7922],
        [0.7663, 0.7714, 0.7603, 0.7583],
        [0.9426, 0.7874, 0.7726, 0.7512],
        [1.0000, 0.8192, 0.7897, 0.7990]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:35,179:INFO::its now!!!!!!!!5
2023-12-01 17:03:35,337:INFO::its now!!!!!!!!0
2023-12-01 17:03:35,338:INFO::its now!!!!!!!!3
2023-12-01 17:03:35,383:INFO::its now!!!!!!!!5
2023-12-01 17:03:35,553:INFO::its now!!!!!!!!
2023-12-01 17:03:35,554:INFO::its now!!!!!!!! on 
2023-12-01 17:03:35,607:INFO::its now!!!!!!!!5
2023-12-01 17:03:35,774:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:35,775:INFO::Epoch 00152 | lr 0.00050 | Train_Loss 0.0079 | Train_Classification_Loss 0.1157 | Dmon_Loss -0.2156 | Val_Loss 0.2808 | Search Time(s) 0.4304 | Infer Time(s) 0.1686 | Time(s) 0.5990 
2023-12-01 17:03:35,818:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:35,819:INFO::Validation loss decreased (0.282193 --> 0.280783).  Saving model ...
2023-12-01 17:03:35,823:INFO::Epoch: 153
tensor([[0.7592, 0.7406, 0.7578, 0.7930],
        [0.7635, 0.7714, 0.7575, 0.7549],
        [0.9454, 0.7846, 0.7697, 0.7473],
        [1.0000, 0.8165, 0.7869, 0.7964]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:35,825:INFO::its now!!!!!!!!5
2023-12-01 17:03:36,019:INFO::its now!!!!!!!!0
2023-12-01 17:03:36,019:INFO::its now!!!!!!!!3
2023-12-01 17:03:36,068:INFO::its now!!!!!!!!5
2023-12-01 17:03:36,274:INFO::its now!!!!!!!!
2023-12-01 17:03:36,274:INFO::its now!!!!!!!! on 
2023-12-01 17:03:36,331:INFO::its now!!!!!!!!5
2023-12-01 17:03:36,511:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:36,513:INFO::Epoch 00153 | lr 0.00050 | Train_Loss 0.0071 | Train_Classification_Loss 0.1153 | Dmon_Loss -0.2164 | Val_Loss 0.2794 | Search Time(s) 0.5088 | Infer Time(s) 0.1825 | Time(s) 0.6913 
2023-12-01 17:03:36,552:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:36,553:INFO::Validation loss decreased (0.280783 --> 0.279400).  Saving model ...
2023-12-01 17:03:36,556:INFO::Epoch: 154
tensor([[0.7604, 0.7412, 0.7586, 0.7934],
        [0.7643, 0.7714, 0.7584, 0.7560],
        [0.9477, 0.7854, 0.7705, 0.7478],
        [1.0000, 0.8173, 0.7877, 0.7972]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:36,557:INFO::its now!!!!!!!!5
2023-12-01 17:03:36,710:INFO::its now!!!!!!!!0
2023-12-01 17:03:36,711:INFO::its now!!!!!!!!3
2023-12-01 17:03:36,757:INFO::its now!!!!!!!!5
2023-12-01 17:03:36,919:INFO::its now!!!!!!!!
2023-12-01 17:03:36,919:INFO::its now!!!!!!!! on 
2023-12-01 17:03:36,974:INFO::its now!!!!!!!!5
2023-12-01 17:03:37,146:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:37,148:INFO::Epoch 00154 | lr 0.00050 | Train_Loss 0.0040 | Train_Classification_Loss 0.1119 | Dmon_Loss -0.2158 | Val_Loss 0.2781 | Search Time(s) 0.4189 | Infer Time(s) 0.1731 | Time(s) 0.5920 
2023-12-01 17:03:37,197:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:37,198:INFO::Validation loss decreased (0.279400 --> 0.278081).  Saving model ...
2023-12-01 17:03:37,200:INFO::Epoch: 155
tensor([[0.7596, 0.7403, 0.7580, 0.7936],
        [0.7637, 0.7714, 0.7578, 0.7552],
        [0.9498, 0.7848, 0.7699, 0.7469],
        [1.0000, 0.8167, 0.7871, 0.7966]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:37,201:INFO::its now!!!!!!!!5
2023-12-01 17:03:37,368:INFO::its now!!!!!!!!0
2023-12-01 17:03:37,370:INFO::its now!!!!!!!!3
2023-12-01 17:03:37,419:INFO::its now!!!!!!!!5
2023-12-01 17:03:37,580:INFO::its now!!!!!!!!
2023-12-01 17:03:37,580:INFO::its now!!!!!!!! on 
2023-12-01 17:03:37,633:INFO::its now!!!!!!!!5
2023-12-01 17:03:37,842:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:37,844:INFO::Epoch 00155 | lr 0.00050 | Train_Loss 0.0031 | Train_Classification_Loss 0.1115 | Dmon_Loss -0.2169 | Val_Loss 0.2768 | Search Time(s) 0.4324 | Infer Time(s) 0.2124 | Time(s) 0.6448 
2023-12-01 17:03:37,913:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:37,914:INFO::Validation loss decreased (0.278081 --> 0.276828).  Saving model ...
2023-12-01 17:03:37,920:INFO::Epoch: 156
tensor([[0.7599, 0.7405, 0.7583, 0.7937],
        [0.7640, 0.7714, 0.7581, 0.7556],
        [0.9515, 0.7851, 0.7701, 0.7471],
        [1.0000, 0.8170, 0.7873, 0.7969]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:37,922:INFO::its now!!!!!!!!5
2023-12-01 17:03:38,134:INFO::its now!!!!!!!!0
2023-12-01 17:03:38,135:INFO::its now!!!!!!!!3
2023-12-01 17:03:38,183:INFO::its now!!!!!!!!5
2023-12-01 17:03:38,363:INFO::its now!!!!!!!!
2023-12-01 17:03:38,363:INFO::its now!!!!!!!! on 
2023-12-01 17:03:38,420:INFO::its now!!!!!!!!5
2023-12-01 17:03:38,610:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:38,611:INFO::Epoch 00156 | lr 0.00050 | Train_Loss 0.0035 | Train_Classification_Loss 0.1121 | Dmon_Loss -0.2172 | Val_Loss 0.2757 | Search Time(s) 0.5048 | Infer Time(s) 0.1905 | Time(s) 0.6953 
2023-12-01 17:03:38,663:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:38,664:INFO::Validation loss decreased (0.276828 --> 0.275662).  Saving model ...
2023-12-01 17:03:38,666:INFO::Epoch: 157
tensor([[0.7603, 0.7408, 0.7586, 0.7937],
        [0.7643, 0.7714, 0.7583, 0.7559],
        [0.9530, 0.7854, 0.7704, 0.7474],
        [1.0000, 0.8173, 0.7876, 0.7972]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:38,667:INFO::its now!!!!!!!!5
2023-12-01 17:03:38,853:INFO::its now!!!!!!!!0
2023-12-01 17:03:38,853:INFO::its now!!!!!!!!3
2023-12-01 17:03:38,899:INFO::its now!!!!!!!!5
2023-12-01 17:03:39,084:INFO::its now!!!!!!!!
2023-12-01 17:03:39,085:INFO::its now!!!!!!!! on 
2023-12-01 17:03:39,140:INFO::its now!!!!!!!!5
2023-12-01 17:03:39,326:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:39,328:INFO::Epoch 00157 | lr 0.00050 | Train_Loss 0.0038 | Train_Classification_Loss 0.1124 | Dmon_Loss -0.2172 | Val_Loss 0.2745 | Search Time(s) 0.4744 | Infer Time(s) 0.1871 | Time(s) 0.6615 
2023-12-01 17:03:39,389:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:39,429:INFO::Validation loss decreased (0.275662 --> 0.274485).  Saving model ...
2023-12-01 17:03:39,431:INFO::Epoch: 158
tensor([[0.7632, 0.7432, 0.7609, 0.7937],
        [0.7666, 0.7714, 0.7606, 0.7587],
        [0.9547, 0.7877, 0.7727, 0.7500],
        [1.0000, 0.8195, 0.7898, 0.7993]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:39,432:INFO::its now!!!!!!!!5
2023-12-01 17:03:39,589:INFO::its now!!!!!!!!0
2023-12-01 17:03:39,589:INFO::its now!!!!!!!!3
2023-12-01 17:03:39,633:INFO::its now!!!!!!!!5
2023-12-01 17:03:39,855:INFO::its now!!!!!!!!
2023-12-01 17:03:39,855:INFO::its now!!!!!!!! on 
2023-12-01 17:03:39,912:INFO::its now!!!!!!!!5
2023-12-01 17:03:40,120:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:40,121:INFO::Epoch 00158 | lr 0.00050 | Train_Loss -0.0006 | Train_Classification_Loss 0.1084 | Dmon_Loss -0.2178 | Val_Loss 0.2733 | Search Time(s) 0.4827 | Infer Time(s) 0.2090 | Time(s) 0.6917 
2023-12-01 17:03:40,185:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:40,187:INFO::Validation loss decreased (0.274485 --> 0.273347).  Saving model ...
2023-12-01 17:03:40,190:INFO::Epoch: 159
tensor([[0.7602, 0.7445, 0.7585, 0.7900],
        [0.7642, 0.7714, 0.7583, 0.7558],
        [0.9512, 0.7853, 0.7703, 0.7513],
        [0.9967, 0.8189, 0.7875, 0.7971]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:40,191:INFO::its now!!!!!!!!5
2023-12-01 17:03:40,356:INFO::its now!!!!!!!!0
2023-12-01 17:03:40,357:INFO::its now!!!!!!!!3
2023-12-01 17:03:40,405:INFO::its now!!!!!!!!5
2023-12-01 17:03:40,584:INFO::its now!!!!!!!!
2023-12-01 17:03:40,584:INFO::its now!!!!!!!! on 
2023-12-01 17:03:40,640:INFO::its now!!!!!!!!5
2023-12-01 17:03:40,816:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:40,995:INFO::Epoch 00159 | lr 0.00050 | Train_Loss -0.0033 | Train_Classification_Loss 0.1063 | Dmon_Loss -0.2191 | Val_Loss 0.2722 | Search Time(s) 0.4524 | Infer Time(s) 0.1765 | Time(s) 0.6289 
2023-12-01 17:03:41,041:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:41,042:INFO::Validation loss decreased (0.273347 --> 0.272241).  Saving model ...
2023-12-01 17:03:41,046:INFO::Epoch: 160
tensor([[0.7589, 0.7453, 0.7575, 0.7881],
        [0.7632, 0.7714, 0.7573, 0.7546],
        [0.9504, 0.7843, 0.7693, 0.7522],
        [0.9968, 0.8187, 0.7865, 0.7961]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:41,047:INFO::its now!!!!!!!!5
2023-12-01 17:03:41,291:INFO::its now!!!!!!!!0
2023-12-01 17:03:41,292:INFO::its now!!!!!!!!3
2023-12-01 17:03:41,340:INFO::its now!!!!!!!!5
2023-12-01 17:03:41,520:INFO::its now!!!!!!!!
2023-12-01 17:03:41,520:INFO::its now!!!!!!!! on 
2023-12-01 17:03:41,577:INFO::its now!!!!!!!!5
2023-12-01 17:03:41,737:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:41,738:INFO::Epoch 00160 | lr 0.00050 | Train_Loss -0.0032 | Train_Classification_Loss 0.1060 | Dmon_Loss -0.2184 | Val_Loss 0.2711 | Search Time(s) 0.5327 | Infer Time(s) 0.1616 | Time(s) 0.6943 
2023-12-01 17:03:41,787:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:41,788:INFO::Validation loss decreased (0.272241 --> 0.271102).  Saving model ...
2023-12-01 17:03:41,790:INFO::Epoch: 161
tensor([[0.7565, 0.7442, 0.7556, 0.7871],
        [0.7613, 0.7714, 0.7554, 0.7523],
        [0.9507, 0.7824, 0.7674, 0.7511],
        [0.9986, 0.8173, 0.7847, 0.7943]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:41,791:INFO::its now!!!!!!!!5
2023-12-01 17:03:41,980:INFO::its now!!!!!!!!0
2023-12-01 17:03:41,980:INFO::its now!!!!!!!!3
2023-12-01 17:03:42,029:INFO::its now!!!!!!!!5
2023-12-01 17:03:42,198:INFO::its now!!!!!!!!
2023-12-01 17:03:42,198:INFO::its now!!!!!!!! on 
2023-12-01 17:03:42,255:INFO::its now!!!!!!!!5
2023-12-01 17:03:42,444:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:42,446:INFO::Epoch 00161 | lr 0.00050 | Train_Loss -0.0001 | Train_Classification_Loss 0.1092 | Dmon_Loss -0.2186 | Val_Loss 0.2701 | Search Time(s) 0.4633 | Infer Time(s) 0.1930 | Time(s) 0.6563 
2023-12-01 17:03:42,498:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:42,499:INFO::Validation loss decreased (0.271102 --> 0.270089).  Saving model ...
2023-12-01 17:03:42,502:INFO::Epoch: 162
tensor([[0.7546, 0.7430, 0.7540, 0.7867],
        [0.7597, 0.7713, 0.7539, 0.7504],
        [0.9517, 0.7808, 0.7659, 0.7499],
        [1.0000, 0.8160, 0.7832, 0.7929]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:42,503:INFO::its now!!!!!!!!5
2023-12-01 17:03:42,691:INFO::its now!!!!!!!!0
2023-12-01 17:03:42,691:INFO::its now!!!!!!!!3
2023-12-01 17:03:42,738:INFO::its now!!!!!!!!5
2023-12-01 17:03:42,917:INFO::its now!!!!!!!!
2023-12-01 17:03:42,917:INFO::its now!!!!!!!! on 
2023-12-01 17:03:42,970:INFO::its now!!!!!!!!5
2023-12-01 17:03:43,140:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:43,142:INFO::Epoch 00162 | lr 0.00050 | Train_Loss -0.0029 | Train_Classification_Loss 0.1066 | Dmon_Loss -0.2190 | Val_Loss 0.2688 | Search Time(s) 0.4678 | Infer Time(s) 0.1731 | Time(s) 0.6409 
2023-12-01 17:03:43,183:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:43,184:INFO::Validation loss decreased (0.270089 --> 0.268753).  Saving model ...
2023-12-01 17:03:43,187:INFO::Epoch: 163
tensor([[0.7536, 0.7424, 0.7532, 0.7864],
        [0.7590, 0.7713, 0.7531, 0.7495],
        [0.9529, 0.7800, 0.7651, 0.7492],
        [1.0000, 0.8154, 0.7824, 0.7921]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:43,188:INFO::its now!!!!!!!!5
2023-12-01 17:03:43,351:INFO::its now!!!!!!!!0
2023-12-01 17:03:43,352:INFO::its now!!!!!!!!3
2023-12-01 17:03:43,398:INFO::its now!!!!!!!!5
2023-12-01 17:03:43,578:INFO::its now!!!!!!!!
2023-12-01 17:03:43,579:INFO::its now!!!!!!!! on 
2023-12-01 17:03:43,632:INFO::its now!!!!!!!!5
2023-12-01 17:03:43,781:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:43,782:INFO::Epoch 00163 | lr 0.00050 | Train_Loss -0.0097 | Train_Classification_Loss 0.1001 | Dmon_Loss -0.2197 | Val_Loss 0.2677 | Search Time(s) 0.4442 | Infer Time(s) 0.1526 | Time(s) 0.5967 
2023-12-01 17:03:43,833:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:43,834:INFO::Validation loss decreased (0.268753 --> 0.267650).  Saving model ...
2023-12-01 17:03:43,836:INFO::Epoch: 164
tensor([[0.7656, 0.7531, 0.7529, 0.7971],
        [0.7586, 0.7837, 0.7628, 0.7611],
        [0.9656, 0.7799, 0.7749, 0.7602],
        [1.0000, 0.8250, 0.7919, 0.8015]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:43,837:INFO::its now!!!!!!!!5
2023-12-01 17:03:44,012:INFO::its now!!!!!!!!0
2023-12-01 17:03:44,012:INFO::its now!!!!!!!!3
2023-12-01 17:03:44,061:INFO::its now!!!!!!!!5
2023-12-01 17:03:44,214:INFO::its now!!!!!!!!
2023-12-01 17:03:44,214:INFO::its now!!!!!!!! on 
2023-12-01 17:03:44,270:INFO::its now!!!!!!!!5
2023-12-01 17:03:44,438:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:44,439:INFO::Epoch 00164 | lr 0.00050 | Train_Loss -0.0144 | Train_Classification_Loss 0.0960 | Dmon_Loss -0.2209 | Val_Loss 0.2666 | Search Time(s) 0.4351 | Infer Time(s) 0.1686 | Time(s) 0.6038 
2023-12-01 17:03:44,486:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:44,487:INFO::Validation loss decreased (0.267650 --> 0.266624).  Saving model ...
2023-12-01 17:03:44,490:INFO::Epoch: 165
tensor([[0.7685, 0.7558, 0.7500, 0.8024],
        [0.7557, 0.7899, 0.7652, 0.7639],
        [0.9728, 0.7771, 0.7773, 0.7629],
        [1.0000, 0.8273, 0.7943, 0.8038]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:44,491:INFO::its now!!!!!!!!5
2023-12-01 17:03:44,674:INFO::its now!!!!!!!!0
2023-12-01 17:03:44,675:INFO::its now!!!!!!!!3
2023-12-01 17:03:44,722:INFO::its now!!!!!!!!5
2023-12-01 17:03:44,883:INFO::its now!!!!!!!!
2023-12-01 17:03:44,924:INFO::its now!!!!!!!! on 
2023-12-01 17:03:44,979:INFO::its now!!!!!!!!5
2023-12-01 17:03:45,148:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:45,150:INFO::Epoch 00165 | lr 0.00050 | Train_Loss -0.0145 | Train_Classification_Loss 0.0958 | Dmon_Loss -0.2207 | Val_Loss 0.2657 | Search Time(s) 0.4887 | Infer Time(s) 0.1711 | Time(s) 0.6598 
2023-12-01 17:03:45,201:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:45,202:INFO::Validation loss decreased (0.266624 --> 0.265703).  Saving model ...
2023-12-01 17:03:45,205:INFO::Epoch: 166
tensor([[0.7679, 0.7553, 0.7468, 0.8051],
        [0.7525, 0.7930, 0.7647, 0.7633],
        [0.9773, 0.7740, 0.7769, 0.7624],
        [1.0000, 0.8269, 0.7938, 0.8033]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:45,206:INFO::its now!!!!!!!!5
2023-12-01 17:03:45,469:INFO::its now!!!!!!!!0
2023-12-01 17:03:45,470:INFO::its now!!!!!!!!3
2023-12-01 17:03:45,516:INFO::its now!!!!!!!!5
2023-12-01 17:03:45,710:INFO::its now!!!!!!!!
2023-12-01 17:03:45,710:INFO::its now!!!!!!!! on 
2023-12-01 17:03:45,762:INFO::its now!!!!!!!!5
2023-12-01 17:03:45,907:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:45,908:INFO::Epoch 00166 | lr 0.00050 | Train_Loss -0.0149 | Train_Classification_Loss 0.0953 | Dmon_Loss -0.2205 | Val_Loss 0.2648 | Search Time(s) 0.5561 | Infer Time(s) 0.1486 | Time(s) 0.7047 
2023-12-01 17:03:45,948:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:45,949:INFO::Validation loss decreased (0.265703 --> 0.264824).  Saving model ...
2023-12-01 17:03:45,951:INFO::Epoch: 167
tensor([[0.7669, 0.7544, 0.7445, 0.8065],
        [0.7502, 0.7945, 0.7639, 0.7623],
        [0.9801, 0.7717, 0.7760, 0.7615],
        [1.0000, 0.8261, 0.7930, 0.8025]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:45,951:INFO::its now!!!!!!!!5
2023-12-01 17:03:46,102:INFO::its now!!!!!!!!0
2023-12-01 17:03:46,103:INFO::its now!!!!!!!!3
2023-12-01 17:03:46,131:INFO::its now!!!!!!!!5
2023-12-01 17:03:46,307:INFO::its now!!!!!!!!
2023-12-01 17:03:46,308:INFO::its now!!!!!!!! on 
2023-12-01 17:03:46,365:INFO::its now!!!!!!!!5
2023-12-01 17:03:46,520:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:46,522:INFO::Epoch 00167 | lr 0.00050 | Train_Loss -0.0148 | Train_Classification_Loss 0.0957 | Dmon_Loss -0.2210 | Val_Loss 0.2640 | Search Time(s) 0.4160 | Infer Time(s) 0.1546 | Time(s) 0.5706 
2023-12-01 17:03:46,558:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:46,572:INFO::Validation loss decreased (0.264824 --> 0.264050).  Saving model ...
2023-12-01 17:03:46,576:INFO::Epoch: 168
tensor([[0.7597, 0.7480, 0.7376, 0.8071],
        [0.7433, 0.7886, 0.7580, 0.7619],
        [0.9749, 0.7647, 0.7756, 0.7550],
        [0.9933, 0.8203, 0.7872, 0.8014]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:46,577:INFO::its now!!!!!!!!5
2023-12-01 17:03:46,749:INFO::its now!!!!!!!!0
2023-12-01 17:03:46,749:INFO::its now!!!!!!!!3
2023-12-01 17:03:46,795:INFO::its now!!!!!!!!5
2023-12-01 17:03:46,985:INFO::its now!!!!!!!!
2023-12-01 17:03:46,985:INFO::its now!!!!!!!! on 
2023-12-01 17:03:47,040:INFO::its now!!!!!!!!5
2023-12-01 17:03:47,205:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:47,207:INFO::Epoch 00168 | lr 0.00050 | Train_Loss -0.0159 | Train_Classification_Loss 0.0950 | Dmon_Loss -0.2216 | Val_Loss 0.2639 | Search Time(s) 0.4657 | Infer Time(s) 0.1661 | Time(s) 0.6318 
2023-12-01 17:03:47,252:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:47,253:INFO::Validation loss decreased (0.264050 --> 0.263913).  Saving model ...
2023-12-01 17:03:47,256:INFO::Epoch: 169
tensor([[0.7564, 0.7450, 0.7343, 0.8075],
        [0.7400, 0.7856, 0.7552, 0.7619],
        [0.9731, 0.7615, 0.7757, 0.7519],
        [0.9915, 0.8176, 0.7846, 0.8011]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:47,257:INFO::its now!!!!!!!!5
2023-12-01 17:03:47,416:INFO::its now!!!!!!!!0
2023-12-01 17:03:47,416:INFO::its now!!!!!!!!3
2023-12-01 17:03:47,462:INFO::its now!!!!!!!!5
2023-12-01 17:03:47,619:INFO::its now!!!!!!!!
2023-12-01 17:03:47,619:INFO::its now!!!!!!!! on 
2023-12-01 17:03:47,673:INFO::its now!!!!!!!!5
2023-12-01 17:03:47,842:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:47,843:INFO::Epoch 00169 | lr 0.00050 | Train_Loss -0.0181 | Train_Classification_Loss 0.0930 | Dmon_Loss -0.2223 | Val_Loss 0.2626 | Search Time(s) 0.4145 | Infer Time(s) 0.1735 | Time(s) 0.5880 
2023-12-01 17:03:47,890:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:47,892:INFO::Validation loss decreased (0.263913 --> 0.262558).  Saving model ...
2023-12-01 17:03:47,895:INFO::Epoch: 170
tensor([[0.7513, 0.7405, 0.7297, 0.8077],
        [0.7354, 0.7841, 0.7511, 0.7585],
        [0.9727, 0.7568, 0.7728, 0.7473],
        [0.9922, 0.8135, 0.7805, 0.7982]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:47,896:INFO::its now!!!!!!!!5
2023-12-01 17:03:48,051:INFO::its now!!!!!!!!0
2023-12-01 17:03:48,051:INFO::its now!!!!!!!!3
2023-12-01 17:03:48,096:INFO::its now!!!!!!!!5
2023-12-01 17:03:48,255:INFO::its now!!!!!!!!
2023-12-01 17:03:48,255:INFO::its now!!!!!!!! on 
2023-12-01 17:03:48,308:INFO::its now!!!!!!!!5
2023-12-01 17:03:48,469:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:48,470:INFO::Epoch 00170 | lr 0.00050 | Train_Loss -0.0197 | Train_Classification_Loss 0.0915 | Dmon_Loss -0.2224 | Val_Loss 0.2618 | Search Time(s) 0.4130 | Infer Time(s) 0.1636 | Time(s) 0.5766 
2023-12-01 17:03:48,514:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:48,515:INFO::Validation loss decreased (0.262558 --> 0.261799).  Saving model ...
2023-12-01 17:03:48,520:INFO::Epoch: 171
tensor([[0.7452, 0.7350, 0.7242, 0.8077],
        [0.7299, 0.7833, 0.7461, 0.7533],
        [0.9732, 0.7513, 0.7683, 0.7418],
        [0.9940, 0.8086, 0.7756, 0.7939]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:48,521:INFO::its now!!!!!!!!5
2023-12-01 17:03:48,710:INFO::its now!!!!!!!!0
2023-12-01 17:03:48,711:INFO::its now!!!!!!!!3
2023-12-01 17:03:48,761:INFO::its now!!!!!!!!5
2023-12-01 17:03:48,952:INFO::its now!!!!!!!!
2023-12-01 17:03:48,952:INFO::its now!!!!!!!! on 
2023-12-01 17:03:49,009:INFO::its now!!!!!!!!5
2023-12-01 17:03:49,187:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:49,189:INFO::Epoch 00171 | lr 0.00050 | Train_Loss -0.0236 | Train_Classification_Loss 0.0876 | Dmon_Loss -0.2222 | Val_Loss 0.2609 | Search Time(s) 0.4883 | Infer Time(s) 0.1821 | Time(s) 0.6703 
2023-12-01 17:03:49,246:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:49,247:INFO::Validation loss decreased (0.261799 --> 0.260920).  Saving model ...
2023-12-01 17:03:49,251:INFO::Epoch: 172
tensor([[0.7399, 0.7303, 0.7195, 0.8078],
        [0.7252, 0.7830, 0.7417, 0.7484],
        [0.9739, 0.7466, 0.7642, 0.7369],
        [0.9966, 0.8043, 0.7713, 0.7899]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:49,251:INFO::its now!!!!!!!!5
2023-12-01 17:03:49,436:INFO::its now!!!!!!!!0
2023-12-01 17:03:49,437:INFO::its now!!!!!!!!3
2023-12-01 17:03:49,484:INFO::its now!!!!!!!!5
2023-12-01 17:03:49,660:INFO::its now!!!!!!!!
2023-12-01 17:03:49,660:INFO::its now!!!!!!!! on 
2023-12-01 17:03:49,716:INFO::its now!!!!!!!!5
2023-12-01 17:03:49,911:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:49,913:INFO::Epoch 00172 | lr 0.00050 | Train_Loss -0.0260 | Train_Classification_Loss 0.0857 | Dmon_Loss -0.2233 | Val_Loss 0.2601 | Search Time(s) 0.4669 | Infer Time(s) 0.1975 | Time(s) 0.6643 
2023-12-01 17:03:49,962:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:49,963:INFO::Validation loss decreased (0.260920 --> 0.260115).  Saving model ...
2023-12-01 17:03:49,965:INFO::Epoch: 173
tensor([[0.7350, 0.7258, 0.7151, 0.8078],
        [0.7208, 0.7828, 0.7376, 0.7437],
        [0.9749, 0.7421, 0.7601, 0.7324],
        [0.9997, 0.8002, 0.7673, 0.7860]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:49,966:INFO::its now!!!!!!!!5
2023-12-01 17:03:50,123:INFO::its now!!!!!!!!0
2023-12-01 17:03:50,124:INFO::its now!!!!!!!!3
2023-12-01 17:03:50,172:INFO::its now!!!!!!!!5
2023-12-01 17:03:50,358:INFO::its now!!!!!!!!
2023-12-01 17:03:50,358:INFO::its now!!!!!!!! on 
2023-12-01 17:03:50,417:INFO::its now!!!!!!!!5
2023-12-01 17:03:50,585:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:50,586:INFO::Epoch 00173 | lr 0.00050 | Train_Loss -0.0250 | Train_Classification_Loss 0.0864 | Dmon_Loss -0.2228 | Val_Loss 0.2593 | Search Time(s) 0.4509 | Infer Time(s) 0.1705 | Time(s) 0.6214 
2023-12-01 17:03:50,631:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:50,632:INFO::Validation loss decreased (0.260115 --> 0.259324).  Saving model ...
2023-12-01 17:03:50,634:INFO::Epoch: 174
tensor([[0.7296, 0.7210, 0.7104, 0.8078],
        [0.7161, 0.7827, 0.7332, 0.7385],
        [0.9762, 0.7374, 0.7556, 0.7275],
        [1.0000, 0.7959, 0.7629, 0.7818]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:50,635:INFO::its now!!!!!!!!5
2023-12-01 17:03:50,815:INFO::its now!!!!!!!!0
2023-12-01 17:03:50,816:INFO::its now!!!!!!!!3
2023-12-01 17:03:50,862:INFO::its now!!!!!!!!5
2023-12-01 17:03:51,111:INFO::its now!!!!!!!!
2023-12-01 17:03:51,111:INFO::its now!!!!!!!! on 
2023-12-01 17:03:51,165:INFO::its now!!!!!!!!5
2023-12-01 17:03:51,351:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:51,352:INFO::Epoch 00174 | lr 0.00050 | Train_Loss -0.0300 | Train_Classification_Loss 0.0817 | Dmon_Loss -0.2235 | Val_Loss 0.2586 | Search Time(s) 0.5301 | Infer Time(s) 0.1891 | Time(s) 0.7192 
2023-12-01 17:03:51,393:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:51,394:INFO::Validation loss decreased (0.259324 --> 0.258591).  Saving model ...
2023-12-01 17:03:51,397:INFO::Epoch: 175
tensor([[0.7259, 0.7177, 0.7071, 0.8078],
        [0.7128, 0.7826, 0.7301, 0.7349],
        [0.9774, 0.7341, 0.7525, 0.7241],
        [1.0000, 0.7929, 0.7599, 0.7788]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:51,398:INFO::its now!!!!!!!!5
2023-12-01 17:03:51,539:INFO::its now!!!!!!!!0
2023-12-01 17:03:51,540:INFO::its now!!!!!!!!3
2023-12-01 17:03:51,589:INFO::its now!!!!!!!!5
2023-12-01 17:03:51,750:INFO::its now!!!!!!!!
2023-12-01 17:03:51,750:INFO::its now!!!!!!!! on 
2023-12-01 17:03:51,806:INFO::its now!!!!!!!!5
2023-12-01 17:03:51,968:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:51,969:INFO::Epoch 00175 | lr 0.00050 | Train_Loss -0.0295 | Train_Classification_Loss 0.0822 | Dmon_Loss -0.2234 | Val_Loss 0.2579 | Search Time(s) 0.4099 | Infer Time(s) 0.1626 | Time(s) 0.5725 
2023-12-01 17:03:52,019:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:52,020:INFO::Validation loss decreased (0.258591 --> 0.257910).  Saving model ...
2023-12-01 17:03:52,025:INFO::Epoch: 176
tensor([[0.7208, 0.7131, 0.7025, 0.8078],
        [0.7083, 0.7826, 0.7259, 0.7298],
        [0.9785, 0.7295, 0.7482, 0.7194],
        [1.0000, 0.7887, 0.7558, 0.7747]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:52,027:INFO::its now!!!!!!!!5
2023-12-01 17:03:52,186:INFO::its now!!!!!!!!0
2023-12-01 17:03:52,186:INFO::its now!!!!!!!!3
2023-12-01 17:03:52,233:INFO::its now!!!!!!!!5
2023-12-01 17:03:52,410:INFO::its now!!!!!!!!
2023-12-01 17:03:52,411:INFO::its now!!!!!!!! on 
2023-12-01 17:03:52,464:INFO::its now!!!!!!!!5
2023-12-01 17:03:52,609:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:52,610:INFO::Epoch 00176 | lr 0.00050 | Train_Loss -0.0318 | Train_Classification_Loss 0.0800 | Dmon_Loss -0.2236 | Val_Loss 0.2577 | Search Time(s) 0.4420 | Infer Time(s) 0.1466 | Time(s) 0.5886 
2023-12-01 17:03:52,674:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:52,675:INFO::Validation loss decreased (0.257910 --> 0.257693).  Saving model ...
2023-12-01 17:03:52,679:INFO::Epoch: 177
tensor([[0.7181, 0.7107, 0.7002, 0.8078],
        [0.7059, 0.7826, 0.7237, 0.7272],
        [0.9797, 0.7271, 0.7459, 0.7170],
        [1.0000, 0.7866, 0.7536, 0.7726]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:52,680:INFO::its now!!!!!!!!5
2023-12-01 17:03:52,820:INFO::its now!!!!!!!!0
2023-12-01 17:03:52,821:INFO::its now!!!!!!!!3
2023-12-01 17:03:52,850:INFO::its now!!!!!!!!5
2023-12-01 17:03:52,998:INFO::its now!!!!!!!!
2023-12-01 17:03:52,998:INFO::its now!!!!!!!! on 
2023-12-01 17:03:53,053:INFO::its now!!!!!!!!5
2023-12-01 17:03:53,223:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:53,224:INFO::Epoch 00177 | lr 0.00050 | Train_Loss -0.0277 | Train_Classification_Loss 0.0843 | Dmon_Loss -0.2239 | Val_Loss 0.2568 | Search Time(s) 0.3770 | Infer Time(s) 0.1711 | Time(s) 0.5481 
2023-12-01 17:03:53,273:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:53,274:INFO::Validation loss decreased (0.257693 --> 0.256774).  Saving model ...
2023-12-01 17:03:53,276:INFO::Epoch: 178
tensor([[0.7293, 0.7209, 0.7102, 0.8078],
        [0.7159, 0.7952, 0.7226, 0.7383],
        [0.9927, 0.7372, 0.7453, 0.7273],
        [1.0000, 0.7958, 0.7629, 0.7818]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:53,277:INFO::its now!!!!!!!!5
2023-12-01 17:03:53,439:INFO::its now!!!!!!!!0
2023-12-01 17:03:53,440:INFO::its now!!!!!!!!3
2023-12-01 17:03:53,485:INFO::its now!!!!!!!!5
2023-12-01 17:03:53,660:INFO::its now!!!!!!!!
2023-12-01 17:03:53,660:INFO::its now!!!!!!!! on 
2023-12-01 17:03:53,719:INFO::its now!!!!!!!!5
2023-12-01 17:03:53,887:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:53,889:INFO::Epoch 00178 | lr 0.00050 | Train_Loss -0.0329 | Train_Classification_Loss 0.0792 | Dmon_Loss -0.2240 | Val_Loss 0.2561 | Search Time(s) 0.4434 | Infer Time(s) 0.1695 | Time(s) 0.6129 
2023-12-01 17:03:53,958:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:53,960:INFO::Validation loss decreased (0.256774 --> 0.256066).  Saving model ...
2023-12-01 17:03:53,963:INFO::Epoch: 179
tensor([[0.7362, 0.7260, 0.7164, 0.8091],
        [0.7221, 0.8029, 0.7233, 0.7438],
        [1.0000, 0.7416, 0.7461, 0.7337],
        [1.0000, 0.8016, 0.7686, 0.7858]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:53,963:INFO::its now!!!!!!!!5
2023-12-01 17:03:54,130:INFO::its now!!!!!!!!0
2023-12-01 17:03:54,130:INFO::its now!!!!!!!!3
2023-12-01 17:03:54,179:INFO::its now!!!!!!!!5
2023-12-01 17:03:54,343:INFO::its now!!!!!!!!
2023-12-01 17:03:54,343:INFO::its now!!!!!!!! on 
2023-12-01 17:03:54,401:INFO::its now!!!!!!!!5
2023-12-01 17:03:54,572:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:54,573:INFO::Epoch 00179 | lr 0.00050 | Train_Loss -0.0293 | Train_Classification_Loss 0.0830 | Dmon_Loss -0.2247 | Val_Loss 0.2554 | Search Time(s) 0.4369 | Infer Time(s) 0.1755 | Time(s) 0.6124 
2023-12-01 17:03:54,612:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:54,613:INFO::Validation loss decreased (0.256066 --> 0.255396).  Saving model ...
2023-12-01 17:03:54,616:INFO::Epoch: 180
tensor([[0.7378, 0.7269, 0.7179, 0.8098],
        [0.7236, 0.8068, 0.7220, 0.7448],
        [1.0000, 0.7422, 0.7449, 0.7353],
        [1.0000, 0.8030, 0.7700, 0.7863]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:54,618:INFO::its now!!!!!!!!5
2023-12-01 17:03:54,804:INFO::its now!!!!!!!!0
2023-12-01 17:03:54,805:INFO::its now!!!!!!!!3
2023-12-01 17:03:54,831:INFO::its now!!!!!!!!5
2023-12-01 17:03:54,997:INFO::its now!!!!!!!!
2023-12-01 17:03:54,997:INFO::its now!!!!!!!! on 
2023-12-01 17:03:55,053:INFO::its now!!!!!!!!5
2023-12-01 17:03:55,240:INFO::Epoch 00180 | lr 0.00050 | Train_Loss -0.0364 | Train_Classification_Loss 0.0762 | Dmon_Loss -0.2251 | Val_Loss 0.2558 | Search Time(s) 0.4389 | Infer Time(s) 0.1885 | Time(s) 0.6274 
2023-12-01 17:03:55,300:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:55,301:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:03:55,304:INFO::Epoch: 181
tensor([[0.7439, 0.7321, 0.7187, 0.8154],
        [0.7291, 0.8141, 0.7260, 0.7453],
        [1.0000, 0.7472, 0.7492, 0.7361],
        [1.0000, 0.8081, 0.7708, 0.7909]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:55,304:INFO::its now!!!!!!!!5
2023-12-01 17:03:55,450:INFO::its now!!!!!!!!0
2023-12-01 17:03:55,451:INFO::its now!!!!!!!!3
2023-12-01 17:03:55,491:INFO::its now!!!!!!!!5
2023-12-01 17:03:55,667:INFO::its now!!!!!!!!
2023-12-01 17:03:55,667:INFO::its now!!!!!!!! on 
2023-12-01 17:03:55,720:INFO::its now!!!!!!!!5
2023-12-01 17:03:55,908:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:55,909:INFO::Epoch 00181 | lr 0.00050 | Train_Loss -0.0391 | Train_Classification_Loss 0.0732 | Dmon_Loss -0.2246 | Val_Loss 0.2539 | Search Time(s) 0.4164 | Infer Time(s) 0.1905 | Time(s) 0.6069 
2023-12-01 17:03:55,970:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:55,971:INFO::Validation loss decreased (0.255396 --> 0.253945).  Saving model ...
2023-12-01 17:03:55,973:INFO::Epoch: 182
tensor([[0.7523, 0.7397, 0.7190, 0.8235],
        [0.7367, 0.8177, 0.7329, 0.7510],
        [1.0000, 0.7493, 0.7563, 0.7416],
        [1.0000, 0.8152, 0.7712, 0.7977]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:55,973:INFO::its now!!!!!!!!5
2023-12-01 17:03:56,156:INFO::its now!!!!!!!!0
2023-12-01 17:03:56,157:INFO::its now!!!!!!!!3
2023-12-01 17:03:56,203:INFO::its now!!!!!!!!5
2023-12-01 17:03:56,409:INFO::its now!!!!!!!!
2023-12-01 17:03:56,409:INFO::its now!!!!!!!! on 
2023-12-01 17:03:56,464:INFO::its now!!!!!!!!5
2023-12-01 17:03:56,644:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:56,646:INFO::Epoch 00182 | lr 0.00050 | Train_Loss -0.0393 | Train_Classification_Loss 0.0732 | Dmon_Loss -0.2250 | Val_Loss 0.2533 | Search Time(s) 0.4929 | Infer Time(s) 0.1805 | Time(s) 0.6734 
2023-12-01 17:03:56,693:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:56,695:INFO::Validation loss decreased (0.253945 --> 0.253304).  Saving model ...
2023-12-01 17:03:56,700:INFO::Epoch: 183
tensor([[0.7575, 0.7444, 0.7202, 0.8276],
        [0.7414, 0.8196, 0.7373, 0.7548],
        [1.0000, 0.7513, 0.7608, 0.7453],
        [1.0000, 0.8196, 0.7722, 0.8020]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:56,702:INFO::its now!!!!!!!!5
2023-12-01 17:03:56,854:INFO::its now!!!!!!!!0
2023-12-01 17:03:56,855:INFO::its now!!!!!!!!3
2023-12-01 17:03:56,901:INFO::its now!!!!!!!!5
2023-12-01 17:03:57,097:INFO::its now!!!!!!!!
2023-12-01 17:03:57,097:INFO::its now!!!!!!!! on 
2023-12-01 17:03:57,149:INFO::its now!!!!!!!!5
2023-12-01 17:03:57,291:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:57,292:INFO::Epoch 00183 | lr 0.00050 | Train_Loss -0.0379 | Train_Classification_Loss 0.0749 | Dmon_Loss -0.2254 | Val_Loss 0.2533 | Search Time(s) 0.4534 | Infer Time(s) 0.1422 | Time(s) 0.5955 
2023-12-01 17:03:57,336:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:57,337:INFO::Validation loss decreased (0.253304 --> 0.253265).  Saving model ...
2023-12-01 17:03:57,340:INFO::Epoch: 184
tensor([[0.7581, 0.7449, 0.7188, 0.8297],
        [0.7419, 0.8204, 0.7377, 0.7547],
        [1.0000, 0.7505, 0.7612, 0.7452],
        [1.0000, 0.8201, 0.7710, 0.8024]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:57,341:INFO::its now!!!!!!!!5
2023-12-01 17:03:57,506:INFO::its now!!!!!!!!0
2023-12-01 17:03:57,507:INFO::its now!!!!!!!!3
2023-12-01 17:03:57,551:INFO::its now!!!!!!!!5
2023-12-01 17:03:57,717:INFO::its now!!!!!!!!
2023-12-01 17:03:57,717:INFO::its now!!!!!!!! on 
2023-12-01 17:03:57,771:INFO::its now!!!!!!!!5
2023-12-01 17:03:57,949:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:57,952:INFO::Epoch 00184 | lr 0.00050 | Train_Loss -0.0423 | Train_Classification_Loss 0.0706 | Dmon_Loss -0.2258 | Val_Loss 0.2518 | Search Time(s) 0.4299 | Infer Time(s) 0.1815 | Time(s) 0.6114 
2023-12-01 17:03:57,993:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:57,994:INFO::Validation loss decreased (0.253265 --> 0.251837).  Saving model ...
2023-12-01 17:03:57,998:INFO::Epoch: 185
tensor([[0.7539, 0.7410, 0.7140, 0.8307],
        [0.7381, 0.8209, 0.7338, 0.7502],
        [1.0000, 0.7459, 0.7572, 0.7410],
        [1.0000, 0.8165, 0.7665, 0.7989]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:57,998:INFO::its now!!!!!!!!5
2023-12-01 17:03:58,153:INFO::its now!!!!!!!!0
2023-12-01 17:03:58,153:INFO::its now!!!!!!!!3
2023-12-01 17:03:58,197:INFO::its now!!!!!!!!5
2023-12-01 17:03:58,364:INFO::its now!!!!!!!!
2023-12-01 17:03:58,364:INFO::its now!!!!!!!! on 
2023-12-01 17:03:58,418:INFO::its now!!!!!!!!5
2023-12-01 17:03:58,586:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:58,588:INFO::Epoch 00185 | lr 0.00050 | Train_Loss -0.0379 | Train_Classification_Loss 0.0746 | Dmon_Loss -0.2251 | Val_Loss 0.2512 | Search Time(s) 0.4210 | Infer Time(s) 0.1716 | Time(s) 0.5926 
2023-12-01 17:03:58,645:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:58,646:INFO::Validation loss decreased (0.251837 --> 0.251151).  Saving model ...
2023-12-01 17:03:58,648:INFO::Epoch: 186
tensor([[0.7464, 0.7341, 0.7067, 0.8312],
        [0.7313, 0.8211, 0.7270, 0.7425],
        [1.0000, 0.7387, 0.7502, 0.7338],
        [1.0000, 0.8102, 0.7597, 0.7925]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:58,649:INFO::its now!!!!!!!!5
2023-12-01 17:03:58,831:INFO::its now!!!!!!!!0
2023-12-01 17:03:58,832:INFO::its now!!!!!!!!3
2023-12-01 17:03:58,880:INFO::its now!!!!!!!!5
2023-12-01 17:03:59,068:INFO::its now!!!!!!!!
2023-12-01 17:03:59,068:INFO::its now!!!!!!!! on 
2023-12-01 17:03:59,124:INFO::its now!!!!!!!!5
2023-12-01 17:03:59,288:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:59,291:INFO::Epoch 00186 | lr 0.00050 | Train_Loss -0.0437 | Train_Classification_Loss 0.0692 | Dmon_Loss -0.2259 | Val_Loss 0.2505 | Search Time(s) 0.4743 | Infer Time(s) 0.1680 | Time(s) 0.6423 
2023-12-01 17:03:59,340:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:59,341:INFO::Validation loss decreased (0.251151 --> 0.250549).  Saving model ...
2023-12-01 17:03:59,345:INFO::Epoch: 187
tensor([[0.7386, 0.7269, 0.6991, 0.8315],
        [0.7242, 0.8212, 0.7198, 0.7345],
        [1.0000, 0.7312, 0.7429, 0.7263],
        [1.0000, 0.8035, 0.7527, 0.7859]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:59,345:INFO::its now!!!!!!!!5
2023-12-01 17:03:59,502:INFO::its now!!!!!!!!0
2023-12-01 17:03:59,503:INFO::its now!!!!!!!!3
2023-12-01 17:03:59,550:INFO::its now!!!!!!!!5
2023-12-01 17:03:59,727:INFO::its now!!!!!!!!
2023-12-01 17:03:59,727:INFO::its now!!!!!!!! on 
2023-12-01 17:03:59,783:INFO::its now!!!!!!!!5
2023-12-01 17:03:59,923:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:03:59,924:INFO::Epoch 00187 | lr 0.00050 | Train_Loss -0.0392 | Train_Classification_Loss 0.0734 | Dmon_Loss -0.2252 | Val_Loss 0.2499 | Search Time(s) 0.4388 | Infer Time(s) 0.1426 | Time(s) 0.5814 
2023-12-01 17:03:59,972:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:03:59,973:INFO::Validation loss decreased (0.250549 --> 0.249944).  Saving model ...
2023-12-01 17:03:59,975:INFO::Epoch: 188
tensor([[0.7356, 0.7242, 0.6963, 0.8316],
        [0.7216, 0.8213, 0.7172, 0.7315],
        [1.0000, 0.7284, 0.7401, 0.7235],
        [1.0000, 0.8010, 0.7501, 0.7834]], device='cuda:0', requires_grad=True)
2023-12-01 17:03:59,975:INFO::its now!!!!!!!!5
2023-12-01 17:04:00,133:INFO::its now!!!!!!!!0
2023-12-01 17:04:00,134:INFO::its now!!!!!!!!3
2023-12-01 17:04:00,177:INFO::its now!!!!!!!!5
2023-12-01 17:04:00,343:INFO::its now!!!!!!!!
2023-12-01 17:04:00,343:INFO::its now!!!!!!!! on 
2023-12-01 17:04:00,396:INFO::its now!!!!!!!!5
2023-12-01 17:04:00,569:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:00,570:INFO::Epoch 00188 | lr 0.00050 | Train_Loss -0.0456 | Train_Classification_Loss 0.0674 | Dmon_Loss -0.2259 | Val_Loss 0.2494 | Search Time(s) 0.4215 | Infer Time(s) 0.1745 | Time(s) 0.5961 
2023-12-01 17:04:00,620:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:00,621:INFO::Validation loss decreased (0.249944 --> 0.249422).  Saving model ...
2023-12-01 17:04:00,624:INFO::Epoch: 189
tensor([[0.7339, 0.7226, 0.6946, 0.8317],
        [0.7200, 0.8213, 0.7156, 0.7297],
        [1.0000, 0.7268, 0.7385, 0.7219],
        [1.0000, 0.7995, 0.7485, 0.7819]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:00,626:INFO::its now!!!!!!!!5
2023-12-01 17:04:00,808:INFO::its now!!!!!!!!0
2023-12-01 17:04:00,808:INFO::its now!!!!!!!!3
2023-12-01 17:04:00,856:INFO::its now!!!!!!!!5
2023-12-01 17:04:01,035:INFO::its now!!!!!!!!
2023-12-01 17:04:01,036:INFO::its now!!!!!!!! on 
2023-12-01 17:04:01,093:INFO::its now!!!!!!!!5
2023-12-01 17:04:01,264:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:01,266:INFO::Epoch 00189 | lr 0.00050 | Train_Loss -0.0423 | Train_Classification_Loss 0.0707 | Dmon_Loss -0.2260 | Val_Loss 0.2490 | Search Time(s) 0.4697 | Infer Time(s) 0.1741 | Time(s) 0.6439 
2023-12-01 17:04:01,305:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:01,306:INFO::Validation loss decreased (0.249422 --> 0.248968).  Saving model ...
2023-12-01 17:04:01,308:INFO::Epoch: 190
tensor([[0.7309, 0.7198, 0.6918, 0.8317],
        [0.7172, 0.8213, 0.7129, 0.7267],
        [1.0000, 0.7240, 0.7357, 0.7190],
        [1.0000, 0.7970, 0.7459, 0.7794]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:01,309:INFO::its now!!!!!!!!5
2023-12-01 17:04:01,450:INFO::its now!!!!!!!!0
2023-12-01 17:04:01,451:INFO::its now!!!!!!!!3
2023-12-01 17:04:01,492:INFO::its now!!!!!!!!5
2023-12-01 17:04:01,635:INFO::its now!!!!!!!!
2023-12-01 17:04:01,636:INFO::its now!!!!!!!! on 
2023-12-01 17:04:01,689:INFO::its now!!!!!!!!5
2023-12-01 17:04:01,851:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:01,853:INFO::Epoch 00190 | lr 0.00050 | Train_Loss -0.0457 | Train_Classification_Loss 0.0674 | Dmon_Loss -0.2262 | Val_Loss 0.2486 | Search Time(s) 0.3800 | Infer Time(s) 0.1656 | Time(s) 0.5455 
2023-12-01 17:04:01,905:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:01,906:INFO::Validation loss decreased (0.248968 --> 0.248553).  Saving model ...
2023-12-01 17:04:01,909:INFO::Epoch: 191
tensor([[0.7330, 0.7217, 0.6938, 0.8317],
        [0.7191, 0.8213, 0.7148, 0.7288],
        [1.0000, 0.7259, 0.7376, 0.7176],
        [1.0000, 0.7987, 0.7477, 0.7775]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:01,910:INFO::its now!!!!!!!!5
2023-12-01 17:04:02,085:INFO::its now!!!!!!!!0
2023-12-01 17:04:02,086:INFO::its now!!!!!!!!3
2023-12-01 17:04:02,131:INFO::its now!!!!!!!!5
2023-12-01 17:04:02,323:INFO::its now!!!!!!!!
2023-12-01 17:04:02,323:INFO::its now!!!!!!!! on 
2023-12-01 17:04:02,375:INFO::its now!!!!!!!!5
2023-12-01 17:04:02,537:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:02,539:INFO::Epoch 00191 | lr 0.00050 | Train_Loss -0.0456 | Train_Classification_Loss 0.0672 | Dmon_Loss -0.2255 | Val_Loss 0.2482 | Search Time(s) 0.4649 | Infer Time(s) 0.1646 | Time(s) 0.6295 
2023-12-01 17:04:02,579:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:02,580:INFO::Validation loss decreased (0.248553 --> 0.248186).  Saving model ...
2023-12-01 17:04:02,583:INFO::Epoch: 192
tensor([[0.7310, 0.7199, 0.6919, 0.8317],
        [0.7173, 0.8213, 0.7129, 0.7268],
        [1.0000, 0.7240, 0.7357, 0.7140],
        [1.0000, 0.7970, 0.7459, 0.7739]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:02,584:INFO::its now!!!!!!!!5
2023-12-01 17:04:02,764:INFO::its now!!!!!!!!0
2023-12-01 17:04:02,765:INFO::its now!!!!!!!!3
2023-12-01 17:04:02,814:INFO::its now!!!!!!!!5
2023-12-01 17:04:02,972:INFO::its now!!!!!!!!
2023-12-01 17:04:02,972:INFO::its now!!!!!!!! on 
2023-12-01 17:04:03,028:INFO::its now!!!!!!!!5
2023-12-01 17:04:03,185:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:03,186:INFO::Epoch 00192 | lr 0.00050 | Train_Loss -0.0464 | Train_Classification_Loss 0.0668 | Dmon_Loss -0.2264 | Val_Loss 0.2479 | Search Time(s) 0.4458 | Infer Time(s) 0.1582 | Time(s) 0.6040 
2023-12-01 17:04:03,227:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:03,228:INFO::Validation loss decreased (0.248186 --> 0.247898).  Saving model ...
2023-12-01 17:04:03,231:INFO::Epoch: 193
tensor([[0.7285, 0.7176, 0.6895, 0.8317],
        [0.7150, 0.8213, 0.7107, 0.7243],
        [1.0000, 0.7217, 0.7334, 0.7108],
        [1.0000, 0.7949, 0.7438, 0.7709]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:03,231:INFO::its now!!!!!!!!5
2023-12-01 17:04:03,395:INFO::its now!!!!!!!!0
2023-12-01 17:04:03,396:INFO::its now!!!!!!!!3
2023-12-01 17:04:03,441:INFO::its now!!!!!!!!5
2023-12-01 17:04:03,612:INFO::its now!!!!!!!!
2023-12-01 17:04:03,612:INFO::its now!!!!!!!! on 
2023-12-01 17:04:03,669:INFO::its now!!!!!!!!5
2023-12-01 17:04:03,848:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:03,849:INFO::Epoch 00193 | lr 0.00050 | Train_Loss -0.0415 | Train_Classification_Loss 0.0718 | Dmon_Loss -0.2265 | Val_Loss 0.2476 | Search Time(s) 0.4374 | Infer Time(s) 0.1825 | Time(s) 0.6199 
2023-12-01 17:04:03,901:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:03,903:INFO::Validation loss decreased (0.247898 --> 0.247609).  Saving model ...
2023-12-01 17:04:03,906:INFO::Epoch: 194
tensor([[0.7298, 0.7188, 0.6908, 0.8317],
        [0.7163, 0.8213, 0.7119, 0.7256],
        [1.0000, 0.7230, 0.7347, 0.7116],
        [1.0000, 0.7960, 0.7449, 0.7716]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:03,907:INFO::its now!!!!!!!!5
2023-12-01 17:04:04,064:INFO::its now!!!!!!!!0
2023-12-01 17:04:04,065:INFO::its now!!!!!!!!3
2023-12-01 17:04:04,112:INFO::its now!!!!!!!!5
2023-12-01 17:04:04,267:INFO::its now!!!!!!!!
2023-12-01 17:04:04,268:INFO::its now!!!!!!!! on 
2023-12-01 17:04:04,325:INFO::its now!!!!!!!!5
2023-12-01 17:04:04,466:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:04,467:INFO::Epoch 00194 | lr 0.00050 | Train_Loss -0.0482 | Train_Classification_Loss 0.0654 | Dmon_Loss -0.2272 | Val_Loss 0.2473 | Search Time(s) 0.4180 | Infer Time(s) 0.1446 | Time(s) 0.5626 
2023-12-01 17:04:04,504:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:04,505:INFO::Validation loss decreased (0.247609 --> 0.247269).  Saving model ...
2023-12-01 17:04:04,509:INFO::Epoch: 195
tensor([[0.7274, 0.7166, 0.6885, 0.8317],
        [0.7140, 0.8213, 0.7097, 0.7232],
        [1.0000, 0.7207, 0.7324, 0.7091],
        [1.0000, 0.7940, 0.7428, 0.7692]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:04,510:INFO::its now!!!!!!!!5
2023-12-01 17:04:04,656:INFO::its now!!!!!!!!0
2023-12-01 17:04:04,657:INFO::its now!!!!!!!!3
2023-12-01 17:04:04,700:INFO::its now!!!!!!!!5
2023-12-01 17:04:04,851:INFO::its now!!!!!!!!
2023-12-01 17:04:04,852:INFO::its now!!!!!!!! on 
2023-12-01 17:04:04,907:INFO::its now!!!!!!!!5
2023-12-01 17:04:05,074:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:05,077:INFO::Epoch 00195 | lr 0.00050 | Train_Loss -0.0460 | Train_Classification_Loss 0.0676 | Dmon_Loss -0.2272 | Val_Loss 0.2470 | Search Time(s) 0.3999 | Infer Time(s) 0.1696 | Time(s) 0.5695 
2023-12-01 17:04:05,119:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:05,120:INFO::Validation loss decreased (0.247269 --> 0.247015).  Saving model ...
2023-12-01 17:04:05,123:INFO::Epoch: 196
tensor([[0.7298, 0.7154, 0.6908, 0.8356],
        [0.7163, 0.8253, 0.7086, 0.7256],
        [1.0000, 0.7192, 0.7347, 0.7113],
        [1.0000, 0.7960, 0.7418, 0.7712]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:05,124:INFO::its now!!!!!!!!5
2023-12-01 17:04:05,270:INFO::its now!!!!!!!!0
2023-12-01 17:04:05,271:INFO::its now!!!!!!!!3
2023-12-01 17:04:05,316:INFO::its now!!!!!!!!5
2023-12-01 17:04:05,487:INFO::its now!!!!!!!!
2023-12-01 17:04:05,487:INFO::its now!!!!!!!! on 
2023-12-01 17:04:05,540:INFO::its now!!!!!!!!5
2023-12-01 17:04:05,702:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:05,704:INFO::Epoch 00196 | lr 0.00050 | Train_Loss -0.0490 | Train_Classification_Loss 0.0645 | Dmon_Loss -0.2272 | Val_Loss 0.2468 | Search Time(s) 0.4155 | Infer Time(s) 0.1656 | Time(s) 0.5810 
2023-12-01 17:04:05,749:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:05,750:INFO::Validation loss decreased (0.247015 --> 0.246770).  Saving model ...
2023-12-01 17:04:05,752:INFO::Epoch: 197
tensor([[0.7311, 0.7149, 0.6920, 0.8375],
        [0.7174, 0.8273, 0.7080, 0.7269],
        [1.0000, 0.7184, 0.7358, 0.7124],
        [1.0000, 0.7971, 0.7413, 0.7722]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:05,753:INFO::its now!!!!!!!!5
2023-12-01 17:04:05,886:INFO::its now!!!!!!!!0
2023-12-01 17:04:05,887:INFO::its now!!!!!!!!3
2023-12-01 17:04:05,933:INFO::its now!!!!!!!!5
2023-12-01 17:04:06,109:INFO::its now!!!!!!!!
2023-12-01 17:04:06,109:INFO::its now!!!!!!!! on 
2023-12-01 17:04:06,162:INFO::its now!!!!!!!!5
2023-12-01 17:04:06,331:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:06,333:INFO::Epoch 00197 | lr 0.00050 | Train_Loss -0.0527 | Train_Classification_Loss 0.0609 | Dmon_Loss -0.2273 | Val_Loss 0.2465 | Search Time(s) 0.4105 | Infer Time(s) 0.1711 | Time(s) 0.5816 
2023-12-01 17:04:06,384:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:06,385:INFO::Validation loss decreased (0.246770 --> 0.246519).  Saving model ...
2023-12-01 17:04:06,388:INFO::Epoch: 198
tensor([[0.7323, 0.7151, 0.6931, 0.8385],
        [0.7185, 0.8283, 0.7083, 0.7281],
        [1.0000, 0.7185, 0.7369, 0.7135],
        [1.0000, 0.7981, 0.7416, 0.7732]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:06,390:INFO::its now!!!!!!!!5
2023-12-01 17:04:06,549:INFO::its now!!!!!!!!0
2023-12-01 17:04:06,550:INFO::its now!!!!!!!!3
2023-12-01 17:04:06,597:INFO::its now!!!!!!!!5
2023-12-01 17:04:06,747:INFO::its now!!!!!!!!
2023-12-01 17:04:06,748:INFO::its now!!!!!!!! on 
2023-12-01 17:04:06,804:INFO::its now!!!!!!!!5
2023-12-01 17:04:06,971:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:06,973:INFO::Epoch 00198 | lr 0.00050 | Train_Loss -0.0536 | Train_Classification_Loss 0.0601 | Dmon_Loss -0.2275 | Val_Loss 0.2461 | Search Time(s) 0.4149 | Infer Time(s) 0.1705 | Time(s) 0.5854 
2023-12-01 17:04:07,024:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:07,025:INFO::Validation loss decreased (0.246519 --> 0.246086).  Saving model ...
2023-12-01 17:04:07,027:INFO::Epoch: 199
tensor([[0.7450, 0.7153, 0.7051, 0.8518],
        [0.7190, 0.8420, 0.7197, 0.7409],
        [1.0000, 0.7186, 0.7490, 0.7258],
        [1.0000, 0.8093, 0.7525, 0.7844]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:07,028:INFO::its now!!!!!!!!5
2023-12-01 17:04:07,169:INFO::its now!!!!!!!!0
2023-12-01 17:04:07,170:INFO::its now!!!!!!!!3
2023-12-01 17:04:07,215:INFO::its now!!!!!!!!5
2023-12-01 17:04:07,406:INFO::its now!!!!!!!!
2023-12-01 17:04:07,407:INFO::its now!!!!!!!! on 
2023-12-01 17:04:07,462:INFO::its now!!!!!!!!5
2023-12-01 17:04:07,648:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:07,650:INFO::Epoch 00199 | lr 0.00050 | Train_Loss -0.0544 | Train_Classification_Loss 0.0591 | Dmon_Loss -0.2270 | Val_Loss 0.2457 | Search Time(s) 0.4321 | Infer Time(s) 0.1905 | Time(s) 0.6225 
2023-12-01 17:04:07,704:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:07,705:INFO::Validation loss decreased (0.246086 --> 0.245739).  Saving model ...
2023-12-01 17:04:07,708:INFO::Epoch: 200
tensor([[0.7534, 0.7173, 0.7129, 0.8584],
        [0.7212, 0.8489, 0.7272, 0.7493],
        [1.0000, 0.7206, 0.7569, 0.7337],
        [1.0000, 0.8166, 0.7598, 0.7917]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:07,709:INFO::its now!!!!!!!!5
2023-12-01 17:04:07,860:INFO::its now!!!!!!!!0
2023-12-01 17:04:07,861:INFO::its now!!!!!!!!3
2023-12-01 17:04:07,911:INFO::its now!!!!!!!!5
2023-12-01 17:04:08,093:INFO::its now!!!!!!!!
2023-12-01 17:04:08,093:INFO::its now!!!!!!!! on 
2023-12-01 17:04:08,150:INFO::its now!!!!!!!!5
2023-12-01 17:04:08,289:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:08,291:INFO::Epoch 00200 | lr 0.00050 | Train_Loss -0.0543 | Train_Classification_Loss 0.0593 | Dmon_Loss -0.2272 | Val_Loss 0.2454 | Search Time(s) 0.4411 | Infer Time(s) 0.1432 | Time(s) 0.5843 
2023-12-01 17:04:08,329:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:08,331:INFO::Validation loss decreased (0.245739 --> 0.245405).  Saving model ...
2023-12-01 17:04:08,334:INFO::Epoch: 201
tensor([[0.7590, 0.7197, 0.7182, 0.8618],
        [0.7237, 0.8524, 0.7323, 0.7549],
        [1.0000, 0.7230, 0.7622, 0.7391],
        [1.0000, 0.8215, 0.7646, 0.7965]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:08,335:INFO::its now!!!!!!!!5
2023-12-01 17:04:08,485:INFO::its now!!!!!!!!0
2023-12-01 17:04:08,486:INFO::its now!!!!!!!!3
2023-12-01 17:04:08,531:INFO::its now!!!!!!!!5
2023-12-01 17:04:08,680:INFO::its now!!!!!!!!
2023-12-01 17:04:08,681:INFO::its now!!!!!!!! on 
2023-12-01 17:04:08,737:INFO::its now!!!!!!!!5
2023-12-01 17:04:08,869:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:08,871:INFO::Epoch 00201 | lr 0.00050 | Train_Loss -0.0579 | Train_Classification_Loss 0.0563 | Dmon_Loss -0.2284 | Val_Loss 0.2450 | Search Time(s) 0.4019 | Infer Time(s) 0.1356 | Time(s) 0.5376 
2023-12-01 17:04:08,914:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:08,915:INFO::Validation loss decreased (0.245405 --> 0.245044).  Saving model ...
2023-12-01 17:04:08,918:INFO::Epoch: 202
tensor([[0.7719, 0.7311, 0.7305, 0.8634],
        [0.7350, 0.8651, 0.7349, 0.7680],
        [1.0000, 0.7244, 0.7745, 0.7515],
        [1.0000, 0.8329, 0.7762, 0.8080]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:08,919:INFO::its now!!!!!!!!5
2023-12-01 17:04:09,078:INFO::its now!!!!!!!!0
2023-12-01 17:04:09,078:INFO::its now!!!!!!!!3
2023-12-01 17:04:09,122:INFO::its now!!!!!!!!5
2023-12-01 17:04:09,283:INFO::its now!!!!!!!!
2023-12-01 17:04:09,283:INFO::its now!!!!!!!! on 
2023-12-01 17:04:09,338:INFO::its now!!!!!!!!5
2023-12-01 17:04:09,484:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:09,494:INFO::Epoch 00202 | lr 0.00050 | Train_Loss -0.0604 | Train_Classification_Loss 0.0538 | Dmon_Loss -0.2284 | Val_Loss 0.2447 | Search Time(s) 0.4190 | Infer Time(s) 0.1496 | Time(s) 0.5686 
2023-12-01 17:04:09,533:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:09,534:INFO::Validation loss decreased (0.245044 --> 0.244676).  Saving model ...
2023-12-01 17:04:09,536:INFO::Epoch: 203
tensor([[0.7757, 0.7342, 0.7341, 0.8643],
        [0.7380, 0.8715, 0.7335, 0.7718],
        [1.0000, 0.7222, 0.7781, 0.7552],
        [1.0000, 0.8363, 0.7796, 0.8114]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:09,536:INFO::its now!!!!!!!!5
2023-12-01 17:04:09,692:INFO::its now!!!!!!!!0
2023-12-01 17:04:09,692:INFO::its now!!!!!!!!3
2023-12-01 17:04:09,740:INFO::its now!!!!!!!!5
2023-12-01 17:04:09,881:INFO::its now!!!!!!!!
2023-12-01 17:04:09,881:INFO::its now!!!!!!!! on 
2023-12-01 17:04:09,939:INFO::its now!!!!!!!!5
2023-12-01 17:04:10,100:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:10,101:INFO::Epoch 00203 | lr 0.00050 | Train_Loss -0.0545 | Train_Classification_Loss 0.0593 | Dmon_Loss -0.2275 | Val_Loss 0.2444 | Search Time(s) 0.4009 | Infer Time(s) 0.1651 | Time(s) 0.5660 
2023-12-01 17:04:10,149:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:10,151:INFO::Validation loss decreased (0.244676 --> 0.244427).  Saving model ...
2023-12-01 17:04:10,154:INFO::Epoch: 204
tensor([[0.7755, 0.7336, 0.7339, 0.8647],
        [0.7374, 0.8747, 0.7308, 0.7716],
        [1.0000, 0.7190, 0.7779, 0.7550],
        [1.0000, 0.8361, 0.7794, 0.8112]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:10,154:INFO::its now!!!!!!!!5
2023-12-01 17:04:10,309:INFO::its now!!!!!!!!0
2023-12-01 17:04:10,310:INFO::its now!!!!!!!!3
2023-12-01 17:04:10,356:INFO::its now!!!!!!!!5
2023-12-01 17:04:10,535:INFO::its now!!!!!!!!
2023-12-01 17:04:10,535:INFO::its now!!!!!!!! on 
2023-12-01 17:04:10,589:INFO::its now!!!!!!!!5
2023-12-01 17:04:10,751:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:10,753:INFO::Epoch 00204 | lr 0.00050 | Train_Loss -0.0574 | Train_Classification_Loss 0.0569 | Dmon_Loss -0.2286 | Val_Loss 0.2441 | Search Time(s) 0.4354 | Infer Time(s) 0.1646 | Time(s) 0.5999 
2023-12-01 17:04:10,804:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:10,806:INFO::Validation loss decreased (0.244427 --> 0.244148).  Saving model ...
2023-12-01 17:04:10,808:INFO::Epoch: 205
tensor([[0.7743, 0.7321, 0.7327, 0.8649],
        [0.7360, 0.8763, 0.7283, 0.7703],
        [1.0000, 0.7161, 0.7767, 0.7538],
        [1.0000, 0.8350, 0.7783, 0.8101]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:10,809:INFO::its now!!!!!!!!5
2023-12-01 17:04:10,971:INFO::its now!!!!!!!!0
2023-12-01 17:04:10,972:INFO::its now!!!!!!!!3
2023-12-01 17:04:11,019:INFO::its now!!!!!!!!5
2023-12-01 17:04:11,191:INFO::its now!!!!!!!!
2023-12-01 17:04:11,192:INFO::its now!!!!!!!! on 
2023-12-01 17:04:11,245:INFO::its now!!!!!!!!5
2023-12-01 17:04:11,391:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:11,393:INFO::Epoch 00205 | lr 0.00050 | Train_Loss -0.0584 | Train_Classification_Loss 0.0560 | Dmon_Loss -0.2287 | Val_Loss 0.2438 | Search Time(s) 0.4364 | Infer Time(s) 0.1492 | Time(s) 0.5856 
2023-12-01 17:04:11,440:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:11,441:INFO::Validation loss decreased (0.244148 --> 0.243832).  Saving model ...
2023-12-01 17:04:11,444:INFO::Epoch: 206
tensor([[0.7717, 0.7294, 0.7302, 0.8650],
        [0.7333, 0.8771, 0.7251, 0.7677],
        [1.0000, 0.7126, 0.7742, 0.7513],
        [1.0000, 0.8327, 0.7759, 0.8078]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:11,445:INFO::its now!!!!!!!!5
2023-12-01 17:04:11,605:INFO::its now!!!!!!!!0
2023-12-01 17:04:11,606:INFO::its now!!!!!!!!3
2023-12-01 17:04:11,655:INFO::its now!!!!!!!!5
2023-12-01 17:04:11,797:INFO::its now!!!!!!!!
2023-12-01 17:04:11,797:INFO::its now!!!!!!!! on 
2023-12-01 17:04:11,854:INFO::its now!!!!!!!!5
2023-12-01 17:04:12,024:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:12,026:INFO::Epoch 00206 | lr 0.00050 | Train_Loss -0.0592 | Train_Classification_Loss 0.0548 | Dmon_Loss -0.2280 | Val_Loss 0.2436 | Search Time(s) 0.4089 | Infer Time(s) 0.1725 | Time(s) 0.5814 
2023-12-01 17:04:12,088:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:12,089:INFO::Validation loss decreased (0.243832 --> 0.243596).  Saving model ...
2023-12-01 17:04:12,092:INFO::Epoch: 207
tensor([[0.7688, 0.7265, 0.7274, 0.8651],
        [0.7304, 0.8775, 0.7220, 0.7648],
        [1.0000, 0.7091, 0.7715, 0.7485],
        [1.0000, 0.8301, 0.7733, 0.8052]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:12,092:INFO::its now!!!!!!!!5
2023-12-01 17:04:12,236:INFO::its now!!!!!!!!0
2023-12-01 17:04:12,236:INFO::its now!!!!!!!!3
2023-12-01 17:04:12,283:INFO::its now!!!!!!!!5
2023-12-01 17:04:12,434:INFO::its now!!!!!!!!
2023-12-01 17:04:12,434:INFO::its now!!!!!!!! on 
2023-12-01 17:04:12,487:INFO::its now!!!!!!!!5
2023-12-01 17:04:12,649:INFO::Epoch 00207 | lr 0.00050 | Train_Loss -0.0528 | Train_Classification_Loss 0.0613 | Dmon_Loss -0.2282 | Val_Loss 0.2442 | Search Time(s) 0.3941 | Infer Time(s) 0.1656 | Time(s) 0.5596 
2023-12-01 17:04:12,693:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:12,693:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:04:12,698:INFO::Epoch: 208
tensor([[0.7651, 0.7228, 0.7240, 0.8651],
        [0.7269, 0.8777, 0.7183, 0.7611],
        [1.0000, 0.7052, 0.7680, 0.7450],
        [1.0000, 0.8269, 0.7701, 0.8020]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:12,699:INFO::its now!!!!!!!!5
2023-12-01 17:04:12,847:INFO::its now!!!!!!!!0
2023-12-01 17:04:12,847:INFO::its now!!!!!!!!3
2023-12-01 17:04:12,894:INFO::its now!!!!!!!!5
2023-12-01 17:04:13,080:INFO::its now!!!!!!!!
2023-12-01 17:04:13,080:INFO::its now!!!!!!!! on 
2023-12-01 17:04:13,136:INFO::its now!!!!!!!!5
2023-12-01 17:04:13,314:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:13,316:INFO::Epoch 00208 | lr 0.00050 | Train_Loss -0.0575 | Train_Classification_Loss 0.0572 | Dmon_Loss -0.2293 | Val_Loss 0.2429 | Search Time(s) 0.4409 | Infer Time(s) 0.1790 | Time(s) 0.6200 
2023-12-01 17:04:13,367:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:13,369:INFO::Validation loss decreased (0.243596 --> 0.242880).  Saving model ...
2023-12-01 17:04:13,371:INFO::Epoch: 209
tensor([[0.7644, 0.7221, 0.7233, 0.8651],
        [0.7261, 0.8778, 0.7175, 0.7604],
        [1.0000, 0.7043, 0.7674, 0.7443],
        [1.0000, 0.8263, 0.7694, 0.8013]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:13,372:INFO::its now!!!!!!!!5
2023-12-01 17:04:13,533:INFO::its now!!!!!!!!0
2023-12-01 17:04:13,534:INFO::its now!!!!!!!!3
2023-12-01 17:04:13,581:INFO::its now!!!!!!!!5
2023-12-01 17:04:13,742:INFO::its now!!!!!!!!
2023-12-01 17:04:13,742:INFO::its now!!!!!!!! on 
2023-12-01 17:04:13,801:INFO::its now!!!!!!!!5
2023-12-01 17:04:13,955:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:13,956:INFO::Epoch 00209 | lr 0.00050 | Train_Loss -0.0611 | Train_Classification_Loss 0.0535 | Dmon_Loss -0.2292 | Val_Loss 0.2426 | Search Time(s) 0.4279 | Infer Time(s) 0.1586 | Time(s) 0.5864 
2023-12-01 17:04:13,993:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:13,995:INFO::Validation loss decreased (0.242880 --> 0.242571).  Saving model ...
2023-12-01 17:04:13,998:INFO::Epoch: 210
tensor([[0.7648, 0.7224, 0.7237, 0.8651],
        [0.7265, 0.8779, 0.7178, 0.7608],
        [1.0000, 0.7046, 0.7677, 0.7446],
        [1.0000, 0.8266, 0.7697, 0.8016]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:13,999:INFO::its now!!!!!!!!5
2023-12-01 17:04:14,161:INFO::its now!!!!!!!!0
2023-12-01 17:04:14,161:INFO::its now!!!!!!!!3
2023-12-01 17:04:14,207:INFO::its now!!!!!!!!5
2023-12-01 17:04:14,363:INFO::its now!!!!!!!!
2023-12-01 17:04:14,363:INFO::its now!!!!!!!! on 
2023-12-01 17:04:14,417:INFO::its now!!!!!!!!5
2023-12-01 17:04:14,571:INFO::Epoch 00210 | lr 0.00050 | Train_Loss -0.0613 | Train_Classification_Loss 0.0529 | Dmon_Loss -0.2285 | Val_Loss 0.2428 | Search Time(s) 0.4177 | Infer Time(s) 0.1576 | Time(s) 0.5752 
2023-12-01 17:04:14,615:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:14,616:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:04:14,618:INFO::Epoch: 211
tensor([[0.7666, 0.7242, 0.7254, 0.8651],
        [0.7282, 0.8779, 0.7196, 0.7626],
        [1.0000, 0.7065, 0.7694, 0.7464],
        [1.0000, 0.8282, 0.7713, 0.8032]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:14,619:INFO::its now!!!!!!!!5
2023-12-01 17:04:14,770:INFO::its now!!!!!!!!0
2023-12-01 17:04:14,771:INFO::its now!!!!!!!!3
2023-12-01 17:04:14,819:INFO::its now!!!!!!!!5
2023-12-01 17:04:15,015:INFO::its now!!!!!!!!
2023-12-01 17:04:15,016:INFO::its now!!!!!!!! on 
2023-12-01 17:04:15,074:INFO::its now!!!!!!!!5
2023-12-01 17:04:15,243:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:15,245:INFO::Epoch 00211 | lr 0.00050 | Train_Loss -0.0587 | Train_Classification_Loss 0.0559 | Dmon_Loss -0.2292 | Val_Loss 0.2421 | Search Time(s) 0.4548 | Infer Time(s) 0.1721 | Time(s) 0.6269 
2023-12-01 17:04:15,286:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:15,287:INFO::Validation loss decreased (0.242571 --> 0.242149).  Saving model ...
2023-12-01 17:04:15,290:INFO::Epoch: 212
tensor([[0.7671, 0.7248, 0.7259, 0.8651],
        [0.7288, 0.8779, 0.7201, 0.7631],
        [1.0000, 0.7070, 0.7699, 0.7469],
        [1.0000, 0.8286, 0.7718, 0.8037]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:15,291:INFO::its now!!!!!!!!5
2023-12-01 17:04:15,450:INFO::its now!!!!!!!!0
2023-12-01 17:04:15,451:INFO::its now!!!!!!!!3
2023-12-01 17:04:15,497:INFO::its now!!!!!!!!5
2023-12-01 17:04:15,675:INFO::its now!!!!!!!!
2023-12-01 17:04:15,676:INFO::its now!!!!!!!! on 
2023-12-01 17:04:15,733:INFO::its now!!!!!!!!5
2023-12-01 17:04:15,886:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:15,887:INFO::Epoch 00212 | lr 0.00050 | Train_Loss -0.0639 | Train_Classification_Loss 0.0510 | Dmon_Loss -0.2298 | Val_Loss 0.2420 | Search Time(s) 0.4434 | Infer Time(s) 0.1556 | Time(s) 0.5990 
2023-12-01 17:04:15,923:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:15,925:INFO::Validation loss decreased (0.242149 --> 0.241954).  Saving model ...
2023-12-01 17:04:15,928:INFO::Epoch: 213
tensor([[0.7674, 0.7238, 0.7249, 0.8637],
        [0.7278, 0.8779, 0.7191, 0.7621],
        [1.0000, 0.7060, 0.7689, 0.7459],
        [1.0000, 0.8277, 0.7709, 0.8028]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:15,929:INFO::its now!!!!!!!!5
2023-12-01 17:04:16,087:INFO::its now!!!!!!!!0
2023-12-01 17:04:16,087:INFO::its now!!!!!!!!3
2023-12-01 17:04:16,136:INFO::its now!!!!!!!!5
2023-12-01 17:04:16,279:INFO::its now!!!!!!!!
2023-12-01 17:04:16,279:INFO::its now!!!!!!!! on 
2023-12-01 17:04:16,340:INFO::its now!!!!!!!!5
2023-12-01 17:04:16,499:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:16,501:INFO::Epoch 00213 | lr 0.00050 | Train_Loss -0.0636 | Train_Classification_Loss 0.0513 | Dmon_Loss -0.2298 | Val_Loss 0.2417 | Search Time(s) 0.4110 | Infer Time(s) 0.1636 | Time(s) 0.5746 
2023-12-01 17:04:16,537:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:16,538:INFO::Validation loss decreased (0.241954 --> 0.241748).  Saving model ...
2023-12-01 17:04:16,541:INFO::Epoch: 214
tensor([[0.7673, 0.7231, 0.7243, 0.8630],
        [0.7271, 0.8779, 0.7184, 0.7614],
        [1.0000, 0.7053, 0.7683, 0.7453],
        [1.0000, 0.8271, 0.7703, 0.8022]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:16,542:INFO::its now!!!!!!!!5
2023-12-01 17:04:16,705:INFO::its now!!!!!!!!0
2023-12-01 17:04:16,705:INFO::its now!!!!!!!!3
2023-12-01 17:04:16,750:INFO::its now!!!!!!!!5
2023-12-01 17:04:16,922:INFO::its now!!!!!!!!
2023-12-01 17:04:16,922:INFO::its now!!!!!!!! on 
2023-12-01 17:04:16,976:INFO::its now!!!!!!!!5
2023-12-01 17:04:17,141:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:17,142:INFO::Epoch 00214 | lr 0.00050 | Train_Loss -0.0661 | Train_Classification_Loss 0.0488 | Dmon_Loss -0.2297 | Val_Loss 0.2416 | Search Time(s) 0.4338 | Infer Time(s) 0.1691 | Time(s) 0.6029 
2023-12-01 17:04:17,180:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:17,181:INFO::Validation loss decreased (0.241748 --> 0.241553).  Saving model ...
2023-12-01 17:04:17,184:INFO::Epoch: 215
tensor([[0.7714, 0.7228, 0.7279, 0.8673],
        [0.7309, 0.8824, 0.7221, 0.7611],
        [1.0000, 0.7044, 0.7719, 0.7489],
        [1.0000, 0.8305, 0.7700, 0.8056]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:17,185:INFO::its now!!!!!!!!5
2023-12-01 17:04:17,325:INFO::its now!!!!!!!!0
2023-12-01 17:04:17,326:INFO::its now!!!!!!!!3
2023-12-01 17:04:17,372:INFO::its now!!!!!!!!5
2023-12-01 17:04:17,549:INFO::its now!!!!!!!!
2023-12-01 17:04:17,549:INFO::its now!!!!!!!! on 
2023-12-01 17:04:17,601:INFO::its now!!!!!!!!5
2023-12-01 17:04:17,760:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:17,761:INFO::Epoch 00215 | lr 0.00050 | Train_Loss -0.0622 | Train_Classification_Loss 0.0525 | Dmon_Loss -0.2296 | Val_Loss 0.2412 | Search Time(s) 0.4165 | Infer Time(s) 0.1626 | Time(s) 0.5790 
2023-12-01 17:04:17,798:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:17,800:INFO::Validation loss decreased (0.241553 --> 0.241241).  Saving model ...
2023-12-01 17:04:17,803:INFO::Epoch: 216
tensor([[0.7729, 0.7219, 0.7291, 0.8694],
        [0.7321, 0.8847, 0.7234, 0.7603],
        [1.0000, 0.7034, 0.7731, 0.7502],
        [1.0000, 0.8316, 0.7693, 0.8067]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:17,804:INFO::its now!!!!!!!!5
2023-12-01 17:04:17,936:INFO::its now!!!!!!!!0
2023-12-01 17:04:17,937:INFO::its now!!!!!!!!3
2023-12-01 17:04:17,980:INFO::its now!!!!!!!!5
2023-12-01 17:04:18,142:INFO::its now!!!!!!!!
2023-12-01 17:04:18,142:INFO::its now!!!!!!!! on 
2023-12-01 17:04:18,195:INFO::its now!!!!!!!!5
2023-12-01 17:04:18,362:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:18,363:INFO::Epoch 00216 | lr 0.00050 | Train_Loss -0.0656 | Train_Classification_Loss 0.0493 | Dmon_Loss -0.2297 | Val_Loss 0.2410 | Search Time(s) 0.3916 | Infer Time(s) 0.1701 | Time(s) 0.5617 
2023-12-01 17:04:18,417:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:18,418:INFO::Validation loss decreased (0.241241 --> 0.240987).  Saving model ...
2023-12-01 17:04:18,421:INFO::Epoch: 217
tensor([[0.7702, 0.7181, 0.7264, 0.8705],
        [0.7294, 0.8858, 0.7207, 0.7564],
        [1.0000, 0.6992, 0.7705, 0.7475],
        [1.0000, 0.8292, 0.7658, 0.8042]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:18,422:INFO::its now!!!!!!!!5
2023-12-01 17:04:18,608:INFO::its now!!!!!!!!0
2023-12-01 17:04:18,609:INFO::its now!!!!!!!!3
2023-12-01 17:04:18,653:INFO::its now!!!!!!!!5
2023-12-01 17:04:18,837:INFO::its now!!!!!!!!
2023-12-01 17:04:18,837:INFO::its now!!!!!!!! on 
2023-12-01 17:04:18,890:INFO::its now!!!!!!!!5
2023-12-01 17:04:19,061:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:19,063:INFO::Epoch 00217 | lr 0.00050 | Train_Loss -0.0638 | Train_Classification_Loss 0.0511 | Dmon_Loss -0.2298 | Val_Loss 0.2407 | Search Time(s) 0.4687 | Infer Time(s) 0.1746 | Time(s) 0.6433 
2023-12-01 17:04:19,104:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:19,105:INFO::Validation loss decreased (0.240987 --> 0.240737).  Saving model ...
2023-12-01 17:04:19,108:INFO::Epoch: 218
tensor([[0.7685, 0.7159, 0.7248, 0.8710],
        [0.7277, 0.8864, 0.7190, 0.7542],
        [1.0000, 0.6968, 0.7689, 0.7458],
        [1.0000, 0.8277, 0.7638, 0.8027]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:19,108:INFO::its now!!!!!!!!5
2023-12-01 17:04:19,297:INFO::its now!!!!!!!!0
2023-12-01 17:04:19,297:INFO::its now!!!!!!!!3
2023-12-01 17:04:19,346:INFO::its now!!!!!!!!5
2023-12-01 17:04:19,510:INFO::its now!!!!!!!!
2023-12-01 17:04:19,510:INFO::its now!!!!!!!! on 
2023-12-01 17:04:19,566:INFO::its now!!!!!!!!5
2023-12-01 17:04:19,725:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:19,726:INFO::Epoch 00218 | lr 0.00050 | Train_Loss -0.0655 | Train_Classification_Loss 0.0495 | Dmon_Loss -0.2299 | Val_Loss 0.2406 | Search Time(s) 0.4599 | Infer Time(s) 0.1596 | Time(s) 0.6195 
2023-12-01 17:04:19,767:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:19,768:INFO::Validation loss decreased (0.240737 --> 0.240600).  Saving model ...
2023-12-01 17:04:19,770:INFO::Epoch: 219
tensor([[0.7676, 0.7147, 0.7240, 0.8713],
        [0.7268, 0.8866, 0.7181, 0.7530],
        [1.0000, 0.6955, 0.7680, 0.7450],
        [1.0000, 0.8269, 0.7628, 0.8020]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:19,771:INFO::its now!!!!!!!!5
2023-12-01 17:04:19,910:INFO::its now!!!!!!!!0
2023-12-01 17:04:19,911:INFO::its now!!!!!!!!3
2023-12-01 17:04:19,959:INFO::its now!!!!!!!!5
2023-12-01 17:04:20,128:INFO::its now!!!!!!!!
2023-12-01 17:04:20,128:INFO::its now!!!!!!!! on 
2023-12-01 17:04:20,184:INFO::its now!!!!!!!!5
2023-12-01 17:04:20,343:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:20,344:INFO::Epoch 00219 | lr 0.00050 | Train_Loss -0.0632 | Train_Classification_Loss 0.0519 | Dmon_Loss -0.2303 | Val_Loss 0.2404 | Search Time(s) 0.4123 | Infer Time(s) 0.1621 | Time(s) 0.5744 
2023-12-01 17:04:20,382:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:20,383:INFO::Validation loss decreased (0.240600 --> 0.240405).  Saving model ...
2023-12-01 17:04:20,386:INFO::Epoch: 220
tensor([[0.7630, 0.7099, 0.7196, 0.8714],
        [0.7223, 0.8868, 0.7137, 0.7482],
        [1.0000, 0.6905, 0.7636, 0.7405],
        [1.0000, 0.8228, 0.7585, 0.7979]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:20,387:INFO::its now!!!!!!!!5
2023-12-01 17:04:20,526:INFO::its now!!!!!!!!0
2023-12-01 17:04:20,527:INFO::its now!!!!!!!!3
2023-12-01 17:04:20,575:INFO::its now!!!!!!!!5
2023-12-01 17:04:20,739:INFO::its now!!!!!!!!
2023-12-01 17:04:20,739:INFO::its now!!!!!!!! on 
2023-12-01 17:04:20,794:INFO::its now!!!!!!!!5
2023-12-01 17:04:20,955:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:20,956:INFO::Epoch 00220 | lr 0.00050 | Train_Loss -0.0682 | Train_Classification_Loss 0.0469 | Dmon_Loss -0.2301 | Val_Loss 0.2403 | Search Time(s) 0.4069 | Infer Time(s) 0.1646 | Time(s) 0.5715 
2023-12-01 17:04:20,998:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:20,999:INFO::Validation loss decreased (0.240405 --> 0.240319).  Saving model ...
2023-12-01 17:04:21,003:INFO::Epoch: 221
tensor([[0.7601, 0.7069, 0.7168, 0.8715],
        [0.7194, 0.8869, 0.7108, 0.7451],
        [1.0000, 0.6873, 0.7608, 0.7377],
        [1.0000, 0.8201, 0.7557, 0.7952]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:21,004:INFO::its now!!!!!!!!5
2023-12-01 17:04:21,191:INFO::its now!!!!!!!!0
2023-12-01 17:04:21,191:INFO::its now!!!!!!!!3
2023-12-01 17:04:21,235:INFO::its now!!!!!!!!5
2023-12-01 17:04:21,388:INFO::its now!!!!!!!!
2023-12-01 17:04:21,389:INFO::its now!!!!!!!! on 
2023-12-01 17:04:21,442:INFO::its now!!!!!!!!5
2023-12-01 17:04:21,602:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:21,604:INFO::Epoch 00221 | lr 0.00050 | Train_Loss -0.0698 | Train_Classification_Loss 0.0456 | Dmon_Loss -0.2307 | Val_Loss 0.2402 | Search Time(s) 0.4400 | Infer Time(s) 0.1636 | Time(s) 0.6036 
2023-12-01 17:04:21,640:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:21,641:INFO::Validation loss decreased (0.240319 --> 0.240228).  Saving model ...
2023-12-01 17:04:21,645:INFO::Epoch: 222
tensor([[0.7577, 0.7044, 0.7145, 0.8715],
        [0.7170, 0.8869, 0.7084, 0.7427],
        [1.0000, 0.6847, 0.7585, 0.7354],
        [1.0000, 0.8180, 0.7535, 0.7931]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:21,646:INFO::its now!!!!!!!!5
2023-12-01 17:04:21,807:INFO::its now!!!!!!!!0
2023-12-01 17:04:21,808:INFO::its now!!!!!!!!3
2023-12-01 17:04:21,848:INFO::its now!!!!!!!!5
2023-12-01 17:04:22,039:INFO::its now!!!!!!!!
2023-12-01 17:04:22,039:INFO::its now!!!!!!!! on 
2023-12-01 17:04:22,092:INFO::its now!!!!!!!!5
2023-12-01 17:04:22,242:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:22,244:INFO::Epoch 00222 | lr 0.00050 | Train_Loss -0.0679 | Train_Classification_Loss 0.0475 | Dmon_Loss -0.2308 | Val_Loss 0.2401 | Search Time(s) 0.4478 | Infer Time(s) 0.1532 | Time(s) 0.6010 
2023-12-01 17:04:22,296:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:22,297:INFO::Validation loss decreased (0.240228 --> 0.240115).  Saving model ...
2023-12-01 17:04:22,301:INFO::Epoch: 223
tensor([[0.7404, 0.7032, 0.6980, 0.8537],
        [0.6999, 0.8869, 0.6915, 0.7252],
        [0.9989, 0.6667, 0.7419, 0.7186],
        [0.9789, 0.8152, 0.7375, 0.7773]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:22,302:INFO::its now!!!!!!!!5
2023-12-01 17:04:22,471:INFO::its now!!!!!!!!0
2023-12-01 17:04:22,471:INFO::its now!!!!!!!!3
2023-12-01 17:04:22,517:INFO::its now!!!!!!!!5
2023-12-01 17:04:22,676:INFO::its now!!!!!!!!
2023-12-01 17:04:22,676:INFO::its now!!!!!!!! on 
2023-12-01 17:04:22,733:INFO::its now!!!!!!!!5
2023-12-01 17:04:22,881:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:22,883:INFO::Epoch 00223 | lr 0.00050 | Train_Loss -0.0686 | Train_Classification_Loss 0.0467 | Dmon_Loss -0.2307 | Val_Loss 0.2400 | Search Time(s) 0.4338 | Infer Time(s) 0.1496 | Time(s) 0.5834 
2023-12-01 17:04:22,924:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:22,925:INFO::Validation loss decreased (0.240115 --> 0.239993).  Saving model ...
2023-12-01 17:04:22,928:INFO::Epoch: 224
tensor([[0.7317, 0.7029, 0.6899, 0.8451],
        [0.6917, 0.8869, 0.6833, 0.7168],
        [0.9986, 0.6571, 0.7338, 0.7105],
        [0.9687, 0.8141, 0.7298, 0.7689]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:22,928:INFO::its now!!!!!!!!5
2023-12-01 17:04:23,086:INFO::its now!!!!!!!!0
2023-12-01 17:04:23,087:INFO::its now!!!!!!!!3
2023-12-01 17:04:23,133:INFO::its now!!!!!!!!5
2023-12-01 17:04:23,269:INFO::its now!!!!!!!!
2023-12-01 17:04:23,270:INFO::its now!!!!!!!! on 
2023-12-01 17:04:23,321:INFO::its now!!!!!!!!5
2023-12-01 17:04:23,481:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:23,483:INFO::Epoch 00224 | lr 0.00050 | Train_Loss -0.0711 | Train_Classification_Loss 0.0443 | Dmon_Loss -0.2307 | Val_Loss 0.2399 | Search Time(s) 0.3921 | Infer Time(s) 0.1646 | Time(s) 0.5566 
2023-12-01 17:04:23,537:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:23,538:INFO::Validation loss decreased (0.239993 --> 0.239855).  Saving model ...
2023-12-01 17:04:23,542:INFO::Epoch: 225
tensor([[0.7254, 0.7005, 0.6840, 0.8408],
        [0.6856, 0.8869, 0.6772, 0.7105],
        [0.9987, 0.6502, 0.7279, 0.7045],
        [0.9641, 0.8115, 0.7240, 0.7628]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:23,542:INFO::its now!!!!!!!!5
2023-12-01 17:04:23,690:INFO::its now!!!!!!!!0
2023-12-01 17:04:23,691:INFO::its now!!!!!!!!3
2023-12-01 17:04:23,737:INFO::its now!!!!!!!!5
2023-12-01 17:04:23,908:INFO::its now!!!!!!!!
2023-12-01 17:04:23,909:INFO::its now!!!!!!!! on 
2023-12-01 17:04:23,962:INFO::its now!!!!!!!!5
2023-12-01 17:04:24,134:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:24,135:INFO::Epoch 00225 | lr 0.00050 | Train_Loss -0.0690 | Train_Classification_Loss 0.0460 | Dmon_Loss -0.2301 | Val_Loss 0.2397 | Search Time(s) 0.4209 | Infer Time(s) 0.1741 | Time(s) 0.5950 
2023-12-01 17:04:24,179:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:24,180:INFO::Validation loss decreased (0.239855 --> 0.239692).  Saving model ...
2023-12-01 17:04:24,183:INFO::Epoch: 226
tensor([[0.7203, 0.6972, 0.6792, 0.8387],
        [0.6807, 0.8869, 0.6724, 0.7055],
        [0.9989, 0.6448, 0.7231, 0.6997],
        [0.9626, 0.8084, 0.7194, 0.7581]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:24,184:INFO::its now!!!!!!!!5
2023-12-01 17:04:24,358:INFO::its now!!!!!!!!0
2023-12-01 17:04:24,359:INFO::its now!!!!!!!!3
2023-12-01 17:04:24,403:INFO::its now!!!!!!!!5
2023-12-01 17:04:24,580:INFO::its now!!!!!!!!
2023-12-01 17:04:24,581:INFO::its now!!!!!!!! on 
2023-12-01 17:04:24,633:INFO::its now!!!!!!!!5
2023-12-01 17:04:24,804:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:24,805:INFO::Epoch 00226 | lr 0.00050 | Train_Loss -0.0702 | Train_Classification_Loss 0.0454 | Dmon_Loss -0.2313 | Val_Loss 0.2395 | Search Time(s) 0.4494 | Infer Time(s) 0.1745 | Time(s) 0.6239 
2023-12-01 17:04:24,861:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:24,863:INFO::Validation loss decreased (0.239692 --> 0.239527).  Saving model ...
2023-12-01 17:04:24,865:INFO::Epoch: 227
tensor([[0.7177, 0.6955, 0.6768, 0.8376],
        [0.6781, 0.8869, 0.6698, 0.7029],
        [0.9993, 0.6420, 0.7206, 0.6971],
        [0.9625, 0.8067, 0.7170, 0.7557]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:24,866:INFO::its now!!!!!!!!5
2023-12-01 17:04:25,005:INFO::its now!!!!!!!!0
2023-12-01 17:04:25,005:INFO::its now!!!!!!!!3
2023-12-01 17:04:25,058:INFO::its now!!!!!!!!5
2023-12-01 17:04:25,249:INFO::its now!!!!!!!!
2023-12-01 17:04:25,249:INFO::its now!!!!!!!! on 
2023-12-01 17:04:25,308:INFO::its now!!!!!!!!5
2023-12-01 17:04:25,473:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:25,474:INFO::Epoch 00227 | lr 0.00050 | Train_Loss -0.0704 | Train_Classification_Loss 0.0448 | Dmon_Loss -0.2305 | Val_Loss 0.2394 | Search Time(s) 0.4406 | Infer Time(s) 0.1696 | Time(s) 0.6102 
2023-12-01 17:04:25,518:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:25,519:INFO::Validation loss decreased (0.239527 --> 0.239366).  Saving model ...
2023-12-01 17:04:25,521:INFO::Epoch: 228
tensor([[0.7152, 0.6932, 0.6744, 0.8371],
        [0.6757, 0.8869, 0.6674, 0.7004],
        [0.9998, 0.6394, 0.7183, 0.6947],
        [0.9629, 0.8047, 0.7148, 0.7533]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:25,521:INFO::its now!!!!!!!!5
2023-12-01 17:04:25,670:INFO::its now!!!!!!!!0
2023-12-01 17:04:25,671:INFO::its now!!!!!!!!3
2023-12-01 17:04:25,717:INFO::its now!!!!!!!!5
2023-12-01 17:04:25,882:INFO::its now!!!!!!!!
2023-12-01 17:04:25,882:INFO::its now!!!!!!!! on 
2023-12-01 17:04:25,937:INFO::its now!!!!!!!!5
2023-12-01 17:04:26,096:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:26,097:INFO::Epoch 00228 | lr 0.00050 | Train_Loss -0.0700 | Train_Classification_Loss 0.0455 | Dmon_Loss -0.2311 | Val_Loss 0.2392 | Search Time(s) 0.4139 | Infer Time(s) 0.1626 | Time(s) 0.5765 
2023-12-01 17:04:26,134:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:26,136:INFO::Validation loss decreased (0.239366 --> 0.239215).  Saving model ...
2023-12-01 17:04:26,139:INFO::Epoch: 229
tensor([[0.7153, 0.6936, 0.6744, 0.8368],
        [0.6757, 0.8869, 0.6675, 0.7004],
        [1.0000, 0.6394, 0.7183, 0.6948],
        [0.9638, 0.8050, 0.7148, 0.7534]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:26,139:INFO::its now!!!!!!!!5
2023-12-01 17:04:26,312:INFO::its now!!!!!!!!0
2023-12-01 17:04:26,313:INFO::its now!!!!!!!!3
2023-12-01 17:04:26,358:INFO::its now!!!!!!!!5
2023-12-01 17:04:26,518:INFO::its now!!!!!!!!
2023-12-01 17:04:26,518:INFO::its now!!!!!!!! on 
2023-12-01 17:04:26,571:INFO::its now!!!!!!!!5
2023-12-01 17:04:26,721:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:26,723:INFO::Epoch 00229 | lr 0.00050 | Train_Loss -0.0716 | Train_Classification_Loss 0.0437 | Dmon_Loss -0.2305 | Val_Loss 0.2391 | Search Time(s) 0.4314 | Infer Time(s) 0.1536 | Time(s) 0.5850 
2023-12-01 17:04:26,779:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:26,781:INFO::Validation loss decreased (0.239215 --> 0.239106).  Saving model ...
2023-12-01 17:04:26,785:INFO::Epoch: 230
tensor([[0.7145, 0.6928, 0.6737, 0.8366],
        [0.6749, 0.8869, 0.6667, 0.6996],
        [1.0000, 0.6386, 0.7175, 0.6940],
        [0.9651, 0.8043, 0.7141, 0.7526]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:26,786:INFO::its now!!!!!!!!5
2023-12-01 17:04:26,940:INFO::its now!!!!!!!!0
2023-12-01 17:04:26,941:INFO::its now!!!!!!!!3
2023-12-01 17:04:26,989:INFO::its now!!!!!!!!5
2023-12-01 17:04:27,154:INFO::its now!!!!!!!!
2023-12-01 17:04:27,154:INFO::its now!!!!!!!! on 
2023-12-01 17:04:27,212:INFO::its now!!!!!!!!5
2023-12-01 17:04:27,372:INFO::Epoch 00230 | lr 0.00050 | Train_Loss -0.0680 | Train_Classification_Loss 0.0477 | Dmon_Loss -0.2314 | Val_Loss 0.2392 | Search Time(s) 0.4275 | Infer Time(s) 0.1641 | Time(s) 0.5916 
2023-12-01 17:04:27,413:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 2;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:27,414:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:04:27,417:INFO::Epoch: 231
tensor([[0.7124, 0.6906, 0.6717, 0.8366],
        [0.6729, 0.8869, 0.6647, 0.6975],
        [1.0000, 0.6364, 0.7155, 0.6920],
        [0.9665, 0.8023, 0.7121, 0.7507]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:27,419:INFO::its now!!!!!!!!5
2023-12-01 17:04:27,559:INFO::its now!!!!!!!!0
2023-12-01 17:04:27,559:INFO::its now!!!!!!!!3
2023-12-01 17:04:27,603:INFO::its now!!!!!!!!5
2023-12-01 17:04:27,775:INFO::its now!!!!!!!!
2023-12-01 17:04:27,775:INFO::its now!!!!!!!! on 
2023-12-01 17:04:27,829:INFO::its now!!!!!!!!5
2023-12-01 17:04:27,981:INFO::Epoch 00231 | lr 0.00050 | Train_Loss -0.0704 | Train_Classification_Loss 0.0453 | Dmon_Loss -0.2315 | Val_Loss 0.2392 | Search Time(s) 0.4139 | Infer Time(s) 0.1526 | Time(s) 0.5665 
2023-12-01 17:04:28,037:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:28,038:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:04:28,040:INFO::Epoch: 232
tensor([[0.7106, 0.6886, 0.6700, 0.8365],
        [0.6711, 0.8869, 0.6629, 0.6957],
        [1.0000, 0.6345, 0.7138, 0.6903],
        [0.9680, 0.8005, 0.7105, 0.7491]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:28,041:INFO::its now!!!!!!!!5
2023-12-01 17:04:28,195:INFO::its now!!!!!!!!0
2023-12-01 17:04:28,195:INFO::its now!!!!!!!!3
2023-12-01 17:04:28,241:INFO::its now!!!!!!!!5
2023-12-01 17:04:28,406:INFO::its now!!!!!!!!
2023-12-01 17:04:28,406:INFO::its now!!!!!!!! on 
2023-12-01 17:04:28,460:INFO::its now!!!!!!!!5
2023-12-01 17:04:28,601:INFO::Epoch 00232 | lr 0.00050 | Train_Loss -0.0759 | Train_Classification_Loss 0.0397 | Dmon_Loss -0.2313 | Val_Loss 0.2392 | Search Time(s) 0.4200 | Infer Time(s) 0.1436 | Time(s) 0.5637 
2023-12-01 17:04:28,638:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:28,639:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 17:04:28,642:INFO::Epoch: 233
tensor([[0.7060, 0.6834, 0.6656, 0.8365],
        [0.6666, 0.8869, 0.6584, 0.6911],
        [1.0000, 0.6298, 0.7094, 0.6858],
        [0.9691, 0.7959, 0.7062, 0.7449]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:28,643:INFO::its now!!!!!!!!5
2023-12-01 17:04:28,788:INFO::its now!!!!!!!!0
2023-12-01 17:04:28,788:INFO::its now!!!!!!!!3
2023-12-01 17:04:28,837:INFO::its now!!!!!!!!5
2023-12-01 17:04:28,992:INFO::its now!!!!!!!!
2023-12-01 17:04:28,992:INFO::its now!!!!!!!! on 
2023-12-01 17:04:29,049:INFO::its now!!!!!!!!5
2023-12-01 17:04:29,198:INFO::Epoch 00233 | lr 0.00050 | Train_Loss -0.0728 | Train_Classification_Loss 0.0428 | Dmon_Loss -0.2311 | Val_Loss 0.2392 | Search Time(s) 0.4089 | Infer Time(s) 0.1492 | Time(s) 0.5581 
2023-12-01 17:04:29,236:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:29,237:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 17:04:29,240:INFO::Epoch: 234
tensor([[0.7023, 0.6792, 0.6620, 0.8365],
        [0.6629, 0.8869, 0.6548, 0.6874],
        [1.0000, 0.6259, 0.7058, 0.6822],
        [0.9703, 0.7922, 0.7028, 0.7415]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:29,241:INFO::its now!!!!!!!!5
2023-12-01 17:04:29,409:INFO::its now!!!!!!!!0
2023-12-01 17:04:29,410:INFO::its now!!!!!!!!3
2023-12-01 17:04:29,454:INFO::its now!!!!!!!!5
2023-12-01 17:04:29,631:INFO::its now!!!!!!!!
2023-12-01 17:04:29,631:INFO::its now!!!!!!!! on 
2023-12-01 17:04:29,684:INFO::its now!!!!!!!!5
2023-12-01 17:04:29,840:INFO::Epoch 00234 | lr 0.00050 | Train_Loss -0.0714 | Train_Classification_Loss 0.0443 | Dmon_Loss -0.2315 | Val_Loss 0.2392 | Search Time(s) 0.4432 | Infer Time(s) 0.1586 | Time(s) 0.6017 
2023-12-01 17:04:29,895:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:29,896:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 17:04:29,899:INFO::Epoch: 235
tensor([[0.7012, 0.6780, 0.6610, 0.8365],
        [0.6619, 0.8869, 0.6537, 0.6863],
        [1.0000, 0.6248, 0.7048, 0.6811],
        [0.9714, 0.7911, 0.7018, 0.7405]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:29,900:INFO::its now!!!!!!!!5
2023-12-01 17:04:30,039:INFO::its now!!!!!!!!0
2023-12-01 17:04:30,039:INFO::its now!!!!!!!!3
2023-12-01 17:04:30,082:INFO::its now!!!!!!!!5
2023-12-01 17:04:30,263:INFO::its now!!!!!!!!
2023-12-01 17:04:30,263:INFO::its now!!!!!!!! on 
2023-12-01 17:04:30,316:INFO::its now!!!!!!!!5
2023-12-01 17:04:30,477:INFO::Epoch 00235 | lr 0.00050 | Train_Loss -0.0711 | Train_Classification_Loss 0.0444 | Dmon_Loss -0.2310 | Val_Loss 0.2392 | Search Time(s) 0.4170 | Infer Time(s) 0.1646 | Time(s) 0.5816 
2023-12-01 17:04:30,513:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:30,515:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 17:04:30,517:INFO::Epoch: 236
tensor([[0.6997, 0.6763, 0.6595, 0.8365],
        [0.6604, 0.8869, 0.6522, 0.6847],
        [1.0000, 0.6232, 0.7033, 0.6797],
        [0.9725, 0.7896, 0.7004, 0.7391]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:30,518:INFO::its now!!!!!!!!5
2023-12-01 17:04:30,664:INFO::its now!!!!!!!!0
2023-12-01 17:04:30,664:INFO::its now!!!!!!!!3
2023-12-01 17:04:30,710:INFO::its now!!!!!!!!5
2023-12-01 17:04:30,870:INFO::its now!!!!!!!!
2023-12-01 17:04:30,870:INFO::its now!!!!!!!! on 
2023-12-01 17:04:30,921:INFO::its now!!!!!!!!5
2023-12-01 17:04:31,088:INFO::Epoch 00236 | lr 0.00050 | Train_Loss -0.0746 | Train_Classification_Loss 0.0411 | Dmon_Loss -0.2313 | Val_Loss 0.2391 | Search Time(s) 0.4029 | Infer Time(s) 0.1695 | Time(s) 0.5725 
2023-12-01 17:04:31,126:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:31,127:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 17:04:31,129:INFO::Epoch: 237
tensor([[0.6992, 0.6757, 0.6590, 0.8365],
        [0.6598, 0.8869, 0.6517, 0.6842],
        [1.0000, 0.6226, 0.7028, 0.6792],
        [0.9737, 0.7891, 0.6999, 0.7387]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:31,129:INFO::its now!!!!!!!!5
2023-12-01 17:04:31,281:INFO::its now!!!!!!!!0
2023-12-01 17:04:31,282:INFO::its now!!!!!!!!3
2023-12-01 17:04:31,329:INFO::its now!!!!!!!!5
2023-12-01 17:04:31,481:INFO::its now!!!!!!!!
2023-12-01 17:04:31,481:INFO::its now!!!!!!!! on 
2023-12-01 17:04:31,538:INFO::its now!!!!!!!!5
2023-12-01 17:04:31,693:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:31,694:INFO::Epoch 00237 | lr 0.00050 | Train_Loss -0.0739 | Train_Classification_Loss 0.0419 | Dmon_Loss -0.2317 | Val_Loss 0.2391 | Search Time(s) 0.4085 | Infer Time(s) 0.1576 | Time(s) 0.5660 
2023-12-01 17:04:31,744:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:31,745:INFO::Validation loss decreased (0.239106 --> 0.239083).  Saving model ...
2023-12-01 17:04:31,747:INFO::Epoch: 238
tensor([[0.6980, 0.6744, 0.6579, 0.8365],
        [0.6587, 0.8869, 0.6506, 0.6830],
        [1.0000, 0.6214, 0.7017, 0.6780],
        [0.9755, 0.7880, 0.6988, 0.7376]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:31,748:INFO::its now!!!!!!!!5
2023-12-01 17:04:31,914:INFO::its now!!!!!!!!0
2023-12-01 17:04:31,915:INFO::its now!!!!!!!!3
2023-12-01 17:04:31,959:INFO::its now!!!!!!!!5
2023-12-01 17:04:32,110:INFO::its now!!!!!!!!
2023-12-01 17:04:32,110:INFO::its now!!!!!!!! on 
2023-12-01 17:04:32,161:INFO::its now!!!!!!!!5
2023-12-01 17:04:32,311:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:32,312:INFO::Epoch 00238 | lr 0.00050 | Train_Loss -0.0728 | Train_Classification_Loss 0.0432 | Dmon_Loss -0.2320 | Val_Loss 0.2390 | Search Time(s) 0.4134 | Infer Time(s) 0.1512 | Time(s) 0.5646 
2023-12-01 17:04:32,369:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:32,370:INFO::Validation loss decreased (0.239083 --> 0.238968).  Saving model ...
2023-12-01 17:04:32,372:INFO::Epoch: 239
tensor([[0.6959, 0.6720, 0.6558, 0.8365],
        [0.6566, 0.8869, 0.6485, 0.6809],
        [1.0000, 0.6192, 0.6996, 0.6760],
        [0.9770, 0.7858, 0.6968, 0.7357]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:32,373:INFO::its now!!!!!!!!5
2023-12-01 17:04:32,519:INFO::its now!!!!!!!!0
2023-12-01 17:04:32,520:INFO::its now!!!!!!!!3
2023-12-01 17:04:32,566:INFO::its now!!!!!!!!5
2023-12-01 17:04:32,770:INFO::its now!!!!!!!!
2023-12-01 17:04:32,770:INFO::its now!!!!!!!! on 
2023-12-01 17:04:32,825:INFO::its now!!!!!!!!5
2023-12-01 17:04:32,985:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:32,986:INFO::Epoch 00239 | lr 0.00050 | Train_Loss -0.0742 | Train_Classification_Loss 0.0416 | Dmon_Loss -0.2315 | Val_Loss 0.2388 | Search Time(s) 0.4528 | Infer Time(s) 0.1626 | Time(s) 0.6154 
2023-12-01 17:04:33,038:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:33,039:INFO::Validation loss decreased (0.238968 --> 0.238842).  Saving model ...
2023-12-01 17:04:33,042:INFO::Epoch: 240
tensor([[0.6939, 0.6698, 0.6539, 0.8365],
        [0.6547, 0.8869, 0.6465, 0.6789],
        [1.0000, 0.6171, 0.6978, 0.6740],
        [0.9788, 0.7838, 0.6950, 0.7339]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:33,043:INFO::its now!!!!!!!!5
2023-12-01 17:04:33,192:INFO::its now!!!!!!!!0
2023-12-01 17:04:33,192:INFO::its now!!!!!!!!3
2023-12-01 17:04:33,241:INFO::its now!!!!!!!!5
2023-12-01 17:04:33,384:INFO::its now!!!!!!!!
2023-12-01 17:04:33,385:INFO::its now!!!!!!!! on 
2023-12-01 17:04:33,440:INFO::its now!!!!!!!!5
2023-12-01 17:04:33,583:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:33,585:INFO::Epoch 00240 | lr 0.00050 | Train_Loss -0.0764 | Train_Classification_Loss 0.0396 | Dmon_Loss -0.2320 | Val_Loss 0.2388 | Search Time(s) 0.3981 | Infer Time(s) 0.1466 | Time(s) 0.5447 
2023-12-01 17:04:33,629:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:33,629:INFO::Validation loss decreased (0.238842 --> 0.238777).  Saving model ...
2023-12-01 17:04:33,631:INFO::Epoch: 241
tensor([[0.6889, 0.6642, 0.6492, 0.8365],
        [0.6497, 0.8869, 0.6417, 0.6739],
        [1.0000, 0.6119, 0.6929, 0.6692],
        [0.9802, 0.7789, 0.6904, 0.7293]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:33,632:INFO::its now!!!!!!!!5
2023-12-01 17:04:33,780:INFO::its now!!!!!!!!0
2023-12-01 17:04:33,781:INFO::its now!!!!!!!!3
2023-12-01 17:04:33,826:INFO::its now!!!!!!!!5
2023-12-01 17:04:33,990:INFO::its now!!!!!!!!
2023-12-01 17:04:33,990:INFO::its now!!!!!!!! on 
2023-12-01 17:04:34,042:INFO::its now!!!!!!!!5
2023-12-01 17:04:34,186:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:34,189:INFO::Epoch 00241 | lr 0.00050 | Train_Loss -0.0747 | Train_Classification_Loss 0.0412 | Dmon_Loss -0.2317 | Val_Loss 0.2386 | Search Time(s) 0.4089 | Infer Time(s) 0.1472 | Time(s) 0.5561 
2023-12-01 17:04:34,232:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:34,233:INFO::Validation loss decreased (0.238777 --> 0.238561).  Saving model ...
2023-12-01 17:04:34,236:INFO::Epoch: 242
tensor([[0.6851, 0.6599, 0.6455, 0.8365],
        [0.6460, 0.8869, 0.6380, 0.6701],
        [0.9999, 0.6080, 0.6893, 0.6655],
        [0.9819, 0.7751, 0.6869, 0.7259]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:34,237:INFO::its now!!!!!!!!5
2023-12-01 17:04:34,387:INFO::its now!!!!!!!!0
2023-12-01 17:04:34,388:INFO::its now!!!!!!!!3
2023-12-01 17:04:34,432:INFO::its now!!!!!!!!5
2023-12-01 17:04:34,571:INFO::its now!!!!!!!!
2023-12-01 17:04:34,571:INFO::its now!!!!!!!! on 
2023-12-01 17:04:34,622:INFO::its now!!!!!!!!5
2023-12-01 17:04:34,807:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:34,810:INFO::Epoch 00242 | lr 0.00050 | Train_Loss -0.0770 | Train_Classification_Loss 0.0388 | Dmon_Loss -0.2317 | Val_Loss 0.2383 | Search Time(s) 0.3861 | Infer Time(s) 0.1875 | Time(s) 0.5736 
2023-12-01 17:04:34,860:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:34,861:INFO::Validation loss decreased (0.238561 --> 0.238305).  Saving model ...
2023-12-01 17:04:34,864:INFO::Epoch: 243
tensor([[0.6850, 0.6598, 0.6454, 0.8365],
        [0.6459, 0.8869, 0.6379, 0.6699],
        [1.0000, 0.6079, 0.6892, 0.6654],
        [0.9833, 0.7750, 0.6868, 0.7258]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:34,865:INFO::its now!!!!!!!!5
2023-12-01 17:04:35,046:INFO::its now!!!!!!!!0
2023-12-01 17:04:35,047:INFO::its now!!!!!!!!3
2023-12-01 17:04:35,099:INFO::its now!!!!!!!!5
2023-12-01 17:04:35,247:INFO::its now!!!!!!!!
2023-12-01 17:04:35,248:INFO::its now!!!!!!!! on 
2023-12-01 17:04:35,303:INFO::its now!!!!!!!!5
2023-12-01 17:04:35,471:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:35,473:INFO::Epoch 00243 | lr 0.00050 | Train_Loss -0.0768 | Train_Classification_Loss 0.0391 | Dmon_Loss -0.2319 | Val_Loss 0.2381 | Search Time(s) 0.4390 | Infer Time(s) 0.1715 | Time(s) 0.6105 
2023-12-01 17:04:35,515:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:35,516:INFO::Validation loss decreased (0.238305 --> 0.238090).  Saving model ...
2023-12-01 17:04:35,519:INFO::Epoch: 244
tensor([[0.6857, 0.6605, 0.6460, 0.8365],
        [0.6465, 0.8869, 0.6385, 0.6706],
        [1.0000, 0.6086, 0.6898, 0.6660],
        [0.9848, 0.7756, 0.6874, 0.7263]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:35,520:INFO::its now!!!!!!!!5
2023-12-01 17:04:35,657:INFO::its now!!!!!!!!0
2023-12-01 17:04:35,658:INFO::its now!!!!!!!!3
2023-12-01 17:04:35,703:INFO::its now!!!!!!!!5
2023-12-01 17:04:35,845:INFO::its now!!!!!!!!
2023-12-01 17:04:35,845:INFO::its now!!!!!!!! on 
2023-12-01 17:04:35,898:INFO::its now!!!!!!!!5
2023-12-01 17:04:36,024:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:36,026:INFO::Epoch 00244 | lr 0.00050 | Train_Loss -0.0734 | Train_Classification_Loss 0.0426 | Dmon_Loss -0.2319 | Val_Loss 0.2379 | Search Time(s) 0.3790 | Infer Time(s) 0.1287 | Time(s) 0.5076 
2023-12-01 17:04:36,063:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:36,064:INFO::Validation loss decreased (0.238090 --> 0.237896).  Saving model ...
2023-12-01 17:04:36,068:INFO::Epoch: 245
tensor([[0.6866, 0.6615, 0.6469, 0.8365],
        [0.6474, 0.8869, 0.6394, 0.6715],
        [1.0000, 0.6095, 0.6907, 0.6669],
        [0.9861, 0.7765, 0.6882, 0.7272]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:36,069:INFO::its now!!!!!!!!5
2023-12-01 17:04:36,229:INFO::its now!!!!!!!!0
2023-12-01 17:04:36,230:INFO::its now!!!!!!!!3
2023-12-01 17:04:36,280:INFO::its now!!!!!!!!5
2023-12-01 17:04:36,441:INFO::its now!!!!!!!!
2023-12-01 17:04:36,442:INFO::its now!!!!!!!! on 
2023-12-01 17:04:36,498:INFO::its now!!!!!!!!5
2023-12-01 17:04:36,676:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:36,678:INFO::Epoch 00245 | lr 0.00050 | Train_Loss -0.0807 | Train_Classification_Loss 0.0355 | Dmon_Loss -0.2324 | Val_Loss 0.2378 | Search Time(s) 0.4300 | Infer Time(s) 0.1825 | Time(s) 0.6125 
2023-12-01 17:04:36,722:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:36,724:INFO::Validation loss decreased (0.237896 --> 0.237795).  Saving model ...
2023-12-01 17:04:36,727:INFO::Epoch: 246
tensor([[0.6872, 0.6622, 0.6475, 0.8365],
        [0.6480, 0.8869, 0.6399, 0.6721],
        [1.0000, 0.6101, 0.6913, 0.6675],
        [0.9875, 0.7771, 0.6888, 0.7277]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:36,727:INFO::its now!!!!!!!!5
2023-12-01 17:04:36,867:INFO::its now!!!!!!!!0
2023-12-01 17:04:36,868:INFO::its now!!!!!!!!3
2023-12-01 17:04:36,913:INFO::its now!!!!!!!!5
2023-12-01 17:04:37,087:INFO::its now!!!!!!!!
2023-12-01 17:04:37,088:INFO::its now!!!!!!!! on 
2023-12-01 17:04:37,145:INFO::its now!!!!!!!!5
2023-12-01 17:04:37,286:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:37,288:INFO::Epoch 00246 | lr 0.00050 | Train_Loss -0.0777 | Train_Classification_Loss 0.0384 | Dmon_Loss -0.2320 | Val_Loss 0.2376 | Search Time(s) 0.4170 | Infer Time(s) 0.1446 | Time(s) 0.5616 
2023-12-01 17:04:37,330:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:37,331:INFO::Validation loss decreased (0.237795 --> 0.237553).  Saving model ...
2023-12-01 17:04:37,335:INFO::Epoch: 247
tensor([[0.6898, 0.6652, 0.6478, 0.8392],
        [0.6507, 0.8869, 0.6426, 0.6748],
        [1.0000, 0.6129, 0.6915, 0.6701],
        [0.9914, 0.7798, 0.6891, 0.7302]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:37,336:INFO::its now!!!!!!!!5
2023-12-01 17:04:37,521:INFO::its now!!!!!!!!0
2023-12-01 17:04:37,522:INFO::its now!!!!!!!!3
2023-12-01 17:04:37,566:INFO::its now!!!!!!!!5
2023-12-01 17:04:37,721:INFO::its now!!!!!!!!
2023-12-01 17:04:37,721:INFO::its now!!!!!!!! on 
2023-12-01 17:04:37,773:INFO::its now!!!!!!!!5
2023-12-01 17:04:37,916:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:37,918:INFO::Epoch 00247 | lr 0.00050 | Train_Loss -0.0789 | Train_Classification_Loss 0.0372 | Dmon_Loss -0.2322 | Val_Loss 0.2374 | Search Time(s) 0.4378 | Infer Time(s) 0.1466 | Time(s) 0.5844 
2023-12-01 17:04:37,954:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:37,954:INFO::Validation loss decreased (0.237553 --> 0.237374).  Saving model ...
2023-12-01 17:04:37,956:INFO::Epoch: 248
tensor([[0.6873, 0.6624, 0.6442, 0.8405],
        [0.6482, 0.8869, 0.6401, 0.6723],
        [1.0000, 0.6103, 0.6878, 0.6677],
        [0.9942, 0.7773, 0.6857, 0.7279]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:37,957:INFO::its now!!!!!!!!5
2023-12-01 17:04:38,122:INFO::its now!!!!!!!!0
2023-12-01 17:04:38,122:INFO::its now!!!!!!!!3
2023-12-01 17:04:38,171:INFO::its now!!!!!!!!5
2023-12-01 17:04:38,348:INFO::its now!!!!!!!!
2023-12-01 17:04:38,348:INFO::its now!!!!!!!! on 
2023-12-01 17:04:38,406:INFO::its now!!!!!!!!5
2023-12-01 17:04:38,576:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:38,577:INFO::Epoch 00248 | lr 0.00050 | Train_Loss -0.0744 | Train_Classification_Loss 0.0416 | Dmon_Loss -0.2320 | Val_Loss 0.2373 | Search Time(s) 0.4480 | Infer Time(s) 0.1735 | Time(s) 0.6215 
2023-12-01 17:04:38,624:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 2;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:38,625:INFO::Validation loss decreased (0.237374 --> 0.237266).  Saving model ...
2023-12-01 17:04:38,629:INFO::Epoch: 249
tensor([[0.6852, 0.6600, 0.6416, 0.8412],
        [0.6461, 0.8869, 0.6380, 0.6701],
        [1.0000, 0.6081, 0.6852, 0.6656],
        [0.9962, 0.7751, 0.6832, 0.7259]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:38,630:INFO::its now!!!!!!!!5
2023-12-01 17:04:38,784:INFO::its now!!!!!!!!0
2023-12-01 17:04:38,785:INFO::its now!!!!!!!!3
2023-12-01 17:04:38,833:INFO::its now!!!!!!!!5
2023-12-01 17:04:39,000:INFO::its now!!!!!!!!
2023-12-01 17:04:39,000:INFO::its now!!!!!!!! on 
2023-12-01 17:04:39,057:INFO::its now!!!!!!!!5
2023-12-01 17:04:39,218:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:39,219:INFO::Epoch 00249 | lr 0.00050 | Train_Loss -0.0812 | Train_Classification_Loss 0.0351 | Dmon_Loss -0.2326 | Val_Loss 0.2372 | Search Time(s) 0.4289 | Infer Time(s) 0.1631 | Time(s) 0.5920 
2023-12-01 17:04:39,269:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:39,270:INFO::Validation loss decreased (0.237266 --> 0.237160).  Saving model ...
2023-12-01 17:04:39,271:INFO::Epoch: 250
tensor([[0.6837, 0.6583, 0.6399, 0.8415],
        [0.6446, 0.8869, 0.6366, 0.6686],
        [1.0000, 0.6066, 0.6835, 0.6642],
        [0.9980, 0.7737, 0.6816, 0.7246]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:39,272:INFO::its now!!!!!!!!5
2023-12-01 17:04:39,418:INFO::its now!!!!!!!!0
2023-12-01 17:04:39,418:INFO::its now!!!!!!!!3
2023-12-01 17:04:39,461:INFO::its now!!!!!!!!5
2023-12-01 17:04:39,616:INFO::its now!!!!!!!!
2023-12-01 17:04:39,616:INFO::its now!!!!!!!! on 
2023-12-01 17:04:39,669:INFO::its now!!!!!!!!5
2023-12-01 17:04:39,830:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:39,832:INFO::Epoch 00250 | lr 0.00050 | Train_Loss -0.0807 | Train_Classification_Loss 0.0355 | Dmon_Loss -0.2323 | Val_Loss 0.2371 | Search Time(s) 0.3956 | Infer Time(s) 0.1646 | Time(s) 0.5602 
2023-12-01 17:04:39,875:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:39,876:INFO::Validation loss decreased (0.237160 --> 0.237065).  Saving model ...
2023-12-01 17:04:39,879:INFO::Epoch: 251
tensor([[0.6838, 0.6585, 0.6398, 0.8417],
        [0.6447, 0.8869, 0.6367, 0.6688],
        [1.0000, 0.6067, 0.6834, 0.6643],
        [0.9995, 0.7738, 0.6816, 0.7247]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:39,879:INFO::its now!!!!!!!!5
2023-12-01 17:04:40,032:INFO::its now!!!!!!!!0
2023-12-01 17:04:40,033:INFO::its now!!!!!!!!3
2023-12-01 17:04:40,078:INFO::its now!!!!!!!!5
2023-12-01 17:04:40,247:INFO::its now!!!!!!!!
2023-12-01 17:04:40,248:INFO::its now!!!!!!!! on 
2023-12-01 17:04:40,300:INFO::its now!!!!!!!!5
2023-12-01 17:04:40,480:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:40,482:INFO::Epoch 00251 | lr 0.00050 | Train_Loss -0.0818 | Train_Classification_Loss 0.0344 | Dmon_Loss -0.2323 | Val_Loss 0.2369 | Search Time(s) 0.4224 | Infer Time(s) 0.1815 | Time(s) 0.6039 
2023-12-01 17:04:40,543:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:40,544:INFO::Validation loss decreased (0.237065 --> 0.236910).  Saving model ...
2023-12-01 17:04:40,546:INFO::Epoch: 252
tensor([[0.6802, 0.6544, 0.6363, 0.8418],
        [0.6412, 0.8869, 0.6331, 0.6651],
        [1.0000, 0.6029, 0.6798, 0.6608],
        [1.0000, 0.7702, 0.6781, 0.7214]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:40,547:INFO::its now!!!!!!!!5
2023-12-01 17:04:40,758:INFO::its now!!!!!!!!0
2023-12-01 17:04:40,759:INFO::its now!!!!!!!!3
2023-12-01 17:04:40,803:INFO::its now!!!!!!!!5
2023-12-01 17:04:41,017:INFO::its now!!!!!!!!
2023-12-01 17:04:41,017:INFO::its now!!!!!!!! on 
2023-12-01 17:04:41,098:INFO::its now!!!!!!!!5
2023-12-01 17:04:41,316:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:41,318:INFO::Epoch 00252 | lr 0.00050 | Train_Loss -0.0830 | Train_Classification_Loss 0.0332 | Dmon_Loss -0.2324 | Val_Loss 0.2368 | Search Time(s) 0.5535 | Infer Time(s) 0.2185 | Time(s) 0.7720 
2023-12-01 17:04:41,367:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:41,368:INFO::Validation loss decreased (0.236910 --> 0.236791).  Saving model ...
2023-12-01 17:04:41,370:INFO::Epoch: 253
tensor([[0.6750, 0.6485, 0.6312, 0.8418],
        [0.6360, 0.8869, 0.6280, 0.6598],
        [0.9999, 0.5974, 0.6747, 0.6557],
        [1.0000, 0.7649, 0.6732, 0.7166]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:41,371:INFO::its now!!!!!!!!5
2023-12-01 17:04:41,534:INFO::its now!!!!!!!!0
2023-12-01 17:04:41,535:INFO::its now!!!!!!!!3
2023-12-01 17:04:41,583:INFO::its now!!!!!!!!5
2023-12-01 17:04:41,773:INFO::its now!!!!!!!!
2023-12-01 17:04:41,773:INFO::its now!!!!!!!! on 
2023-12-01 17:04:41,831:INFO::its now!!!!!!!!5
2023-12-01 17:04:41,991:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:41,992:INFO::Epoch 00253 | lr 0.00050 | Train_Loss -0.0806 | Train_Classification_Loss 0.0359 | Dmon_Loss -0.2330 | Val_Loss 0.2367 | Search Time(s) 0.4618 | Infer Time(s) 0.1606 | Time(s) 0.6223 
2023-12-01 17:04:42,040:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:42,041:INFO::Validation loss decreased (0.236791 --> 0.236707).  Saving model ...
2023-12-01 17:04:42,043:INFO::Epoch: 254
tensor([[0.6706, 0.6437, 0.6270, 0.8419],
        [0.6317, 0.8869, 0.6237, 0.6554],
        [1.0000, 0.5929, 0.6705, 0.6514],
        [1.0000, 0.7606, 0.6691, 0.7126]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:42,044:INFO::its now!!!!!!!!5
2023-12-01 17:04:42,179:INFO::its now!!!!!!!!0
2023-12-01 17:04:42,180:INFO::its now!!!!!!!!3
2023-12-01 17:04:42,224:INFO::its now!!!!!!!!5
2023-12-01 17:04:42,376:INFO::its now!!!!!!!!
2023-12-01 17:04:42,376:INFO::its now!!!!!!!! on 
2023-12-01 17:04:42,430:INFO::its now!!!!!!!!5
2023-12-01 17:04:42,575:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:42,577:INFO::Epoch 00254 | lr 0.00050 | Train_Loss -0.0788 | Train_Classification_Loss 0.0377 | Dmon_Loss -0.2331 | Val_Loss 0.2367 | Search Time(s) 0.3852 | Infer Time(s) 0.1496 | Time(s) 0.5348 
2023-12-01 17:04:42,627:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:42,628:INFO::Validation loss decreased (0.236707 --> 0.236692).  Saving model ...
2023-12-01 17:04:42,631:INFO::Epoch: 255
tensor([[0.6674, 0.6401, 0.6239, 0.8419],
        [0.6285, 0.8869, 0.6206, 0.6522],
        [1.0000, 0.5896, 0.6674, 0.6483],
        [1.0000, 0.7574, 0.6662, 0.7097]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:42,632:INFO::its now!!!!!!!!5
2023-12-01 17:04:42,788:INFO::its now!!!!!!!!0
2023-12-01 17:04:42,789:INFO::its now!!!!!!!!3
2023-12-01 17:04:42,833:INFO::its now!!!!!!!!5
2023-12-01 17:04:43,012:INFO::its now!!!!!!!!
2023-12-01 17:04:43,012:INFO::its now!!!!!!!! on 
2023-12-01 17:04:43,066:INFO::its now!!!!!!!!5
2023-12-01 17:04:43,213:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:43,215:INFO::Epoch 00255 | lr 0.00050 | Train_Loss -0.0799 | Train_Classification_Loss 0.0364 | Dmon_Loss -0.2328 | Val_Loss 0.2367 | Search Time(s) 0.4348 | Infer Time(s) 0.1502 | Time(s) 0.5850 
2023-12-01 17:04:43,260:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:43,261:INFO::Validation loss decreased (0.236692 --> 0.236661).  Saving model ...
2023-12-01 17:04:43,264:INFO::Epoch: 256
tensor([[0.6655, 0.6379, 0.6220, 0.8419],
        [0.6266, 0.8869, 0.6186, 0.6502],
        [1.0000, 0.5875, 0.6655, 0.6464],
        [1.0000, 0.7554, 0.6643, 0.7078]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:43,264:INFO::its now!!!!!!!!5
2023-12-01 17:04:43,427:INFO::its now!!!!!!!!0
2023-12-01 17:04:43,428:INFO::its now!!!!!!!!3
2023-12-01 17:04:43,471:INFO::its now!!!!!!!!5
2023-12-01 17:04:43,650:INFO::its now!!!!!!!!
2023-12-01 17:04:43,650:INFO::its now!!!!!!!! on 
2023-12-01 17:04:43,702:INFO::its now!!!!!!!!5
2023-12-01 17:04:43,842:INFO::Epoch 00256 | lr 0.00050 | Train_Loss -0.0805 | Train_Classification_Loss 0.0355 | Dmon_Loss -0.2321 | Val_Loss 0.2367 | Search Time(s) 0.4364 | Infer Time(s) 0.1446 | Time(s) 0.5810 
2023-12-01 17:04:43,885:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:43,886:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:04:43,889:INFO::Epoch: 257
tensor([[0.6638, 0.6360, 0.6204, 0.8419],
        [0.6249, 0.8869, 0.6170, 0.6486],
        [0.9996, 0.5858, 0.6639, 0.6448],
        [1.0000, 0.7538, 0.6628, 0.7063]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:43,890:INFO::its now!!!!!!!!5
2023-12-01 17:04:44,039:INFO::its now!!!!!!!!0
2023-12-01 17:04:44,040:INFO::its now!!!!!!!!3
2023-12-01 17:04:44,085:INFO::its now!!!!!!!!5
2023-12-01 17:04:44,246:INFO::its now!!!!!!!!
2023-12-01 17:04:44,246:INFO::its now!!!!!!!! on 
2023-12-01 17:04:44,298:INFO::its now!!!!!!!!5
2023-12-01 17:04:44,451:INFO::Epoch 00257 | lr 0.00050 | Train_Loss -0.0817 | Train_Classification_Loss 0.0346 | Dmon_Loss -0.2326 | Val_Loss 0.2368 | Search Time(s) 0.4101 | Infer Time(s) 0.1548 | Time(s) 0.5649 
2023-12-01 17:04:44,496:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:44,496:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:04:44,499:INFO::Epoch: 258
tensor([[0.6603, 0.6321, 0.6170, 0.8419],
        [0.6215, 0.8869, 0.6136, 0.6450],
        [0.9992, 0.5822, 0.6605, 0.6414],
        [1.0000, 0.7503, 0.6595, 0.7031]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:44,500:INFO::its now!!!!!!!!5
2023-12-01 17:04:44,664:INFO::its now!!!!!!!!0
2023-12-01 17:04:44,665:INFO::its now!!!!!!!!3
2023-12-01 17:04:44,713:INFO::its now!!!!!!!!5
2023-12-01 17:04:44,888:INFO::its now!!!!!!!!
2023-12-01 17:04:44,888:INFO::its now!!!!!!!! on 
2023-12-01 17:04:44,945:INFO::its now!!!!!!!!5
2023-12-01 17:04:45,110:INFO::Epoch 00258 | lr 0.00050 | Train_Loss -0.0801 | Train_Classification_Loss 0.0365 | Dmon_Loss -0.2331 | Val_Loss 0.2367 | Search Time(s) 0.4438 | Infer Time(s) 0.1682 | Time(s) 0.6120 
2023-12-01 17:04:45,149:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:45,150:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 17:04:45,152:INFO::Epoch: 259
tensor([[0.6536, 0.6246, 0.6105, 0.8419],
        [0.6148, 0.8869, 0.6070, 0.6382],
        [0.9986, 0.5752, 0.6540, 0.6348],
        [1.0000, 0.7435, 0.6532, 0.6970]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:45,152:INFO::its now!!!!!!!!5
2023-12-01 17:04:45,300:INFO::its now!!!!!!!!0
2023-12-01 17:04:45,301:INFO::its now!!!!!!!!3
2023-12-01 17:04:45,332:INFO::its now!!!!!!!!5
2023-12-01 17:04:45,509:INFO::its now!!!!!!!!
2023-12-01 17:04:45,509:INFO::its now!!!!!!!! on 
2023-12-01 17:04:45,564:INFO::its now!!!!!!!!5
2023-12-01 17:04:45,751:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:45,753:INFO::Epoch 00259 | lr 0.00050 | Train_Loss -0.0827 | Train_Classification_Loss 0.0338 | Dmon_Loss -0.2330 | Val_Loss 0.2366 | Search Time(s) 0.4135 | Infer Time(s) 0.1875 | Time(s) 0.6010 
2023-12-01 17:04:45,807:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:45,809:INFO::Validation loss decreased (0.236661 --> 0.236619).  Saving model ...
2023-12-01 17:04:45,811:INFO::Epoch: 260
tensor([[0.6502, 0.6300, 0.6152, 0.8512],
        [0.6196, 0.8974, 0.6037, 0.6431],
        [1.0000, 0.5803, 0.6587, 0.6316],
        [1.0000, 0.7484, 0.6500, 0.7014]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:45,812:INFO::its now!!!!!!!!5
2023-12-01 17:04:46,006:INFO::its now!!!!!!!!0
2023-12-01 17:04:46,007:INFO::its now!!!!!!!!3
2023-12-01 17:04:46,052:INFO::its now!!!!!!!!5
2023-12-01 17:04:46,216:INFO::its now!!!!!!!!
2023-12-01 17:04:46,216:INFO::its now!!!!!!!! on 
2023-12-01 17:04:46,270:INFO::its now!!!!!!!!5
2023-12-01 17:04:46,440:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:46,442:INFO::Epoch 00260 | lr 0.00050 | Train_Loss -0.0810 | Train_Classification_Loss 0.0355 | Dmon_Loss -0.2330 | Val_Loss 0.2364 | Search Time(s) 0.4574 | Infer Time(s) 0.1742 | Time(s) 0.6315 
2023-12-01 17:04:46,490:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:46,491:INFO::Validation loss decreased (0.236619 --> 0.236436).  Saving model ...
2023-12-01 17:04:46,493:INFO::Epoch: 261
tensor([[0.6462, 0.6302, 0.6154, 0.8559],
        [0.6198, 0.9027, 0.5998, 0.6433],
        [1.0000, 0.5804, 0.6589, 0.6277],
        [1.0000, 0.7486, 0.6463, 0.7016]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:46,493:INFO::its now!!!!!!!!5
2023-12-01 17:04:46,655:INFO::its now!!!!!!!!0
2023-12-01 17:04:46,656:INFO::its now!!!!!!!!3
2023-12-01 17:04:46,706:INFO::its now!!!!!!!!5
2023-12-01 17:04:46,857:INFO::its now!!!!!!!!
2023-12-01 17:04:46,857:INFO::its now!!!!!!!! on 
2023-12-01 17:04:46,915:INFO::its now!!!!!!!!5
2023-12-01 17:04:47,071:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:47,072:INFO::Epoch 00261 | lr 0.00050 | Train_Loss -0.0823 | Train_Classification_Loss 0.0342 | Dmon_Loss -0.2331 | Val_Loss 0.2362 | Search Time(s) 0.4209 | Infer Time(s) 0.1596 | Time(s) 0.5804 
2023-12-01 17:04:47,133:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:47,134:INFO::Validation loss decreased (0.236436 --> 0.236223).  Saving model ...
2023-12-01 17:04:47,137:INFO::Epoch: 262
tensor([[0.6413, 0.6272, 0.6128, 0.8582],
        [0.6171, 0.9053, 0.5950, 0.6406],
        [1.0000, 0.5776, 0.6563, 0.6230],
        [1.0000, 0.7459, 0.6417, 0.6991]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:47,138:INFO::its now!!!!!!!!5
2023-12-01 17:04:47,306:INFO::its now!!!!!!!!0
2023-12-01 17:04:47,306:INFO::its now!!!!!!!!3
2023-12-01 17:04:47,351:INFO::its now!!!!!!!!5
2023-12-01 17:04:47,499:INFO::its now!!!!!!!!
2023-12-01 17:04:47,499:INFO::its now!!!!!!!! on 
2023-12-01 17:04:47,551:INFO::its now!!!!!!!!5
2023-12-01 17:04:47,712:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:47,714:INFO::Epoch 00262 | lr 0.00050 | Train_Loss -0.0804 | Train_Classification_Loss 0.0360 | Dmon_Loss -0.2329 | Val_Loss 0.2360 | Search Time(s) 0.4130 | Infer Time(s) 0.1646 | Time(s) 0.5776 
2023-12-01 17:04:47,763:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:47,764:INFO::Validation loss decreased (0.236223 --> 0.235974).  Saving model ...
2023-12-01 17:04:47,767:INFO::Epoch: 263
tensor([[0.6378, 0.6245, 0.6104, 0.8594],
        [0.6147, 0.9066, 0.5915, 0.6381],
        [1.0000, 0.5751, 0.6539, 0.6196],
        [1.0000, 0.7434, 0.6384, 0.6969]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:47,768:INFO::its now!!!!!!!!5
2023-12-01 17:04:47,923:INFO::its now!!!!!!!!0
2023-12-01 17:04:47,923:INFO::its now!!!!!!!!3
2023-12-01 17:04:47,967:INFO::its now!!!!!!!!5
2023-12-01 17:04:48,154:INFO::its now!!!!!!!!
2023-12-01 17:04:48,154:INFO::its now!!!!!!!! on 
2023-12-01 17:04:48,207:INFO::its now!!!!!!!!5
2023-12-01 17:04:48,352:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:48,354:INFO::Epoch 00263 | lr 0.00050 | Train_Loss -0.0811 | Train_Classification_Loss 0.0356 | Dmon_Loss -0.2334 | Val_Loss 0.2357 | Search Time(s) 0.4404 | Infer Time(s) 0.1472 | Time(s) 0.5876 
2023-12-01 17:04:48,399:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:48,401:INFO::Validation loss decreased (0.235974 --> 0.235715).  Saving model ...
2023-12-01 17:04:48,404:INFO::Epoch: 264
tensor([[0.6348, 0.6218, 0.6081, 0.8600],
        [0.6123, 0.9073, 0.5886, 0.6357],
        [1.0000, 0.5726, 0.6516, 0.6166],
        [1.0000, 0.7410, 0.6356, 0.6946]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:48,405:INFO::its now!!!!!!!!5
2023-12-01 17:04:48,554:INFO::its now!!!!!!!!0
2023-12-01 17:04:48,555:INFO::its now!!!!!!!!3
2023-12-01 17:04:48,599:INFO::its now!!!!!!!!5
2023-12-01 17:04:48,761:INFO::its now!!!!!!!!
2023-12-01 17:04:48,761:INFO::its now!!!!!!!! on 
2023-12-01 17:04:48,815:INFO::its now!!!!!!!!5
2023-12-01 17:04:48,971:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:48,973:INFO::Epoch 00264 | lr 0.00050 | Train_Loss -0.0833 | Train_Classification_Loss 0.0333 | Dmon_Loss -0.2333 | Val_Loss 0.2355 | Search Time(s) 0.4109 | Infer Time(s) 0.1596 | Time(s) 0.5705 
2023-12-01 17:04:49,014:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:49,015:INFO::Validation loss decreased (0.235715 --> 0.235457).  Saving model ...
2023-12-01 17:04:49,019:INFO::Epoch: 265
tensor([[0.6336, 0.6208, 0.6072, 0.8603],
        [0.6115, 0.9076, 0.5874, 0.6348],
        [1.0000, 0.5717, 0.6507, 0.6155],
        [1.0000, 0.7401, 0.6345, 0.6938]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:49,020:INFO::its now!!!!!!!!5
2023-12-01 17:04:49,180:INFO::its now!!!!!!!!0
2023-12-01 17:04:49,181:INFO::its now!!!!!!!!3
2023-12-01 17:04:49,230:INFO::its now!!!!!!!!5
2023-12-01 17:04:49,378:INFO::its now!!!!!!!!
2023-12-01 17:04:49,378:INFO::its now!!!!!!!! on 
2023-12-01 17:04:49,435:INFO::its now!!!!!!!!5
2023-12-01 17:04:49,588:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:49,589:INFO::Epoch 00265 | lr 0.00050 | Train_Loss -0.0844 | Train_Classification_Loss 0.0324 | Dmon_Loss -0.2335 | Val_Loss 0.2352 | Search Time(s) 0.4156 | Infer Time(s) 0.1566 | Time(s) 0.5721 
2023-12-01 17:04:49,625:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 3;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:49,626:INFO::Validation loss decreased (0.235457 --> 0.235241).  Saving model ...
2023-12-01 17:04:49,630:INFO::Epoch: 266
tensor([[0.6322, 0.6194, 0.6060, 0.8605],
        [0.6102, 0.9078, 0.5860, 0.6335],
        [1.0000, 0.5703, 0.6495, 0.6141],
        [1.0000, 0.7388, 0.6331, 0.6926]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:49,630:INFO::its now!!!!!!!!5
2023-12-01 17:04:49,778:INFO::its now!!!!!!!!0
2023-12-01 17:04:49,779:INFO::its now!!!!!!!!3
2023-12-01 17:04:49,825:INFO::its now!!!!!!!!5
2023-12-01 17:04:49,989:INFO::its now!!!!!!!!
2023-12-01 17:04:49,990:INFO::its now!!!!!!!! on 
2023-12-01 17:04:50,044:INFO::its now!!!!!!!!5
2023-12-01 17:04:50,213:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:50,215:INFO::Epoch 00266 | lr 0.00050 | Train_Loss -0.0820 | Train_Classification_Loss 0.0347 | Dmon_Loss -0.2334 | Val_Loss 0.2350 | Search Time(s) 0.4129 | Infer Time(s) 0.1731 | Time(s) 0.5860 
2023-12-01 17:04:50,263:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:50,264:INFO::Validation loss decreased (0.235241 --> 0.235042).  Saving model ...
2023-12-01 17:04:50,268:INFO::Epoch: 267
tensor([[0.6310, 0.6182, 0.6049, 0.8605],
        [0.6091, 0.9079, 0.5848, 0.6324],
        [1.0000, 0.5692, 0.6484, 0.6129],
        [1.0000, 0.7378, 0.6320, 0.6916]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:50,269:INFO::its now!!!!!!!!5
2023-12-01 17:04:50,442:INFO::its now!!!!!!!!0
2023-12-01 17:04:50,442:INFO::its now!!!!!!!!3
2023-12-01 17:04:50,487:INFO::its now!!!!!!!!5
2023-12-01 17:04:50,628:INFO::its now!!!!!!!!
2023-12-01 17:04:50,628:INFO::its now!!!!!!!! on 
2023-12-01 17:04:50,682:INFO::its now!!!!!!!!5
2023-12-01 17:04:50,850:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:50,852:INFO::Epoch 00267 | lr 0.00050 | Train_Loss -0.0826 | Train_Classification_Loss 0.0344 | Dmon_Loss -0.2338 | Val_Loss 0.2349 | Search Time(s) 0.4126 | Infer Time(s) 0.1725 | Time(s) 0.5851 
2023-12-01 17:04:50,895:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:50,897:INFO::Validation loss decreased (0.235042 --> 0.234926).  Saving model ...
2023-12-01 17:04:50,900:INFO::Epoch: 268
tensor([[0.6306, 0.6179, 0.6046, 0.8606],
        [0.6088, 0.9079, 0.5845, 0.6321],
        [0.9999, 0.5689, 0.6481, 0.6126],
        [1.0000, 0.7375, 0.6317, 0.6913]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:50,901:INFO::its now!!!!!!!!5
2023-12-01 17:04:51,050:INFO::its now!!!!!!!!0
2023-12-01 17:04:51,050:INFO::its now!!!!!!!!3
2023-12-01 17:04:51,099:INFO::its now!!!!!!!!5
2023-12-01 17:04:51,349:INFO::its now!!!!!!!!
2023-12-01 17:04:51,349:INFO::its now!!!!!!!! on 
2023-12-01 17:04:51,406:INFO::its now!!!!!!!!5
2023-12-01 17:04:51,566:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:51,567:INFO::Epoch 00268 | lr 0.00050 | Train_Loss -0.0845 | Train_Classification_Loss 0.0324 | Dmon_Loss -0.2339 | Val_Loss 0.2349 | Search Time(s) 0.5078 | Infer Time(s) 0.1616 | Time(s) 0.6694 
2023-12-01 17:04:51,623:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:51,624:INFO::Validation loss decreased (0.234926 --> 0.234862).  Saving model ...
2023-12-01 17:04:51,627:INFO::Epoch: 269
tensor([[0.6303, 0.6175, 0.6043, 0.8606],
        [0.6085, 0.9079, 0.5841, 0.6317],
        [0.9997, 0.5685, 0.6478, 0.6122],
        [1.0000, 0.7371, 0.6314, 0.6910]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:51,628:INFO::its now!!!!!!!!5
2023-12-01 17:04:51,776:INFO::its now!!!!!!!!0
2023-12-01 17:04:51,777:INFO::its now!!!!!!!!3
2023-12-01 17:04:51,823:INFO::its now!!!!!!!!5
2023-12-01 17:04:51,986:INFO::its now!!!!!!!!
2023-12-01 17:04:51,986:INFO::its now!!!!!!!! on 
2023-12-01 17:04:52,039:INFO::its now!!!!!!!!5
2023-12-01 17:04:52,193:INFO::Epoch 00269 | lr 0.00050 | Train_Loss -0.0845 | Train_Classification_Loss 0.0321 | Dmon_Loss -0.2332 | Val_Loss 0.2349 | Search Time(s) 0.4099 | Infer Time(s) 0.1582 | Time(s) 0.5681 
2023-12-01 17:04:52,240:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:52,242:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:04:52,244:INFO::Epoch: 270
tensor([[0.6284, 0.6154, 0.6025, 0.8606],
        [0.6066, 0.9079, 0.5822, 0.6299],
        [0.9995, 0.5666, 0.6460, 0.6104],
        [1.0000, 0.7352, 0.6296, 0.6893]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:52,245:INFO::its now!!!!!!!!5
2023-12-01 17:04:52,407:INFO::its now!!!!!!!!0
2023-12-01 17:04:52,408:INFO::its now!!!!!!!!3
2023-12-01 17:04:52,450:INFO::its now!!!!!!!!5
2023-12-01 17:04:52,622:INFO::its now!!!!!!!!
2023-12-01 17:04:52,622:INFO::its now!!!!!!!! on 
2023-12-01 17:04:52,672:INFO::its now!!!!!!!!5
2023-12-01 17:04:52,822:INFO::Epoch 00270 | lr 0.00050 | Train_Loss -0.0841 | Train_Classification_Loss 0.0322 | Dmon_Loss -0.2326 | Val_Loss 0.2350 | Search Time(s) 0.4265 | Infer Time(s) 0.1526 | Time(s) 0.5790 
2023-12-01 17:04:52,866:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 2;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:52,868:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:04:52,871:INFO::Epoch: 271
tensor([[0.6258, 0.6126, 0.6000, 0.8606],
        [0.6041, 0.9079, 0.5797, 0.6273],
        [0.9992, 0.5640, 0.6435, 0.6078],
        [1.0000, 0.7327, 0.6271, 0.6869]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:52,872:INFO::its now!!!!!!!!5
2023-12-01 17:04:53,041:INFO::its now!!!!!!!!0
2023-12-01 17:04:53,042:INFO::its now!!!!!!!!3
2023-12-01 17:04:53,090:INFO::its now!!!!!!!!5
2023-12-01 17:04:53,270:INFO::its now!!!!!!!!
2023-12-01 17:04:53,271:INFO::its now!!!!!!!! on 
2023-12-01 17:04:53,327:INFO::its now!!!!!!!!5
2023-12-01 17:04:53,508:INFO::Epoch 00271 | lr 0.00050 | Train_Loss -0.0863 | Train_Classification_Loss 0.0304 | Dmon_Loss -0.2335 | Val_Loss 0.2352 | Search Time(s) 0.4549 | Infer Time(s) 0.1855 | Time(s) 0.6404 
2023-12-01 17:04:53,552:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:53,553:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 17:04:53,556:INFO::Epoch: 272
tensor([[0.6232, 0.6098, 0.5976, 0.8606],
        [0.6016, 0.9079, 0.5772, 0.6248],
        [0.9990, 0.5614, 0.6411, 0.6053],
        [1.0000, 0.7302, 0.6247, 0.6846]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:53,557:INFO::its now!!!!!!!!5
2023-12-01 17:04:53,697:INFO::its now!!!!!!!!0
2023-12-01 17:04:53,698:INFO::its now!!!!!!!!3
2023-12-01 17:04:53,728:INFO::its now!!!!!!!!5
2023-12-01 17:04:53,891:INFO::its now!!!!!!!!
2023-12-01 17:04:53,891:INFO::its now!!!!!!!! on 
2023-12-01 17:04:53,944:INFO::its now!!!!!!!!5
2023-12-01 17:04:54,088:INFO::Epoch 00272 | lr 0.00050 | Train_Loss -0.0870 | Train_Classification_Loss 0.0303 | Dmon_Loss -0.2345 | Val_Loss 0.2353 | Search Time(s) 0.3860 | Infer Time(s) 0.1466 | Time(s) 0.5326 
2023-12-01 17:04:54,125:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:54,126:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 17:04:54,129:INFO::Epoch: 273
tensor([[0.6219, 0.6192, 0.6059, 0.8717],
        [0.6101, 0.9203, 0.5858, 0.6235],
        [1.0000, 0.5702, 0.6402, 0.6139],
        [1.0000, 0.7387, 0.6329, 0.6926]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:54,130:INFO::its now!!!!!!!!5
2023-12-01 17:04:54,293:INFO::its now!!!!!!!!0
2023-12-01 17:04:54,294:INFO::its now!!!!!!!!3
2023-12-01 17:04:54,338:INFO::its now!!!!!!!!5
2023-12-01 17:04:54,491:INFO::its now!!!!!!!!
2023-12-01 17:04:54,492:INFO::its now!!!!!!!! on 
2023-12-01 17:04:54,546:INFO::its now!!!!!!!!5
2023-12-01 17:04:54,721:INFO::Epoch 00273 | lr 0.00050 | Train_Loss -0.0862 | Train_Classification_Loss 0.0310 | Dmon_Loss -0.2344 | Val_Loss 0.2355 | Search Time(s) 0.4157 | Infer Time(s) 0.1795 | Time(s) 0.5952 
2023-12-01 17:04:54,773:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:54,774:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 17:04:54,777:INFO::Epoch: 274
tensor([[0.6188, 0.6213, 0.6077, 0.8773],
        [0.6120, 0.9265, 0.5877, 0.6204],
        [1.0000, 0.5722, 0.6373, 0.6157],
        [1.0000, 0.7406, 0.6347, 0.6943]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:54,778:INFO::its now!!!!!!!!5
2023-12-01 17:04:54,913:INFO::its now!!!!!!!!0
2023-12-01 17:04:54,914:INFO::its now!!!!!!!!3
2023-12-01 17:04:54,963:INFO::its now!!!!!!!!5
2023-12-01 17:04:55,135:INFO::its now!!!!!!!!
2023-12-01 17:04:55,135:INFO::its now!!!!!!!! on 
2023-12-01 17:04:55,193:INFO::its now!!!!!!!!5
2023-12-01 17:04:55,372:INFO::Epoch 00274 | lr 0.00050 | Train_Loss -0.0868 | Train_Classification_Loss 0.0300 | Dmon_Loss -0.2334 | Val_Loss 0.2357 | Search Time(s) 0.4156 | Infer Time(s) 0.1809 | Time(s) 0.5965 
2023-12-01 17:04:55,407:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:55,407:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 17:04:55,409:INFO::Epoch: 275
tensor([[0.6134, 0.6184, 0.6051, 0.8801],
        [0.6093, 0.9297, 0.5850, 0.6151],
        [1.0000, 0.5694, 0.6323, 0.6131],
        [1.0000, 0.7380, 0.6322, 0.6919]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:55,410:INFO::its now!!!!!!!!5
2023-12-01 17:04:55,571:INFO::its now!!!!!!!!0
2023-12-01 17:04:55,572:INFO::its now!!!!!!!!3
2023-12-01 17:04:55,616:INFO::its now!!!!!!!!5
2023-12-01 17:04:55,808:INFO::its now!!!!!!!!
2023-12-01 17:04:55,808:INFO::its now!!!!!!!! on 
2023-12-01 17:04:55,860:INFO::its now!!!!!!!!5
2023-12-01 17:04:56,017:INFO::Epoch 00275 | lr 0.00050 | Train_Loss -0.0879 | Train_Classification_Loss 0.0291 | Dmon_Loss -0.2339 | Val_Loss 0.2360 | Search Time(s) 0.4498 | Infer Time(s) 0.1586 | Time(s) 0.6084 
2023-12-01 17:04:56,072:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 2;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 3;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:56,073:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 17:04:56,077:INFO::Epoch: 276
tensor([[0.6093, 0.6155, 0.6026, 0.8815],
        [0.6067, 0.9312, 0.5824, 0.6111],
        [1.0000, 0.5667, 0.6285, 0.6105],
        [1.0000, 0.7354, 0.6297, 0.6894]], device='cuda:0', requires_grad=True)
2023-12-01 17:04:56,077:INFO::its now!!!!!!!!5
2023-12-01 17:04:56,211:INFO::its now!!!!!!!!0
2023-12-01 17:04:56,211:INFO::its now!!!!!!!!3
2023-12-01 17:04:56,255:INFO::its now!!!!!!!!5
2023-12-01 17:04:56,448:INFO::its now!!!!!!!!
2023-12-01 17:04:56,448:INFO::its now!!!!!!!! on 
2023-12-01 17:04:56,501:INFO::its now!!!!!!!!5
2023-12-01 17:04:56,695:INFO::Epoch 00276 | lr 0.00050 | Train_Loss -0.0878 | Train_Classification_Loss 0.0291 | Dmon_Loss -0.2337 | Val_Loss 0.2362 | Search Time(s) 0.4261 | Infer Time(s) 0.1955 | Time(s) 0.6216 
2023-12-01 17:04:56,750:INFO::cluster info:
0: 3;	1: 3;	2: 3;	3: 3;	4: 2;	5: 3;	6: 3;	7: 3;	8: 3;	9: 3;	10: 3;	11: 3;	12: 3;	13: 2;	14: 3;	15: 2;	16: 3;	17: 2;	18: 3;	19: 3;	20: 3;	21: 3;	22: 3;	23: 3;	24: 2;	25: 3;	26: 3;	27: 3;	28: 2;	29: 3;	30: 2;	31: 3;	32: 3;	33: 2;	34: 2;	35: 3;	36: 2;	37: 2;	38: 2;	39: 3;	40: 2;	41: 2;	42: 3;	43: 3;	44
26098: 3;	26099: 3;	26100: 2;	26101: 2;	26102: 3;	26103: 2;	26104: 3;	26105: 2;	26106: 2;	26107: 2;	26108: 3;	26109: 2;	26110: 3;	26111: 3;	26112: 3;	26113: 2;	26114: 2;	26115: 2;	26116: 3;	26117: 3;	26118: 2;	26119: 2;	26120: 2;	26121: 2;	26122: 2;	26123: 3;	26124: 2;	26125: 2;	26126: 3;	26127: 3;	
2023-12-01 17:04:56,751:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 17:04:56,751:INFO::Eearly stopping!
2023-12-01 17:04:56,945:INFO::############### Search Stage Ends! ###############
2023-12-01 17:04:56,981:INFO::=============== Retrain Stage Starts:
2023-12-01 17:04:56,981:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:57,004:INFO::node_assign_Counter:
Counter({-1: 14328, 3: 6419, 2: 5380, 1: 1})
2023-12-01 17:04:57,004:INFO::save_dir_name: gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:04:57,397:INFO::============= repeat round: 4; seed: 2022
2023-12-01 17:04:57,435:INFO::arch_weights:
[[0.63029045 0.61748666 0.6042873  0.8605811 ]
 [0.60847074 0.907933   0.5841449  0.6317487 ]
 [0.99970853 0.5685424  0.6477825  0.6122496 ]
 [1.         0.7371192  0.6313638  0.69102293]]
2023-12-01 17:04:57,436:INFO::arch_weights_softmax:
[[0.23693448 0.23392017 0.23085289 0.29829246]
 [0.22995633 0.31024173 0.22442995 0.23537202]
 [0.32983023 0.2143075  0.2319802  0.22388202]
 [0.31301764 0.24065846 0.2165071  0.2298168 ]]
2023-12-01 17:04:57,436:INFO::genotype choice:
['one-hot', 'ppnp', 'gcn', 'gcn']
2023-12-01 17:04:58,010:INFO::Epoch 00000 | lr 0.00050 |Train_Loss 1.3865 | Val_Loss 1.3818 | Time(s) 0.5376
2023-12-01 17:04:58,377:INFO::Epoch 00001 | lr 0.00050 |Train_Loss 1.3818 | Val_Loss 1.3776 | Time(s) 0.3584
2023-12-01 17:04:58,389:INFO::Validation loss decreased (inf --> 1.377625).  Saving model ...
2023-12-01 17:04:58,746:INFO::Epoch 00002 | lr 0.00050 |Train_Loss 1.3776 | Val_Loss 1.3735 | Time(s) 0.3570
2023-12-01 17:04:58,755:INFO::Validation loss decreased (1.377625 --> 1.373521).  Saving model ...
2023-12-01 17:04:59,111:INFO::Epoch 00003 | lr 0.00050 |Train_Loss 1.3706 | Val_Loss 1.3696 | Time(s) 0.3557
2023-12-01 17:04:59,119:INFO::Validation loss decreased (1.373521 --> 1.369581).  Saving model ...
2023-12-01 17:04:59,472:INFO::Epoch 00004 | lr 0.00050 |Train_Loss 1.3683 | Val_Loss 1.3657 | Time(s) 0.3531
2023-12-01 17:04:59,482:INFO::Validation loss decreased (1.369581 --> 1.365715).  Saving model ...
2023-12-01 17:04:59,855:INFO::Epoch 00005 | lr 0.00050 |Train_Loss 1.3620 | Val_Loss 1.3619 | Time(s) 0.3720
2023-12-01 17:04:59,863:INFO::Validation loss decreased (1.365715 --> 1.361927).  Saving model ...
2023-12-01 17:05:00,208:INFO::Epoch 00006 | lr 0.00050 |Train_Loss 1.3566 | Val_Loss 1.3582 | Time(s) 0.3437
2023-12-01 17:05:00,216:INFO::Validation loss decreased (1.361927 --> 1.358189).  Saving model ...
2023-12-01 17:05:00,551:INFO::Epoch 00007 | lr 0.00050 |Train_Loss 1.3539 | Val_Loss 1.3545 | Time(s) 0.3348
2023-12-01 17:05:00,560:INFO::Validation loss decreased (1.358189 --> 1.354515).  Saving model ...
2023-12-01 17:05:00,918:INFO::Epoch 00008 | lr 0.00050 |Train_Loss 1.3500 | Val_Loss 1.3509 | Time(s) 0.3580
2023-12-01 17:05:00,927:INFO::Validation loss decreased (1.354515 --> 1.350864).  Saving model ...
2023-12-01 17:05:01,315:INFO::Epoch 00009 | lr 0.00050 |Train_Loss 1.3449 | Val_Loss 1.3472 | Time(s) 0.3871
2023-12-01 17:05:01,323:INFO::Validation loss decreased (1.350864 --> 1.347205).  Saving model ...
2023-12-01 17:05:01,698:INFO::Epoch 00010 | lr 0.00050 |Train_Loss 1.3407 | Val_Loss 1.3435 | Time(s) 0.3750
2023-12-01 17:05:01,707:INFO::Validation loss decreased (1.347205 --> 1.343539).  Saving model ...
2023-12-01 17:05:02,073:INFO::Epoch 00011 | lr 0.00050 |Train_Loss 1.3363 | Val_Loss 1.3399 | Time(s) 0.3660
2023-12-01 17:05:02,081:INFO::Validation loss decreased (1.343539 --> 1.339872).  Saving model ...
2023-12-01 17:05:02,474:INFO::Epoch 00012 | lr 0.00050 |Train_Loss 1.3327 | Val_Loss 1.3362 | Time(s) 0.3931
2023-12-01 17:05:02,482:INFO::Validation loss decreased (1.339872 --> 1.336151).  Saving model ...
2023-12-01 17:05:02,850:INFO::Epoch 00013 | lr 0.00050 |Train_Loss 1.3271 | Val_Loss 1.3324 | Time(s) 0.3670
2023-12-01 17:05:02,858:INFO::Validation loss decreased (1.336151 --> 1.332365).  Saving model ...
2023-12-01 17:05:03,200:INFO::Epoch 00014 | lr 0.00050 |Train_Loss 1.3227 | Val_Loss 1.3285 | Time(s) 0.3420
2023-12-01 17:05:03,208:INFO::Validation loss decreased (1.332365 --> 1.328470).  Saving model ...
2023-12-01 17:05:03,579:INFO::Epoch 00015 | lr 0.00050 |Train_Loss 1.3198 | Val_Loss 1.3245 | Time(s) 0.3686
2023-12-01 17:05:03,589:INFO::Validation loss decreased (1.328470 --> 1.324489).  Saving model ...
2023-12-01 17:05:03,968:INFO::Epoch 00016 | lr 0.00050 |Train_Loss 1.3132 | Val_Loss 1.3204 | Time(s) 0.3780
2023-12-01 17:05:03,978:INFO::Validation loss decreased (1.324489 --> 1.320398).  Saving model ...
2023-12-01 17:05:04,328:INFO::Epoch 00017 | lr 0.00050 |Train_Loss 1.3076 | Val_Loss 1.3162 | Time(s) 0.3492
2023-12-01 17:05:04,337:INFO::Validation loss decreased (1.320398 --> 1.316180).  Saving model ...
2023-12-01 17:05:04,724:INFO::Epoch 00018 | lr 0.00050 |Train_Loss 1.3035 | Val_Loss 1.3118 | Time(s) 0.3851
2023-12-01 17:05:04,735:INFO::Validation loss decreased (1.316180 --> 1.311812).  Saving model ...
2023-12-01 17:05:05,081:INFO::Epoch 00019 | lr 0.00050 |Train_Loss 1.2990 | Val_Loss 1.3073 | Time(s) 0.3461
2023-12-01 17:05:05,089:INFO::Validation loss decreased (1.311812 --> 1.307262).  Saving model ...
2023-12-01 17:05:05,455:INFO::Epoch 00020 | lr 0.00050 |Train_Loss 1.2950 | Val_Loss 1.3025 | Time(s) 0.3655
2023-12-01 17:05:05,465:INFO::Validation loss decreased (1.307262 --> 1.302528).  Saving model ...
2023-12-01 17:05:05,839:INFO::Epoch 00021 | lr 0.00050 |Train_Loss 1.2869 | Val_Loss 1.2976 | Time(s) 0.3740
2023-12-01 17:05:05,848:INFO::Validation loss decreased (1.302528 --> 1.297580).  Saving model ...
2023-12-01 17:05:06,190:INFO::Epoch 00022 | lr 0.00050 |Train_Loss 1.2831 | Val_Loss 1.2924 | Time(s) 0.3417
2023-12-01 17:05:06,199:INFO::Validation loss decreased (1.297580 --> 1.292405).  Saving model ...
2023-12-01 17:05:06,574:INFO::Epoch 00023 | lr 0.00050 |Train_Loss 1.2776 | Val_Loss 1.2870 | Time(s) 0.3744
2023-12-01 17:05:06,583:INFO::Validation loss decreased (1.292405 --> 1.287000).  Saving model ...
2023-12-01 17:05:06,966:INFO::Epoch 00024 | lr 0.00050 |Train_Loss 1.2691 | Val_Loss 1.2813 | Time(s) 0.3830
2023-12-01 17:05:06,977:INFO::Validation loss decreased (1.287000 --> 1.281347).  Saving model ...
2023-12-01 17:05:07,343:INFO::Epoch 00025 | lr 0.00050 |Train_Loss 1.2629 | Val_Loss 1.2754 | Time(s) 0.3662
2023-12-01 17:05:07,354:INFO::Validation loss decreased (1.281347 --> 1.275443).  Saving model ...
2023-12-01 17:05:07,736:INFO::Epoch 00026 | lr 0.00050 |Train_Loss 1.2528 | Val_Loss 1.2692 | Time(s) 0.3820
2023-12-01 17:05:07,745:INFO::Validation loss decreased (1.275443 --> 1.269238).  Saving model ...
2023-12-01 17:05:08,095:INFO::Epoch 00027 | lr 0.00050 |Train_Loss 1.2529 | Val_Loss 1.2628 | Time(s) 0.3501
2023-12-01 17:05:08,105:INFO::Validation loss decreased (1.269238 --> 1.262771).  Saving model ...
2023-12-01 17:05:08,457:INFO::Epoch 00028 | lr 0.00050 |Train_Loss 1.2419 | Val_Loss 1.2560 | Time(s) 0.3521
2023-12-01 17:05:08,466:INFO::Validation loss decreased (1.262771 --> 1.256028).  Saving model ...
2023-12-01 17:05:08,825:INFO::Epoch 00029 | lr 0.00050 |Train_Loss 1.2340 | Val_Loss 1.2490 | Time(s) 0.3580
2023-12-01 17:05:08,834:INFO::Validation loss decreased (1.256028 --> 1.249003).  Saving model ...
2023-12-01 17:05:09,184:INFO::Epoch 00030 | lr 0.00050 |Train_Loss 1.2237 | Val_Loss 1.2417 | Time(s) 0.3496
2023-12-01 17:05:09,193:INFO::Validation loss decreased (1.249003 --> 1.241708).  Saving model ...
2023-12-01 17:05:09,555:INFO::Epoch 00031 | lr 0.00050 |Train_Loss 1.2200 | Val_Loss 1.2341 | Time(s) 0.3621
2023-12-01 17:05:09,564:INFO::Validation loss decreased (1.241708 --> 1.234147).  Saving model ...
2023-12-01 17:05:09,926:INFO::Epoch 00032 | lr 0.00050 |Train_Loss 1.2152 | Val_Loss 1.2263 | Time(s) 0.3620
2023-12-01 17:05:09,937:INFO::Validation loss decreased (1.234147 --> 1.226295).  Saving model ...
2023-12-01 17:05:10,322:INFO::Epoch 00033 | lr 0.00050 |Train_Loss 1.1997 | Val_Loss 1.2182 | Time(s) 0.3847
2023-12-01 17:05:10,335:INFO::Validation loss decreased (1.226295 --> 1.218152).  Saving model ...
2023-12-01 17:05:10,731:INFO::Epoch 00034 | lr 0.00050 |Train_Loss 1.1929 | Val_Loss 1.2097 | Time(s) 0.3949
2023-12-01 17:05:10,740:INFO::Validation loss decreased (1.218152 --> 1.209723).  Saving model ...
2023-12-01 17:05:11,132:INFO::Epoch 00035 | lr 0.00050 |Train_Loss 1.1818 | Val_Loss 1.2010 | Time(s) 0.3916
2023-12-01 17:05:11,140:INFO::Validation loss decreased (1.209723 --> 1.200988).  Saving model ...
2023-12-01 17:05:11,465:INFO::Epoch 00036 | lr 0.00050 |Train_Loss 1.1695 | Val_Loss 1.1920 | Time(s) 0.3247
2023-12-01 17:05:11,474:INFO::Validation loss decreased (1.200988 --> 1.191977).  Saving model ...
2023-12-01 17:05:11,840:INFO::Epoch 00037 | lr 0.00050 |Train_Loss 1.1651 | Val_Loss 1.1827 | Time(s) 0.3660
2023-12-01 17:05:11,851:INFO::Validation loss decreased (1.191977 --> 1.182680).  Saving model ...
2023-12-01 17:05:12,211:INFO::Epoch 00038 | lr 0.00050 |Train_Loss 1.1504 | Val_Loss 1.1731 | Time(s) 0.3606
2023-12-01 17:05:12,219:INFO::Validation loss decreased (1.182680 --> 1.173125).  Saving model ...
2023-12-01 17:05:12,567:INFO::Epoch 00039 | lr 0.00050 |Train_Loss 1.1427 | Val_Loss 1.1633 | Time(s) 0.3476
2023-12-01 17:05:12,577:INFO::Validation loss decreased (1.173125 --> 1.163273).  Saving model ...
2023-12-01 17:05:12,942:INFO::Epoch 00040 | lr 0.00050 |Train_Loss 1.1343 | Val_Loss 1.1532 | Time(s) 0.3650
2023-12-01 17:05:12,953:INFO::Validation loss decreased (1.163273 --> 1.153160).  Saving model ...
2023-12-01 17:05:13,344:INFO::Epoch 00041 | lr 0.00050 |Train_Loss 1.1220 | Val_Loss 1.1428 | Time(s) 0.3910
2023-12-01 17:05:13,355:INFO::Validation loss decreased (1.153160 --> 1.142784).  Saving model ...
2023-12-01 17:05:13,730:INFO::Epoch 00042 | lr 0.00050 |Train_Loss 1.1106 | Val_Loss 1.1322 | Time(s) 0.3750
2023-12-01 17:05:13,740:INFO::Validation loss decreased (1.142784 --> 1.132176).  Saving model ...
2023-12-01 17:05:14,086:INFO::Epoch 00043 | lr 0.00050 |Train_Loss 1.0958 | Val_Loss 1.1213 | Time(s) 0.3441
2023-12-01 17:05:14,095:INFO::Validation loss decreased (1.132176 --> 1.121316).  Saving model ...
2023-12-01 17:05:14,440:INFO::Epoch 00044 | lr 0.00050 |Train_Loss 1.0848 | Val_Loss 1.1102 | Time(s) 0.3452
2023-12-01 17:05:14,448:INFO::Validation loss decreased (1.121316 --> 1.110211).  Saving model ...
2023-12-01 17:05:14,799:INFO::Epoch 00045 | lr 0.00050 |Train_Loss 1.0744 | Val_Loss 1.0988 | Time(s) 0.3511
2023-12-01 17:05:14,807:INFO::Validation loss decreased (1.110211 --> 1.098831).  Saving model ...
2023-12-01 17:05:15,151:INFO::Epoch 00046 | lr 0.00050 |Train_Loss 1.0517 | Val_Loss 1.0872 | Time(s) 0.3427
2023-12-01 17:05:15,161:INFO::Validation loss decreased (1.098831 --> 1.087217).  Saving model ...
2023-12-01 17:05:15,546:INFO::Epoch 00047 | lr 0.00050 |Train_Loss 1.0446 | Val_Loss 1.0754 | Time(s) 0.3835
2023-12-01 17:05:15,554:INFO::Validation loss decreased (1.087217 --> 1.075365).  Saving model ...
2023-12-01 17:05:15,917:INFO::Epoch 00048 | lr 0.00050 |Train_Loss 1.0322 | Val_Loss 1.0633 | Time(s) 0.3630
2023-12-01 17:05:15,926:INFO::Validation loss decreased (1.075365 --> 1.063305).  Saving model ...
2023-12-01 17:05:16,311:INFO::Epoch 00049 | lr 0.00050 |Train_Loss 1.0181 | Val_Loss 1.0510 | Time(s) 0.3841
2023-12-01 17:05:16,321:INFO::Validation loss decreased (1.063305 --> 1.051044).  Saving model ...
2023-12-01 17:05:16,667:INFO::Epoch 00050 | lr 0.00050 |Train_Loss 1.0071 | Val_Loss 1.0385 | Time(s) 0.3451
2023-12-01 17:05:16,676:INFO::Validation loss decreased (1.051044 --> 1.038546).  Saving model ...
2023-12-01 17:05:17,053:INFO::Epoch 00051 | lr 0.00050 |Train_Loss 0.9920 | Val_Loss 1.0258 | Time(s) 0.3770
2023-12-01 17:05:17,064:INFO::Validation loss decreased (1.038546 --> 1.025826).  Saving model ...
2023-12-01 17:05:17,398:INFO::Epoch 00052 | lr 0.00050 |Train_Loss 0.9759 | Val_Loss 1.0129 | Time(s) 0.3333
2023-12-01 17:05:17,409:INFO::Validation loss decreased (1.025826 --> 1.012916).  Saving model ...
2023-12-01 17:05:17,760:INFO::Epoch 00053 | lr 0.00050 |Train_Loss 0.9635 | Val_Loss 0.9998 | Time(s) 0.3501
2023-12-01 17:05:17,771:INFO::Validation loss decreased (1.012916 --> 0.999814).  Saving model ...
2023-12-01 17:05:18,139:INFO::Epoch 00054 | lr 0.00050 |Train_Loss 0.9486 | Val_Loss 0.9865 | Time(s) 0.3676
2023-12-01 17:05:18,148:INFO::Validation loss decreased (0.999814 --> 0.986534).  Saving model ...
2023-12-01 17:05:18,518:INFO::Epoch 00055 | lr 0.00050 |Train_Loss 0.9308 | Val_Loss 0.9731 | Time(s) 0.3706
2023-12-01 17:05:18,527:INFO::Validation loss decreased (0.986534 --> 0.973095).  Saving model ...
2023-12-01 17:05:18,892:INFO::Epoch 00056 | lr 0.00050 |Train_Loss 0.9122 | Val_Loss 0.9595 | Time(s) 0.3650
2023-12-01 17:05:18,901:INFO::Validation loss decreased (0.973095 --> 0.959526).  Saving model ...
2023-12-01 17:05:19,226:INFO::Epoch 00057 | lr 0.00050 |Train_Loss 0.9006 | Val_Loss 0.9458 | Time(s) 0.3247
2023-12-01 17:05:19,235:INFO::Validation loss decreased (0.959526 --> 0.945842).  Saving model ...
2023-12-01 17:05:19,586:INFO::Epoch 00058 | lr 0.00050 |Train_Loss 0.8826 | Val_Loss 0.9320 | Time(s) 0.3515
2023-12-01 17:05:19,596:INFO::Validation loss decreased (0.945842 --> 0.932033).  Saving model ...
2023-12-01 17:05:19,921:INFO::Epoch 00059 | lr 0.00050 |Train_Loss 0.8673 | Val_Loss 0.9181 | Time(s) 0.3251
2023-12-01 17:05:19,930:INFO::Validation loss decreased (0.932033 --> 0.918106).  Saving model ...
2023-12-01 17:05:20,279:INFO::Epoch 00060 | lr 0.00050 |Train_Loss 0.8507 | Val_Loss 0.9041 | Time(s) 0.3476
2023-12-01 17:05:20,287:INFO::Validation loss decreased (0.918106 --> 0.904081).  Saving model ...
2023-12-01 17:05:20,637:INFO::Epoch 00061 | lr 0.00050 |Train_Loss 0.8361 | Val_Loss 0.8900 | Time(s) 0.3486
2023-12-01 17:05:20,645:INFO::Validation loss decreased (0.904081 --> 0.889992).  Saving model ...
2023-12-01 17:05:21,016:INFO::Epoch 00062 | lr 0.00050 |Train_Loss 0.8218 | Val_Loss 0.8759 | Time(s) 0.3710
2023-12-01 17:05:21,028:INFO::Validation loss decreased (0.889992 --> 0.875867).  Saving model ...
2023-12-01 17:05:21,410:INFO::Epoch 00063 | lr 0.00050 |Train_Loss 0.8077 | Val_Loss 0.8617 | Time(s) 0.3821
2023-12-01 17:05:21,419:INFO::Validation loss decreased (0.875867 --> 0.861724).  Saving model ...
2023-12-01 17:05:21,755:INFO::Epoch 00064 | lr 0.00050 |Train_Loss 0.7932 | Val_Loss 0.8476 | Time(s) 0.3361
2023-12-01 17:05:21,765:INFO::Validation loss decreased (0.861724 --> 0.847582).  Saving model ...
2023-12-01 17:05:22,113:INFO::Epoch 00065 | lr 0.00050 |Train_Loss 0.7708 | Val_Loss 0.8334 | Time(s) 0.3477
2023-12-01 17:05:22,123:INFO::Validation loss decreased (0.847582 --> 0.833414).  Saving model ...
2023-12-01 17:05:22,474:INFO::Epoch 00066 | lr 0.00050 |Train_Loss 0.7585 | Val_Loss 0.8193 | Time(s) 0.3496
2023-12-01 17:05:22,483:INFO::Validation loss decreased (0.833414 --> 0.819256).  Saving model ...
2023-12-01 17:05:22,832:INFO::Epoch 00067 | lr 0.00050 |Train_Loss 0.7444 | Val_Loss 0.8051 | Time(s) 0.3491
2023-12-01 17:05:22,842:INFO::Validation loss decreased (0.819256 --> 0.805130).  Saving model ...
2023-12-01 17:05:23,190:INFO::Epoch 00068 | lr 0.00050 |Train_Loss 0.7304 | Val_Loss 0.7911 | Time(s) 0.3477
2023-12-01 17:05:23,201:INFO::Validation loss decreased (0.805130 --> 0.791063).  Saving model ...
2023-12-01 17:05:23,545:INFO::Epoch 00069 | lr 0.00050 |Train_Loss 0.7095 | Val_Loss 0.7771 | Time(s) 0.3437
2023-12-01 17:05:23,556:INFO::Validation loss decreased (0.791063 --> 0.777076).  Saving model ...
2023-12-01 17:05:23,935:INFO::Epoch 00070 | lr 0.00050 |Train_Loss 0.6955 | Val_Loss 0.7632 | Time(s) 0.3790
2023-12-01 17:05:23,945:INFO::Validation loss decreased (0.777076 --> 0.763194).  Saving model ...
2023-12-01 17:05:24,318:INFO::Epoch 00071 | lr 0.00050 |Train_Loss 0.6856 | Val_Loss 0.7494 | Time(s) 0.3731
2023-12-01 17:05:24,368:INFO::Validation loss decreased (0.763194 --> 0.749435).  Saving model ...
2023-12-01 17:05:24,711:INFO::Epoch 00072 | lr 0.00050 |Train_Loss 0.6632 | Val_Loss 0.7358 | Time(s) 0.3427
2023-12-01 17:05:24,722:INFO::Validation loss decreased (0.749435 --> 0.735819).  Saving model ...
2023-12-01 17:05:25,101:INFO::Epoch 00073 | lr 0.00050 |Train_Loss 0.6371 | Val_Loss 0.7223 | Time(s) 0.3796
2023-12-01 17:05:25,109:INFO::Validation loss decreased (0.735819 --> 0.722340).  Saving model ...
2023-12-01 17:05:25,488:INFO::Epoch 00074 | lr 0.00050 |Train_Loss 0.6275 | Val_Loss 0.7090 | Time(s) 0.3785
2023-12-01 17:05:25,497:INFO::Validation loss decreased (0.722340 --> 0.709005).  Saving model ...
2023-12-01 17:05:25,852:INFO::Epoch 00075 | lr 0.00050 |Train_Loss 0.6152 | Val_Loss 0.6958 | Time(s) 0.3541
2023-12-01 17:05:25,862:INFO::Validation loss decreased (0.709005 --> 0.695841).  Saving model ...
2023-12-01 17:05:26,244:INFO::Epoch 00076 | lr 0.00050 |Train_Loss 0.5953 | Val_Loss 0.6828 | Time(s) 0.3826
2023-12-01 17:05:26,253:INFO::Validation loss decreased (0.695841 --> 0.682838).  Saving model ...
2023-12-01 17:05:26,596:INFO::Epoch 00077 | lr 0.00050 |Train_Loss 0.5828 | Val_Loss 0.6700 | Time(s) 0.3427
2023-12-01 17:05:26,605:INFO::Validation loss decreased (0.682838 --> 0.670035).  Saving model ...
2023-12-01 17:05:26,984:INFO::Epoch 00078 | lr 0.00050 |Train_Loss 0.5711 | Val_Loss 0.6574 | Time(s) 0.3786
2023-12-01 17:05:26,992:INFO::Validation loss decreased (0.670035 --> 0.657432).  Saving model ...
2023-12-01 17:05:27,343:INFO::Epoch 00079 | lr 0.00050 |Train_Loss 0.5619 | Val_Loss 0.6450 | Time(s) 0.3502
2023-12-01 17:05:27,353:INFO::Validation loss decreased (0.657432 --> 0.645038).  Saving model ...
2023-12-01 17:05:27,711:INFO::Epoch 00080 | lr 0.00050 |Train_Loss 0.5435 | Val_Loss 0.6328 | Time(s) 0.3570
2023-12-01 17:05:27,719:INFO::Validation loss decreased (0.645038 --> 0.632828).  Saving model ...
2023-12-01 17:05:28,084:INFO::Epoch 00081 | lr 0.00050 |Train_Loss 0.5230 | Val_Loss 0.6209 | Time(s) 0.3650
2023-12-01 17:05:28,092:INFO::Validation loss decreased (0.632828 --> 0.620864).  Saving model ...
2023-12-01 17:05:28,447:INFO::Epoch 00082 | lr 0.00050 |Train_Loss 0.5085 | Val_Loss 0.6091 | Time(s) 0.3552
2023-12-01 17:05:28,457:INFO::Validation loss decreased (0.620864 --> 0.609134).  Saving model ...
2023-12-01 17:05:28,809:INFO::Epoch 00083 | lr 0.00050 |Train_Loss 0.4998 | Val_Loss 0.5977 | Time(s) 0.3521
2023-12-01 17:05:28,817:INFO::Validation loss decreased (0.609134 --> 0.597673).  Saving model ...
2023-12-01 17:05:29,153:INFO::Epoch 00084 | lr 0.00050 |Train_Loss 0.4947 | Val_Loss 0.5865 | Time(s) 0.3357
2023-12-01 17:05:29,162:INFO::Validation loss decreased (0.597673 --> 0.586501).  Saving model ...
2023-12-01 17:05:29,548:INFO::Epoch 00085 | lr 0.00050 |Train_Loss 0.4800 | Val_Loss 0.5756 | Time(s) 0.3866
2023-12-01 17:05:29,557:INFO::Validation loss decreased (0.586501 --> 0.575626).  Saving model ...
2023-12-01 17:05:29,910:INFO::Epoch 00086 | lr 0.00050 |Train_Loss 0.4658 | Val_Loss 0.5651 | Time(s) 0.3521
2023-12-01 17:05:29,922:INFO::Validation loss decreased (0.575626 --> 0.565053).  Saving model ...
2023-12-01 17:05:30,289:INFO::Epoch 00087 | lr 0.00050 |Train_Loss 0.4608 | Val_Loss 0.5548 | Time(s) 0.3671
2023-12-01 17:05:30,297:INFO::Validation loss decreased (0.565053 --> 0.554781).  Saving model ...
2023-12-01 17:05:30,689:INFO::Epoch 00088 | lr 0.00050 |Train_Loss 0.4396 | Val_Loss 0.5448 | Time(s) 0.3920
2023-12-01 17:05:30,720:INFO::Validation loss decreased (0.554781 --> 0.544774).  Saving model ...
2023-12-01 17:05:31,087:INFO::Epoch 00089 | lr 0.00050 |Train_Loss 0.4258 | Val_Loss 0.5350 | Time(s) 0.3670
2023-12-01 17:05:31,096:INFO::Validation loss decreased (0.544774 --> 0.535003).  Saving model ...
2023-12-01 17:05:31,441:INFO::Epoch 00090 | lr 0.00050 |Train_Loss 0.4213 | Val_Loss 0.5255 | Time(s) 0.3456
2023-12-01 17:05:31,450:INFO::Validation loss decreased (0.535003 --> 0.525469).  Saving model ...
2023-12-01 17:05:31,791:INFO::Epoch 00091 | lr 0.00050 |Train_Loss 0.4097 | Val_Loss 0.5162 | Time(s) 0.3411
2023-12-01 17:05:31,801:INFO::Validation loss decreased (0.525469 --> 0.516215).  Saving model ...
2023-12-01 17:05:32,173:INFO::Epoch 00092 | lr 0.00050 |Train_Loss 0.3936 | Val_Loss 0.5072 | Time(s) 0.3716
2023-12-01 17:05:32,181:INFO::Validation loss decreased (0.516215 --> 0.507180).  Saving model ...
2023-12-01 17:05:32,566:INFO::Epoch 00093 | lr 0.00050 |Train_Loss 0.3859 | Val_Loss 0.4984 | Time(s) 0.3846
2023-12-01 17:05:32,574:INFO::Validation loss decreased (0.507180 --> 0.498406).  Saving model ...
2023-12-01 17:05:32,934:INFO::Epoch 00094 | lr 0.00050 |Train_Loss 0.3789 | Val_Loss 0.4899 | Time(s) 0.3590
2023-12-01 17:05:32,944:INFO::Validation loss decreased (0.498406 --> 0.489851).  Saving model ...
2023-12-01 17:05:33,285:INFO::Epoch 00095 | lr 0.00050 |Train_Loss 0.3707 | Val_Loss 0.4815 | Time(s) 0.3403
2023-12-01 17:05:33,293:INFO::Validation loss decreased (0.489851 --> 0.481520).  Saving model ...
2023-12-01 17:05:33,649:INFO::Epoch 00096 | lr 0.00050 |Train_Loss 0.3595 | Val_Loss 0.4734 | Time(s) 0.3551
2023-12-01 17:05:33,656:INFO::Validation loss decreased (0.481520 --> 0.473433).  Saving model ...
2023-12-01 17:05:34,017:INFO::Epoch 00097 | lr 0.00050 |Train_Loss 0.3512 | Val_Loss 0.4656 | Time(s) 0.3610
2023-12-01 17:05:34,028:INFO::Validation loss decreased (0.473433 --> 0.465614).  Saving model ...
2023-12-01 17:05:34,354:INFO::Epoch 00098 | lr 0.00050 |Train_Loss 0.3428 | Val_Loss 0.4581 | Time(s) 0.3254
2023-12-01 17:05:34,365:INFO::Validation loss decreased (0.465614 --> 0.458063).  Saving model ...
2023-12-01 17:05:34,731:INFO::Epoch 00099 | lr 0.00050 |Train_Loss 0.3202 | Val_Loss 0.4507 | Time(s) 0.3650
2023-12-01 17:05:34,740:INFO::Validation loss decreased (0.458063 --> 0.450743).  Saving model ...
2023-12-01 17:05:35,144:INFO::Epoch 00100 | lr 0.00050 |Train_Loss 0.3244 | Val_Loss 0.4437 | Time(s) 0.4035
2023-12-01 17:05:35,152:INFO::Validation loss decreased (0.450743 --> 0.443654).  Saving model ...
2023-12-01 17:05:35,501:INFO::Epoch 00101 | lr 0.00050 |Train_Loss 0.3164 | Val_Loss 0.4368 | Time(s) 0.3496
2023-12-01 17:05:35,511:INFO::Validation loss decreased (0.443654 --> 0.436816).  Saving model ...
2023-12-01 17:05:35,857:INFO::Epoch 00102 | lr 0.00050 |Train_Loss 0.3132 | Val_Loss 0.4302 | Time(s) 0.3451
2023-12-01 17:05:35,866:INFO::Validation loss decreased (0.436816 --> 0.430234).  Saving model ...
2023-12-01 17:05:36,232:INFO::Epoch 00103 | lr 0.00050 |Train_Loss 0.3052 | Val_Loss 0.4239 | Time(s) 0.3656
2023-12-01 17:05:36,241:INFO::Validation loss decreased (0.430234 --> 0.423875).  Saving model ...
2023-12-01 17:05:36,574:INFO::Epoch 00104 | lr 0.00050 |Train_Loss 0.2911 | Val_Loss 0.4177 | Time(s) 0.3327
2023-12-01 17:05:36,585:INFO::Validation loss decreased (0.423875 --> 0.417729).  Saving model ...
2023-12-01 17:05:36,922:INFO::Epoch 00105 | lr 0.00050 |Train_Loss 0.2835 | Val_Loss 0.4118 | Time(s) 0.3371
2023-12-01 17:05:36,931:INFO::Validation loss decreased (0.417729 --> 0.411792).  Saving model ...
2023-12-01 17:05:37,296:INFO::Epoch 00106 | lr 0.00050 |Train_Loss 0.2782 | Val_Loss 0.4061 | Time(s) 0.3652
2023-12-01 17:05:37,308:INFO::Validation loss decreased (0.411792 --> 0.406061).  Saving model ...
2023-12-01 17:05:37,724:INFO::Epoch 00107 | lr 0.00050 |Train_Loss 0.2699 | Val_Loss 0.4005 | Time(s) 0.4159
2023-12-01 17:05:37,732:INFO::Validation loss decreased (0.406061 --> 0.400494).  Saving model ...
2023-12-01 17:05:38,125:INFO::Epoch 00108 | lr 0.00050 |Train_Loss 0.2627 | Val_Loss 0.3951 | Time(s) 0.3935
2023-12-01 17:05:38,133:INFO::Validation loss decreased (0.400494 --> 0.395141).  Saving model ...
2023-12-01 17:05:38,519:INFO::Epoch 00109 | lr 0.00050 |Train_Loss 0.2601 | Val_Loss 0.3900 | Time(s) 0.3846
2023-12-01 17:05:38,528:INFO::Validation loss decreased (0.395141 --> 0.389992).  Saving model ...
2023-12-01 17:05:38,882:INFO::Epoch 00110 | lr 0.00050 |Train_Loss 0.2474 | Val_Loss 0.3850 | Time(s) 0.3541
2023-12-01 17:05:38,892:INFO::Validation loss decreased (0.389992 --> 0.385023).  Saving model ...
2023-12-01 17:05:39,249:INFO::Epoch 00111 | lr 0.00050 |Train_Loss 0.2508 | Val_Loss 0.3802 | Time(s) 0.3556
2023-12-01 17:05:39,258:INFO::Validation loss decreased (0.385023 --> 0.380233).  Saving model ...
2023-12-01 17:05:39,627:INFO::Epoch 00112 | lr 0.00050 |Train_Loss 0.2437 | Val_Loss 0.3756 | Time(s) 0.3682
2023-12-01 17:05:39,639:INFO::Validation loss decreased (0.380233 --> 0.375621).  Saving model ...
2023-12-01 17:05:39,968:INFO::Epoch 00113 | lr 0.00050 |Train_Loss 0.2333 | Val_Loss 0.3711 | Time(s) 0.3291
2023-12-01 17:05:39,976:INFO::Validation loss decreased (0.375621 --> 0.371146).  Saving model ...
2023-12-01 17:05:40,332:INFO::Epoch 00114 | lr 0.00050 |Train_Loss 0.2262 | Val_Loss 0.3668 | Time(s) 0.3562
2023-12-01 17:05:40,341:INFO::Validation loss decreased (0.371146 --> 0.366815).  Saving model ...
2023-12-01 17:05:40,735:INFO::Epoch 00115 | lr 0.00050 |Train_Loss 0.2274 | Val_Loss 0.3626 | Time(s) 0.3939
2023-12-01 17:05:40,743:INFO::Validation loss decreased (0.366815 --> 0.362627).  Saving model ...
2023-12-01 17:05:41,145:INFO::Epoch 00116 | lr 0.00050 |Train_Loss 0.2197 | Val_Loss 0.3586 | Time(s) 0.4025
2023-12-01 17:05:41,152:INFO::Validation loss decreased (0.362627 --> 0.358580).  Saving model ...
2023-12-01 17:05:41,529:INFO::Epoch 00117 | lr 0.00050 |Train_Loss 0.2160 | Val_Loss 0.3546 | Time(s) 0.3766
2023-12-01 17:05:41,541:INFO::Validation loss decreased (0.358580 --> 0.354647).  Saving model ...
2023-12-01 17:05:41,893:INFO::Epoch 00118 | lr 0.00050 |Train_Loss 0.2091 | Val_Loss 0.3509 | Time(s) 0.3521
2023-12-01 17:05:41,901:INFO::Validation loss decreased (0.354647 --> 0.350871).  Saving model ...
2023-12-01 17:05:42,243:INFO::Epoch 00119 | lr 0.00050 |Train_Loss 0.2005 | Val_Loss 0.3472 | Time(s) 0.3408
2023-12-01 17:05:42,252:INFO::Validation loss decreased (0.350871 --> 0.347244).  Saving model ...
2023-12-01 17:05:42,620:INFO::Epoch 00120 | lr 0.00050 |Train_Loss 0.2033 | Val_Loss 0.3438 | Time(s) 0.3667
2023-12-01 17:05:42,632:INFO::Validation loss decreased (0.347244 --> 0.343776).  Saving model ...
2023-12-01 17:05:43,008:INFO::Epoch 00121 | lr 0.00050 |Train_Loss 0.1951 | Val_Loss 0.3404 | Time(s) 0.3760
2023-12-01 17:05:43,019:INFO::Validation loss decreased (0.343776 --> 0.340380).  Saving model ...
2023-12-01 17:05:43,373:INFO::Epoch 00122 | lr 0.00050 |Train_Loss 0.1944 | Val_Loss 0.3371 | Time(s) 0.3542
2023-12-01 17:05:43,384:INFO::Validation loss decreased (0.340380 --> 0.337100).  Saving model ...
2023-12-01 17:05:43,761:INFO::Epoch 00123 | lr 0.00050 |Train_Loss 0.1910 | Val_Loss 0.3340 | Time(s) 0.3770
2023-12-01 17:05:43,770:INFO::Validation loss decreased (0.337100 --> 0.333992).  Saving model ...
2023-12-01 17:05:44,131:INFO::Epoch 00124 | lr 0.00050 |Train_Loss 0.1840 | Val_Loss 0.3310 | Time(s) 0.3606
2023-12-01 17:05:44,141:INFO::Validation loss decreased (0.333992 --> 0.330993).  Saving model ...
2023-12-01 17:05:44,495:INFO::Epoch 00125 | lr 0.00050 |Train_Loss 0.1793 | Val_Loss 0.3281 | Time(s) 0.3546
2023-12-01 17:05:44,503:INFO::Validation loss decreased (0.330993 --> 0.328096).  Saving model ...
2023-12-01 17:05:44,860:INFO::Epoch 00126 | lr 0.00050 |Train_Loss 0.1730 | Val_Loss 0.3253 | Time(s) 0.3550
2023-12-01 17:05:44,869:INFO::Validation loss decreased (0.328096 --> 0.325278).  Saving model ...
2023-12-01 17:05:45,198:INFO::Epoch 00127 | lr 0.00050 |Train_Loss 0.1741 | Val_Loss 0.3225 | Time(s) 0.3287
2023-12-01 17:05:45,207:INFO::Validation loss decreased (0.325278 --> 0.322520).  Saving model ...
2023-12-01 17:05:45,563:INFO::Epoch 00128 | lr 0.00050 |Train_Loss 0.1750 | Val_Loss 0.3198 | Time(s) 0.3546
2023-12-01 17:05:45,571:INFO::Validation loss decreased (0.322520 --> 0.319771).  Saving model ...
2023-12-01 17:05:45,985:INFO::Epoch 00129 | lr 0.00050 |Train_Loss 0.1625 | Val_Loss 0.3171 | Time(s) 0.4129
2023-12-01 17:05:45,994:INFO::Validation loss decreased (0.319771 --> 0.317114).  Saving model ...
2023-12-01 17:05:46,346:INFO::Epoch 00130 | lr 0.00050 |Train_Loss 0.1656 | Val_Loss 0.3145 | Time(s) 0.3526
2023-12-01 17:05:46,354:INFO::Validation loss decreased (0.317114 --> 0.314501).  Saving model ...
2023-12-01 17:05:46,726:INFO::Epoch 00131 | lr 0.00050 |Train_Loss 0.1563 | Val_Loss 0.3121 | Time(s) 0.3710
2023-12-01 17:05:46,735:INFO::Validation loss decreased (0.314501 --> 0.312056).  Saving model ...
2023-12-01 17:05:47,117:INFO::Epoch 00132 | lr 0.00050 |Train_Loss 0.1561 | Val_Loss 0.3097 | Time(s) 0.3805
2023-12-01 17:05:47,129:INFO::Validation loss decreased (0.312056 --> 0.309702).  Saving model ...
2023-12-01 17:05:47,486:INFO::Epoch 00133 | lr 0.00050 |Train_Loss 0.1493 | Val_Loss 0.3074 | Time(s) 0.3576
2023-12-01 17:05:47,495:INFO::Validation loss decreased (0.309702 --> 0.307446).  Saving model ...
2023-12-01 17:05:47,847:INFO::Epoch 00134 | lr 0.00050 |Train_Loss 0.1530 | Val_Loss 0.3053 | Time(s) 0.3521
2023-12-01 17:05:47,858:INFO::Validation loss decreased (0.307446 --> 0.305253).  Saving model ...
2023-12-01 17:05:48,203:INFO::Epoch 00135 | lr 0.00050 |Train_Loss 0.1440 | Val_Loss 0.3031 | Time(s) 0.3447
2023-12-01 17:05:48,214:INFO::Validation loss decreased (0.305253 --> 0.303075).  Saving model ...
2023-12-01 17:05:48,587:INFO::Epoch 00136 | lr 0.00050 |Train_Loss 0.1385 | Val_Loss 0.3010 | Time(s) 0.3736
2023-12-01 17:05:48,597:INFO::Validation loss decreased (0.303075 --> 0.300993).  Saving model ...
2023-12-01 17:05:48,953:INFO::Epoch 00137 | lr 0.00050 |Train_Loss 0.1377 | Val_Loss 0.2990 | Time(s) 0.3551
2023-12-01 17:05:48,962:INFO::Validation loss decreased (0.300993 --> 0.298998).  Saving model ...
2023-12-01 17:05:49,324:INFO::Epoch 00138 | lr 0.00050 |Train_Loss 0.1376 | Val_Loss 0.2971 | Time(s) 0.3612
2023-12-01 17:05:49,336:INFO::Validation loss decreased (0.298998 --> 0.297106).  Saving model ...
2023-12-01 17:05:49,659:INFO::Epoch 00139 | lr 0.00050 |Train_Loss 0.1333 | Val_Loss 0.2953 | Time(s) 0.3219
2023-12-01 17:05:49,667:INFO::Validation loss decreased (0.297106 --> 0.295321).  Saving model ...
2023-12-01 17:05:50,034:INFO::Epoch 00140 | lr 0.00050 |Train_Loss 0.1365 | Val_Loss 0.2936 | Time(s) 0.3660
2023-12-01 17:05:50,041:INFO::Validation loss decreased (0.295321 --> 0.293631).  Saving model ...
2023-12-01 17:05:50,408:INFO::Epoch 00141 | lr 0.00050 |Train_Loss 0.1300 | Val_Loss 0.2920 | Time(s) 0.3662
2023-12-01 17:05:50,416:INFO::Validation loss decreased (0.293631 --> 0.291987).  Saving model ...
2023-12-01 17:05:50,789:INFO::Epoch 00142 | lr 0.00050 |Train_Loss 0.1269 | Val_Loss 0.2905 | Time(s) 0.3720
2023-12-01 17:05:50,799:INFO::Validation loss decreased (0.291987 --> 0.290502).  Saving model ...
2023-12-01 17:05:51,202:INFO::Epoch 00143 | lr 0.00050 |Train_Loss 0.1250 | Val_Loss 0.2890 | Time(s) 0.4031
2023-12-01 17:05:51,212:INFO::Validation loss decreased (0.290502 --> 0.289043).  Saving model ...
2023-12-01 17:05:51,596:INFO::Epoch 00144 | lr 0.00050 |Train_Loss 0.1261 | Val_Loss 0.2876 | Time(s) 0.3845
2023-12-01 17:05:51,606:INFO::Validation loss decreased (0.289043 --> 0.287624).  Saving model ...
2023-12-01 17:05:51,944:INFO::Epoch 00145 | lr 0.00050 |Train_Loss 0.1207 | Val_Loss 0.2862 | Time(s) 0.3381
2023-12-01 17:05:51,956:INFO::Validation loss decreased (0.287624 --> 0.286225).  Saving model ...
2023-12-01 17:05:52,337:INFO::Epoch 00146 | lr 0.00050 |Train_Loss 0.1147 | Val_Loss 0.2847 | Time(s) 0.3801
2023-12-01 17:05:52,346:INFO::Validation loss decreased (0.286225 --> 0.284731).  Saving model ...
2023-12-01 17:05:52,712:INFO::Epoch 00147 | lr 0.00050 |Train_Loss 0.1157 | Val_Loss 0.2833 | Time(s) 0.3660
2023-12-01 17:05:52,721:INFO::Validation loss decreased (0.284731 --> 0.283251).  Saving model ...
2023-12-01 17:05:53,085:INFO::Epoch 00148 | lr 0.00050 |Train_Loss 0.1197 | Val_Loss 0.2818 | Time(s) 0.3640
2023-12-01 17:05:53,094:INFO::Validation loss decreased (0.283251 --> 0.281782).  Saving model ...
2023-12-01 17:05:53,473:INFO::Epoch 00149 | lr 0.00050 |Train_Loss 0.1168 | Val_Loss 0.2804 | Time(s) 0.3791
2023-12-01 17:05:53,482:INFO::Validation loss decreased (0.281782 --> 0.280401).  Saving model ...
2023-12-01 17:05:53,809:INFO::Epoch 00150 | lr 0.00050 |Train_Loss 0.1156 | Val_Loss 0.2791 | Time(s) 0.3271
2023-12-01 17:05:53,817:INFO::Validation loss decreased (0.280401 --> 0.279066).  Saving model ...
2023-12-01 17:05:54,191:INFO::Epoch 00151 | lr 0.00050 |Train_Loss 0.1101 | Val_Loss 0.2777 | Time(s) 0.3716
2023-12-01 17:05:54,202:INFO::Validation loss decreased (0.279066 --> 0.277726).  Saving model ...
2023-12-01 17:05:54,544:INFO::Epoch 00152 | lr 0.00050 |Train_Loss 0.1049 | Val_Loss 0.2764 | Time(s) 0.3423
2023-12-01 17:05:54,552:INFO::Validation loss decreased (0.277726 --> 0.276439).  Saving model ...
2023-12-01 17:05:54,918:INFO::Epoch 00153 | lr 0.00050 |Train_Loss 0.1101 | Val_Loss 0.2753 | Time(s) 0.3648
2023-12-01 17:05:54,927:INFO::Validation loss decreased (0.276439 --> 0.275252).  Saving model ...
2023-12-01 17:05:55,297:INFO::Epoch 00154 | lr 0.00050 |Train_Loss 0.1022 | Val_Loss 0.2741 | Time(s) 0.3702
2023-12-01 17:05:55,306:INFO::Validation loss decreased (0.275252 --> 0.274101).  Saving model ...
2023-12-01 17:05:55,646:INFO::Epoch 00155 | lr 0.00050 |Train_Loss 0.0975 | Val_Loss 0.2730 | Time(s) 0.3391
2023-12-01 17:05:55,656:INFO::Validation loss decreased (0.274101 --> 0.273046).  Saving model ...
2023-12-01 17:05:56,006:INFO::Epoch 00156 | lr 0.00050 |Train_Loss 0.1019 | Val_Loss 0.2721 | Time(s) 0.3491
2023-12-01 17:05:56,017:INFO::Validation loss decreased (0.273046 --> 0.272060).  Saving model ...
2023-12-01 17:05:56,382:INFO::Epoch 00157 | lr 0.00050 |Train_Loss 0.0971 | Val_Loss 0.2711 | Time(s) 0.3642
2023-12-01 17:05:56,391:INFO::Validation loss decreased (0.272060 --> 0.271073).  Saving model ...
2023-12-01 17:05:56,748:INFO::Epoch 00158 | lr 0.00050 |Train_Loss 0.1032 | Val_Loss 0.2702 | Time(s) 0.3570
2023-12-01 17:05:56,757:INFO::Validation loss decreased (0.271073 --> 0.270168).  Saving model ...
2023-12-01 17:05:57,116:INFO::Epoch 00159 | lr 0.00050 |Train_Loss 0.0892 | Val_Loss 0.2694 | Time(s) 0.3576
2023-12-01 17:05:57,125:INFO::Validation loss decreased (0.270168 --> 0.269367).  Saving model ...
2023-12-01 17:05:57,468:INFO::Epoch 00160 | lr 0.00050 |Train_Loss 0.0954 | Val_Loss 0.2685 | Time(s) 0.3437
2023-12-01 17:05:57,477:INFO::Validation loss decreased (0.269367 --> 0.268504).  Saving model ...
2023-12-01 17:05:57,831:INFO::Epoch 00161 | lr 0.00050 |Train_Loss 0.0924 | Val_Loss 0.2675 | Time(s) 0.3531
2023-12-01 17:05:57,840:INFO::Validation loss decreased (0.268504 --> 0.267539).  Saving model ...
2023-12-01 17:05:58,192:INFO::Epoch 00162 | lr 0.00050 |Train_Loss 0.0901 | Val_Loss 0.2666 | Time(s) 0.3506
2023-12-01 17:05:58,201:INFO::Validation loss decreased (0.267539 --> 0.266551).  Saving model ...
2023-12-01 17:05:58,559:INFO::Epoch 00163 | lr 0.00050 |Train_Loss 0.0903 | Val_Loss 0.2655 | Time(s) 0.3580
2023-12-01 17:05:58,569:INFO::Validation loss decreased (0.266551 --> 0.265489).  Saving model ...
2023-12-01 17:05:58,959:INFO::Epoch 00164 | lr 0.00050 |Train_Loss 0.0889 | Val_Loss 0.2644 | Time(s) 0.3900
2023-12-01 17:05:58,968:INFO::Validation loss decreased (0.265489 --> 0.264361).  Saving model ...
2023-12-01 17:05:59,344:INFO::Epoch 00165 | lr 0.00050 |Train_Loss 0.0885 | Val_Loss 0.2633 | Time(s) 0.3761
2023-12-01 17:05:59,354:INFO::Validation loss decreased (0.264361 --> 0.263307).  Saving model ...
2023-12-01 17:05:59,722:INFO::Epoch 00166 | lr 0.00050 |Train_Loss 0.0876 | Val_Loss 0.2624 | Time(s) 0.3670
2023-12-01 17:05:59,731:INFO::Validation loss decreased (0.263307 --> 0.262355).  Saving model ...
2023-12-01 17:06:00,089:INFO::Epoch 00167 | lr 0.00050 |Train_Loss 0.0845 | Val_Loss 0.2615 | Time(s) 0.3580
2023-12-01 17:06:00,098:INFO::Validation loss decreased (0.262355 --> 0.261468).  Saving model ...
2023-12-01 17:06:00,481:INFO::Epoch 00168 | lr 0.00050 |Train_Loss 0.0853 | Val_Loss 0.2607 | Time(s) 0.3831
2023-12-01 17:06:00,490:INFO::Validation loss decreased (0.261468 --> 0.260714).  Saving model ...
2023-12-01 17:06:00,832:INFO::Epoch 00169 | lr 0.00050 |Train_Loss 0.0848 | Val_Loss 0.2600 | Time(s) 0.3411
2023-12-01 17:06:00,842:INFO::Validation loss decreased (0.260714 --> 0.260023).  Saving model ...
2023-12-01 17:06:01,207:INFO::Epoch 00170 | lr 0.00050 |Train_Loss 0.0838 | Val_Loss 0.2594 | Time(s) 0.3646
2023-12-01 17:06:01,220:INFO::Validation loss decreased (0.260023 --> 0.259357).  Saving model ...
2023-12-01 17:06:01,585:INFO::Epoch 00171 | lr 0.00050 |Train_Loss 0.0799 | Val_Loss 0.2587 | Time(s) 0.3656
2023-12-01 17:06:01,593:INFO::Validation loss decreased (0.259357 --> 0.258722).  Saving model ...
2023-12-01 17:06:01,963:INFO::Epoch 00172 | lr 0.00050 |Train_Loss 0.0807 | Val_Loss 0.2581 | Time(s) 0.3690
2023-12-01 17:06:01,975:INFO::Validation loss decreased (0.258722 --> 0.258087).  Saving model ...
2023-12-01 17:06:02,356:INFO::Epoch 00173 | lr 0.00050 |Train_Loss 0.0804 | Val_Loss 0.2574 | Time(s) 0.3792
2023-12-01 17:06:02,365:INFO::Validation loss decreased (0.258087 --> 0.257409).  Saving model ...
2023-12-01 17:06:02,740:INFO::Epoch 00174 | lr 0.00050 |Train_Loss 0.0810 | Val_Loss 0.2567 | Time(s) 0.3750
2023-12-01 17:06:02,749:INFO::Validation loss decreased (0.257409 --> 0.256748).  Saving model ...
2023-12-01 17:06:03,121:INFO::Epoch 00175 | lr 0.00050 |Train_Loss 0.0737 | Val_Loss 0.2561 | Time(s) 0.3716
2023-12-01 17:06:03,131:INFO::Validation loss decreased (0.256748 --> 0.256080).  Saving model ...
2023-12-01 17:06:03,485:INFO::Epoch 00176 | lr 0.00050 |Train_Loss 0.0782 | Val_Loss 0.2554 | Time(s) 0.3532
2023-12-01 17:06:03,495:INFO::Validation loss decreased (0.256080 --> 0.255440).  Saving model ...
2023-12-01 17:06:03,849:INFO::Epoch 00177 | lr 0.00050 |Train_Loss 0.0723 | Val_Loss 0.2549 | Time(s) 0.3541
2023-12-01 17:06:03,858:INFO::Validation loss decreased (0.255440 --> 0.254872).  Saving model ...
2023-12-01 17:06:04,214:INFO::Epoch 00178 | lr 0.00050 |Train_Loss 0.0695 | Val_Loss 0.2544 | Time(s) 0.3546
2023-12-01 17:06:04,223:INFO::Validation loss decreased (0.254872 --> 0.254359).  Saving model ...
2023-12-01 17:06:04,570:INFO::Epoch 00179 | lr 0.00050 |Train_Loss 0.0727 | Val_Loss 0.2539 | Time(s) 0.3472
2023-12-01 17:06:04,579:INFO::Validation loss decreased (0.254359 --> 0.253938).  Saving model ...
2023-12-01 17:06:04,929:INFO::Epoch 00180 | lr 0.00050 |Train_Loss 0.0724 | Val_Loss 0.2536 | Time(s) 0.3501
2023-12-01 17:06:04,937:INFO::Validation loss decreased (0.253938 --> 0.253576).  Saving model ...
2023-12-01 17:06:05,327:INFO::Epoch 00181 | lr 0.00050 |Train_Loss 0.0698 | Val_Loss 0.2532 | Time(s) 0.3901
2023-12-01 17:06:05,338:INFO::Validation loss decreased (0.253576 --> 0.253194).  Saving model ...
2023-12-01 17:06:05,710:INFO::Epoch 00182 | lr 0.00050 |Train_Loss 0.0660 | Val_Loss 0.2528 | Time(s) 0.3720
2023-12-01 17:06:05,719:INFO::Validation loss decreased (0.253194 --> 0.252822).  Saving model ...
2023-12-01 17:06:06,077:INFO::Epoch 00183 | lr 0.00050 |Train_Loss 0.0663 | Val_Loss 0.2524 | Time(s) 0.3580
2023-12-01 17:06:06,086:INFO::Validation loss decreased (0.252822 --> 0.252395).  Saving model ...
2023-12-01 17:06:06,448:INFO::Epoch 00184 | lr 0.00050 |Train_Loss 0.0663 | Val_Loss 0.2520 | Time(s) 0.3614
2023-12-01 17:06:06,457:INFO::Validation loss decreased (0.252395 --> 0.251951).  Saving model ...
2023-12-01 17:06:06,828:INFO::Epoch 00185 | lr 0.00050 |Train_Loss 0.0665 | Val_Loss 0.2516 | Time(s) 0.3710
2023-12-01 17:06:06,836:INFO::Validation loss decreased (0.251951 --> 0.251554).  Saving model ...
2023-12-01 17:06:07,209:INFO::Epoch 00186 | lr 0.00050 |Train_Loss 0.0679 | Val_Loss 0.2513 | Time(s) 0.3726
2023-12-01 17:06:07,220:INFO::Validation loss decreased (0.251554 --> 0.251269).  Saving model ...
2023-12-01 17:06:07,566:INFO::Epoch 00187 | lr 0.00050 |Train_Loss 0.0672 | Val_Loss 0.2510 | Time(s) 0.3456
2023-12-01 17:06:07,578:INFO::Validation loss decreased (0.251269 --> 0.250989).  Saving model ...
2023-12-01 17:06:07,970:INFO::Epoch 00188 | lr 0.00050 |Train_Loss 0.0641 | Val_Loss 0.2506 | Time(s) 0.3909
2023-12-01 17:06:07,979:INFO::Validation loss decreased (0.250989 --> 0.250588).  Saving model ...
2023-12-01 17:06:08,323:INFO::Epoch 00189 | lr 0.00050 |Train_Loss 0.0622 | Val_Loss 0.2501 | Time(s) 0.3442
2023-12-01 17:06:08,332:INFO::Validation loss decreased (0.250588 --> 0.250113).  Saving model ...
2023-12-01 17:06:08,705:INFO::Epoch 00190 | lr 0.00050 |Train_Loss 0.0630 | Val_Loss 0.2497 | Time(s) 0.3720
2023-12-01 17:06:08,720:INFO::Validation loss decreased (0.250113 --> 0.249693).  Saving model ...
2023-12-01 17:06:09,095:INFO::Epoch 00191 | lr 0.00050 |Train_Loss 0.0602 | Val_Loss 0.2492 | Time(s) 0.3740
2023-12-01 17:06:09,107:INFO::Validation loss decreased (0.249693 --> 0.249159).  Saving model ...
2023-12-01 17:06:09,463:INFO::Epoch 00192 | lr 0.00050 |Train_Loss 0.0609 | Val_Loss 0.2486 | Time(s) 0.3556
2023-12-01 17:06:09,471:INFO::Validation loss decreased (0.249159 --> 0.248600).  Saving model ...
2023-12-01 17:06:09,834:INFO::Epoch 00193 | lr 0.00050 |Train_Loss 0.0611 | Val_Loss 0.2481 | Time(s) 0.3627
2023-12-01 17:06:09,844:INFO::Validation loss decreased (0.248600 --> 0.248057).  Saving model ...
2023-12-01 17:06:10,201:INFO::Epoch 00194 | lr 0.00050 |Train_Loss 0.0612 | Val_Loss 0.2477 | Time(s) 0.3566
2023-12-01 17:06:10,210:INFO::Validation loss decreased (0.248057 --> 0.247660).  Saving model ...
2023-12-01 17:06:10,552:INFO::Epoch 00195 | lr 0.00050 |Train_Loss 0.0612 | Val_Loss 0.2474 | Time(s) 0.3426
2023-12-01 17:06:10,563:INFO::Validation loss decreased (0.247660 --> 0.247370).  Saving model ...
2023-12-01 17:06:10,926:INFO::Epoch 00196 | lr 0.00050 |Train_Loss 0.0563 | Val_Loss 0.2472 | Time(s) 0.3630
2023-12-01 17:06:10,936:INFO::Validation loss decreased (0.247370 --> 0.247196).  Saving model ...
2023-12-01 17:06:11,317:INFO::Epoch 00197 | lr 0.00050 |Train_Loss 0.0563 | Val_Loss 0.2470 | Time(s) 0.3811
2023-12-01 17:06:11,326:INFO::Validation loss decreased (0.247196 --> 0.247025).  Saving model ...
2023-12-01 17:06:11,668:INFO::Epoch 00198 | lr 0.00050 |Train_Loss 0.0572 | Val_Loss 0.2468 | Time(s) 0.3420
2023-12-01 17:06:11,677:INFO::Validation loss decreased (0.247025 --> 0.246751).  Saving model ...
2023-12-01 17:06:12,045:INFO::Epoch 00199 | lr 0.00050 |Train_Loss 0.0563 | Val_Loss 0.2465 | Time(s) 0.3680
2023-12-01 17:06:12,057:INFO::Validation loss decreased (0.246751 --> 0.246487).  Saving model ...
2023-12-01 17:06:12,417:INFO::Epoch 00200 | lr 0.00050 |Train_Loss 0.0556 | Val_Loss 0.2462 | Time(s) 0.3602
2023-12-01 17:06:12,425:INFO::Validation loss decreased (0.246487 --> 0.246212).  Saving model ...
2023-12-01 17:06:12,791:INFO::Epoch 00201 | lr 0.00050 |Train_Loss 0.0573 | Val_Loss 0.2459 | Time(s) 0.3640
2023-12-01 17:06:12,800:INFO::Validation loss decreased (0.246212 --> 0.245874).  Saving model ...
2023-12-01 17:06:13,172:INFO::Epoch 00202 | lr 0.00050 |Train_Loss 0.0555 | Val_Loss 0.2456 | Time(s) 0.3715
2023-12-01 17:06:13,182:INFO::Validation loss decreased (0.245874 --> 0.245594).  Saving model ...
2023-12-01 17:06:13,555:INFO::Epoch 00203 | lr 0.00050 |Train_Loss 0.0516 | Val_Loss 0.2453 | Time(s) 0.3726
2023-12-01 17:06:13,564:INFO::Validation loss decreased (0.245594 --> 0.245337).  Saving model ...
2023-12-01 17:06:13,914:INFO::Epoch 00204 | lr 0.00050 |Train_Loss 0.0542 | Val_Loss 0.2450 | Time(s) 0.3491
2023-12-01 17:06:13,923:INFO::Validation loss decreased (0.245337 --> 0.245021).  Saving model ...
2023-12-01 17:06:14,284:INFO::Epoch 00205 | lr 0.00050 |Train_Loss 0.0544 | Val_Loss 0.2447 | Time(s) 0.3613
2023-12-01 17:06:14,292:INFO::Validation loss decreased (0.245021 --> 0.244705).  Saving model ...
2023-12-01 17:06:14,657:INFO::Epoch 00206 | lr 0.00050 |Train_Loss 0.0535 | Val_Loss 0.2444 | Time(s) 0.3640
2023-12-01 17:06:14,667:INFO::Validation loss decreased (0.244705 --> 0.244447).  Saving model ...
2023-12-01 17:06:15,024:INFO::Epoch 00207 | lr 0.00050 |Train_Loss 0.0515 | Val_Loss 0.2442 | Time(s) 0.3570
2023-12-01 17:06:15,034:INFO::Validation loss decreased (0.244447 --> 0.244222).  Saving model ...
2023-12-01 17:06:15,397:INFO::Epoch 00208 | lr 0.00050 |Train_Loss 0.0489 | Val_Loss 0.2440 | Time(s) 0.3632
2023-12-01 17:06:15,407:INFO::Validation loss decreased (0.244222 --> 0.244034).  Saving model ...
2023-12-01 17:06:15,749:INFO::Epoch 00209 | lr 0.00050 |Train_Loss 0.0510 | Val_Loss 0.2438 | Time(s) 0.3421
2023-12-01 17:06:15,758:INFO::Validation loss decreased (0.244034 --> 0.243789).  Saving model ...
2023-12-01 17:06:16,098:INFO::Epoch 00210 | lr 0.00050 |Train_Loss 0.0490 | Val_Loss 0.2435 | Time(s) 0.3401
2023-12-01 17:06:16,107:INFO::Validation loss decreased (0.243789 --> 0.243496).  Saving model ...
2023-12-01 17:06:16,477:INFO::Epoch 00211 | lr 0.00050 |Train_Loss 0.0509 | Val_Loss 0.2432 | Time(s) 0.3691
2023-12-01 17:06:16,485:INFO::Validation loss decreased (0.243496 --> 0.243166).  Saving model ...
2023-12-01 17:06:16,839:INFO::Epoch 00212 | lr 0.00050 |Train_Loss 0.0495 | Val_Loss 0.2428 | Time(s) 0.3541
2023-12-01 17:06:16,850:INFO::Validation loss decreased (0.243166 --> 0.242783).  Saving model ...
2023-12-01 17:06:17,242:INFO::Epoch 00213 | lr 0.00050 |Train_Loss 0.0472 | Val_Loss 0.2423 | Time(s) 0.3925
2023-12-01 17:06:17,252:INFO::Validation loss decreased (0.242783 --> 0.242316).  Saving model ...
2023-12-01 17:06:17,627:INFO::Epoch 00214 | lr 0.00050 |Train_Loss 0.0483 | Val_Loss 0.2418 | Time(s) 0.3746
2023-12-01 17:06:17,636:INFO::Validation loss decreased (0.242316 --> 0.241818).  Saving model ...
2023-12-01 17:06:17,980:INFO::Epoch 00215 | lr 0.00050 |Train_Loss 0.0510 | Val_Loss 0.2414 | Time(s) 0.3431
2023-12-01 17:06:17,989:INFO::Validation loss decreased (0.241818 --> 0.241445).  Saving model ...
2023-12-01 17:06:18,304:INFO::Epoch 00216 | lr 0.00050 |Train_Loss 0.0442 | Val_Loss 0.2412 | Time(s) 0.3143
2023-12-01 17:06:18,312:INFO::Validation loss decreased (0.241445 --> 0.241214).  Saving model ...
2023-12-01 17:06:18,726:INFO::Epoch 00217 | lr 0.00050 |Train_Loss 0.0453 | Val_Loss 0.2410 | Time(s) 0.4119
2023-12-01 17:06:18,736:INFO::Validation loss decreased (0.241214 --> 0.240998).  Saving model ...
2023-12-01 17:06:19,087:INFO::Epoch 00218 | lr 0.00050 |Train_Loss 0.0466 | Val_Loss 0.2408 | Time(s) 0.3511
2023-12-01 17:06:19,098:INFO::Validation loss decreased (0.240998 --> 0.240833).  Saving model ...
2023-12-01 17:06:19,465:INFO::Epoch 00219 | lr 0.00050 |Train_Loss 0.0468 | Val_Loss 0.2407 | Time(s) 0.3672
2023-12-01 17:06:19,475:INFO::Validation loss decreased (0.240833 --> 0.240678).  Saving model ...
2023-12-01 17:06:19,819:INFO::Epoch 00220 | lr 0.00050 |Train_Loss 0.0462 | Val_Loss 0.2406 | Time(s) 0.3436
2023-12-01 17:06:19,827:INFO::Validation loss decreased (0.240678 --> 0.240568).  Saving model ...
2023-12-01 17:06:20,159:INFO::Epoch 00221 | lr 0.00050 |Train_Loss 0.0453 | Val_Loss 0.2404 | Time(s) 0.3317
2023-12-01 17:06:20,167:INFO::Validation loss decreased (0.240568 --> 0.240434).  Saving model ...
2023-12-01 17:06:20,529:INFO::Epoch 00222 | lr 0.00050 |Train_Loss 0.0425 | Val_Loss 0.2404 | Time(s) 0.3616
2023-12-01 17:06:20,538:INFO::Validation loss decreased (0.240434 --> 0.240398).  Saving model ...
2023-12-01 17:06:20,893:INFO::Epoch 00223 | lr 0.00050 |Train_Loss 0.0435 | Val_Loss 0.2403 | Time(s) 0.3550
2023-12-01 17:06:20,902:INFO::Validation loss decreased (0.240398 --> 0.240270).  Saving model ...
2023-12-01 17:06:21,300:INFO::Epoch 00224 | lr 0.00050 |Train_Loss 0.0446 | Val_Loss 0.2402 | Time(s) 0.3981
2023-12-01 17:06:21,311:INFO::Validation loss decreased (0.240270 --> 0.240168).  Saving model ...
2023-12-01 17:06:21,688:INFO::Epoch 00225 | lr 0.00050 |Train_Loss 0.0435 | Val_Loss 0.2400 | Time(s) 0.3770
2023-12-01 17:06:21,755:INFO::Validation loss decreased (0.240168 --> 0.240000).  Saving model ...
2023-12-01 17:06:22,120:INFO::Epoch 00226 | lr 0.00050 |Train_Loss 0.0443 | Val_Loss 0.2398 | Time(s) 0.3656
2023-12-01 17:06:22,128:INFO::Validation loss decreased (0.240000 --> 0.239795).  Saving model ...
2023-12-01 17:06:22,505:INFO::Epoch 00227 | lr 0.00050 |Train_Loss 0.0403 | Val_Loss 0.2396 | Time(s) 0.3766
2023-12-01 17:06:22,514:INFO::Validation loss decreased (0.239795 --> 0.239637).  Saving model ...
2023-12-01 17:06:22,866:INFO::Epoch 00228 | lr 0.00050 |Train_Loss 0.0402 | Val_Loss 0.2395 | Time(s) 0.3521
2023-12-01 17:06:22,875:INFO::Validation loss decreased (0.239637 --> 0.239535).  Saving model ...
2023-12-01 17:06:23,248:INFO::Epoch 00229 | lr 0.00050 |Train_Loss 0.0414 | Val_Loss 0.2394 | Time(s) 0.3735
2023-12-01 17:06:23,256:INFO::Validation loss decreased (0.239535 --> 0.239360).  Saving model ...
2023-12-01 17:06:23,603:INFO::Epoch 00230 | lr 0.00050 |Train_Loss 0.0408 | Val_Loss 0.2392 | Time(s) 0.3466
2023-12-01 17:06:23,612:INFO::Validation loss decreased (0.239360 --> 0.239208).  Saving model ...
2023-12-01 17:06:23,983:INFO::Epoch 00231 | lr 0.00050 |Train_Loss 0.0379 | Val_Loss 0.2391 | Time(s) 0.3700
2023-12-01 17:06:23,994:INFO::Validation loss decreased (0.239208 --> 0.239114).  Saving model ...
2023-12-01 17:06:24,383:INFO::Epoch 00232 | lr 0.00050 |Train_Loss 0.0396 | Val_Loss 0.2390 | Time(s) 0.3882
2023-12-01 17:06:24,393:INFO::Validation loss decreased (0.239114 --> 0.238989).  Saving model ...
2023-12-01 17:06:24,760:INFO::Epoch 00233 | lr 0.00050 |Train_Loss 0.0400 | Val_Loss 0.2390 | Time(s) 0.3662
2023-12-01 17:06:24,770:INFO::Validation loss decreased (0.238989 --> 0.238967).  Saving model ...
2023-12-01 17:06:25,139:INFO::Epoch 00234 | lr 0.00050 |Train_Loss 0.0375 | Val_Loss 0.2390 | Time(s) 0.3690
2023-12-01 17:06:25,140:INFO::EarlyStopping counter: 1 out of 8
2023-12-01 17:06:25,508:INFO::Epoch 00235 | lr 0.00050 |Train_Loss 0.0396 | Val_Loss 0.2390 | Time(s) 0.3656
2023-12-01 17:06:25,508:INFO::EarlyStopping counter: 2 out of 8
2023-12-01 17:06:25,861:INFO::Epoch 00236 | lr 0.00050 |Train_Loss 0.0381 | Val_Loss 0.2391 | Time(s) 0.3531
2023-12-01 17:06:25,862:INFO::EarlyStopping counter: 3 out of 8
2023-12-01 17:06:26,192:INFO::Epoch 00237 | lr 0.00050 |Train_Loss 0.0380 | Val_Loss 0.2392 | Time(s) 0.3297
2023-12-01 17:06:26,193:INFO::EarlyStopping counter: 4 out of 8
2023-12-01 17:06:26,566:INFO::Epoch 00238 | lr 0.00050 |Train_Loss 0.0397 | Val_Loss 0.2393 | Time(s) 0.3735
2023-12-01 17:06:26,567:INFO::EarlyStopping counter: 5 out of 8
2023-12-01 17:06:26,915:INFO::Epoch 00239 | lr 0.00050 |Train_Loss 0.0418 | Val_Loss 0.2395 | Time(s) 0.3471
2023-12-01 17:06:26,915:INFO::EarlyStopping counter: 6 out of 8
2023-12-01 17:06:27,270:INFO::Epoch 00240 | lr 0.00050 |Train_Loss 0.0373 | Val_Loss 0.2396 | Time(s) 0.3546
2023-12-01 17:06:27,271:INFO::EarlyStopping counter: 7 out of 8
2023-12-01 17:06:27,645:INFO::Epoch 00241 | lr 0.00050 |Train_Loss 0.0377 | Val_Loss 0.2395 | Time(s) 0.3746
2023-12-01 17:06:27,646:INFO::EarlyStopping counter: 8 out of 8
2023-12-01 17:06:27,646:INFO::Eearly stopping!
2023-12-01 17:06:27,646:INFO::
testing...
2023-12-01 17:06:27,680:INFO::submit dir: submit/submit_gcn_nasp_egreedy0.1_C4_useDmon_coef0.5_Adam_gcn.ppnp.mean.one-hot_noTypeLinear_014_64_shared_ops_lr0.0005_wd0.0001_use5seeds_use_adam_patience-8_8_not_use_skip
2023-12-01 17:06:27,865:INFO::{'micro-f1': 0.8802816901408451, 'macro-f1': 0.8725589947406074}
2023-12-01 17:06:27,976:INFO::############### Retrain Stage Ends! #################
